{
    "bq011": {
        "query": "SELECT   COUNT(DISTINCT MDaysUsers.user_pseudo_id) AS n_day_inactive_users_count FROM   (     SELECT       user_pseudo_id     FROM       `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*` AS T     CROSS JOIN       UNNEST(T.event_params) AS event_params     WHERE       event_params.key = 'engagement_time_msec' AND event_params.value.int_value > 0       /* Has engaged in last M = 7 days */       AND event_timestamp > UNIX_MICROS(TIMESTAMP_SUB(TIMESTAMP('2021-01-07 23:59:59'), INTERVAL 7 DAY))       /* Include only relevant tables based on the fixed timestamp */       AND _TABLE_SUFFIX BETWEEN '20210101' AND '20210107'   ) AS MDaysUsers LEFT JOIN   (     SELECT       user_pseudo_id     FROM       `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*` AS T     CROSS JOIN       UNNEST(T.event_params) AS event_params     WHERE       event_params.key = 'engagement_time_msec' AND event_params.value.int_value > 0       /* Has engaged in last N = 2 days */       AND event_timestamp > UNIX_MICROS(TIMESTAMP_SUB(TIMESTAMP('2021-01-07 23:59:59'), INTERVAL 2 DAY))       /* Include only relevant tables based on the fixed timestamp */       AND _TABLE_SUFFIX BETWEEN '20210105' AND '20210107'   ) AS NDaysUsers ON MDaysUsers.user_pseudo_id = NDaysUsers.user_pseudo_id WHERE   NDaysUsers.user_pseudo_id IS NULL;",
        "schema": {
            "bigquery-public-data.ga4_obfuscated_sample_ecommerce": {
                "events_*": [
                    "user_pseudo_id",
                    "event_params.key",
                    "event_params.value.int_value",
                    "event_timestamp",
                    "_TABLE_SUFFIX"
                ]
            }
        }
    },
    "bq010": {
        "query": "WITH GET_CUS_ID AS (     SELECT          DISTINCT fullVisitorId as Henley_CUSTOMER_ID     FROM          `bigquery-public-data.google_analytics_sample.ga_sessions_201707*`,         UNNEST(hits) AS hits,         UNNEST(hits.product) as product     WHERE         product.v2ProductName = \"YouTube Men's Vintage Henley\"         AND product.productRevenue IS NOT NULL     )  SELECT     product.v2ProductName AS other_purchased_products FROM     `bigquery-public-data.google_analytics_sample.ga_sessions_201707*` TAB_A      RIGHT JOIN GET_CUS_ID     ON GET_CUS_ID.Henley_CUSTOMER_ID=TAB_A.fullVisitorId,     UNNEST(hits) AS hits,     UNNEST(hits.product) as product WHERE     TAB_A.fullVisitorId IN (         SELECT * FROM GET_CUS_ID     )     AND product.v2ProductName <> \"YouTube Men's Vintage Henley\"     AND product.productRevenue IS NOT NULL GROUP BY     product.v2ProductName ORDER BY     SUM(product.productQuantity) DESC LIMIT 1;",
        "schema": {
            "bigquery-public-data.google_analytics_sample": {
                "ga_sessions_201707*": [
                    "fullVisitorId",
                    "hits.product.v2ProductName",
                    "hits.product.productRevenue",
                    "hits.product.productQuantity"
                ]
            }
        }
    },
    "bq009": {
        "query": "WITH MONTHLY_REVENUE AS (     SELECT          FORMAT_DATE(\"%Y%m\", PARSE_DATE(\"%Y%m%d\", date)) AS month,         trafficSource.source AS source,         ROUND(SUM(totals.totalTransactionRevenue) / 1000000, 2) AS revenue     FROM `bigquery-public-data.google_analytics_sample.ga_sessions_2017*`     GROUP BY 1, 2 ),  YEARLY_REVENUE AS (     SELECT         source,         SUM(revenue) AS total_revenue     FROM MONTHLY_REVENUE     GROUP BY source ),  TOP_SOURCE AS (     SELECT          source     FROM YEARLY_REVENUE     ORDER BY total_revenue DESC     LIMIT 1 ),  SOURCE_MONTHLY_REVENUE AS (     SELECT         month,         source,         revenue     FROM MONTHLY_REVENUE     WHERE source IN (SELECT source FROM TOP_SOURCE) ),  REVENUE_DIFF AS (     SELECT          source,         ROUND(MAX(revenue), 2) AS max_revenue,         ROUND(MIN(revenue), 2) AS min_revenue,         ROUND(MAX(revenue) - MIN(revenue), 2) AS diff_revenue     FROM SOURCE_MONTHLY_REVENUE     GROUP BY source )  SELECT      source,     diff_revenue FROM REVENUE_DIFF;",
        "schema": {
            "bigquery-public-data.google_analytics_sample": {
                "ga_sessions_2017*": [
                    "date",
                    "trafficSource.source",
                    "totals.totalTransactionRevenue"
                ]
            }
        }
    },
    "bq001": {
        "query": "DECLARE start_date STRING DEFAULT '20170201'; DECLARE end_date STRING DEFAULT '20170228';  WITH visit AS (     SELECT         fullvisitorid,         MIN(date) AS date_first_visit     FROM         `bigquery-public-data.google_analytics_sample.ga_sessions_*`     WHERE        _TABLE_SUFFIX BETWEEN start_date AND end_date     GROUP BY fullvisitorid ),  transactions AS (     SELECT         fullvisitorid,         MIN(date) AS date_transactions     FROM         `bigquery-public-data.google_analytics_sample.ga_sessions_*` AS ga,         UNNEST(ga.hits) AS hits     WHERE         hits.transaction.transactionId IS NOT NULL         AND         _TABLE_SUFFIX BETWEEN start_date AND end_date     GROUP BY fullvisitorid ),  device_transactions AS (     SELECT DISTINCT         fullvisitorid,         date,         device.deviceCategory     FROM         `bigquery-public-data.google_analytics_sample.ga_sessions_*` AS ga,         UNNEST(ga.hits) AS hits     WHERE         hits.transaction.transactionId IS NOT NULL         AND         _TABLE_SUFFIX BETWEEN start_date AND end_date ),  visits_transactions AS (     SELECT         visit.fullvisitorid,         date_first_visit,         date_transactions,         device_transactions.deviceCategory AS device_transaction     FROM         visit         JOIN transactions         ON visit.fullvisitorid = transactions.fullvisitorid         JOIN device_transactions         ON visit.fullvisitorid = device_transactions.fullvisitorid          AND transactions.date_transactions = device_transactions.date )  SELECT        fullvisitorid,        DATE_DIFF(PARSE_DATE('%Y%m%d', date_transactions), PARSE_DATE('%Y%m%d', date_first_visit), DAY) AS time,        device_transaction FROM visits_transactions ORDER BY fullvisitorid;",
        "schema": {
            "bigquery-public-data.google_analytics_sample": {
                "ga_sessions_*": [
                    "fullvisitorid",
                    "date",
                    "_TABLE_SUFFIX",
                    "hits.transaction.transactionId",
                    "device.deviceCategory"
                ]
            }
        }
    },
    "bq002": {
        "query": "DECLARE start_date STRING DEFAULT '20170101'; DECLARE end_date STRING DEFAULT '20170630';  -- Step 1: Calculate daily, weekly, and monthly revenues for each traffic source WITH daily_revenue AS (     SELECT         trafficSource.source AS source,         date,         SUM(productRevenue) / 1000000 AS revenue     FROM         `bigquery-public-data.google_analytics_sample.ga_sessions_*`,         UNNEST (hits) AS hits,         UNNEST (hits.product) AS product     WHERE         _table_suffix BETWEEN start_date AND end_date     GROUP BY         source, date ), weekly_revenue AS (     SELECT         source,         CONCAT(EXTRACT(YEAR FROM (PARSE_DATE('%Y%m%d', date))), 'W', EXTRACT(WEEK FROM (PARSE_DATE('%Y%m%d', date)))) AS week,         SUM(revenue) AS revenue     FROM daily_revenue     GROUP BY source, week ), monthly_revenue AS (     SELECT         source,         CONCAT(EXTRACT(YEAR FROM (PARSE_DATE('%Y%m%d', date))),'0', EXTRACT(MONTH FROM (PARSE_DATE('%Y%m%d', date)))) AS month,         SUM(revenue) AS revenue     FROM daily_revenue     GROUP BY source, month ),  -- Step 2: Determine the top-performing traffic source top_source AS (     SELECT source, SUM(revenue) AS total_revenue     FROM daily_revenue     GROUP BY source     ORDER BY total_revenue DESC     LIMIT 1 ),  -- Step 3: Calculate maximum revenues for the top-performing traffic source max_revenues AS (     (       SELECT         'Daily' AS time_type,         date AS time,         source,         MAX(revenue) AS max_revenue       FROM daily_revenue       WHERE source = (SELECT source FROM top_source)       GROUP BY source, date       ORDER BY max_revenue DESC       LIMIT 1     )      UNION ALL      (       SELECT         'Weekly' AS time_type,         week AS time,         source,         MAX(revenue) AS max_revenue       FROM weekly_revenue       WHERE source = (SELECT source FROM top_source)       GROUP BY source, week       ORDER BY max_revenue DESC       LIMIT 1     )      UNION ALL      (       SELECT           'Monthly' AS time_type,           month AS time,           source,           MAX(revenue) AS max_revenue       FROM monthly_revenue       WHERE source = (SELECT source FROM top_source)       GROUP BY source, month       ORDER BY max_revenue DESC       LIMIT 1     ) )  -- Step 4: Select final results SELECT     time_type,     time,     source,     max_revenue FROM max_revenues ORDER BY time_type, time;",
        "schema": {
            "bigquery-public-data.google_analytics_sample": {
                "ga_sessions_*": [
                    "trafficSource.source",
                    "date",
                    "productRevenue",
                    "hits.product"
                ]
            }
        }
    },
    "bq003": {
        "query": "WITH cte1 AS (     SELECT         CONCAT(EXTRACT(YEAR FROM (PARSE_DATE('%Y%m%d', date))), '0',             EXTRACT(MONTH FROM (PARSE_DATE('%Y%m%d', date)))) AS month,         SUM(totals.pageviews) / COUNT(DISTINCT fullVisitorId) AS avg_pageviews_non_purchase     FROM         `bigquery-public-data.google_analytics_sample.ga_sessions_2017*`,         UNNEST (hits) AS hits,         UNNEST (hits.product) AS product     WHERE         _table_suffix BETWEEN '0401' AND '0731'         AND totals.transactions IS NULL         AND product.productRevenue IS NULL     GROUP BY month ), cte2 AS (     SELECT         CONCAT(EXTRACT(YEAR FROM (PARSE_DATE('%Y%m%d', date))), '0',             EXTRACT(MONTH FROM (PARSE_DATE('%Y%m%d', date)))) AS month,         SUM(totals.pageviews) / COUNT(DISTINCT fullVisitorId) AS avg_pageviews_purchase     FROM         `bigquery-public-data.google_analytics_sample.ga_sessions_2017*`,         UNNEST (hits) AS hits,         UNNEST (hits.product) AS product     WHERE         _table_suffix BETWEEN '0401' AND '0731'         AND totals.transactions >= 1         AND product.productRevenue IS NOT NULL     GROUP BY month ) SELECT     month, avg_pageviews_purchase, avg_pageviews_non_purchase FROM cte1 INNER JOIN cte2 USING(month) ORDER BY month;",
        "schema": {
            "bigquery-public-data.google_analytics_sample": {
                "ga_sessions_2017*": [
                    "date",
                    "fullVisitorId",
                    "totals.pageviews",
                    "totals.transactions",
                    "hits.product.productRevenue"
                ]
            }
        }
    },
    "bq004": {
        "query": "with product_and_quatity AS (     SELECT          DISTINCT v2ProductName AS other_purchased_products,         SUM(productQuantity) AS quatity     FROM         `bigquery-public-data.google_analytics_sample.ga_sessions_2017*`,         UNNEST(hits) AS hits,         UNNEST(hits.product) AS product     WHERE         _table_suffix BETWEEN '0701' AND '0731'         AND product.productRevenue IS NOT NULL         AND v2ProductName NOT LIKE '%YouTube%'         AND fullVisitorID IN (             SELECT              DISTINCT fullVisitorId             FROM                 `bigquery-public-data.google_analytics_sample.ga_sessions_2017*`,                 UNNEST(hits) AS hits,                 UNNEST(hits.product) AS product             WHERE                 _table_suffix BETWEEN '0701' AND '0731'                 AND product.productRevenue IS NOT NULL                 AND v2ProductName LIKE '%YouTube%'         )     GROUP BY v2ProductName ) SELECT other_purchased_products FROM product_and_quatity ORDER BY quatity DESC LIMIT 1;",
        "schema": {
            "bigquery-public-data.google_analytics_sample": {
                "ga_sessions_2017*": [
                    "v2ProductName",
                    "productQuantity",
                    "fullVisitorID",
                    "hits.product.productRevenue",
                    "hits.product.v2ProductName"
                ]
            }
        }
    },
    "bq008": {
        "query": "with page_visit_sequence AS (     SELECT         fullVisitorID,         visitID,         pagePath,         LEAD(timestamp, 1) OVER (PARTITION BY fullVisitorId, visitID order by timestamp) - timestamp AS page_duration,         LEAD(pagePath, 1) OVER (PARTITION BY fullVisitorId, visitID order by timestamp) AS next_page,         RANK() OVER (PARTITION BY fullVisitorId, visitID order by timestamp) AS step_number     FROM (         SELECT             pages.fullVisitorID,             pages.visitID,             pages.pagePath,             visitors.campaign,             MIN(pages.timestamp) timestamp         FROM (             SELECT                 fullVisitorId,                 visitId,                 trafficSource.campaign campaign             FROM                 `bigquery-public-data.google_analytics_sample.ga_sessions_*`,                 UNNEST(hits) as hits             WHERE                 _TABLE_SUFFIX BETWEEN '20170101' AND '20170131'                 AND hits.type='PAGE'                 AND REGEXP_CONTAINS(hits.page.pagePath, r'^/home')                 AND REGEXP_CONTAINS(trafficSource.campaign, r'Data Share')         ) AS visitors         JOIN(             SELECT                 fullVisitorId,                 visitId,                 visitStartTime + hits.time / 1000 AS timestamp,                 hits.page.pagePath AS pagePath             FROM                 `bigquery-public-data.google_analytics_sample.ga_sessions_*`,                 UNNEST(hits) as hits             WHERE                 _TABLE_SUFFIX BETWEEN '20170101' AND '20170131'         ) as pages         ON             visitors.fullVisitorID = pages.fullVisitorID             AND visitors.visitID = pages.visitID         GROUP BY              pages.fullVisitorID, visitors.campaign, pages.visitID, pages.pagePath         ORDER BY              pages.fullVisitorID, pages.visitID, timestamp     )     ORDER BY fullVisitorId, visitID, step_number ), most_common_next_page AS (     SELECT         next_page,         COUNT(next_page) as page_count     FROM page_visit_sequence     WHERE         next_page IS NOT NULL         AND REGEXP_CONTAINS(pagePath, r'^/home')     GROUP BY next_page     ORDER BY page_count DESC     LIMIT 1 ), max_page_duration AS (     SELECT MAX(page_duration) as max_duration     FROM page_visit_sequence     WHERE         page_duration IS NOT NULL         AND REGEXP_CONTAINS(pagePath, r'^/home') ) SELECT     next_page,     max_duration FROM     most_common_next_page,     max_page_duration;",
        "schema": {
            "bigquery-public-data.google_analytics_sample": {
                "ga_sessions_*": [
                    "fullVisitorId",
                    "visitId",
                    "trafficSource.campaign",
                    "hits.type",
                    "hits.page.pagePath",
                    "visitStartTime",
                    "hits.time",
                    "hits.page.pagePath"
                ]
            }
        }
    },
    "bq029": {
        "query": "SELECT    AVG(num_inventors) AS avg_inventors,   COUNT(*) AS cnt,   filing_year FROM (   SELECT      ANY_VALUE(ARRAY_LENGTH(inventor)) AS num_inventors,     ANY_VALUE(country_code) AS country_code,     ANY_VALUE(CAST(FLOOR(filing_date / (5 * 10000)) AS INT64)) * 5 AS filing_year   FROM      `patents-public-data.patents.publications` AS pubs   WHERE      filing_date > 19450000      AND filing_date < 20200000     AND ARRAY_LENGTH(inventor) > 0   GROUP BY      publication_number ) WHERE country_code in ('US') GROUP BY    filing_year,    country_code ORDER BY    filing_year;",
        "schema": {
            "patents-public-data.patents": {
                "publications": [
                    "inventor",
                    "country_code",
                    "filing_date",
                    "publication_number"
                ]
            }
        }
    },
    "bq026": {
        "query": "WITH PatentApplications AS (     SELECT          ANY_VALUE(assignee_harmonized) AS assignee_harmonized,  -- Collects any sample of harmonized assignee data.         ANY_VALUE(filing_date) AS filing_date,  -- Collects any sample of filing date.         ANY_VALUE(country_code) AS country_code,  -- Collects any sample of country code.         application_number  -- The unique identifier for each patent application.     FROM          `patents-public-data.patents.publications` AS pubs  -- Using the patents publications dataset.     WHERE EXISTS (         -- Checks if there exists a CPC code \"A61K39\" within the nested CPC field.         SELECT 1 FROM UNNEST(pubs.cpc) AS c WHERE REGEXP_CONTAINS(c.code, \"A61K39\")     )     GROUP BY          application_number  -- Group by application number to ensure distinct entries. )  ,AssigneeApplications AS (     SELECT          COUNT(*) AS year_country_cnt,  -- Count of applications per assignee, year, and country.         a.name AS assignee_name,  -- Name of the assignee.         CAST(FLOOR(filing_date / 10000) AS INT64) AS filing_year,  -- Extracts the year from the filing date.         apps.country_code  -- Country code of the application.     FROM          PatentApplications AS apps  -- Using the previously defined CTE.     CROSS JOIN     UNNEST(assignee_harmonized) AS a  -- Expanding the assignee_harmonized array.     GROUP BY          a.name, filing_year, country_code  -- Grouping by assignee, year, and country. )  -- CTE to aggregate data by assignee and year and to collect top 5 countries by application count. ,AggregatedData AS (     SELECT          SUM(year_country_cnt) AS year_cnt,  -- Sum of all applications per assignee per year.         assignee_name,          filing_year,          -- Aggregates the top 5 countries by their application counts in descending order.         STRING_AGG(country_code ORDER BY year_country_cnt DESC LIMIT 5) AS countries     FROM          AssigneeApplications  -- Using the AssigneeApplications CTE.     GROUP BY          assignee_name, filing_year  -- Grouping results by assignee and year. )  -- Final aggregation to find the year with the highest application count for each assignee. ,FinalAggregation AS (     SELECT          SUM(year_cnt) AS total_count,  -- Total count of applications for each assignee.         assignee_name,         -- Aggregates into a structure the year and countries data with the highest application count.         ARRAY_AGG(             STRUCT<cnt INT64, filing_year INT64, countries STRING>             (year_cnt, filing_year, countries)              ORDER BY year_cnt DESC LIMIT 1         )[SAFE_ORDINAL(1)] AS largest_year  -- Selects the year with the highest application count.     FROM          AggregatedData  -- Using the AggregatedData CTE.     GROUP BY          assignee_name  -- Grouping by assignee. ), Final_data AS ( SELECT      total_count,     assignee_name,     largest_year FROM      FinalAggregation  -- Using the FinalAggregation CTE. ORDER BY      total_count DESC )  SELECT largest_year.countries FROM Final_data LIMIT 1",
        "schema": {
            "patents-public-data.patents": {
                "publications": [
                    "assignee_harmonized",
                    "filing_date",
                    "country_code",
                    "application_number",
                    "cpc.code"
                ]
            }
        }
    },
    "bq026_1": {
        "query": "WITH PatentApplications AS (     SELECT          ANY_VALUE(assignee_harmonized) AS assignee_harmonized,  -- Randomly sampling assignee data         ANY_VALUE(filing_date) AS filing_date,  -- Randomly sampling filing date         application_number  -- The unique identifier for each patent application     FROM          `patents-public-data.patents.publications` AS pubs  -- Using the patent publications dataset     WHERE EXISTS (         -- Checks if there is a CPC code \"A61K39\"         SELECT 1 FROM UNNEST(pubs.cpc) AS c WHERE REGEXP_CONTAINS(c.code, \"A61K39\")     )     GROUP BY          application_number  -- Grouping by application number to ensure unique entries )  , AssigneeApplications AS (     SELECT          COUNT(*) AS total_applications,  -- Calculating the total number of applications         a.name AS assignee_name,  -- Name of the assignee         CAST(FLOOR(filing_date / 10000) AS INT64) AS filing_year  -- Extracting the year from the filing date     FROM          PatentApplications     CROSS JOIN         UNNEST(assignee_harmonized) AS a  -- Expanding the assignee_harmonized array     GROUP BY          a.name, filing_year  -- Grouping by assignee and year )  , TotalApplicationsPerAssignee AS (     SELECT         assignee_name,         SUM(total_applications) AS total_applications  -- Sum of all applications per assignee     FROM          AssigneeApplications     GROUP BY          assignee_name     ORDER BY          total_applications DESC     LIMIT 1  -- Selecting only the assignee with the highest total applications )  , MaxYearForTopAssignee AS (     SELECT         aa.assignee_name,         aa.filing_year,         aa.total_applications     FROM          AssigneeApplications aa     INNER JOIN         TotalApplicationsPerAssignee tapa ON aa.assignee_name = tapa.assignee_name     ORDER BY          aa.total_applications DESC     LIMIT 1  -- Finding the year with the most applications for the top assignee )  SELECT filing_year FROM      MaxYearForTopAssignee",
        "schema": {
            "patents-public-data.patents": {
                "publications": [
                    "assignee_harmonized",
                    "filing_date",
                    "application_number",
                    "cpc.code"
                ]
            }
        }
    },
    "bq026_2": {
        "query": "WITH PatentApplications AS (     SELECT          ANY_VALUE(assignee_harmonized) AS assignee_harmonized,  -- Collects any sample of harmonized assignee data.         ANY_VALUE(filing_date) AS filing_date,  -- Collects any sample of filing date.         ANY_VALUE(country_code) AS country_code,  -- Collects any sample of country code.         application_number  -- The unique identifier for each patent application.     FROM          `patents-public-data.patents.publications` AS pubs  -- Using the patents publications dataset.     WHERE EXISTS (         SELECT 1 FROM UNNEST(pubs.cpc) AS c WHERE REGEXP_CONTAINS(c.code, \"A01B3\")     )     GROUP BY          application_number  -- Group by application number to ensure distinct entries. )  ,AssigneeApplications AS (     SELECT          COUNT(*) AS year_country_cnt,  -- Count of applications per assignee, year, and country.         a.name AS assignee_name,  -- Name of the assignee.         CAST(FLOOR(filing_date / 10000) AS INT64) AS filing_year,  -- Extracts the year from the filing date.         apps.country_code  -- Country code of the application.     FROM          PatentApplications AS apps  -- Using the previously defined CTE.     CROSS JOIN     UNNEST(assignee_harmonized) AS a  -- Expanding the assignee_harmonized array.     GROUP BY          a.name, filing_year, country_code  -- Grouping by assignee, year, and country. )  -- CTE to aggregate data by assignee and year and to collect top 5 countries by application count. ,AggregatedData AS (     SELECT          SUM(year_country_cnt) AS year_cnt,  -- Sum of all applications per assignee per year.         assignee_name,          filing_year,          -- Aggregates the top 5 countries by their application counts in descending order.         STRING_AGG(country_code ORDER BY year_country_cnt DESC LIMIT 1) AS countries     FROM          AssigneeApplications  -- Using the AssigneeApplications CTE.     GROUP BY          assignee_name, filing_year  -- Grouping results by assignee and year. )  -- Final aggregation to find the year with the highest application count for each assignee. ,FinalAggregation AS (     SELECT          SUM(year_cnt) AS total_count,  -- Total count of applications for each assignee.         assignee_name,         -- Aggregates into a structure the year and countries data with the highest application count.         ARRAY_AGG(             STRUCT<cnt INT64, filing_year INT64, countries STRING>             (year_cnt, filing_year, countries)              ORDER BY year_cnt DESC LIMIT 1         )[SAFE_ORDINAL(1)] AS largest_year  -- Selects the year with the highest application count.     FROM          AggregatedData  -- Using the AggregatedData CTE.     GROUP BY          assignee_name  -- Grouping by assignee. )  -- Selecting final results including total application count, assignee name, and details of their largest year. SELECT      total_count,     assignee_name,     largest_year.cnt,     largest_year.filing_year,     largest_year.countries FROM      FinalAggregation  -- Using the FinalAggregation CTE. ORDER BY      total_count DESC  -- Ordering by total application count in descending order. LIMIT 20;  -- Limits the results to the top 20 assignees.",
        "schema": {
            "patents-public-data.patents": {
                "publications": [
                    "assignee_harmonized",
                    "filing_date",
                    "country_code",
                    "application_number",
                    "cpc.code"
                ]
            }
        }
    },
    "bq033": {
        "query": "WITH   Patent_Matches AS (     SELECT       PARSE_DATE('%Y%m%d', SAFE_CAST(ANY_VALUE(patentsdb.filing_date) AS STRING)) AS Patent_Filing_Date,       patentsdb.application_number AS Patent_Application_Number,       ANY_VALUE(abstract_info.text) AS Patent_Title,       ANY_VALUE(abstract_info.language) AS Patent_Title_Language     FROM       `patents-public-data.patents.publications` AS patentsdb,       UNNEST(abstract_localized) AS abstract_info     WHERE       LOWER(abstract_info.text) LIKE '%internet of things%'       AND patentsdb.country_code = 'US'     GROUP BY       Patent_Application_Number   ),    Date_Series_Table AS (     SELECT       day,       0 AS Number_of_Patents     FROM       UNNEST(GENERATE_DATE_ARRAY(         DATE '2008-01-01',          DATE '2022-12-31'       )) AS day   )  SELECT   SAFE_CAST(FORMAT_DATE('%Y-%m', Date_Series_Table.day) AS STRING) AS Patent_Date_YearMonth,   COUNT(Patent_Matches.Patent_Application_Number) AS Number_of_Patent_Applications FROM   Date_Series_Table   LEFT JOIN Patent_Matches     ON Date_Series_Table.day = Patent_Matches.Patent_Filing_Date GROUP BY   Patent_Date_YearMonth ORDER BY   Patent_Date_YearMonth;",
        "schema": {
            "patents-public-data.patents": {
                "publications": [
                    "filing_date",
                    "application_number",
                    "country_code"
                ]
            }
        }
    },
    "bq209": {
        "query": "WITH patents_sample AS (               -- name of our table SELECT    t1.publication_number,    t1.application_number  FROM    `patents-public-data.patents.publications` t1  WHERE    country_code = 'US'                                                        -- only consider US patents   AND grant_date between 20100101 AND 20100131                               -- grant dates between 2002 and 2006   AND grant_date != 0                                                        -- only consider granted patents   AND publication_number LIKE '%B2%'                                         -- only consider patents with kind code B2 ), Forward_citation AS (      SELECT      DISTINCT patents_sample.publication_number,      COUNT(DISTINCT t3.citing_application_number) AS forward_citations      FROM      patents_sample      LEFT JOIN (      SELECT      x2.publication_number,      PARSE_DATE('%Y%m%d', CAST(x2.filing_date AS STRING)) AS filing_date      FROM      `patents-public-data.patents.publications` x2      WHERE      x2.filing_date != 0) t2      ON      t2.publication_number = patents_sample.publication_number      LEFT JOIN (      SELECT      x3.publication_number AS citing_publication_number,      x3.application_number AS citing_application_number,      PARSE_DATE('%Y%m%d', CAST(x3.filing_date AS STRING)) AS joined_filing_date,      citation_u.publication_number AS cited_publication_number      FROM      `patents-public-data.patents.publications` x3,      UNNEST(citation) AS citation_u      WHERE      x3.filing_date!=0) t3      ON      patents_sample.publication_number = t3.cited_publication_number      AND t3.joined_filing_date BETWEEN t2.filing_date      AND DATE_ADD(t2.filing_date, INTERVAL 10 YEAR)      GROUP BY      patents_sample.publication_number )  SELECT       publication_number FROM      Forward_citation ORDER BY   forward_citations DESC LIMIT 1",
        "schema": {
            "patents-public-data.patents": {
                "publications": [
                    "publication_number",
                    "application_number",
                    "country_code",
                    "grant_date",
                    "filing_date",
                    "citation.publication_number"
                ]
            }
        }
    },
    "bq027": {
        "query": "WITH patents_sample AS (               -- name of our table SELECT    t1.publication_number,    t1.application_number  FROM    `patents-public-data.patents.publications` t1  WHERE    country_code = 'US'                                                        -- only consider US patents   AND grant_date between 20180101 AND 20180107                               -- grant dates between 2002 and 2006   AND grant_date != 0                                                        -- only consider granted patents   AND publication_number LIKE '%B2%'                                         -- only consider patents with kind code B2 )  SELECT   t1.publication_number,   -- count disctinct application numbers cited by our focal patent   COUNT(DISTINCT t3.application_number) AS backward_citations FROM   patents_sample t1 LEFT OUTER JOIN (   SELECT     -- the publication number in the joined table is the citing publication number     x2.publication_number AS citing_publication_number,     -- the publication number in the unnested citation record is the cited publication number     citation_u.publication_number AS cited_publication_number,     -- the category in the unnested citation record is the category of the cited publication     citation_u.category AS cited_publication_category   FROM     `patents-public-data.patents.publications` x2,     UNNEST(citation) AS citation_u ) t2 ON   t2.citing_publication_number = t1.publication_number   -- citation category has to contain 'SEA'   AND CONTAINS_SUBSTR(t2.cited_publication_category, 'SEA')   -- one more join to publications table to get the application number LEFT OUTER JOIN   `patents-public-data.patents.publications` t3 ON   t2.cited_publication_number = t3.publication_number GROUP BY   t1.publication_number ORDER BY   t1.publication_number",
        "schema": {
            "patents-public-data.patents": {
                "publications": [
                    "publication_number",
                    "application_number",
                    "country_code",
                    "grant_date",
                    "citation.publication_number",
                    "citation.category"
                ]
            }
        }
    },
    "bq210": {
        "query": "WITH patents_sample AS (   SELECT      t1.publication_number,     claim.text AS claims_text   FROM      patents-public-data.patents.publications t1,     UNNEST(t1.claims_localized) AS claim   WHERE      t1.country_code = 'US'     AND t1.grant_date BETWEEN 20150101 AND 20181231     AND t1.grant_date != 0     AND t1.publication_number LIKE '%B2%' ), Publication_data AS (   SELECT     publication_number,     COUNTIF(claims_text NOT LIKE '%claim%') AS nb_indep_claims   FROM     patents_sample   GROUP BY     publication_number )  SELECT COUNT(nb_indep_claims) FROM Publication_data WHERE nb_indep_claims != 0",
        "schema": {
            "patents-public-data.patents": {
                "publications": [
                    "publication_number",
                    "claims_localized",
                    "country_code",
                    "grant_date"
                ]
            }
        }
    },
    "bq211": {
        "query": "WITH patents_sample AS (               -- name of our table SELECT    t1.publication_number,    t1.application_number  FROM    patents-public-data.patents.publications t1  WHERE    country_code = 'US'                                                        -- only consider US patents   AND grant_date between 20080101 AND 20080131                               -- grant dates between 2002 and 2006   AND grant_date != 0                                                        -- only consider granted patents   AND publication_number LIKE '%B2%'                                         -- only consider patents with kind code B2 ),  family_number AS ( SELECT   t1.publication_number,   -- count distinct application numbers sharing same family id with our focal patents   COUNT(DISTINCT t3.application_number) AS family_size, FROM   patents_sample t1   -- join publications table to obtain family id of our focal patents LEFT JOIN   patents-public-data.patents.publications t2 ON   t1.publication_number = t2.publication_number   -- join publications table on family id to get all publications sharing the same family id LEFT JOIN   patents-public-data.patents.publications t3 ON   t2.family_id = t3.family_id GROUP BY   t1.publication_number )  SELECT COUNT(*) FROM family_number WHERE family_size>300",
        "schema": {
            "patents-public-data.patents": {
                "publications": [
                    "publication_number",
                    "application_number",
                    "country_code",
                    "grant_date",
                    "family_id"
                ]
            }
        }
    },
    "bq213": {
        "query": "WITH interim_table as( SELECT      t1.publication_number,      SUBSTR(ipc_u.code, 0, 4) as ipc4 FROM      `patents-public-data.patents.publications` t1,      UNNEST(ipc) AS ipc_u  WHERE country_code = 'US'   AND grant_date between 20180601 AND 20180607   AND grant_date != 0   AND publication_number LIKE '%B2%'   GROUP BY      t1.publication_number,      ipc4 )  SELECT  ipc4 FROM  interim_table  GROUP BY ipc4 ORDER BY COUNT(publication_number) DESC LIMIT 1",
        "schema": {
            "patents-public-data.patents": {
                "publications": [
                    "publication_number",
                    "ipc",
                    "country_code",
                    "grant_date"
                ]
            }
        }
    },
    "bq213_1": {
        "query": "WITH interim_table as( SELECT      t1.publication_number,      SUBSTR(ipc_u.code, 0, 4) as ipc4,      COUNT(     SUBSTR(ipc_u.code, 0, 4)     ) as ipc4_count  FROM      `patents-public-data.patents.publications` t1,      UNNEST(ipc) AS ipc_u  WHERE country_code = 'US'   AND grant_date between 20150401 AND 20150430   AND grant_date != 0   AND publication_number LIKE '%B2%'   GROUP BY      t1.publication_number,      ipc4 )  SELECT  publication_number, ipc4 FROM  interim_table  where  concat(     interim_table.publication_number,      interim_table.ipc4_count ) IN (     SELECT      concat(         publication_number,          MAX(ipc4_count)     )      FROM      interim_table      group by      publication_number ) AND ipc4_count >= 20",
        "schema": {
            "patents-public-data.patents": {
                "publications": [
                    "publication_number",
                    "ipc",
                    "country_code",
                    "grant_date"
                ]
            }
        }
    },
    "bq214": {
        "query": "WITH patents_sample AS (     SELECT          t1.publication_number,          t1.application_number      FROM          `patents-public-data.patents.publications` t1      WHERE          country_code = 'US' AND         grant_date BETWEEN 20170101 AND 20170131 AND         publication_number LIKE '%B2%' ),  Forward_citation AS (     SELECT         DISTINCT patents_sample.publication_number,         COUNT(DISTINCT t3.citing_application_number) AS forward_citations     FROM         patents_sample     LEFT JOIN (         SELECT             x2.publication_number,             PARSE_DATE('%Y%m%d', CAST(x2.filing_date AS STRING)) AS filing_date         FROM             `patents-public-data.patents.publications` x2         WHERE             x2.filing_date != 0     ) t2 ON t2.publication_number = patents_sample.publication_number     LEFT JOIN (         SELECT             x3.publication_number AS citing_publication_number,             x3.application_number AS citing_application_number,             PARSE_DATE('%Y%m%d', CAST(x3.filing_date AS STRING)) AS joined_filing_date,             citation_u.publication_number AS cited_publication_number         FROM             `patents-public-data.patents.publications` x3,             UNNEST(citation) AS citation_u         WHERE             x3.filing_date != 0     ) t3 ON patents_sample.publication_number = t3.cited_publication_number AND              t3.joined_filing_date BETWEEN t2.filing_date AND DATE_ADD(t2.filing_date, INTERVAL 1 MONTH)     GROUP BY         patents_sample.publication_number ),  select_sample AS (     SELECT          publication_number     FROM         Forward_citation     ORDER BY         forward_citations DESC     LIMIT 1 ),  t AS (     SELECT         t1.publication_number,         t4.publication_number AS similar_publication_number,         (SELECT SUM(element1 * element2)          FROM t5.embedding_v1 element1 WITH OFFSET pos          JOIN t6.embedding_v1 element2 WITH OFFSET pos USING (pos)) AS similarity     FROM          (SELECT * FROM select_sample LIMIT 1) t1     LEFT JOIN (         SELECT              x3.publication_number,             EXTRACT(YEAR FROM PARSE_DATE('%Y%m%d', CAST(x3.filing_date AS STRING))) AS focal_filing_year         FROM              `patents-public-data.patents.publications` x3         WHERE              x3.filing_date != 0     ) t3 ON t3.publication_number = t1.publication_number     LEFT JOIN (         SELECT              x4.publication_number,             EXTRACT(YEAR FROM PARSE_DATE('%Y%m%d', CAST(x4.filing_date AS STRING))) AS filing_year         FROM              `patents-public-data.patents.publications` x4         WHERE              x4.filing_date != 0     ) t4 ON  t4.publication_number != t1.publication_number AND              t3.focal_filing_year = t4.filing_year     LEFT JOIN `patents-public-data.google_patents_research.publications` t5 ON t5.publication_number = t1.publication_number     LEFT JOIN `patents-public-data.google_patents_research.publications` t6 ON t6.publication_number = t4.publication_number     ORDER BY          t1.publication_number, similarity DESC )  SELECT     t.similar_publication_number FROM (     SELECT         t.*,         ROW_NUMBER() OVER (PARTITION BY publication_number ORDER BY similarity DESC) AS seqnum     FROM         t ) t WHERE     seqnum <= 1;",
        "schema": {
            "patents-public-data.patents": {
                "publications": [
                    "publication_number",
                    "application_number",
                    "country_code",
                    "grant_date",
                    "filing_date",
                    "citation.publication_number"
                ]
            },
            "patents-public-data.google_patents_research": {
                "publications": [
                    "publication_number",
                    "embedding_v1"
                ]
            }
        }
    },
    "bq214_1": {
        "query": "WITH patents_sample AS (     SELECT publication_number, application_number     FROM         `patents-public-data.patents.publications`     WHERE     publication_number = 'US-9023721-B2' ), t AS (     SELECT         t1.publication_number,         t4.publication_number AS similar_publication_number,         (SELECT SUM(element1 * element2)          FROM t5.embedding_v1 element1 WITH OFFSET pos          JOIN t6.embedding_v1 element2 WITH OFFSET pos USING (pos)) AS similarity     FROM          (SELECT * FROM patents_sample LIMIT 1) t1     LEFT JOIN (         SELECT              x3.publication_number,             EXTRACT(YEAR FROM PARSE_DATE('%Y%m%d', CAST(x3.filing_date AS STRING))) AS focal_filing_year         FROM              `patents-public-data.patents.publications` x3         WHERE              x3.filing_date != 0     ) t3 ON t3.publication_number = t1.publication_number     LEFT JOIN (         SELECT              x4.publication_number,             EXTRACT(YEAR FROM PARSE_DATE('%Y%m%d', CAST(x4.filing_date AS STRING))) AS filing_year         FROM              `patents-public-data.patents.publications` x4         WHERE              x4.filing_date != 0     ) t4 ON     t4.publication_number != t1.publication_number     AND t3.focal_filing_year = t4.filing_year     LEFT JOIN `patents-public-data.google_patents_research.publications` t5 ON t5.publication_number = t1.publication_number     LEFT JOIN `patents-public-data.google_patents_research.publications` t6 ON t6.publication_number = t4.publication_number     ORDER BY          t1.publication_number, similarity DESC ) SELECT     t.similar_publication_number,     t.similarity FROM (     SELECT         t.*,         ROW_NUMBER() OVER (PARTITION BY publication_number ORDER BY similarity DESC) AS seqnum     FROM         t ) t WHERE     seqnum <= 5;",
        "schema": {
            "patents-public-data.patents": {
                "publications": [
                    "publication_number",
                    "application_number",
                    "filing_date"
                ]
            },
            "patents-public-data.google_patents_research": {
                "publications": [
                    "publication_number",
                    "embedding_v1"
                ]
            }
        }
    },
    "bq215": {
        "query": "WITH patents_sample AS (               -- name of our table SELECT    t1.publication_number,    t1.application_number  FROM    `patents-public-data.patents.publications` t1  WHERE    country_code = 'US'                                                        -- only consider US patents   AND grant_date between 20180101 AND 20180131                               -- grant dates between 2002 and 2006   AND grant_date != 0                                                        -- only consider granted patents   AND publication_number LIKE '%B2%'                                         -- only consider patents with kind code B2 ), interim_table AS (     SELECT         t1.publication_number,         SUBSTR(ipc_u.code, 0, 4) AS ipc4,         COUNT(SUBSTR(ipc_u.code, 0, 4)) AS ipc4_count     FROM         patents-public-data.patents.publications t1,         UNNEST(ipc) AS ipc_u     GROUP BY         t1.publication_number,         ipc4 ), chosen_ipc4_view AS (     SELECT         *     FROM         interim_table     WHERE         CONCAT(interim_table.publication_number, interim_table.ipc4_count) IN (             SELECT                 CONCAT(publication_number, MAX(ipc4_count))             FROM                 interim_table             GROUP BY                 publication_number         )     ORDER BY         ipc4_count DESC ), ipc_counts AS (   SELECT     t1.publication_number,     t3.ipc4,     COUNT(t3.ipc4) AS ipc_occurrences   FROM     patents_sample t1     -- joins backward citations   LEFT JOIN (     SELECT       x2.publication_number AS citing_publication_number,       citation_u.publication_number AS backward_citation     FROM       patents-public-data.patents.publications x2,       UNNEST(citation) AS citation_u) t2   ON     t2.citing_publication_number = t1.publication_number     -- joins 4-digit ipc codes of backward citations   LEFT JOIN     chosen_ipc4_view t3   ON     t3.publication_number = t2.backward_citation   GROUP BY     t1.publication_number,     t3.ipc4 ), max_originality AS (   SELECT     publication_number,     1 - SUM(POWER(ipc_occurrences, 2)) / POWER(SUM(ipc_occurrences), 2) AS originality   FROM     ipc_counts   GROUP BY     publication_number   HAVING     SUM(ipc_occurrences) > 0   ORDER BY     originality DESC   LIMIT 1 ) SELECT    publication_number FROM    max_originality",
        "schema": {
            "patents-public-data.patents": {
                "publications": [
                    "publication_number",
                    "application_number",
                    "country_code",
                    "grant_date",
                    "ipc",
                    "citation"
                ]
            }
        }
    },
    "bq221": {
        "query": "CREATE TEMPORARY FUNCTION highest_moving_avg(yearcnt ARRAY<STRUCT<filing_year INT64, cnt INT64>>) RETURNS STRUCT<filing_year INT64, avg INT64> LANGUAGE js AS \"\"\"     let a = 0.2;     let avg = yearcnt.length > 0 ? yearcnt[0].cnt : 0;     let highest = {filing_year: -1, avg: -1};     for (let x of yearcnt) {         avg = a * x.cnt + (1 - a) * avg;         if (avg > highest.avg) {                 highest = {filing_year: x.filing_year, avg: avg};         }     }     return highest; \"\"\";      WITH patent_cpcs AS (     SELECT         cd.parents,         CAST(FLOOR(filing_date/10000) AS INT64) AS filing_year     FROM (         SELECT             ANY_VALUE(cpc) AS cpc,             ANY_VALUE(filing_date) AS filing_date         FROM             `patents-public-data.patents.publications`         WHERE              application_number != \"\"         GROUP BY             application_number         ), UNNEST(cpc) AS cpcs     JOIN         `patents-public-data.cpc.definition` cd     ON cd.symbol = cpcs.code     WHERE         cpcs.first = TRUE         AND filing_date > 0 )  SELECT c.titleFull, cpc_group, best_year.filing_year FROM (     SELECT         cpc_group,         highest_moving_avg(ARRAY_AGG(STRUCT<filing_year INT64, cnt INT64>(filing_year, cnt) ORDER BY filing_year ASC)) AS best_year     FROM (         SELECT             cpc_group,             filing_year,             COUNT(*) AS cnt         FROM (             SELECT                 cpc_parent AS cpc_group,                 filing_year             FROM                 patent_cpcs,                 UNNEST(parents) AS cpc_parent         )         GROUP BY cpc_group, filing_year         ORDER BY filing_year DESC, cnt DESC     )     GROUP BY cpc_group ) JOIN `patents-public-data.cpc.definition` c ON cpc_group = c.symbol WHERE c.level = 5 ORDER BY c.titleFull, cpc_group ASC;",
        "schema": {
            "patents-public-data.patents": {
                "publications": [
                    "cpc",
                    "filing_date",
                    "application_number"
                ]
            },
            "patents-public-data.cpc": {
                "definition": [
                    "symbol",
                    "parents",
                    "titleFull",
                    "level"
                ]
            }
        }
    },
    "bq222": {
        "query": "CREATE TEMPORARY FUNCTION highest_moving_avg(yearcnt ARRAY<STRUCT<filing_year INT64, cnt INT64>>) RETURNS STRUCT<filing_year INT64, avg INT64> LANGUAGE js AS \"\"\" let a = 0.1; let avg = yearcnt.length > 0 ? yearcnt[0].cnt : 0; let highest = {filing_year: -1, avg: -1}; for (let x of yearcnt) {     avg = a * x.cnt + (1 - a) * avg;     if (avg > highest.avg) {         highest = {filing_year: x.filing_year, avg: avg};     } } return highest; \"\"\";      WITH patent_cpcs AS (     SELECT cd.parents,     CAST(FLOOR(filing_date/10000) AS INT64) AS filing_year     FROM (         SELECT ANY_VALUE(cpc) AS cpc, ANY_VALUE(filing_date) AS filing_date         FROM `patents-public-data.patents.publications`         WHERE application_number != \"\"         AND country_code = 'DE'         AND grant_date >= 20161201         AND grant_date <= 20161231         GROUP BY application_number), UNNEST(cpc) AS cpcs     JOIN `patents-public-data.cpc.definition` cd ON cd.symbol = cpcs.code     WHERE cpcs.first = TRUE AND filing_date > 0)  SELECT c.titleFull, cpc_group, best_year.filing_year FROM (     SELECT cpc_group, highest_moving_avg(ARRAY_AGG(STRUCT<filing_year INT64, cnt INT64>(filing_year, cnt) ORDER BY filing_year ASC)) AS best_year     FROM (         SELECT cpc_group, filing_year, COUNT(*) AS cnt         FROM (             SELECT cpc_parent AS cpc_group, filing_year             FROM patent_cpcs, UNNEST(parents) AS cpc_parent)         GROUP BY cpc_group, filing_year         ORDER BY filing_year DESC, cnt DESC)     GROUP BY cpc_group) JOIN `patents-public-data.cpc.definition` c ON cpc_group = c.symbol WHERE c.level = 4 ORDER BY titleFull, cpc_group ASC;",
        "schema": {
            "patents-public-data.patents": {
                "publications": [
                    "cpc",
                    "filing_date",
                    "application_number",
                    "country_code",
                    "grant_date"
                ]
            },
            "patents-public-data.cpc": {
                "definition": [
                    "symbol",
                    "parents",
                    "titleFull",
                    "level"
                ]
            }
        }
    },
    "bq223": {
        "query": "SELECT     citing_assignee,     cpcdef.titleFull as cpc_title FROM (     SELECT         pubs.publication_number AS citing_publication_number,         cite.publication_number AS cited_publication_number,         citing_assignee_s.name AS citing_assignee,         SUBSTR(cpcs.code, 0, 4) AS citing_cpc_subclass     FROM          `patents-public-data.patents.publications` AS pubs,         UNNEST(citation) AS cite,         UNNEST(assignee_harmonized) AS citing_assignee_s,         UNNEST(cpc) AS cpcs     WHERE         cpcs.first = TRUE     ) AS pubs     JOIN (         SELECT             publication_number AS cited_publication_number,             cited_assignee_s.name AS cited_assignee         FROM             `patents-public-data.patents.publications`,             UNNEST(assignee_harmonized) AS cited_assignee_s     ) AS refs     ON         pubs.cited_publication_number = refs.cited_publication_number     JOIN         `patents-public-data.cpc.definition` AS cpcdef     ON cpcdef.symbol = citing_cpc_subclass WHERE     cited_assignee = \"AAAA\"     AND citing_assignee != \"AAAA\" GROUP BY     citing_assignee, cpcdef.titleFull ORDER BY      COUNT(*) DESC LIMIT 1",
        "schema": {
            "patents-public-data.patents": {
                "publications": [
                    "publication_number",
                    "citation",
                    "assignee_harmonized",
                    "cpc"
                ]
            },
            "patents-public-data.cpc": {
                "definition": [
                    "symbol",
                    "titleFull"
                ]
            }
        }
    },
    "bq247": {
        "query": "WITH   family_list AS (     SELECT       family_id,       COUNT(publication_number) AS publication_number_count     FROM       `patents-public-data.patents.publications`     GROUP BY       family_id   ),   most_published_family AS (     SELECT       family_id     FROM       family_list     WHERE family_id != '-1'     ORDER BY       publication_number_count DESC     LIMIT 1   ),   publications_with_abstracts AS (     SELECT       p.family_id,       gpr.abstract     FROM       `patents-public-data.google_patents_research.publications` gpr     JOIN       `patents-public-data.patents.publications` p     ON       p.publication_number = gpr.publication_number     WHERE       gpr.abstract IS NOT NULL AND gpr.abstract != ''   ),   abstracts_from_top_family AS (     SELECT       fwa.abstract     FROM       publications_with_abstracts fwa     JOIN       most_published_family mpf     ON       fwa.family_id = mpf.family_id   ) SELECT   abstract FROM   abstracts_from_top_family;",
        "schema": {
            "patents-public-data.patents": {
                "publications": [
                    "family_id",
                    "publication_number"
                ]
            },
            "patents-public-data.google_patents_research": {
                "publications": [
                    "abstract",
                    "publication_number"
                ]
            }
        }
    },
    "bq246": {
        "query": "SELECT filterData.fwrdCitations_3 FROM   `patents-public-data.patentsview.application` as app,   (SELECT DISTINCT cpc.patent_id, IFNULL(citation_3.bkwdCitations_3, 0) as bkwdCitations_3, IFNULL(citation_3.fwrdCitations_3, 0) as fwrdCitations_3   FROM     `patents-public-data.patentsview.cpc_current` AS cpc     LEFT JOIN     (SELECT  b.patent_id, b.bkwdCitations_3, f.fwrdCitations_3       FROM          (SELECT            cited.patent_id,           COUNT(*) as fwrdCitations_3           FROM            `patents-public-data.patentsview.uspatentcitation` AS cited,           `patents-public-data.patentsview.application` AS apps         WHERE           apps.country = 'US'           AND cited.patent_id = apps.patent_id            AND cited.date >= apps.date AND SAFE_CAST(cited.date AS DATE) <= DATE_ADD(SAFE_CAST(apps.date AS DATE), INTERVAL 3 YEAR)          GROUP BY           cited.patent_id) AS f,         (SELECT            cited.patent_id,           COUNT(*) as bkwdCitations_3           FROM            `patents-public-data.patentsview.uspatentcitation` AS cited,           `patents-public-data.patentsview.application` AS apps         WHERE           apps.country = 'US'           AND cited.patent_id = apps.patent_id            AND cited.date < apps.date AND SAFE_CAST(cited.date AS DATE) >= DATE_SUB(SAFE_CAST(apps.date AS DATE), INTERVAL 3 YEAR)          GROUP BY           cited.patent_id) AS b       WHERE       b.patent_id = f.patent_id AND b.bkwdCitations_3 IS NOT NULL AND f.fwrdCitations_3 IS NOT NULL) AS citation_3       ON cpc.patent_id = citation_3.patent_id       )   as filterData   WHERE   app.patent_id = filterData.patent_id   ORDER BY filterData.bkwdCitations_3 DESC   LIMIT 1",
        "schema": {
            "patents-public-data.patentsview": {
                "application": [
                    "patent_id",
                    "country",
                    "date"
                ],
                "cpc_current": [
                    "patent_id"
                ],
                "uspatentcitation": [
                    "patent_id",
                    "date"
                ]
            }
        }
    },
    "bq052": {
        "query": "SELECT     app.patent_id as patent_id,     patent.title,     app.date as application_date,     filterData.bkwdCitations_1,     filterData.fwrdCitations_1,     summary.text as summary_text FROM     `patents-public-data.patentsview.brf_sum_text` as summary,     `patents-public-data.patentsview.patent` as patent,     `patents-public-data.patentsview.application` as app,     (         SELECT DISTINCT             cpc.patent_id,             IFNULL(citation_1.bkwdCitations_1, 0) as bkwdCitations_1,             IFNULL(citation_1.fwrdCitations_1, 0) as fwrdCitations_1         FROM             `patents-public-data.patentsview.cpc_current` AS cpc         JOIN         (             SELECT  b.patent_id, b.bkwdCitations_1, f.fwrdCitations_1             FROM (                 SELECT                      cited.patent_id,                     COUNT(*) as fwrdCitations_1                 FROM                      `patents-public-data.patentsview.uspatentcitation` AS cited,                     `patents-public-data.patentsview.application` AS apps                 WHERE                     apps.country = 'US'                     AND cited.patent_id = apps.patent_id                      AND cited.date >= apps.date                     AND SAFE_CAST(cited.date AS DATE) <= DATE_ADD(SAFE_CAST(apps.date AS DATE), INTERVAL 1 MONTH)                 GROUP BY                      cited.patent_id             ) AS f,             (                 SELECT                      cited.patent_id,                     COUNT(*) as bkwdCitations_1                 FROM                      `patents-public-data.patentsview.uspatentcitation` AS cited,                     `patents-public-data.patentsview.application` AS apps                 WHERE                     apps.country = 'US'                     AND cited.patent_id = apps.patent_id                      AND cited.date < apps.date AND SAFE_CAST(cited.date AS DATE) >= DATE_SUB(SAFE_CAST(apps.date AS DATE), INTERVAL 1 MONTH) -- get in one year interval                  GROUP BY                      cited.patent_id             ) AS b             WHERE                 b.patent_id = f.patent_id                 AND b.bkwdCitations_1 IS NOT NULL                 AND f.fwrdCitations_1 IS NOT NULL                 AND (b.bkwdCitations_1 > 0 OR f.fwrdCitations_1 > 0)         ) AS citation_1          ON cpc.patent_id=citation_1.patent_id         WHERE (             cpc.subsection_id = 'C05'             OR cpc.group_id = 'A01G'         )     ) as filterData WHERE     app.patent_id = filterData.patent_id     AND summary.patent_id = app.patent_id     AND app.patent_id = patent.id ORDER BY application_date;",
        "schema": {
            "patents-public-data.patentsview": {
                "brf_sum_text": [
                    "patent_id",
                    "text"
                ],
                "patent": [
                    "patent_id",
                    "title"
                ],
                "application": [
                    "patent_id",
                    "date",
                    "country"
                ],
                "cpc_current": [
                    "patent_id",
                    "subsection_id",
                    "group_id"
                ],
                "uspatentcitation": [
                    "patent_id",
                    "date"
                ]
            }
        }
    },
    "bq207": {
        "query": "WITH table_a AS(     SELECT          pat_no, claim_no, word_ct     FROM `patents-public-data.uspto_oce_claims.patent_claims_stats`      WHERE ind_flg='1' ), matched_publn AS(     SELECT         publication_number,         claim_no,         CAST(word_ct AS INT64) AS word_ct  -- Cast word_ct to INT64 if it's stored as a string     FROM table_a     INNER JOIN `patents-public-data.uspto_oce_claims.match` USING(pat_no) ), matched_appln AS(     SELECT         application_number appln_nr,         publication_number publn_nr,         claim_no,         word_ct     FROM matched_publn     INNER JOIN(         SELECT              publication_number, application_number, country_code,             ROW_NUMBER() OVER(PARTITION BY application_number ORDER BY publication_date ASC) row_num,             kind_code, publication_date         FROM `patents-public-data.patents.publications`     ) USING(publication_number)     WHERE row_num=1 )  SELECT * FROM matched_appln ORDER BY word_ct DESC LIMIT 100",
        "schema": {
            "patents-public-data.uspto_oce_claims": {
                "patent_claims_stats": [
                    "pat_no",
                    "claim_no",
                    "word_ct",
                    "ind_flg"
                ],
                "match": [
                    "publication_number",
                    "pat_no",
                    "claim_no",
                    "word_ct"
                ]
            },
            "patents-public-data.patents": {
                "publications": [
                    "publication_number",
                    "application_number",
                    "country_code",
                    "publication_date",
                    "kind_code"
                ]
            }
        }
    },
    "bq036": {
        "query": "WITH  CTERepoCommits AS (   SELECT     RName AS repo_name,     committer.date,     t1.COMMIT,     CONCAT(CAST(EXTRACT(YEAR FROM TIMESTAMP_SECONDS(committer.time_sec)) AS STRING), '-',             LPAD(CAST(EXTRACT(MONTH FROM TIMESTAMP_SECONDS(committer.time_sec)) AS STRING), 2, '0')) AS YearMonth   FROM `bigquery-public-data.github_repos.commits` t1   LEFT JOIN UNNEST(t1.repo_name) RName   WHERE EXTRACT(YEAR FROM TIMESTAMP_SECONDS(committer.time_sec)) = 2020 ), CTERepoLang AS (   SELECT     t2.repo_name,     l.name AS LangName   FROM `bigquery-public-data.github_repos.languages` t2   LEFT JOIN UNNEST(t2.LANGUAGE) AS l ) , MonthlyCommits AS (   SELECT     CTERepoCommits.YearMonth,     COUNT(*) AS CommitCnts   FROM CTERepoCommits   INNER JOIN CTERepoLang ON CTERepoCommits.repo_name = CTERepoLang.repo_name   WHERE CTERepoLang.LangName = 'Python'   GROUP BY CTERepoCommits.YearMonth   ORDER BY CTERepoCommits.YearMonth ) SELECT   AVG(CommitCnts) AS AvgMonthlyCommits FROM MonthlyCommits;",
        "schema": {
            "bigquery-public-data.github_repos": {
                "commits": [
                    "repo_name",
                    "committer.date",
                    "COMMIT",
                    "committer.time_sec"
                ],
                "languages": [
                    "repo_name",
                    "LANGUAGE"
                ]
            }
        }
    },
    "bq100": {
        "query": "WITH imports AS (   SELECT     id,     SPLIT(REGEXP_EXTRACT(content, r'import\\s*\\(([^)]*)\\)'), '\\n') AS lines   FROM     `bigquery-public-data.github_repos.sample_contents`   WHERE     REGEXP_CONTAINS(content, r'import\\s*\\([^)]*\\)') ), go_files AS (   SELECT     id   FROM     `bigquery-public-data.github_repos.sample_files`   WHERE     path LIKE '%.go'   GROUP BY     id ), filtered_imports AS (   SELECT     id,     line   FROM     imports, UNNEST(lines) AS line ), joined_data AS (   SELECT     fi.line   FROM     filtered_imports fi   JOIN     go_files gf   ON     fi.id = gf.id ) SELECT   REGEXP_EXTRACT(line, r'\"([^\"]+)\"') AS package FROM   joined_data GROUP BY   package HAVING   package IS NOT NULL ORDER BY   COUNT(*) DESC LIMIT   1;",
        "schema": {
            "bigquery-public-data.github_repos": {
                "sample_contents": [
                    "id",
                    "content"
                ],
                "sample_files": [
                    "id",
                    "path"
                ]
            }
        }
    },
    "bq101": {
        "query": "SELECT   package,   COUNT(*) count FROM (   SELECT     REGEXP_EXTRACT(line, r' ([a-z0-9\\._]*)\\.') AS package,     id   FROM (     SELECT       SPLIT(content, '\\n') AS lines,       id     FROM       `bigquery-public-data.github_repos.sample_contents`     WHERE       REGEXP_CONTAINS(content, r'import')       AND sample_path LIKE '%.java'   ), UNNEST(lines) AS line   WHERE     LEFT(line, 6) = 'import'   GROUP BY     package,     id ) GROUP BY   package ORDER BY   count DESC LIMIT   10;",
        "schema": {
            "bigquery-public-data.github_repos": {
                "sample_contents": [
                    "content",
                    "id",
                    "sample_path"
                ]
            }
        }
    },
    "bq182": {
        "query": "-- Some reformatting and such of GitHub queries.  SELECT language AS name, count FROM (   SELECT *   FROM (     SELECT       lang AS language,       y AS year,       q AS quarter,       type,       COUNT(*) AS count     FROM (       SELECT         a.type AS type,         b.lang AS lang,         a.y AS y,         a.q AS q       FROM (         SELECT           type,           EXTRACT(YEAR FROM created_at) AS y,           EXTRACT(QUARTER FROM created_at) AS q,           REGEXP_REPLACE(             repo.url,             r'https:\\/\\/github\\.com\\/|https:\\/\\/api\\.github\\.com\\/repos\\/',             ''           ) AS name         FROM `githubarchive.day.20230118`         -- If needed, you can uncomment and add more tables         -- , `githubarchive.day.20140118`       ) a       JOIN (         SELECT           repo_name AS name,           lang         FROM (           SELECT             repo_name,             FIRST_VALUE(language) OVER (               PARTITION BY repo_name ORDER BY bytes DESC             ) AS lang           FROM (             SELECT repo_name, language.name AS language, language.bytes             FROM `bigquery-public-data.github_repos.languages`,             UNNEST(language) AS language           )         )         WHERE lang IS NOT NULL         GROUP BY repo_name, lang       ) b       ON a.name = b.name     )     GROUP BY type, language, year, quarter     ORDER BY year, quarter, count DESC   )   WHERE count >= 100 ) WHERE type = 'PullRequestEvent';",
        "schema": {
            "githubarchive.day": {
                "20230118": [
                    "type",
                    "created_at",
                    "repo.url"
                ]
            },
            "bigquery-public-data.github_repos": {
                "languages": [
                    "repo_name",
                    "language.name",
                    "language.bytes"
                ]
            }
        }
    },
    "bq182_1": {
        "query": "SELECT COUNT(*) AS total_pull_requests FROM (   SELECT     a.type AS type,     b.language AS lang,     a.y AS y,     a.q AS q   FROM (     SELECT       type,       EXTRACT(YEAR FROM created_at) AS y,       EXTRACT(QUARTER FROM created_at) AS q,       REGEXP_REPLACE(         repo.url,         r'https:\\/\\/github\\.com\\/|https:\\/\\/api\\.github\\.com\\/repos\\/',         ''       ) AS name     FROM `githubarchive.day.20230118`     -- If needed, you can uncomment and add more tables     -- , `githubarchive.day.20140118`   ) a   JOIN (     SELECT       repo_name AS name,       language     FROM (       SELECT         repo_name,         language       FROM (         SELECT repo_name, language.name AS language, language.bytes         FROM `bigquery-public-data.github_repos.languages`,         UNNEST(language) AS language       )     )     WHERE language = 'JavaScript'     GROUP BY repo_name, language   ) b   ON a.name = b.name ) WHERE type = 'PullRequestEvent';",
        "schema": {
            "githubarchive.day": {
                "20230118": [
                    "type",
                    "created_at",
                    "repo.url"
                ]
            },
            "bigquery-public-data.github_repos": {
                "languages": [
                    "repo_name",
                    "language.name",
                    "language.bytes"
                ]
            }
        }
    },
    "bq191": {
        "query": "WITH repos as (   SELECT b.repo_with_watches as repo_name,          b.watches as watches   FROM (     SELECT DISTINCT repo_name AS repo_in_mirror     FROM `bigquery-public-data.github_repos.sample_files`    ) a RIGHT JOIN (     SELECT repo.name AS repo_with_watches, APPROX_COUNT_DISTINCT(actor.id) watches      FROM `githubarchive.year.2017`      WHERE type='WatchEvent'     GROUP BY 1      HAVING watches > 300   ) b   ON a.repo_in_mirror = b.repo_with_watches   WHERE     a.repo_in_mirror IS NOT NULL ), contents as (   SELECT *   FROM (     SELECT DISTINCT *     FROM `bigquery-public-data.github_repos.sample_files`      WHERE repo_name IN (SELECT repo_name FROM repos)   ) a RIGHT JOIN (     SELECT id as idcontent,            content as content     FROM `bigquery-public-data.github_repos.sample_contents`    ) b   ON a.id = b.idcontent  ) SELECT repos.repo_name,        repos.watches FROM repos JOIN   contents ON   repos.repo_name = contents.repo_name  WHERE   contents.content LIKE '%junit</artifactId>%'   AND contents.path LIKE 'pom.xml' ORDER BY   repos.watches DESC LIMIT 5",
        "schema": {
            "bigquery-public-data.github_repos": {
                "sample_files": [
                    "repo_name",
                    "id"
                ],
                "sample_contents": [
                    "idcontent",
                    "content",
                    "path"
                ]
            },
            "githubarchive.year": {
                "2017": [
                    "repo.name",
                    "actor.id",
                    "type"
                ]
            }
        }
    },
    "bq224": {
        "query": "WITH allowed_repos as (     select         repo_name,         license     from `bigquery-public-data.github_repos.licenses`     where license in unnest(       [\"gpl-3.0\", \"artistic-2.0\", \"isc\", \"cc0-1.0\", \"epl-1.0\", \"gpl-2.0\",        \"mpl-2.0\", \"lgpl-2.1\", \"bsd-2-clause\", \"apache-2.0\", \"mit\", \"lgpl-3.0\"]) ), watch_counts as (     SELECT          repo.name as repo,         COUNT(DISTINCT actor.login) watches,     FROM `githubarchive.month.202204`     WHERE type = \"WatchEvent\"     GROUP BY repo ), issue_counts as (     SELECT          repo.name as repo,         COUNT(*) issue_events,     FROM `githubarchive.month.202204`     WHERE type = 'IssuesEvent'     GROUP BY repo ), fork_counts as (     SELECT          repo.name as repo,         COUNT(*) forks,     FROM `githubarchive.month.202204`     WHERE type = 'ForkEvent'     GROUP BY repo ) SELECT repo_name FROM allowed_repos INNER JOIN fork_counts ON repo_name = fork_counts.repo INNER JOIN issue_counts on repo_name = issue_counts.repo INNER JOIN watch_counts ON repo_name = watch_counts.repo ORDER BY forks + issue_events + watches DESC LIMIT 1;",
        "schema": {
            "bigquery-public-data.github_repos": {
                "licenses": [
                    "repo_name",
                    "license"
                ]
            },
            "githubarchive.month": {
                "202204": [
                    "repo.name",
                    "actor.login",
                    "type"
                ]
            }
        }
    },
    "bq192": {
        "query": "WITH allowed_repos AS (     SELECT          repo_name,          license      FROM          `bigquery-public-data.github_repos.licenses`     WHERE          license IN UNNEST([\"artistic-2.0\", \"isc\", \"mit\", \"apache-2.0\"]) ), watch_counts AS (     SELECT          repo.name AS repo,         COUNT(DISTINCT actor.login) AS watches     FROM          `githubarchive.month.202204`     WHERE          type = \"WatchEvent\"     GROUP BY          repo ), issue_counts AS (     SELECT          repo.name AS repo,         COUNT(*) AS issue_events     FROM          `githubarchive.month.202204`     WHERE          type = 'IssuesEvent'     GROUP BY          repo ), fork_counts AS (     SELECT          repo.name AS repo,         COUNT(*) AS forks     FROM          `githubarchive.month.202204`     WHERE          type = 'ForkEvent'     GROUP BY          repo ), metadata AS (     SELECT          repo_name,          license,          forks,          issue_events,          watches     FROM          allowed_repos     INNER JOIN          fork_counts      ON          repo_name = fork_counts.repo     INNER JOIN          issue_counts      ON          repo_name = issue_counts.repo     INNER JOIN          watch_counts      ON          repo_name = watch_counts.repo ), github_files_at_head AS (     SELECT          repo_name     FROM          `bigquery-public-data.github_repos.sample_files`     WHERE          ref = \"refs/heads/master\"          AND ENDS_WITH(path, \".py\")         AND symlink_target IS NULL     GROUP BY          repo_name ) SELECT      metadata.repo_name AS repository FROM      metadata INNER JOIN      github_files_at_head ON      metadata.repo_name = github_files_at_head.repo_name ORDER BY      (metadata.forks + metadata.issue_events + metadata.watches) DESC LIMIT 1;",
        "schema": {
            "bigquery-public-data.github_repos": {
                "licenses": [
                    "repo_name",
                    "license"
                ],
                "sample_files": [
                    "repo_name",
                    "ref",
                    "path",
                    "symlink_target"
                ]
            },
            "githubarchive.month": {
                "202204": [
                    "repo.name",
                    "actor.login",
                    "type"
                ]
            }
        }
    },
    "bq225": {
        "query": "WITH languages AS (   SELECT     files.id,     CASE REGEXP_EXTRACT(files.path, r'(\\.?[^\\/\\.]*)$')       WHEN '.js'          THEN 'JavaScript'       WHEN '.cjs'         THEN 'JavaScript'       WHEN '.ts'          THEN 'TypeScript'       WHEN '.java'        THEN 'Java'       WHEN '.py'          THEN 'Python'       WHEN '.kt'          THEN 'Kotlin'       WHEN '.ktm'         THEN 'Kotlin'       WHEN '.kts'         THEN 'Kotlin'       WHEN '.c'           THEN 'C'       WHEN '.h'           THEN 'C'       WHEN '.c++'         THEN 'C++'       WHEN '.cpp'         THEN 'C++'       WHEN '.h++'         THEN 'C++'       WHEN '.hpp'         THEN 'C++'       WHEN '.cs'          THEN 'C#'       WHEN '.erl'         THEN 'Erlang'       WHEN '.ex'          THEN 'Elixir'       WHEN '.exs'         THEN 'Elixir'       WHEN '.hs'          THEN 'Haskell'       WHEN '.go'          THEN 'Go'       WHEN '.php'         THEN 'PHP'       WHEN '.rb'          THEN 'Ruby'       WHEN '.rs'          THEN 'Rust'       WHEN '.scala'       THEN 'Scala'       WHEN '.swift'       THEN 'Swift'       WHEN '.lisp'        THEN 'Common Lisp'       WHEN '.clj'         THEN 'Clojure'       WHEN '.r'           THEN 'R'       WHEN '.matlab'      THEN 'MATLAB'       WHEN '.m'           THEN 'MATLAB'       WHEN '.asm'         THEN 'Assembly'       WHEN '.nasm'        THEN 'Assembly'       WHEN '.d'           THEN 'D'       WHEN '.dart'        THEN 'Dart'       WHEN '.jl'          THEN 'Julia'       WHEN '.groovy'      THEN 'Groovy'       WHEN '.hx'          THEN 'Haxe'       WHEN '.lua'         THEN 'Lua'       WHEN '.sh'          THEN 'Shell'       WHEN '.bash'        THEN 'Shell'       WHEN '.ps1'         THEN 'PowerShell'       WHEN '.psd1'        THEN 'PowerShell'       WHEN '.psm1'        THEN 'PowerShell'       WHEN '.sql'         THEN 'SQL'       WHEN 'Dockerfile'   THEN 'Dockerfile'       WHEN '.dockerfile'  THEN 'Dockerfile'       WHEN '.md'          THEN 'Markdown'       WHEN '.markdown'    THEN 'Markdown'       WHEN '.mdown'       THEN 'Markdown'       WHEN '.html'        THEN 'HTML'       WHEN '.htm'         THEN 'HTML'       WHEN '.css'         THEN 'CSS'       WHEN '.sass'        THEN 'Sass'       WHEN '.scss'        THEN 'SCSS'       WHEN '.vue'         THEN 'Vue'       WHEN '.json'        THEN 'JSON'       WHEN '.yml'         THEN 'YAML'       WHEN '.yaml'        THEN 'YAML'       WHEN '.xml'         THEN 'XML'     END AS language   FROM     `bigquery-public-data.github_repos.sample_files` AS files )  SELECT   languages.language FROM   languages INNER JOIN   `bigquery-public-data.github_repos.sample_contents` AS contents ON   contents.id = languages.id WHERE   languages.language IS NOT NULL   AND contents.content IS NOT NULL GROUP BY languages.language ORDER BY COUNT(*) DESC LIMIT 3;",
        "schema": {
            "bigquery-public-data.github_repos": {
                "sample_files": [
                    "id",
                    "path"
                ],
                "sample_contents": [
                    "id",
                    "content"
                ]
            }
        }
    },
    "bq180": {
        "query": "SELECT module, COUNT(*) as occurrence_count FROM (   SELECT      file_id,      repo_name,      path,      line,      ARRAY_CONCAT(       IF(         ENDS_WITH(path, '.py'),         ARRAY_CONCAT(           REGEXP_EXTRACT_ALL(line, r'\\bimport\\s+(\\w+)'),            REGEXP_EXTRACT_ALL(line, r'\\bfrom\\s+(\\w+)')         ),         []       ),       IF(         ENDS_WITH(path, '.r'),         REGEXP_EXTRACT_ALL(line, r'library\\s*\\(\\s*([^\\s)]+)\\s*\\)'),         []       )     ) AS modules   FROM (     SELECT         ct.id AS file_id,          fl.repo_name,          path,          SPLIT(REPLACE(ct.content, \"\\n\", \" \\n\"), \"\\n\") AS lines     FROM `bigquery-public-data.github_repos.sample_files` AS fl     JOIN `bigquery-public-data.github_repos.sample_contents` AS ct ON fl.id = ct.id   ), UNNEST(lines) as line   WHERE     (ENDS_WITH(path, '.py') AND (REGEXP_CONTAINS(line, r'^import ') OR REGEXP_CONTAINS(line, r'^from '))) OR      (ENDS_WITH(path, '.r') AND REGEXP_CONTAINS(line, r'library\\s*\\(')) ), UNNEST(modules) as module GROUP BY module ORDER BY occurrence_count DESC LIMIT 3",
        "schema": {
            "bigquery-public-data.github_repos": {
                "sample_files": [
                    "id",
                    "repo_name"
                ],
                "sample_contents": [
                    "id",
                    "content"
                ]
            }
        }
    },
    "bq180_1": {
        "query": "WITH extracted_modules AS (   SELECT      file_id,      repo_name,      path,      line,      IF(       ENDS_WITH(path, '.py'),       'python',       IF(ENDS_WITH(path, '.r'), 'r', NULL)     ) AS language,     IF(       ENDS_WITH(path, '.py'),       ARRAY_CONCAT(         REGEXP_EXTRACT_ALL(line, r'\\bimport\\s+(\\w+)'),          REGEXP_EXTRACT_ALL(line, r'\\bfrom\\s+(\\w+)')       ),       IF(         ENDS_WITH(path, '.r'),         REGEXP_EXTRACT_ALL(line, r'library\\s*\\(\\s*([^\\s)]+)\\s*\\)'),         []       )     ) AS modules   FROM (     SELECT       ct.id AS file_id,        fl.repo_name,        path,        SPLIT(REPLACE(ct.content, \"\\n\", \" \\n\"), \"\\n\") AS lines     FROM `bigquery-public-data.github_repos.sample_files` AS fl     JOIN `bigquery-public-data.github_repos.sample_contents` AS ct ON fl.id = ct.id   ), UNNEST(lines) as line   WHERE     (ENDS_WITH(path, '.py') AND (REGEXP_CONTAINS(line, r'^import ') OR REGEXP_CONTAINS(line, r'^from '))) OR      (ENDS_WITH(path, '.r') AND REGEXP_CONTAINS(line, r'library\\s*\\(')) ), module_counts AS (   SELECT      language,     module,     COUNT(*) AS occurrence_count   FROM (     SELECT        language,       modules     FROM extracted_modules     WHERE modules IS NOT NULL   ),UNNEST(modules) AS module   GROUP BY language, module ), top5_python AS (   SELECT      'python' AS language,     module,     occurrence_count   FROM module_counts   WHERE language = 'python'   ORDER BY occurrence_count DESC   LIMIT 5 ), top5_r AS (   SELECT      'r' AS language,     module,     occurrence_count   FROM module_counts   WHERE language = 'r'   ORDER BY occurrence_count DESC   LIMIT 5 ) SELECT * FROM top5_python UNION ALL SELECT * FROM top5_r ORDER BY language, occurrence_count DESC;",
        "schema": {
            "bigquery-public-data.github_repos": {
                "sample_files": [
                    "id",
                    "repo_name",
                    "path",
                    "content"
                ],
                "sample_contents": [
                    "id",
                    "content"
                ]
            }
        }
    },
    "bq248": {
        "query": "WITH requests AS (     SELECT          D.id,         D.content,         E.repo_name,         E.path     FROM          (             SELECT                  id,                 content             FROM                  `bigquery-public-data.github_repos.sample_contents`             GROUP BY                  id,                 content         ) AS D         INNER JOIN          (             SELECT                  C.id,                 C.repo_name,                 C.path             FROM                  (                     SELECT                          id,                         repo_name,                         path                     FROM                          `bigquery-public-data.github_repos.sample_files`                     WHERE                          LOWER(path) LIKE '%requirements.txt'                     GROUP BY                          path,                         id,                         repo_name                 ) AS C             INNER JOIN                  (                     SELECT                          repo_name,                         language_struct.name AS language_name                     FROM                          `bigquery-public-data.github_repos.languages`,                         UNNEST(language) AS language_struct                     WHERE                          LOWER(language_struct.name) LIKE '%python%'                     GROUP BY                          language_name,                         repo_name                 ) AS F             ON                  C.repo_name = F.repo_name         ) AS E     ON          D.id = E.id ) SELECT (SELECT COUNT(*) FROM requests WHERE content LIKE '%requests%') / COUNT(*) AS proportion FROM requests",
        "schema": {
            "bigquery-public-data.github_repos": {
                "sample_contents": [
                    "id",
                    "content"
                ],
                "sample_files": [
                    "id",
                    "repo_name",
                    "path"
                ],
                "languages": [
                    "repo_name",
                    "language.name"
                ]
            }
        }
    },
    "bq193": {
        "query": "WITH content_extracted AS (     SELECT          D.id AS id,         repo_name,         path,         SPLIT(content, '\\n') AS lines     FROM          (             SELECT                  id,                 content             FROM                  `bigquery-public-data.github_repos.sample_contents`         ) AS D     INNER JOIN          (             SELECT                  id,                 C.repo_name AS repo_name,                 path             FROM                  (                     SELECT                          id,                         repo_name,                         path                     FROM                          `bigquery-public-data.github_repos.sample_files`                     WHERE                          LOWER(path) LIKE '%requirements.txt'                 ) AS C             INNER JOIN                  (                     SELECT                          repo_name,                         language_struct.name AS language_name                     FROM                          (                             SELECT                                  repo_name,                                  language                             FROM                                  `bigquery-public-data.github_repos.languages`                         )                     CROSS JOIN                          UNNEST(language) AS language_struct                     WHERE                          LOWER(language_struct.name) LIKE '%python%'                 ) AS F             ON                  C.repo_name = F.repo_name         ) AS E     ON          E.id = D.id ), non_empty_lines AS (     SELECT          line     FROM          content_extracted,         UNNEST(lines) AS line     WHERE          TRIM(line) != ''         AND NOT STARTS_WITH(TRIM(line), '#')         AND NOT STARTS_WITH(TRIM(line), '//') ), line_frequencies AS (     SELECT          line,         COUNT(*) AS frequency     FROM          non_empty_lines     GROUP BY          line     ORDER BY          frequency DESC ) SELECT      line FROM      line_frequencies LIMIT 5;",
        "schema": {
            "bigquery-public-data.github_repos": {
                "sample_contents": [
                    "id",
                    "content"
                ],
                "sample_files": [
                    "id",
                    "repo_name",
                    "path"
                ],
                "languages": [
                    "repo_name",
                    "language.name"
                ]
            }
        }
    },
    "bq249": {
        "query": "WITH   lines AS (   SELECT     SPLIT(content, '\\\\n') AS line,     id   FROM     `bigquery-public-data.github_repos.sample_contents`   WHERE     sample_path LIKE \"%.sql\" ) SELECT   Indentation,   COUNT(Indentation) AS number_of_occurence FROM (   SELECT     CASE         WHEN MIN(CHAR_LENGTH(REGEXP_EXTRACT(flatten_line, r\"\\s+$\")))>=1 THEN 'trailing'         WHEN MIN(CHAR_LENGTH(REGEXP_EXTRACT(flatten_line, r\"^ +\")))>=1 THEN 'Space'         ELSE 'Other'     END AS Indentation   FROM     lines   CROSS JOIN     UNNEST(lines.line) AS flatten_line   GROUP BY     id) GROUP BY   Indentation ORDER BY   number_of_occurence DESC",
        "schema": {
            "bigquery-public-data.github_repos": {
                "sample_contents": [
                    "content",
                    "id",
                    "sample_path"
                ]
            }
        }
    },
    "bq375": {
        "query": "WITH files_with_levels AS (   SELECT     files.path AS path,     LENGTH(files.path) - LENGTH(REPLACE(files.path, '/', '')) AS dir_level,     CASE       WHEN REGEXP_CONTAINS(files.path, r'\\.py$') THEN 'Python'       WHEN REGEXP_CONTAINS(files.path, r'\\.c$') THEN 'C'       WHEN REGEXP_CONTAINS(files.path, r'\\.ipynb$') THEN 'Jupyter Notebook'       WHEN REGEXP_CONTAINS(files.path, r'\\.java$') THEN 'Java'       WHEN REGEXP_CONTAINS(files.path, r'\\.js$') THEN 'JavaScript'       ELSE 'Other'     END AS file_type   FROM     `bigquery-public-data.github_repos.sample_files` AS files   WHERE     REGEXP_CONTAINS(files.path, r'\\.py$') OR     REGEXP_CONTAINS(files.path, r'\\.c$') OR     REGEXP_CONTAINS(files.path, r'\\.ipynb$') OR     REGEXP_CONTAINS(files.path, r'\\.java$') OR     REGEXP_CONTAINS(files.path, r'\\.js$') ) SELECT   file_type,   COUNT(*) AS file_count FROM   files_with_levels WHERE   dir_level > 10 GROUP BY   file_type ORDER BY   file_count DESC LIMIT 1;",
        "schema": {
            "bigquery-public-data.github_repos": {
                "sample_files": [
                    "path"
                ]
            }
        }
    },
    "bq255": {
        "query": "SELECT   COUNT(commits_table.message) AS num_messages FROM (   SELECT     repo_name,     lang.name AS language_name   FROM     `bigquery-public-data.github_repos.languages` AS lang_table,     UNNEST(LANGUAGE) AS lang) lang_table JOIN   `bigquery-public-data.github_repos.licenses` AS license_table ON   license_table.repo_name = lang_table.repo_name JOIN (   SELECT     *   FROM     `bigquery-public-data.github_repos.sample_commits`) commits_table ON   commits_table.repo_name = lang_table.repo_name WHERE     (license_table.license LIKE 'apache-2.0')   AND (lang_table.language_name LIKE 'Shell') AND   LENGTH(commits_table.message) > 5 AND    LENGTH(commits_table.message) < 10000 AND LOWER(commits_table.message) NOT LIKE 'update%' AND LOWER(commits_table.message) NOT LIKE 'test%' AND LOWER(commits_table.message) NOT LIKE 'merge%';",
        "schema": {
            "bigquery-public-data.github_repos": {
                "languages": [
                    "repo_name",
                    "LANGUAGE"
                ],
                "licenses": [
                    "repo_name",
                    "license"
                ],
                "sample_commits": [
                    "repo_name",
                    "message"
                ]
            }
        }
    },
    "bq194": {
        "query": "WITH extracted_modules AS (   SELECT     file_id, repo_name, path, line,     IF(       ENDS_WITH(path, '.py'),       'Python',       IF(         (           ENDS_WITH(path, '.r') OR           ENDS_WITH(path, '.R') OR           ENDS_WITH(path, '.Rmd') OR           ENDS_WITH(path, '.rmd')         ),         'R',         IF(           ENDS_WITH(path, '.ipynb'),           'IPython',           'Others'         )       )     ) AS script_type,     IF(       ENDS_WITH(path, '.py'),       IF(         REGEXP_CONTAINS(line, r'^\\s*import\\s+'),         REGEXP_EXTRACT_ALL(line, r'(?:^\\s*import\\s|,)\\s*([a-zA-Z0-9\\_\\.]+)'),         REGEXP_EXTRACT_ALL(line, r'^\\s*from\\s+([a-zA-Z0-9\\_\\.]+)')       ),       IF(         (           ENDS_WITH(path, '.r') OR           ENDS_WITH(path, '.R') OR           ENDS_WITH(path, '.Rmd') OR           ENDS_WITH(path, '.rmd')         ),         REGEXP_EXTRACT_ALL(line, r'library\\s*\\((?:package=|)[\\\"\\']*([a-zA-Z0-9\\_\\.]+)[\\\"\\']*.*?\\)'), -- we're still ignoring commented out imports         IF(           ENDS_WITH(path, '.ipynb'),           IF(             REGEXP_CONTAINS(line, r'\"\\s*import\\s+'),             REGEXP_EXTRACT_ALL(line, r'(?:\"\\s*import\\s|,)\\s*([a-zA-Z0-9\\_\\.]+)'),             REGEXP_EXTRACT_ALL(line, r'\"\\s*from\\s+([a-zA-Z0-9\\_\\.]+)')           ),           ['']         )       )     ) AS modules   FROM (     SELECT       ct.id AS file_id, repo_name, path,       # Add a space after each line.       # It is required to ensure correct line numbering.       SPLIT(REPLACE(content, \"\\n\", \" \\n\"), \"\\n\") AS lines     FROM `bigquery-public-data.github_repos.sample_files` AS fl     JOIN `bigquery-public-data.github_repos.sample_contents` AS ct ON fl.id = ct.id     WHERE       ENDS_WITH(path, '.py') OR       (         ENDS_WITH(path, '.r') OR         ENDS_WITH(path, '.R') OR         ENDS_WITH(path, '.Rmd') OR         ENDS_WITH(path, '.rmd')       ) OR       ENDS_WITH(path, '.ipynb')   ), UNNEST(lines) AS line   WHERE     (ENDS_WITH(path, '.py') AND (REGEXP_CONTAINS(line, r'^\\s*import\\s+') OR REGEXP_CONTAINS(line, r'^\\s*from .* import '))) OR     (       (         ENDS_WITH(path, '.r') OR         ENDS_WITH(path, '.R') OR         ENDS_WITH(path, '.Rmd') OR         ENDS_WITH(path, '.rmd')       ) AND REGEXP_CONTAINS(line, r'library\\s*\\(')     ) OR     (       ENDS_WITH(path, '.ipynb') AND       (         REGEXP_CONTAINS(line, r'\"\\s*import\\s+') OR         REGEXP_CONTAINS(line, r'\"\\s*from .* import ')       )     ) ), unnested_modules AS (   SELECT     file_id, repo_name, path, script_type, module   FROM extracted_modules,   UNNEST(modules) AS module ), module_frequencies AS (   SELECT     module,     script_type,     COUNT(*) AS frequency   FROM unnested_modules   GROUP BY module, script_type   ORDER BY frequency DESC )  SELECT   module FROM module_frequencies ORDER BY frequency DESC LIMIT 1 OFFSET 1;",
        "schema": {
            "bigquery-public-data.github_repos": {
                "sample_files": [
                    "id",
                    "repo_name",
                    "path",
                    "content"
                ],
                "sample_contents": [
                    "id",
                    "content"
                ]
            }
        }
    },
    "bq359": {
        "query": "WITH python_repo AS (     WITH         repositories AS (         SELECT         t2.repo_name,         t2.LANGUAGE         FROM (         SELECT             repo_name,             LANGUAGE,             RANK() OVER (PARTITION BY t1.repo_name ORDER BY t1.language_bytes DESC) AS rank         FROM (             SELECT             repo_name,             arr.name AS LANGUAGE,             arr.bytes AS language_bytes             FROM             `bigquery-public-data.github_repos.languages`,             UNNEST(LANGUAGE) arr ) AS t1 ) AS t2         WHERE         rank = 1)     SELECT         repo_name,         LANGUAGE     FROM         repositories     WHERE         LANGUAGE = 'Python'         ) SELECT Rname, COUNT(commit) AS num_commits FROM `bigquery-public-data.github_repos.commits` LEFT JOIN UNNEST(`bigquery-public-data.github_repos.commits`.repo_name) Rname INNER JOIN python_repo ON python_repo.repo_name = Rname GROUP BY Rname ORDER BY num_commits DESC LIMIT 5",
        "schema": {
            "bigquery-public-data.github_repos": {
                "languages": [
                    "repo_name",
                    "LANGUAGE",
                    "language_bytes"
                ],
                "commits": [
                    "repo_name",
                    "commit"
                ]
            }
        }
    },
    "bq251": {
        "query": "WITH PyPiData AS (     SELECT         name AS pypi_name,         version AS pypi_version,         home_page,         download_url,         project_urls,         requires,         upload_time     FROM         `spider2-public-data.pypi.distribution_metadata` ),  GitHubURLs AS (     SELECT         pypi_name,         pypi_version,         REGEXP_REPLACE(REGEXP_EXTRACT(url, r'(https?://github\\.com/[^/]+/[^/?#]+)'), r'(/issues.*)|(blob/.*)|(/pull/.*)|(tree/.*)', '') AS github_url,         upload_time     FROM         PyPiData,         UNNEST(project_urls) AS url     WHERE         url LIKE '%github.com%'         AND (url LIKE '%https://github.com/%' OR url LIKE '%http://github.com/%') ),  MostRecentVersions AS (     SELECT         pypi_name,         pypi_version,         github_url     FROM (         SELECT *,                ROW_NUMBER() OVER (PARTITION BY pypi_name ORDER BY upload_time DESC) AS rn         FROM GitHubURLs     )     WHERE rn = 1 ),  DownloadMetrics AS (     SELECT         project,         COUNT(*) AS pypi_downloads     FROM         `spider2-public-data.pypi.file_downloads`     GROUP BY         project )  SELECT     mv.github_url FROM     MostRecentVersions mv LEFT JOIN     DownloadMetrics dm ON mv.pypi_name = dm.project WHERE     mv.github_url IS NOT NULL      AND dm.pypi_downloads IS NOT NULL ORDER BY dm.pypi_downloads DESC LIMIT 1;",
        "schema": {
            "spider2-public-data.pypi": {
                "distribution_metadata": [
                    "name",
                    "version",
                    "home_page",
                    "download_url",
                    "project_urls",
                    "requires",
                    "upload_time"
                ],
                "file_downloads": [
                    "project"
                ]
            }
        }
    },
    "bq252": {
        "query": "WITH selected_repos as (   SELECT     f.id,     f.repo_name as repo_name,     f.path as path,   FROM     `bigquery-public-data.github_repos.sample_files` as f ),  deduped_files as (   SELECT     f.id,     MIN(f.repo_name) as repo_name,     MIN(f.path) as path,   FROM     selected_repos as f   GROUP BY     f.id )  SELECT   f.repo_name, FROM   deduped_files as f   JOIN `bigquery-public-data.github_repos.sample_contents` as c on f.id = c.id WHERE   NOT c.binary   AND f.path like '%.swift' ORDER BY c.copies DESC LIMIT 1;",
        "schema": {
            "bigquery-public-data.github_repos": {
                "sample_files": [
                    "id",
                    "repo_name",
                    "path"
                ],
                "sample_contents": [
                    "id",
                    "binary",
                    "copies"
                ]
            }
        }
    },
    "bq019": {
        "query": "WITH most_common_drg AS (   SELECT     drg_definition,     SUM(total_discharges) AS national_num_cases   FROM     `bigquery-public-data.cms_medicare.inpatient_charges_2014`   GROUP BY     drg_definition   ORDER BY     national_num_cases DESC   LIMIT     1 ), city_data AS (   SELECT     drg_definition,     provider_city,     provider_state,     SUM(total_discharges) AS citywise_num_cases,     SUM(average_total_payments * total_discharges) / SUM(total_discharges) AS citywise_avg_total_payments,     SUM(average_total_payments * total_discharges) AS citywise_sum_total_payments   FROM     `bigquery-public-data.cms_medicare.inpatient_charges_2014`   GROUP BY     drg_definition,     provider_city,     provider_state ), ranked_city_data AS (   SELECT     cd.drg_definition,     cd.provider_city,     cd.provider_state,     cd.citywise_avg_total_payments,     RANK() OVER (PARTITION BY cd.drg_definition ORDER BY cd.citywise_num_cases DESC) AS cityrank   FROM     city_data cd   WHERE     cd.drg_definition = (SELECT drg_definition FROM most_common_drg) ) SELECT   drg_definition AS Diagnosis,   provider_city AS City,   provider_state AS State,   cityrank AS City_Rank,   CAST(ROUND(citywise_avg_total_payments) AS INT64) AS Citywise_Avg_Payments, FROM   (SELECT     drg_definition,     provider_city,     provider_state,     cityrank,     citywise_avg_total_payments   FROM     ranked_city_data   WHERE     cityrank <= 3)  # Limit to top 3 cities for the most common diagnosis ORDER BY   cityrank;",
        "schema": {
            "bigquery-public-data.cms_medicare": {
                "inpatient_charges_2014": [
                    "drg_definition",
                    "total_discharges",
                    "provider_city",
                    "provider_state",
                    "average_total_payments"
                ]
            }
        }
    },
    "bq019_1": {
        "query": "SELECT   A.state,   drug_name,   -- total_claim_count,   -- day_supply,   -- ROUND(total_cost_millions) AS total_cost_millions FROM (   SELECT     generic_name AS drug_name,     nppes_provider_state AS state,     ROUND(SUM(total_claim_count)) AS total_claim_count,     ROUND(SUM(total_day_supply)) AS day_supply,     ROUND(SUM(total_drug_cost)) / 1e6 AS total_cost_millions   FROM     `bigquery-public-data.cms_medicare.part_d_prescriber_2014`   GROUP BY     state,     drug_name) A INNER JOIN (   SELECT     state,     MAX(total_claim_count) AS max_total_claim_count   FROM (     SELECT       nppes_provider_state AS state,       ROUND(SUM(total_claim_count)) AS total_claim_count     FROM       `bigquery-public-data.cms_medicare.part_d_prescriber_2014`     GROUP BY       state,       generic_name)   GROUP BY     state) B ON   A.state = B.state   AND A.total_claim_count = B.max_total_claim_count; -- ORDER BY --   A.total_claim_count DESC;",
        "schema": {
            "bigquery-public-data.cms_medicare": {
                "part_d_prescriber_2014": [
                    "generic_name",
                    "nppes_provider_state",
                    "total_claim_count",
                    "total_day_supply",
                    "total_drug_cost"
                ]
            }
        }
    },
    "bq019_2": {
        "query": "SELECT   Provider_Name FROM ( SELECT   OP.provider_state AS State,   OP.provider_city AS City,   OP.provider_id AS Provider_ID,   OP.provider_name AS Provider_Name,   ROUND(OP.average_OP_cost) AS Average_OP_Cost,   ROUND(IP.average_IP_cost) AS Average_IP_Cost,   ROUND(OP.average_OP_cost + IP.average_IP_cost) AS Combined_Average_Cost FROM (   SELECT     provider_state,     provider_city,     provider_id,     provider_name,     SUM(average_total_payments*outpatient_services)/SUM(outpatient_services) AS average_OP_cost   FROM     `bigquery-public-data.cms_medicare.outpatient_charges_2014`   GROUP BY     provider_state,     provider_city,     provider_id,     provider_name ) AS OP INNER JOIN (   SELECT     provider_state,     provider_city,     provider_id,     provider_name,     SUM(average_medicare_payments*total_discharges)/SUM(total_discharges) AS average_IP_cost   FROM     `bigquery-public-data.cms_medicare.inpatient_charges_2014`   GROUP BY     provider_state,     provider_city,     provider_id,     provider_name ) AS IP ON   OP.provider_id = IP.provider_id   AND OP.provider_state = IP.provider_state   AND OP.provider_city = IP.provider_city   AND OP.provider_name = IP.provider_name ORDER BY   combined_average_cost DESC LIMIT   1 );",
        "schema": {
            "bigquery-public-data.cms_medicare": {
                "outpatient_charges_2014": [
                    "provider_state",
                    "provider_city",
                    "provider_id",
                    "provider_name",
                    "average_total_payments",
                    "outpatient_services"
                ],
                "inpatient_charges_2014": [
                    "provider_state",
                    "provider_city",
                    "provider_id",
                    "provider_name",
                    "average_medicare_payments",
                    "total_discharges"
                ]
            }
        }
    },
    "bq172": {
        "query": "WITH ny_top_drug AS (   SELECT     generic_name AS drug_name,     ROUND(SUM(total_claim_count)) AS total_claim_count   FROM     `bigquery-public-data.cms_medicare.part_d_prescriber_2014`   WHERE     nppes_provider_state = 'NY'   GROUP BY     drug_name   ORDER BY     total_claim_count DESC   LIMIT 1 ), top_5_states AS (   SELECT     nppes_provider_state AS state,     ROUND(SUM(total_claim_count)) AS total_claim_count,     ROUND(SUM(total_drug_cost)) AS total_drug_cost   FROM     `bigquery-public-data.cms_medicare.part_d_prescriber_2014`   WHERE     generic_name = (SELECT drug_name FROM ny_top_drug)   GROUP BY     state   ORDER BY     total_claim_count DESC   LIMIT 5 ) SELECT   state,   total_claim_count,   total_drug_cost FROM   top_5_states;",
        "schema": {
            "bigquery-public-data.cms_medicare": {
                "part_d_prescriber_2014": [
                    "generic_name",
                    "total_claim_count",
                    "nppes_provider_state",
                    "total_drug_cost"
                ]
            }
        }
    },
    "bq172_1": {
        "query": "WITH total_ip_cost AS (   SELECT     provider_id,     SUM(average_medicare_payments * total_discharges) AS total_ip_cost   FROM (     SELECT * FROM `bigquery-public-data.cms_medicare.inpatient_charges_2011`     UNION ALL     SELECT * FROM `bigquery-public-data.cms_medicare.inpatient_charges_2012`     UNION ALL     SELECT * FROM `bigquery-public-data.cms_medicare.inpatient_charges_2013`     UNION ALL     SELECT * FROM `bigquery-public-data.cms_medicare.inpatient_charges_2014`     UNION ALL     SELECT * FROM `bigquery-public-data.cms_medicare.inpatient_charges_2015`   )   GROUP BY     provider_id   ORDER BY     total_ip_cost DESC   LIMIT 1 ), provider_id_with_highest_ip_cost AS (   SELECT provider_id FROM total_ip_cost )  -- Step 2: Retrieve the annual inpatient and outpatient costs for the identified provider from 2011-2015 SELECT   ip.provider_name AS Provider_Name,   IP.year,   ROUND(ip.average_ip_cost) AS Average_IP_Cost,   ROUND(op.average_op_cost) AS Average_OP_Cost FROM (   SELECT     provider_id,     provider_state,     provider_city,     provider_name,     _TABLE_SUFFIX AS year,     AVG(average_medicare_payments * total_discharges) AS average_ip_cost   FROM     `bigquery-public-data.cms_medicare.inpatient_charges_*`   WHERE     provider_id IN (SELECT provider_id FROM provider_id_with_highest_ip_cost)   GROUP BY     provider_id,     provider_state,     provider_city,     provider_name,     year ) AS ip LEFT JOIN (   SELECT     provider_id,     provider_state,     provider_city,     provider_name,     _TABLE_SUFFIX AS year,     AVG(average_total_payments * outpatient_services) AS average_op_cost   FROM     `bigquery-public-data.cms_medicare.outpatient_charges_*`   WHERE      provider_id IN (SELECT provider_id FROM provider_id_with_highest_ip_cost)   GROUP BY     provider_id,     provider_state,     provider_city,     provider_name,     year ) AS op ON   ip.provider_id = op.provider_id   AND ip.provider_state = op.provider_state   AND ip.provider_city = op.provider_city   AND ip.provider_name = op.provider_name   AND ip.year = op.year ORDER BY   year;",
        "schema": {
            "bigquery-public-data.cms_medicare": {
                "inpatient_charges_2011": [
                    "provider_id",
                    "average_medicare_payments",
                    "total_discharges"
                ],
                "inpatient_charges_2012": [
                    "provider_id",
                    "average_medicare_payments",
                    "total_discharges"
                ],
                "inpatient_charges_2013": [
                    "provider_id",
                    "average_medicare_payments",
                    "total_discharges"
                ],
                "inpatient_charges_2014": [
                    "provider_id",
                    "average_medicare_payments",
                    "total_discharges"
                ],
                "inpatient_charges_2015": [
                    "provider_id",
                    "average_medicare_payments",
                    "total_discharges"
                ],
                "inpatient_charges_*": [
                    "provider_id",
                    "provider_state",
                    "provider_city",
                    "provider_name",
                    "_TABLE_SUFFIX",
                    "average_medicare_payments",
                    "total_discharges"
                ],
                "outpatient_charges_*": [
                    "provider_id",
                    "provider_state",
                    "provider_city",
                    "provider_name",
                    "_TABLE_SUFFIX",
                    "average_total_payments",
                    "outpatient_services"
                ]
            }
        }
    },
    "bq032": {
        "query": "WITH hurricane_geometry AS (   SELECT     * EXCEPT (longitude, latitude),     ST_GEOGPOINT(longitude, latitude) AS geom,     MAX(usa_wind) OVER (PARTITION BY sid) AS max_wnd_speed   FROM     `bigquery-public-data.noaa_hurricanes.hurricanes`   WHERE     season = '2020'     AND basin = 'NA'     AND name != 'NOT NAMED' ), dist_between_points AS (   SELECT     sid,     name,     season,     iso_time,     max_wnd_speed,     geom,     ST_DISTANCE(geom, LAG(geom, 1) OVER (PARTITION BY sid ORDER BY iso_time ASC)) / 1000 AS dist   FROM     hurricane_geometry ), total_distances AS (   SELECT     sid,     name,     season,     iso_time,     max_wnd_speed,     geom,     SUM(dist) OVER (PARTITION BY sid ORDER BY iso_time ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_distance,     SUM(dist) OVER (PARTITION BY sid) AS total_dist   FROM     dist_between_points ), ranked_hurricanes AS (   SELECT     *,     DENSE_RANK() OVER (ORDER BY total_dist DESC) AS dense_rank   FROM     total_distances )  SELECT   ST_Y(geom) FROM   ranked_hurricanes WHERE   dense_rank = 2 ORDER BY cumulative_distance DESC LIMIT 1 ;",
        "schema": {
            "bigquery-public-data.noaa_hurricanes": {
                "hurricanes": [
                    "longitude",
                    "latitude",
                    "sid",
                    "usa_wind",
                    "season",
                    "basin",
                    "name",
                    "iso_time"
                ]
            }
        }
    },
    "bq032_1": {
        "query": "WITH hurricane_geometry AS (   SELECT     * EXCEPT (longitude, latitude),     ST_GEOGPOINT(longitude, latitude) AS geom,   FROM     `bigquery-public-data.noaa_hurricanes.hurricanes`   WHERE     season = '2020'     AND basin = 'NA'     AND name != 'NOT NAMED' ), dist_between_points AS (   SELECT     sid,     name,     season,     iso_time,     usa_wind,     geom,     ST_DISTANCE(geom, LAG(geom, 1) OVER (PARTITION BY sid ORDER BY iso_time ASC)) / 1000 AS dist   FROM     hurricane_geometry ), total_distances AS (   SELECT     sid,     name,     season,     iso_time,     usa_wind,     geom,     SUM(dist) OVER (PARTITION BY sid ORDER BY iso_time ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_distance,     SUM(dist) OVER (PARTITION BY sid) AS total_dist   FROM     dist_between_points ), ranked_hurricanes AS (   SELECT     *,     DENSE_RANK() OVER (ORDER BY total_dist DESC) AS dense_rank   FROM     total_distances )  SELECT   geom,cumulative_distance,usa_wind FROM   ranked_hurricanes WHERE   dense_rank = 3 ORDER BY cumulative_distance;",
        "schema": {
            "bigquery-public-data.noaa_hurricanes": {
                "hurricanes": [
                    "longitude",
                    "latitude",
                    "geom",
                    "sid",
                    "name",
                    "season",
                    "iso_time",
                    "usa_wind"
                ]
            }
        }
    },
    "bq117": {
        "query": "WITH base_info AS (   SELECT     episode_id,      CONCAT(CAST(EXTRACT(MONTH FROM MIN(event_begin_time)) AS STRING), \"-\", CAST(EXTRACT(year FROM MIN(event_begin_time)) AS STRING)) as episode_month,     EXTRACT(MONTH FROM MIN(event_begin_time)) AS month,     STRING_AGG(DISTINCT(cz_name) LIMIT 5) as counties,      STRING_AGG(DISTINCT(state)) as states,      STRING_AGG(DISTINCT(event_type) LIMIT 5) as event_types,     SUM(damage_property)/1000000000 as damage_property_in_billions   FROM     `bigquery-public-data.noaa_historic_severe_storms.storms_*`   WHERE     _TABLE_SUFFIX BETWEEN CAST((EXTRACT(YEAR from CURRENT_DATE())-15) AS STRING) AND CAST(EXTRACT(YEAR from CURRENT_DATE()) AS STRING)   GROUP BY     episode_id   ORDER BY     damage_property_in_billions desc   LIMIT 100 )  SELECT COUNT(*) AS month_count FROM base_info GROUP BY month ORDER BY month_count DESC LIMIT 1",
        "schema": {
            "bigquery-public-data.noaa_historic_severe_storms": {
                "storms_*": [
                    "episode_id",
                    "event_begin_time",
                    "cz_name",
                    "state",
                    "event_type",
                    "damage_property"
                ]
            }
        }
    },
    "bq071": {
        "query": "SELECT   z.city as city   ,z.zip_code as zip_code   ,z.state_name as state   ,COUNT(DISTINCT(h.name)) as count_hurricanes   ,STRING_AGG(DISTINCT(h.name)) as hurricanes --  ,CONCAT(CAST(latitude as STRING), \",\" , CAST(longitude as STRING)) as position FROM    `bigquery-public-data.geo_us_boundaries.zip_codes` as z   ,`bigquery-public-data.noaa_hurricanes.hurricanes` as h WHERE   ST_WITHIN(ST_GeogPoint(h.longitude,h.latitude), z.zip_code_geom)   AND h.name != \"NOT_NAMED\" GROUP BY    zip_code   ,city   ,state   --  ,position ORDER BY   count_hurricanes desc LIMIT 10",
        "schema": {
            "bigquery-public-data.geo_us_boundaries": {
                "zip_codes": [
                    "city",
                    "zip_code",
                    "state_name",
                    "zip_code_geom"
                ]
            },
            "bigquery-public-data.noaa_hurricanes": {
                "hurricanes": [
                    "name",
                    "longitude",
                    "latitude"
                ]
            }
        }
    },
    "bq117_1": {
        "query": "SELECT   CONCAT(city,\", \", state_name) as city,   zip_code,   COUNT(event_id) as count_storms FROM   `bigquery-public-data.noaa_historic_severe_storms.storms_*`,   `bigquery-public-data.geo_us_boundaries.zip_codes`  WHERE   _TABLE_SUFFIX BETWEEN CAST((EXTRACT(YEAR from CURRENT_DATE())-10) AS STRING) AND CAST(EXTRACT(YEAR from CURRENT_DATE()) AS STRING) AND   LOWER(event_type) = 'hail' AND   ST_WITHIN(event_point, zip_code_geom)    GROUP BY   event_type,   zip_code,    city ORDER BY   count_storms desc LIMIT 5",
        "schema": {
            "bigquery-public-data.noaa_historic_severe_storms": {
                "storms_*": [
                    "city",
                    "state_name",
                    "event_id",
                    "event_type",
                    "event_point"
                ]
            },
            "bigquery-public-data.geo_us_boundaries": {
                "zip_codes": [
                    "zip_code",
                    "zip_code_geom"
                ]
            }
        }
    },
    "bq356": {
        "query": "# Subquery to count # of dates w/ valid temperature data by station WITH Num2019TempDatesByStation AS (     SELECT     daily_weather.stn,      # Count # of distinct dates w/ temperature data for each station     COUNT(DISTINCT         # Convert year/month/day info into date         DATE(         CAST(daily_weather.year AS INT64),         CAST(daily_weather.mo AS INT64),         CAST(daily_weather.da AS INT64)         )) AS num_2019_temp_dates      FROM     bigquery-public-data.noaa_gsod.gsod2019 daily_weather      WHERE     daily_weather.temp IS NOT NULL AND     daily_weather.max IS NOT NULL AND     daily_weather.min IS NOT NULL AND     # Remove days w/ missing temps coded as 9999.9     daily_weather.temp != 9999.9 AND     daily_weather.max != 9999.9 AND     daily_weather.min != 9999.9      GROUP BY     daily_weather.stn ),  # Calculate max number of 2019 temperature dates across all stations MaxNum2019TempDates AS (     SELECT     MAX(num_2019_temp_dates) AS max_num_2019_temp_dates      FROM     Num2019TempDatesByStation )  SELECT     COUNT(*) FROM     bigquery-public-data.noaa_gsod.stations Stations  # Inner join to filter to only stations present in 2019 data INNER JOIN     Num2019TempDatesByStation ON (     stations.usaf = Num2019TempDatesByStation.stn     )  # Cross join to get max number on each row, to use in filtering below CROSS JOIN     MaxNum2019TempDates  WHERE     # Filter to stations that have had tracking since at least 1/1/2000     Stations.begin <= '20000101' AND     # Filter to stations that have had tracking through at least 6/30/2019     Stations.end >= '20190630' AND     # Filter to stations w/ >= 90% of the max number of dates for 2019     Num2019TempDatesByStation.num_2019_temp_dates >=     (0.90 * MaxNum2019TempDates.max_num_2019_temp_dates)",
        "schema": {
            "bigquery-public-data.noaa_gsod": {
                "gsod2019": [
                    "stn",
                    "year",
                    "mo",
                    "da",
                    "temp",
                    "max",
                    "min"
                ],
                "stations": [
                    "usaf",
                    "begin",
                    "end"
                ]
            }
        }
    },
    "bq357": {
        "query": "WITH DailyAverages AS (     SELECT          year, month, day, latitude, longitude,         AVG(wind_speed) AS avg_wind_speed,     FROM          `bigquery-public-data.noaa_icoads.icoads_core_*`     WHERE         _TABLE_SUFFIX BETWEEN '2005' AND '2015'     GROUP BY          year, month, day, latitude, longitude ) SELECT      year, month, day, latitude, longitude,     avg_wind_speed,  FROM      DailyAverages WHERE     avg_wind_speed IS NOT NULL  ORDER BY avg_wind_speed DESC LIMIT 5",
        "schema": {
            "bigquery-public-data.noaa_icoads": {
                "icoads_core_*": [
                    "year",
                    "month",
                    "day",
                    "latitude",
                    "longitude",
                    "wind_speed",
                    "_TABLE_SUFFIX"
                ]
            }
        }
    },
    "bq181": {
        "query": "WITH  Num2022TempDatesByStation AS (   SELECT     daily_weather.stn,     COUNT(DISTINCT DATE(       CAST(daily_weather.year AS INT64),       CAST(daily_weather.mo AS INT64),       CAST(daily_weather.da AS INT64)     )) AS num_2022_temp_dates   FROM     `bigquery-public-data.noaa_gsod.gsod2022` daily_weather   WHERE     daily_weather.temp IS NOT NULL     AND daily_weather.max IS NOT NULL     AND daily_weather.min IS NOT NULL     AND daily_weather.temp != 9999.9     AND daily_weather.max != 9999.9     AND daily_weather.min != 9999.9   GROUP BY     daily_weather.stn ),  TotalStations AS (   SELECT     COUNT(*) AS total_stations   FROM     `bigquery-public-data.noaa_gsod.stations` Stations   WHERE     Stations.usaf != '999999' ),  StationsWith90PercentCoverage AS (   SELECT     COUNT(*) AS stations_with_90_percent_coverage   FROM     Num2022TempDatesByStation   WHERE     num_2022_temp_dates >= 0.90 * 365 )  SELECT   (stations_with_90_percent_coverage / total_stations) * 100 AS percentage_of_stations_with_90_percent_coverage FROM   TotalStations,   StationsWith90PercentCoverage",
        "schema": {
            "bigquery-public-data.noaa_gsod": {
                "gsod2022": [
                    "stn",
                    "year",
                    "mo",
                    "da",
                    "temp",
                    "max",
                    "min"
                ],
                "stations": [
                    "usaf"
                ]
            }
        }
    },
    "bq045": {
        "query": "WITH WashingtonStations2023 AS      (         SELECT              weather.stn AS station_id,             ANY_VALUE(station.name) AS name         FROM             `bigquery-public-data.noaa_gsod.stations` AS station         INNER JOIN             `bigquery-public-data.noaa_gsod.gsod2023` AS weather         ON             station.usaf = weather.stn         WHERE             station.state = 'WA'              AND              station.usaf != '999999'         GROUP BY             station_id     ), prcp2023 AS ( SELECT     washington_stations.name,     (         SELECT              COUNT(*)         FROM             `bigquery-public-data.noaa_gsod.gsod2023` AS weather         WHERE             washington_stations.station_id = weather.stn             AND             prcp > 0             AND             prcp !=99.99     )     AS rainy_days FROM      WashingtonStations2023 AS washington_stations ORDER BY     rainy_days DESC ), WashingtonStations2022 AS      (         SELECT              weather.stn AS station_id,             ANY_VALUE(station.name) AS name         FROM             `bigquery-public-data.noaa_gsod.stations` AS station         INNER JOIN             `bigquery-public-data.noaa_gsod.gsod2022` AS weather         ON             station.usaf = weather.stn         WHERE             station.state = 'WA'              AND              station.usaf != '999999'         GROUP BY             station_id     ), prcp2022 AS ( SELECT     washington_stations.name,     (         SELECT              COUNT(*)         FROM             `bigquery-public-data.noaa_gsod.gsod2022` AS weather         WHERE             washington_stations.station_id = weather.stn             AND             prcp > 0             AND             prcp != 99.99     )     AS rainy_days FROM      WashingtonStations2022 AS washington_stations ORDER BY     rainy_days DESC )  SELECT prcp2023.name FROM prcp2023 JOIN prcp2022 on prcp2023.name = prcp2022.name WHERE prcp2023.rainy_days > 150 AND prcp2023.rainy_days < prcp2022.rainy_days",
        "schema": {
            "bigquery-public-data.noaa_gsod": {
                "gsod2022": [
                    "stn",
                    "prcp"
                ],
                "gsod2023": [
                    "stn",
                    "prcp"
                ],
                "stations": [
                    "usaf",
                    "state",
                    "name"
                ]
            }
        }
    },
    "bq290": {
        "query": "with   stations_selected as (   select     usaf,     wban,     country,     name   from     `bigquery-public-data.noaa_gsod.stations`   where     country in ('US', 'UK') ),  data_filtered as (   select     gsod.*,     stations.country   from     `bigquery-public-data.noaa_gsod.gsod2023` gsod   join     stations_selected stations   on     gsod.stn = stations.usaf     and gsod.wban = stations.wban   where     date(gsod.date) between '2023-10-01' and '2023-10-31'     and gsod.temp != 9999.9 ),  -- US Metrics us_metrics as (   select     date(date) as metric_date,     avg(temp) as avg_temp_us,     min(temp) as min_temp_us,     max(temp) as max_temp_us   from     data_filtered   where     country = 'US'   group by     metric_date ),  -- UK Metrics uk_metrics as (   select     date(date) as metric_date,     avg(temp) as avg_temp_uk,     min(temp) as min_temp_uk,     max(temp) as max_temp_uk   from     data_filtered   where     country = 'UK'   group by     metric_date ),  -- Temperature Differences temp_differences as (   select     us.metric_date,     us.max_temp_us - uk.max_temp_uk as max_temp_diff,     us.min_temp_us - uk.min_temp_uk as min_temp_diff,     us.avg_temp_us - uk.avg_temp_uk as avg_temp_diff   from     us_metrics us   join     uk_metrics uk   on     us.metric_date = uk.metric_date )  select    metric_date,    max_temp_diff,    min_temp_diff,    avg_temp_diff from    temp_differences order by   metric_date;",
        "schema": {
            "bigquery-public-data.noaa_gsod": {
                "stations": [
                    "usaf",
                    "wban",
                    "country",
                    "name"
                ],
                "gsod2023": [
                    "stn",
                    "wban",
                    "date",
                    "temp"
                ]
            }
        }
    },
    "bq031": {
        "query": "WITH transrate AS (     SELECT         DATE(CAST(year AS INT64), CAST(mo AS INT64), CAST(da AS INT64)) AS observation_date         , ROUND((temp - 32.0) / 1.8, 1) AS temp_mean_c -- using Celsius instead of Fahrenheit         , ROUND(prcp * 2.54, 1) AS prcp_cm -- from inches to centimeters         , ROUND(CAST(wdsp AS FLOAT64) * 1.852 / 3.6, 1) AS wdsp_ms -- from knots to meters per second     FROM `bigquery-public-data.noaa_gsod.gsod*`     WHERE _TABLE_SUFFIX = \"2019\"         AND CAST(mo AS INT64) <= 3         AND stn in (SELECT usaf FROM `bigquery-public-data.noaa_gsod.stations` WHERE name = \"ROCHESTER\") ),  moving_avg AS (     SELECT         observation_date         , temp_mean_c         , prcp_cm         , wdsp_ms         , AVG(temp_mean_c) OVER (ORDER BY observation_date ROWS 7 PRECEDING) AS temp_moving_avg         , AVG(prcp_cm) OVER (ORDER BY observation_date ROWS 7 PRECEDING) AS prcp_moving_avg         , AVG(wdsp_ms) OVER (ORDER BY observation_date ROWS 7 PRECEDING) AS wdsp_moving_avg     FROM transrate ),  lag_moving_avg AS (     SELECT         observation_date         , temp_mean_c         , prcp_cm         , wdsp_ms         , LAG(temp_moving_avg, 1) OVER (ORDER BY observation_date) AS lag1_temp_moving_avg         , LAG(prcp_moving_avg, 1) OVER (ORDER BY observation_date) AS lag1_prcp_moving_avg         , LAG(wdsp_moving_avg, 1) OVER (ORDER BY observation_date) AS lag1_wdsp_moving_avg          , LAG(temp_moving_avg, 2) OVER (ORDER BY observation_date) AS lag2_temp_moving_avg         , LAG(prcp_moving_avg, 2) OVER (ORDER BY observation_date) AS lag2_prcp_moving_avg         , LAG(wdsp_moving_avg, 2) OVER (ORDER BY observation_date) AS lag2_wdsp_moving_avg          , LAG(temp_moving_avg, 3) OVER (ORDER BY observation_date) AS lag3_temp_moving_avg         , LAG(prcp_moving_avg, 3) OVER (ORDER BY observation_date) AS lag3_prcp_moving_avg         , LAG(wdsp_moving_avg, 3) OVER (ORDER BY observation_date) AS lag3_wdsp_moving_avg          , LAG(temp_moving_avg, 4) OVER (ORDER BY observation_date) AS lag4_temp_moving_avg         , LAG(prcp_moving_avg, 4) OVER (ORDER BY observation_date) AS lag4_prcp_moving_avg         , LAG(wdsp_moving_avg, 4) OVER (ORDER BY observation_date) AS lag4_wdsp_moving_avg          , LAG(temp_moving_avg, 5) OVER (ORDER BY observation_date) AS lag5_temp_moving_avg         , LAG(prcp_moving_avg, 5) OVER (ORDER BY observation_date) AS lag5_prcp_moving_avg         , LAG(wdsp_moving_avg, 5) OVER (ORDER BY observation_date) AS lag5_wdsp_moving_avg          , LAG(temp_moving_avg, 6) OVER (ORDER BY observation_date) AS lag6_temp_moving_avg         , LAG(prcp_moving_avg, 6) OVER (ORDER BY observation_date) AS lag6_prcp_moving_avg         , LAG(wdsp_moving_avg, 6) OVER (ORDER BY observation_date) AS lag6_wdsp_moving_avg          , LAG(temp_moving_avg, 7) OVER (ORDER BY observation_date) AS lag7_temp_moving_avg         , LAG(prcp_moving_avg, 7) OVER (ORDER BY observation_date) AS lag7_prcp_moving_avg         , LAG(wdsp_moving_avg, 7) OVER (ORDER BY observation_date) AS lag7_wdsp_moving_avg          , LAG(temp_moving_avg, 8) OVER (ORDER BY observation_date) AS lag8_temp_moving_avg         , LAG(prcp_moving_avg, 8) OVER (ORDER BY observation_date) AS lag8_prcp_moving_avg         , LAG(wdsp_moving_avg, 8) OVER (ORDER BY observation_date) AS lag8_wdsp_moving_avg     FROM moving_avg )  SELECT     observation_date     , temp_mean_c     , prcp_cm     , wdsp_ms      , ROUND(lag1_temp_moving_avg, 1) AS lag1_temp_moving_avg     , ROUND(lag1_prcp_moving_avg, 1) AS lag1_prcp_moving_avg     , ROUND(lag1_wdsp_moving_avg, 1) AS lag1_wdsp_moving_avg          , ROUND(lag1_temp_moving_avg - lag2_temp_moving_avg, 1) AS diff2_temp_moving_avg     , ROUND(lag1_prcp_moving_avg - lag2_prcp_moving_avg, 1) AS diff2_prcp_moving_avg     , ROUND(lag1_wdsp_moving_avg - lag2_wdsp_moving_avg, 1) AS diff2_wdsp_moving_avg     , ROUND(lag2_temp_moving_avg, 1) AS lag2_temp_moving_avg     , ROUND(lag2_prcp_moving_avg, 1) AS lag2_prcp_moving_avg     , ROUND(lag2_wdsp_moving_avg, 1) AS lag2_wdsp_moving_avg          , ROUND(lag2_temp_moving_avg - lag3_temp_moving_avg, 1) AS diff3_temp_moving_avg     , ROUND(lag2_prcp_moving_avg - lag3_prcp_moving_avg, 1) AS diff3_prcp_moving_avg     , ROUND(lag2_wdsp_moving_avg - lag3_wdsp_moving_avg, 1) AS diff3_wdsp_moving_avg     , ROUND(lag3_temp_moving_avg, 1) AS lag3_temp_moving_avg     , ROUND(lag3_prcp_moving_avg, 1) AS lag3_prcp_moving_avg     , ROUND(lag3_wdsp_moving_avg, 1) AS lag3_wdsp_moving_avg          , ROUND(lag3_temp_moving_avg - lag4_temp_moving_avg, 1) AS diff4_temp_moving_avg     , ROUND(lag3_prcp_moving_avg - lag4_prcp_moving_avg, 1) AS diff4_prcp_moving_avg     , ROUND(lag3_wdsp_moving_avg - lag4_wdsp_moving_avg, 1) AS diff4_wdsp_moving_avg     , ROUND(lag4_temp_moving_avg, 1) AS lag4_temp_moving_avg     , ROUND(lag4_prcp_moving_avg, 1) AS lag4_prcp_moving_avg     , ROUND(lag4_wdsp_moving_avg, 1) AS lag4_wdsp_moving_avg          , ROUND(lag4_temp_moving_avg - lag5_temp_moving_avg, 1) AS diff5_temp_moving_avg     , ROUND(lag4_prcp_moving_avg - lag5_prcp_moving_avg, 1) AS diff5_prcp_moving_avg     , ROUND(lag4_wdsp_moving_avg - lag5_wdsp_moving_avg, 1) AS diff5_wdsp_moving_avg     , ROUND(lag5_temp_moving_avg, 1) AS lag5_temp_moving_avg     , ROUND(lag5_prcp_moving_avg, 1) AS lag5_prcp_moving_avg     , ROUND(lag5_wdsp_moving_avg, 1) AS lag5_wdsp_moving_avg          , ROUND(lag5_temp_moving_avg - lag6_temp_moving_avg, 1) AS diff6_temp_moving_avg     , ROUND(lag5_prcp_moving_avg - lag6_prcp_moving_avg, 1) AS diff6_prcp_moving_avg     , ROUND(lag5_wdsp_moving_avg - lag6_wdsp_moving_avg, 1) AS diff6_wdsp_moving_avg     , ROUND(lag6_temp_moving_avg, 1) AS lag6_temp_moving_avg     , ROUND(lag6_prcp_moving_avg, 1) AS lag6_prcp_moving_avg     , ROUND(lag6_wdsp_moving_avg, 1) AS lag6_wdsp_moving_avg          , ROUND(lag6_temp_moving_avg - lag7_temp_moving_avg, 1) AS diff7_temp_moving_avg     , ROUND(lag6_prcp_moving_avg - lag7_prcp_moving_avg, 1) AS diff7_prcp_moving_avg     , ROUND(lag6_wdsp_moving_avg - lag7_wdsp_moving_avg, 1) AS diff7_wdsp_moving_avg     , ROUND(lag7_temp_moving_avg, 1) AS lag7_temp_moving_avg     , ROUND(lag7_prcp_moving_avg, 1) AS lag7_prcp_moving_avg     , ROUND(lag7_wdsp_moving_avg, 1) AS lag7_wdsp_moving_avg          , ROUND(lag7_temp_moving_avg - lag8_temp_moving_avg, 1) AS diff8_temp_moving_avg     , ROUND(lag7_prcp_moving_avg - lag8_prcp_moving_avg, 1) AS diff8_prcp_moving_avg     , ROUND(lag7_wdsp_moving_avg - lag8_wdsp_moving_avg, 1) AS diff8_wdsp_moving_avg     , ROUND(lag8_temp_moving_avg, 1) AS lag8_temp_moving_avg     , ROUND(lag8_prcp_moving_avg, 1) AS lag8_prcp_moving_avg     , ROUND(lag8_wdsp_moving_avg, 1) AS lag8_wdsp_moving_avg FROM lag_moving_avg WHERE   lag8_temp_moving_avg IS NOT NULL ORDER BY observation_date; -- all result rounded to 1 decimal place",
        "schema": {
            "bigquery-public-data.noaa_gsod": {
                "gsod*": [
                    "year",
                    "mo",
                    "da",
                    "temp",
                    "prcp",
                    "wdsp",
                    "stn",
                    "_TABLE_SUFFIX"
                ],
                "stations": [
                    "usaf",
                    "name"
                ]
            }
        }
    },
    "bq050": {
        "query": "WITH data AS (     SELECT         ZIPSTARTNAME.borough AS borough_start,         ZIPSTARTNAME.neighborhood AS neighborhood_start,         ZIPENDNAME.borough AS borough_end,         ZIPENDNAME.neighborhood AS neighborhood_end, -- different combinations of start and end neighborhoods         CAST(TRI.tripduration / 60 AS NUMERIC) AS trip_minutes,         WEA.temp AS temperature,         CAST(WEA.wdsp AS NUMERIC) AS wind_speed,         WEA.prcp AS precipitation, -- weather conditoins         EXTRACT(month FROM DATE(TRI.starttime)) AS start_month     FROM         `bigquery-public-data.new_york_citibike.citibike_trips` AS TRI     INNER JOIN         `bigquery-public-data.geo_us_boundaries.zip_codes` ZIPSTART         ON ST_WITHIN(             ST_GEOGPOINT(TRI.start_station_longitude, TRI.start_station_latitude),             ZIPSTART.zip_code_geom)     INNER JOIN         `bigquery-public-data.geo_us_boundaries.zip_codes` ZIPEND         ON ST_WITHIN(             ST_GEOGPOINT(TRI.end_station_longitude, TRI.end_station_latitude),             ZIPEND.zip_code_geom)     INNER JOIN         `bigquery-public-data.noaa_gsod.gsod2014` AS WEA         ON PARSE_DATE(\"%Y%m%d\", CONCAT(WEA.year, WEA.mo, WEA.da)) = DATE(TRI.starttime)     INNER JOIN         `spider2-public-data.cyclistic.zip_codes` AS ZIPSTARTNAME         ON ZIPSTART.zip_code = CAST(ZIPSTARTNAME.zip AS STRING)     INNER JOIN         `spider2-public-data.cyclistic.zip_codes` AS ZIPENDNAME         ON ZIPEND.zip_code = CAST(ZIPENDNAME.zip AS STRING)     WHERE         -- get the weather data for New York Central Park station         WEA.wban = (             SELECT wban              FROM `bigquery-public-data.noaa_gsod.stations`             WHERE                 state = 'NY'                 AND LOWER(name) LIKE LOWER('%New York Central Park%')             LIMIT 1         )         AND EXTRACT(YEAR FROM DATE(TRI.starttime)) = 2014 ), agg_data AS (     SELECT         borough_start,         neighborhood_start,         borough_end,         neighborhood_end,         COUNT(*) AS num_trips,         ROUND(AVG(trip_minutes), 1) AS avg_trip_minutes,         ROUND(AVG(temperature), 1) AS avg_temperature,         ROUND(AVG(wind_speed), 1) AS avg_wind_speed,         ROUND(AVG(precipitation), 1) AS avg_precipitation     FROM data     GROUP BY 1, 2, 3, 4 ), most_common_months AS (     SELECT         borough_start,         neighborhood_start,         borough_end,         neighborhood_end,         start_month,         ROW_NUMBER() OVER (PARTITION BY borough_start, neighborhood_start, borough_end, neighborhood_end ORDER BY COUNT(*) DESC) AS row_num     FROM data     GROUP BY 1, 2, 3, 4, 5 ) SELECT     a.*,     m.start_month AS most_common_month FROM     agg_data a JOIN     most_common_months m ON     a.borough_start = m.borough_start AND     a.neighborhood_start = m.neighborhood_start AND     a.borough_end = m.borough_end AND     a.neighborhood_end = m.neighborhood_end AND     m.row_num = 1 ORDER BY a.neighborhood_start, a.neighborhood_end",
        "schema": {
            "bigquery-public-data.new_york_citibike": {
                "citibike_trips": [
                    "tripduration",
                    "starttime",
                    "start_station_longitude",
                    "start_station_latitude",
                    "end_station_longitude",
                    "end_station_latitude"
                ]
            },
            "bigquery-public-data.geo_us_boundaries": {
                "zip_codes": [
                    "zip_code",
                    "zip_code_geom"
                ]
            },
            "bigquery-public-data.noaa_gsod": {
                "gsod2014": [
                    "year",
                    "mo",
                    "da",
                    "temp",
                    "wdsp",
                    "prcp",
                    "wban"
                ],
                "stations": [
                    "wban",
                    "state",
                    "name"
                ]
            },
            "spider2-public-data.cyclistic": {
                "zip_codes": [
                    "zip",
                    "borough",
                    "neighborhood"
                ]
            }
        }
    },
    "bq291": {
        "query": "WITH daily_forecasts AS (   SELECT     creation_time,     DATE(DATETIME_ADD(forecast.time, INTERVAL 1 HOUR)) AS local_forecast_date,     MAX(IF(forecast.temperature_2m_above_ground IS NOT NULL, forecast.temperature_2m_above_ground, NULL)) AS max_temp,     MIN(IF(forecast.temperature_2m_above_ground IS NOT NULL, forecast.temperature_2m_above_ground, NULL)) AS min_temp,     AVG(IF(forecast.temperature_2m_above_ground IS NOT NULL, forecast.temperature_2m_above_ground, NULL)) AS avg_temp,     SUM(IF(forecast.total_precipitation_surface IS NOT NULL, forecast.total_precipitation_surface, 0)) AS total_precipitation,     AVG(IF(TIME(DATETIME_ADD(forecast.time, INTERVAL 1 HOUR)) BETWEEN '10:00:00' AND '17:00:00' AND forecast.total_cloud_cover_entire_atmosphere IS NOT NULL, forecast.total_cloud_cover_entire_atmosphere, NULL)) AS avg_cloud_cover,     CASE       WHEN AVG(forecast.temperature_2m_above_ground) < 32 THEN SUM(IF(forecast.total_precipitation_surface IS NOT NULL, forecast.total_precipitation_surface, 0))       ELSE 0     END AS total_snow,     CASE       WHEN AVG(forecast.temperature_2m_above_ground) >= 32 THEN SUM(IF(forecast.total_precipitation_surface IS NOT NULL, forecast.total_precipitation_surface, 0))       ELSE 0     END AS total_rain   FROM     `spider2-public-data.noaa_global_forecast_system.NOAA_GFS0P25`,     UNNEST(forecast) AS forecast   WHERE     creation_time BETWEEN '2021-11-28 00:00:00' AND '2021-11-29 00:00:00'     AND ST_DWithin(geography, ST_GeogPoint(17.5, 23.25), 5000)     AND DATE(forecast.time) = DATE_ADD(DATE(creation_time), INTERVAL 1 DAY)   GROUP BY     creation_time,     local_forecast_date ) SELECT   creation_time,   local_forecast_date AS forecast_date,   max_temp,   min_temp,   avg_temp,   total_precipitation,   avg_cloud_cover,   total_snow,   total_rain FROM   daily_forecasts ORDER BY   creation_time,   local_forecast_date",
        "schema": {
            "spider2-public-data.noaa_global_forecast_system": {
                "NOAA_GFS0P25": [
                    "creation_time",
                    "forecast.time",
                    "forecast.temperature_2m_above_ground",
                    "forecast.total_precipitation_surface",
                    "forecast.total_cloud_cover_entire_atmosphere",
                    "geography"
                ]
            }
        }
    },
    "bq208": {
        "query": "with my_location as (   SELECT  ST_GEOGPOINT(-73.764, 41.197) as my_location,           'Chappaqua' as home ), stations as (   SELECT *, ST_GEOGPOINT(lon,lat) as latlon_geo   FROM `bigquery-public-data.noaa_gsod.stations`  ), get_closest as (   SELECT home,my_location, st.*,    FROM (     SELECT ST_ASTEXT(my_location) as my_location,             home,            ARRAY_AGG( # get the closest station               STRUCT(usaf,wban,name,lon,lat,country,state,                     ST_DISTANCE(my_location, b.latlon_geo)*0.00062137 as miles)            ) as stations     FROM my_location a, stations b     WHERE ST_DWITHIN(my_location, b.latlon_geo, 32187)  --meters = 20 miles     GROUP BY my_location, home   ), UNNEST(stations) as st )  -- Thanks to Felipe Hoffa - https://stackoverflow.com/a/53678307/11748236 -- get count of data points from closest stations for 2011-2020 SELECT COUNT(temp) as Data_Points FROM get_closest gc, `bigquery-public-data.noaa_gsod.gsod20*` gs WHERE max != 9999.9 # code for missing data AND   _TABLE_SUFFIX BETWEEN '11' AND '20' AND   gc.usaf = gs.stn AND   gc.wban = gs.wban GROUP BY home, my_location, usaf, gc.wban, name, lon, lat, country, state, miles ORDER BY miles ASC",
        "schema": {
            "bigquery-public-data.noaa_gsod": {
                "stations": [
                    "usaf",
                    "wban",
                    "name",
                    "lon",
                    "lat",
                    "country",
                    "state"
                ],
                "gsod20*": [
                    "temp",
                    "max",
                    "stn",
                    "wban",
                    "_TABLE_SUFFIX"
                ]
            }
        }
    },
    "bq017": {
        "query": "WITH bounding_area AS (   SELECT geometry    FROM `bigquery-public-data.geo_openstreetmap.planet_features`   WHERE feature_type = \"multipolygons\"     AND ('wikidata', 'Q17') IN (       SELECT (key, value)        FROM unnest(all_tags)     ) ),  highway_info AS (   SELECT      SUM(ST_LENGTH(planet_features.geometry)) AS highway_length,     format(\"%'d\", CAST(SUM(ST_LENGTH(planet_features.geometry)) AS INT64)) AS highway_length_formatted,     count(*) AS highway_count,     (       SELECT value        FROM unnest(all_tags)        WHERE key = 'highway'     ) AS highway_type  -- Extract value of \"highway\" tag   FROM      `bigquery-public-data.geo_openstreetmap.planet_features` planet_features,      bounding_area   WHERE      feature_type = 'lines'     AND 'highway' IN (       SELECT key        FROM UNNEST(all_tags)     ) -- Select highways     AND ST_DWithin(bounding_area.geometry, planet_features.geometry, 0)  -- Filter only features within bounding_area   GROUP BY      highway_type )  SELECT    highway_type FROM   highway_info ORDER BY    highway_length DESC LIMIT 5",
        "schema": {
            "bigquery-public-data.geo_openstreetmap": {
                "planet_features": [
                    "geometry",
                    "feature_type",
                    "all_tags.key",
                    "all_tags.value"
                ]
            }
        }
    },
    "bq131": {
        "query": "WITH bounding_area AS (   SELECT geometry   FROM `bigquery-public-data.geo_openstreetmap.planet_features`   WHERE feature_type = \"multipolygons\"     AND ('wikidata', 'Q62') IN (       SELECT (key, value)       FROM unnest(all_tags)     ) ),  INFO AS (   SELECT      COUNT(*) AS stops_count,     (       SELECT value        FROM unnest(all_tags)        WHERE key = 'network'     ) AS bus_network  -- Extract value of \"network\" tag   FROM      `bigquery-public-data.geo_openstreetmap.planet_features` planet_features,     bounding_area   WHERE      feature_type = 'points'     AND ('highway', 'bus_stop') IN (       SELECT (key, value)       FROM UNNEST(all_tags)     ) -- Select bus stops     AND ST_DWithin(bounding_area.geometry, planet_features.geometry, 0)  -- Filter only features within bounding_area   GROUP BY      bus_network   ORDER BY      stops_count DESC  )  SELECT stops_count FROM INFO ORDER BY    stops_count DESC  LIMIT 1",
        "schema": {
            "bigquery-public-data.geo_openstreetmap": {
                "planet_features": [
                    "geometry",
                    "feature_type",
                    "all_tags.key",
                    "all_tags.value"
                ]
            }
        }
    },
    "bq106": {
        "query": "WITH boundary AS (     SELECT         layer_class,         layer_name,         all_tags,         geometry     FROM         `bigquery-public-data.geo_openstreetmap.planet_layers` AS layers     WHERE         TRUE         AND layer_class = 'boundary'         AND layer_name = 'national'         AND EXISTS (             SELECT 1             FROM layers.all_tags             WHERE                 key = 'ISO3166-1'                 AND value IN ('SD')                 -- for country Sudan         ) ), cells AS (     SELECT         gfs.*     FROM         boundary,         `spider2-public-data.noaa_global_forecast_system.NOAA_GFS0P25` AS gfs     WHERE         creation_time = '2021-11-28T00:00:00'         AND ST_WITHIN(gfs.geography,             boundary.geometry) ), pred1 AS (     SELECT         creation_time,         time,         AVG(temperature_2m_above_ground) AS temp     FROM         cells     JOIN         UNNEST(forecast) AS forecast     WHERE         MOD(hours, 24) = 0         AND hours / 24 <= 14         AND temperature_2m_above_ground IS NOT NULL     GROUP BY         creation_time,         time ), observed AS (     SELECT         pred1.creation_time AS prediction_made,         pred1.time AS predicted_time,         gfs.creation_time AS observed_time,         pred1.temp AS predicted_temp,         AVG(forecast.temperature_2m_above_ground) AS observed_temp     FROM         pred1,         boundary,         `spider2-public-data.noaa_global_forecast_system.NOAA_GFS0P25` AS gfs     JOIN         UNNEST(forecast) AS forecast     WHERE         gfs.creation_time = pred1.time         AND ST_WITHIN(gfs.geography,             boundary.geometry)     GROUP BY         prediction_made,         predicted_time,         observed_time,         predicted_temp ) SELECT     observed_time,     observed_temp - predicted_temp AS prediction_error FROM     observed ORDER BY     observed_time ASC",
        "schema": {
            "bigquery-public-data.geo_openstreetmap": {
                "planet_layers": [
                    "layer_class",
                    "layer_name",
                    "all_tags",
                    "geometry"
                ]
            },
            "spider2-public-data.noaa_global_forecast_system": {
                "NOAA_GFS0P25": [
                    "geography",
                    "creation_time",
                    "temperature_2m_above_ground",
                    "hours"
                ]
            }
        }
    },
    "bq293": {
        "query": "WITH base_data AS (     SELECT          nyc_taxi.*,          gis.* EXCEPT (zip_code_geom)     FROM (         SELECT *          FROM `bigquery-public-data.new_york.tlc_yellow_trips_2015`         WHERE DATE(pickup_datetime) = '2015-01-01'             AND pickup_latitude <= 90              AND pickup_latitude >= -90     ) AS nyc_taxi     JOIN (         SELECT              zip_code,              state_code,              state_name,              city,              county,              zip_code_geom          FROM `bigquery-public-data.geo_us_boundaries.zip_codes`         WHERE state_code = 'NY'     ) AS gis      ON ST_CONTAINS(zip_code_geom, ST_GEOGPOINT(pickup_longitude, pickup_latitude)) ), distinct_datetime AS (     SELECT DISTINCT          DATETIME_TRUNC(pickup_datetime, hour) AS pickup_hour     FROM base_data ), distinct_zip_code AS (     SELECT DISTINCT zip_code      FROM base_data ), zip_code_datetime_join AS (     SELECT          *,         EXTRACT(MONTH FROM pickup_hour) AS month,         EXTRACT(DAY FROM pickup_hour) AS day,         CAST(FORMAT_DATETIME('%u', pickup_hour) AS INT64) - 1 AS weekday,         EXTRACT(HOUR FROM pickup_hour) AS hour,         CASE              WHEN CAST(FORMAT_DATETIME('%u', pickup_hour) AS INT64) IN (6, 7) THEN 1              ELSE 0          END AS is_weekend     FROM distinct_zip_code     CROSS JOIN distinct_datetime ), agg_data AS (     SELECT          zip_code,         DATETIME_TRUNC(pickup_datetime, hour) AS pickup_hour,         COUNT(*) AS cnt     FROM base_data     GROUP BY zip_code, pickup_hour ), join_output AS (     SELECT          zip_code_datetime.*,          IFNULL(agg_data.cnt, 0) AS cnt     FROM zip_code_datetime_join AS zip_code_datetime     LEFT JOIN agg_data      ON zip_code_datetime.zip_code = agg_data.zip_code          AND zip_code_datetime.pickup_hour = agg_data.pickup_hour ), final_output AS (     SELECT          *,         LAG(cnt, 1) OVER (PARTITION BY zip_code ORDER BY pickup_hour) AS lag_1h_cnt,         LAG(cnt, 24) OVER (PARTITION BY zip_code ORDER BY pickup_hour) AS lag_1d_cnt,         LAG(cnt, 168) OVER (PARTITION BY zip_code ORDER BY pickup_hour) AS lag_7d_cnt,         LAG(cnt, 336) OVER (PARTITION BY zip_code ORDER BY pickup_hour) AS lag_14d_cnt,         ROUND(AVG(cnt) OVER (PARTITION BY zip_code ORDER BY pickup_hour ROWS BETWEEN 168 PRECEDING AND 1 PRECEDING), 2) AS avg_14d_cnt,         ROUND(AVG(cnt) OVER (PARTITION BY zip_code ORDER BY pickup_hour ROWS BETWEEN 336 PRECEDING AND 1 PRECEDING), 2) AS avg_21d_cnt,         CAST(STDDEV(cnt) OVER (PARTITION BY zip_code ORDER BY pickup_hour ROWS BETWEEN 168 PRECEDING AND 1 PRECEDING) AS INT64) AS std_14d_cnt,         CAST(STDDEV(cnt) OVER (PARTITION BY zip_code ORDER BY pickup_hour ROWS BETWEEN 336 PRECEDING AND 1 PRECEDING) AS INT64) AS std_21d_cnt     FROM join_output ) SELECT * FROM final_output ORDER BY cnt DESC LIMIT 5;",
        "schema": {
            "bigquery-public-data.new_york": {
                "tlc_yellow_trips_2015": [
                    "pickup_datetime",
                    "pickup_longitude",
                    "pickup_latitude"
                ]
            },
            "bigquery-public-data.geo_us_boundaries": {
                "zip_codes": [
                    "zip_code",
                    "state_code",
                    "zip_code_geom"
                ]
            }
        }
    },
    "bq056": {
        "query": "DECLARE var_State            STRING DEFAULT 'MN'; DECLARE var_RoadType        STRING DEFAULT 'motorway';  with t_state_geo as (     select State          , state_geom as StateGeography       from `bigquery-public-data.geo_us_boundaries.states`      where LOWER(State) = LOWER(var_State) ) , t_roads as (     select distinct Id as WayId       from `bigquery-public-data.geo_openstreetmap.planet_ways` pw, pw.all_tags as tag      where LOWER(tag.Key) = 'highway'        and LOWER(tag.Value) = var_RoadType ) , t_state_ways as (     select pw.Id       as WayId          , pw.geometry as WayGeography          , pw.Nodes    as WayNodes       from `bigquery-public-data.geo_openstreetmap.planet_ways` pw       join t_state_geo ts         on ST_CONTAINS(ts.StateGeography, pw.geometry)       join t_roads tr         on pw.Id = tr.WayId ) , t_touching_ways as (     select    LEAST(t1.WayId, t2.WayId) as WayId          , GREATEST(t1.WayId, t2.WayId) as TouchingWayId          , t1.WayNodes, t2.WayNodes as TouchingWayNodes       from t_state_ways t1       join t_state_ways t2         on ST_INTERSECTS(t1.WayGeography, t2.WayGeography)      where not t1.WayId = t2.WayId ) , t_sharing_nodes as (     select distinct WayId, TouchingWayId       from t_touching_ways t, t.WayNodes as WayNode      where WayNode in UNNEST(TouchingWayNodes) ) , t_overlapping_ways as (     select distinct WayId, TouchingWayId       from t_touching_ways tt       left join t_sharing_nodes ts      using (WayId, TouchingWayId)      where ts.WayId is NULL ) , t_with_metadata as (     select WayId, TouchingWayId          , pw1.all_tags as WayTags          , pw2.all_tags as TouchingWayTags          , pw1.geometry as WayGeography          , pw2.geometry as TouchingWayGeography       from t_overlapping_ways tw       join `bigquery-public-data.geo_openstreetmap.planet_ways` pw1         on tw.WayId = pw1.Id       join `bigquery-public-data.geo_openstreetmap.planet_ways` pw2         on tw.TouchingWayId = pw2.Id ) , t_has_bridge_tag as (     select distinct WayId, TouchingWayId       from t_with_metadata t, t.WayTags as WayTag, t.TouchingWayTags as TouchingWayTag      where (LOWER(TouchingWayTag.key) = 'bridge' and LOWER(TouchingWayTag.value) = 'yes')         or (LOWER(WayTag.key) = 'bridge' and LOWER(WayTag.value) = 'yes') ) , filtered_results as (     select WayId, TouchingWayId     from t_with_metadata tm     left join t_has_bridge_tag tb     using (WayId, TouchingWayId)     where tb.WayId is NULL ) SELECT COUNT(*) AS num_overlapping_ways FROM filtered_results;",
        "schema": {
            "bigquery-public-data.geo_us_boundaries": {
                "states": [
                    "State",
                    "state_geom"
                ]
            },
            "bigquery-public-data.geo_openstreetmap": {
                "planet_ways": [
                    "Id",
                    "geometry",
                    "Nodes",
                    "all_tags.Key",
                    "all_tags.Value"
                ]
            }
        }
    },
    "bq253": {
        "query": "WITH bounding_area AS (     SELECT geometry FROM `bigquery-public-data.geo_openstreetmap.planet_features`     WHERE feature_type=\"multipolygons\"     AND ('wikidata', 'Q218') IN (SELECT (key, value) FROM unnest(all_tags)) ), relations_wo_wikidata as (     SELECT planet_relations.id, (SELECT value FROM unnest(planet_relations.all_tags) where key = 'name') as name, m.id as member_id     FROM `bigquery-public-data.geo_openstreetmap.planet_relations` as planet_relations,       planet_relations.members as m,       bounding_area     WHERE 'wikidata' NOT IN (SELECT key FROM UNNEST(all_tags))     AND ST_DWithin(bounding_area.geometry, planet_relations.geometry, 0) ), bounding_area_features AS (     SELECT * FROM `bigquery-public-data.geo_openstreetmap.planet_features` as planet_features, bounding_area     WHERE ST_DWithin(bounding_area.geometry, planet_features.geometry, 0) ) SELECT relations_wo_wikidata.name FROM relations_wo_wikidata  JOIN bounding_area_features as planet_features  ON relations_wo_wikidata.member_id = planet_features.osm_id WHERE 'wikidata' IN  (SELECT key FROM UNNEST(all_tags))  AND relations_wo_wikidata.name IS NOT NULL GROUP BY id, name ORDER BY COUNT(planet_features.osm_id) DESC LIMIT 1;",
        "schema": {
            "bigquery-public-data.geo_openstreetmap": {
                "planet_features": [
                    "geometry",
                    "feature_type",
                    "all_tags",
                    "osm_id"
                ],
                "planet_relations": [
                    "id",
                    "all_tags",
                    "members",
                    "geometry"
                ]
            }
        }
    },
    "bq254": {
        "query": "WITH bounding_area AS (     SELECT geometry FROM `bigquery-public-data.geo_openstreetmap.planet_features`     WHERE feature_type=\"multipolygons\"     AND ('wikidata', 'Q218') IN (SELECT (key, value) FROM unnest(all_tags)) ), bounding_area_features AS (     SELECT planet_features.osm_id, planet_features.feature_type, planet_features.geometry, planet_features.all_tags FROM `bigquery-public-data.geo_openstreetmap.planet_features` as planet_features, bounding_area     WHERE ST_DWithin(bounding_area.geometry, planet_features.geometry, 0) ), polygons_wo_wikidata as (     SELECT planet_multipolygons.osm_id as id, (SELECT value FROM unnest(planet_multipolygons.all_tags) where key = 'name') as name, planet_multipolygons.geometry as geometry     FROM bounding_area_features as planet_multipolygons,       bounding_area     WHERE feature_type = 'multipolygons'     AND osm_id IS NOT NULL     AND 'wikidata' NOT IN (SELECT key FROM UNNEST(all_tags))     AND ST_DWithin(bounding_area.geometry, planet_multipolygons.geometry, 0) ) SELECT polygons_wo_wikidata.name as name FROM bounding_area_features as baf, polygons_wo_wikidata WHERE 'wikidata' IN (SELECT key FROM UNNEST(all_tags)) AND polygons_wo_wikidata.name IS NOT NULL AND baf.feature_type = \"points\" AND ST_DWithin(baf.geometry, polygons_wo_wikidata.geometry, 0) GROUP BY polygons_wo_wikidata.id, polygons_wo_wikidata.name ORDER BY COUNT(baf.osm_id) DESC LIMIT 1 OFFSET 1;",
        "schema": {
            "bigquery-public-data.geo_openstreetmap": {
                "planet_features": [
                    "geometry",
                    "feature_type",
                    "all_tags",
                    "osm_id"
                ]
            }
        }
    },
    "bq184": {
        "query": "WITH a AS (     SELECT          DATE(block_timestamp) AS date,          COUNT(*) AS contracts_creation     FROM           `bigquery-public-data.crypto_ethereum.traces` AS traces     WHERE          block_timestamp < '2021-09-01 00:00:00'         AND trace_type = 'create'         AND trace_address IS null     GROUP BY          date ), b AS (     SELECT          date,          SUM(contracts_creation) OVER (ORDER BY date) AS ccc,          LEAD(date, 1) OVER (ORDER BY date) AS next_date     FROM          a     ORDER BY          date ), calendar AS (     SELECT          date     FROM          UNNEST(generate_date_array('2021-08-01', '2021-08-31')) AS date ), c AS (     SELECT          calendar.date,          b.ccc     FROM          b      JOIN          calendar      ON          b.date <= calendar.date         AND calendar.date < b.next_date     ORDER BY          calendar.date ), d AS (     SELECT          DATE(block_timestamp) AS date1,          COUNT(*) AS contracts_creation1     FROM           `bigquery-public-data.crypto_ethereum.traces` AS traces     WHERE          block_timestamp < '2021-09-01 00:00:00'         AND trace_type = 'create'         AND trace_address IS NOT null     GROUP BY          date1 ), e AS (     SELECT          date1,          SUM(contracts_creation1) OVER (ORDER BY date1) AS ccc1,          LEAD(date1, 1) OVER (ORDER BY date1) AS next_date1     FROM          d     ORDER BY          date1 ), calendar1 AS (     SELECT          date1     FROM          UNNEST(generate_date_array('2021-08-01', '2021-08-31')) AS date1 ), f AS (     SELECT          calendar1.date1,          e.ccc1     FROM          e      JOIN          calendar1      ON          e.date1 <= calendar1.date1         AND calendar1.date1 < e.next_date1     ORDER BY          calendar1.date1 ) SELECT      f.date1,      f.ccc1 AS cumulative_contract_creation_by_contracts,      c.ccc AS cumulative_contract_creation_by_users FROM      c  JOIN      f  ON      f.date1 = c.date ORDER BY      f.date1 ;",
        "schema": {
            "bigquery-public-data.crypto_ethereum": {
                "traces": [
                    "block_timestamp",
                    "trace_type",
                    "trace_address"
                ]
            }
        }
    },
    "bq195": {
        "query": "WITH value_table AS (     SELECT to_address AS address, value AS value     FROM `spider2-public-data.crypto_ethereum.traces`     WHERE to_address IS NOT null     AND block_timestamp < '2021-09-01 00:00:00'     AND status=1     AND (call_type NOT IN ('delegatecall', 'callcode', 'staticcall') OR call_type IS null)          UNION ALL          SELECT from_address AS address, -value AS value     FROM `spider2-public-data.crypto_ethereum.traces`     WHERE from_address IS NOT null     AND block_timestamp < '2021-09-01 00:00:00'     AND status=1     AND (call_type NOT IN ('delegatecall', 'callcode', 'staticcall') OR call_type IS null)          UNION ALL          SELECT miner as address, SUM(CAST(receipt_gas_used AS NUMERIC) * CAST(gas_price AS NUMERIC)) AS value     FROM `spider2-public-data.crypto_ethereum.transactions` AS transactions     JOIN `spider2-public-data.crypto_ethereum.blocks` AS blocks     ON blocks.number = transactions.block_number     WHERE block_timestamp < '2021-09-01 00:00:00'     GROUP BY blocks.miner          UNION ALL          SELECT from_address as address, -(CAST(receipt_gas_used AS NUMERIC) * CAST(gas_price AS NUMERIC)) AS value     FROM  `spider2-public-data.crypto_ethereum.transactions`     WHERE block_timestamp < '2021-09-01 00:00:00' ) SELECT address, FLOOR(SUM(value) / power(10,18)) AS balance FROM value_table GROUP BY address ORDER BY balance DESC LIMIT 10",
        "schema": {
            "spider2-public-data.crypto_ethereum": {
                "traces": [
                    "to_address",
                    "value",
                    "block_timestamp",
                    "status",
                    "call_type",
                    "from_address"
                ],
                "transactions": [
                    "miner",
                    "receipt_gas_used",
                    "gas_price",
                    "block_number",
                    "from_address"
                ],
                "blocks": [
                    "number",
                    "miner"
                ]
            }
        }
    },
    "bq256": {
        "query": "WITH value_table AS (     SELECT to_address AS address, value AS value     FROM `spider2-public-data.crypto_ethereum.traces`     WHERE to_address IS NOT null     AND block_timestamp < '2021-09-01 00:00:00'      AND status=1     AND (call_type NOT IN ('delegatecall', 'callcode', 'staticcall') OR call_type IS null)          UNION ALL          SELECT from_address AS address, -value AS value     FROM `spider2-public-data.crypto_ethereum.traces`     WHERE from_address IS NOT null     AND block_timestamp < '2021-09-01 00:00:00'     AND status=1     AND (call_type NOT IN ('delegatecall', 'callcode', 'staticcall') OR call_type IS null)          UNION ALL          SELECT miner as address, SUM(CAST(receipt_gas_used AS NUMERIC) * CAST(gas_price AS NUMERIC)) AS value     FROM `spider2-public-data.crypto_ethereum.transactions` AS transactions     JOIN `spider2-public-data.crypto_ethereum.blocks` AS blocks     ON blocks.number = transactions.block_number     WHERE block_timestamp < '2021-09-01 00:00:00'     GROUP BY blocks.miner          UNION ALL          SELECT from_address as address, -(CAST(receipt_gas_used AS NUMERIC) * CAST(gas_price AS NUMERIC)) AS value     FROM  `spider2-public-data.crypto_ethereum.transactions`     WHERE block_timestamp < '2021-09-01 00:00:00' ), a AS (     SELECT SUM(value)/POWER(10,18) AS balance, address     FROM value_table     GROUP BY address     ORDER BY balance DESC ), b AS (     SELECT to_address, COUNT(transactions.hash) AS tx_recipient     FROM  `spider2-public-data.crypto_ethereum.transactions` AS transactions     WHERE block_timestamp < '2021-09-01 00:00:00'     GROUP BY to_address ),  c AS (     SELECT from_address, COUNT(transactions.hash) AS tx_sender     FROM  `spider2-public-data.crypto_ethereum.transactions` AS transactions     WHERE block_timestamp < '2021-09-01 00:00:00'     GROUP BY from_address ) SELECT balance FROM c LEFT JOIN a ON (a.address = c.from_address) ORDER BY tx_sender DESC LIMIT 1",
        "schema": {
            "spider2-public-data.crypto_ethereum": {
                "traces": [
                    "to_address",
                    "value",
                    "from_address",
                    "block_timestamp",
                    "status",
                    "call_type"
                ],
                "transactions": [
                    "hash",
                    "receipt_gas_used",
                    "gas_price",
                    "block_number",
                    "from_address",
                    "to_address",
                    "block_timestamp"
                ],
                "blocks": [
                    "number",
                    "miner"
                ]
            }
        }
    },
    "bq341": {
        "query": "WITH transaction_addresses as (           SELECT                 from_address,                 to_address,                 CAST(value as numeric)/1000000 as value           FROM                 `bigquery-public-data.crypto_ethereum.token_transfers`            WHERE                 token_address = \"0xa92a861fc11b99b24296af880011b47f9cafb5ab\"               and DATE(block_timestamp) > \"2023-03-17\"         ),          out_addresses as (           SELECT                 from_address, SUM(-1*value) as total_value           FROM                 transaction_addresses           GROUP BY                 from_address         ),          in_addresses as (           SELECT                 to_address,                 SUM(value) as total_value           FROM                 transaction_addresses           GROUP BY                 to_address         ),          all_addresses as (           SELECT                 from_address as address,                 total_value           FROM                 out_addresses            UNION ALL            SELECT                 to_address as address,                 total_value           FROM              in_addresses         )          SELECT              address         FROM              all_addresses         GROUP BY              address         HAVING              sum(total_value) > 0         ORDER BY              sum(total_value) ASC         LIMIT 1;",
        "schema": {
            "bigquery-public-data.crypto_ethereum": {
                "token_transfers": [
                    "from_address",
                    "to_address",
                    "value",
                    "token_address",
                    "block_timestamp"
                ]
            }
        }
    },
    "bq336": {
        "query": "WITH double_entry_book AS (    -- debits    SELECT     array_to_string(inputs.addresses, \"\",\"\") as address    , inputs.type    , - inputs.value as value    FROM        `bigquery-public-data.crypto_bitcoin.inputs` as inputs    UNION ALL    -- credits    SELECT     array_to_string(outputs.addresses, \"\",\"\") as address    , outputs.type    , outputs.value as value    FROM        `bigquery-public-data.crypto_bitcoin.outputs` as outputs ) SELECT    address  FROM     double_entry_book GROUP BY 1, type ORDER BY sum(value) DESC LIMIT 1;",
        "schema": {
            "bigquery-public-data.crypto_bitcoin": {
                "inputs": [
                    "addresses",
                    "type",
                    "value"
                ],
                "outputs": [
                    "addresses",
                    "type",
                    "value"
                ]
            }
        }
    },
    "bq057": {
        "query": "WITH totals AS ( -- Aggregate monthly totals for Bitcoin txs, input/output UTXOs, -- and input/output values (UTXO stands for Unspent Transaction Output)   SELECT     txs_tot.block_timestamp_month as tx_month,     count(txs_tot.hash) as tx_count,     sum(txs_tot.input_count) as tx_inputs,     sum(txs_tot.output_count) as tx_outputs,     sum(txs_tot.input_value) / 100000000 as tx_input_val,     sum(txs_tot.output_value) / 100000000 as tx_output_val   FROM `bigquery-public-data.crypto_bitcoin.transactions` as txs_tot   WHERE txs_tot.block_timestamp_month BETWEEN cast('2021-01-01' as date) AND cast('2021-12-31' as date)   GROUP BY txs_tot.block_timestamp_month   ORDER BY txs_tot.block_timestamp_month desc ), coinjoinOuts AS( -- Builds a table where each row represents an output of a  -- potential CoinJoin tx, defined as a tx that had more  -- than two outputs and had a total output value less than its -- input value, per Adam Fiscor's description in this article:    SELECT      txs.hash,     txs.block_number,     txs.block_timestamp_month,     txs.input_count,     txs.output_count,     txs.input_value,     txs.output_value,     o.value as outputs_val   FROM `bigquery-public-data.crypto_bitcoin.transactions` as txs, UNNEST(txs.outputs) as o   WHERE output_count > 2 AND      output_value <= input_value AND      block_timestamp_month BETWEEN cast('2021-01-01' as date) AND cast('2021-12-31' as date)   ORDER BY block_number, txs.hash desc ), coinjoinTxs AS( -- Builds a table of just the distinct CoinJoin tx hashes -- which had more than one equal-value output.   SELECT      STRING_AGG(DISTINCT coinjoinOuts.hash LIMIT 1) as cjHash,     CONCAT(coinjoinOuts.hash, \" \", cast(coinjoinOuts.outputs_val as string)) as outputVal,     count(*) as cjOuts   FROM coinjoinOuts   GROUP BY outputVal   having count(*) >1 ), coinjoinsD AS( -- Filter out all potential CoinJoin txs that did not have -- more than one equal-value output. Do not list the -- outputs themselves, only the distinct tx hashes and -- their input/output counts and values.   SELECT      DISTINCT coinjoinOuts.hash,      coinjoinOuts.block_number,      coinjoinOuts.block_timestamp_month,     coinjoinOuts.input_count,     coinjoinOuts.output_count,     coinjoinOuts.input_value,     coinjoinOuts.output_value   FROM coinjoinOuts INNER JOIN coinjoinTxs ON coinjoinOuts.hash = coinjoinTxs.cjHash ), coinjoins AS ( -- Aggregate monthly totals for CoinJoin txs, input/output UTXOs, -- and input/output values   SELECT      block_timestamp_month as cjs_month,     count(cjs.hash) as cjs_count,     sum(cjs.input_count) as cjs_inputs,     sum(cjs.output_count) as cjs_outputs,     sum(cjs.input_value)/100000000 as cjs_input_val,     sum(cjs.output_value)/100000000 as cjs_output_val   FROM coinjoinsD as cjs   GROUP BY cjs.block_timestamp_month   ORDER BY cjs.block_timestamp_month desc ) SELECT extract(month from tx_month) as month, -- Calculate resulting CoinJoin percentages: -- tx_percent = percent of monthly Bitcoin txs that were CoinJoins   ROUND(coinjoins.cjs_count / totals.tx_count * 100, 1) as tx_percent,    -- utxos_percent = percent of monthly Bitcoin utxos that were CoinJoins   ROUND((coinjoins.cjs_inputs / totals.tx_inputs + coinjoins.cjs_outputs / totals.tx_outputs) / 2 * 100, 1) as utxos_percent,    -- value_percent = percent of monthly Bitcoin volume that took place -- in CoinJoined transactions   ROUND(coinjoins.cjs_input_val / totals.tx_input_val * 100, 1) as value_percent FROM totals INNER JOIN coinjoins ON totals.tx_month = coinjoins.cjs_month ORDER BY value_percent DESC LIMIT 1;",
        "schema": {
            "bigquery-public-data.crypto_bitcoin": {
                "transactions": [
                    "hash",
                    "block_timestamp_month",
                    "input_count",
                    "output_count",
                    "input_value",
                    "output_value",
                    "block_number",
                    "outputs.value"
                ]
            }
        }
    },
    "bq068": {
        "query": "WITH double_entry_book AS (     -- debits     SELECT       ARRAY_TO_STRING(inputs.addresses, \",\") AS address,       inputs.type,       - inputs.value AS value     FROM         `bigquery-public-data.crypto_bitcoin_cash.transactions`     JOIN         UNNEST(inputs) AS inputs     WHERE block_timestamp_month = '2019-01-01'      UNION ALL       -- credits     SELECT       ARRAY_TO_STRING(outputs.addresses, \",\") AS address,       outputs.type,       outputs.value AS value     FROM         `bigquery-public-data.crypto_bitcoin_cash.transactions` JOIN UNNEST(outputs) AS outputs     WHERE block_timestamp_month = '2019-01-01' ), address_balances AS (     SELECT          address,         type,         SUM(value) AS balance     FROM double_entry_book     GROUP BY 1, 2 ), max_min_balances AS (     SELECT         type,         MAX(balance) AS max_balance,         MIN(balance) AS min_balance     FROM address_balances     GROUP BY type ) SELECT     type,     max_balance,     min_balance FROM max_min_balances ORDER BY type;",
        "schema": {
            "bigquery-public-data.crypto_bitcoin_cash": {
                "transactions": [
                    "inputs.addresses",
                    "inputs.type",
                    "inputs.value",
                    "outputs.addresses",
                    "outputs.type",
                    "outputs.value",
                    "block_timestamp_month"
                ]
            }
        }
    },
    "bq092": {
        "query": "WITH double_entry_book AS (     -- debits     SELECT       ARRAY_TO_STRING(inputs.addresses, \",\") AS address,       inputs.type,       - inputs.value AS value     FROM         `bigquery-public-data.crypto_dash.transactions`     JOIN         UNNEST(inputs) AS inputs     WHERE block_timestamp_month = '2019-01-01'      UNION ALL       -- credits     SELECT       ARRAY_TO_STRING(outputs.addresses, \",\") AS address,       outputs.type,       outputs.value AS value     FROM         `bigquery-public-data.crypto_dash.transactions` JOIN UNNEST(outputs) AS outputs     WHERE block_timestamp_month = '2019-01-01' ), address_balances AS (     SELECT          address,         type,         SUM(value) AS balance     FROM double_entry_book     GROUP BY 1, 2 ) SELECT     MAX(balance) AS max_balance,     MIN(balance) AS min_balance FROM address_balances;",
        "schema": {
            "bigquery-public-data.crypto_dash": {
                "transactions": [
                    "inputs.addresses",
                    "inputs.type",
                    "inputs.value",
                    "outputs.addresses",
                    "outputs.type",
                    "outputs.value",
                    "block_timestamp_month"
                ]
            }
        }
    },
    "bq093": {
        "query": "WITH double_entry_book AS (     -- Debits     SELECT          to_address AS address,          value AS value     FROM          `bigquery-public-data.crypto_ethereum_classic.traces`     WHERE          to_address IS NOT NULL         AND status = 1         AND (call_type NOT IN ('delegatecall', 'callcode', 'staticcall') OR call_type IS NULL)         AND EXTRACT(DATE FROM block_timestamp) = '2019-01-01'      UNION ALL          -- Credits     SELECT          from_address AS address,          -value AS value     FROM          `bigquery-public-data.crypto_ethereum_classic.traces`     WHERE          from_address IS NOT NULL         AND status = 1         AND (call_type NOT IN ('delegatecall', 'callcode', 'staticcall') OR call_type IS NULL)         AND EXTRACT(DATE FROM block_timestamp) = '2019-01-01'      UNION ALL      -- Transaction Fees Debits     SELECT          miner AS address,          SUM(CAST(receipt_gas_used AS NUMERIC) * CAST(gas_price AS NUMERIC)) AS value     FROM          `bigquery-public-data.crypto_ethereum_classic.transactions` AS transactions     JOIN          `bigquery-public-data.crypto_ethereum_classic.blocks` AS blocks          ON blocks.number = transactions.block_number     WHERE          EXTRACT(DATE FROM block_timestamp) = '2019-01-01'     GROUP BY          blocks.miner,          block_timestamp      UNION ALL          -- Transaction Fees Credits     SELECT          from_address AS address,          -(CAST(receipt_gas_used AS NUMERIC) * CAST(gas_price AS NUMERIC)) AS value     FROM          `bigquery-public-data.crypto_ethereum_classic.transactions`     WHERE          EXTRACT(DATE FROM block_timestamp) = '2019-01-01' ), net_changes AS (     SELECT          address,         SUM(value) AS net_change     FROM          double_entry_book     GROUP BY          address ) select      MAX(net_change) AS max_net_change,     MIN(net_change) AS min_net_change FROM     net_changes;",
        "schema": {
            "bigquery-public-data.crypto_ethereum_classic": {
                "traces": [
                    "to_address",
                    "value",
                    "status",
                    "call_type",
                    "block_timestamp",
                    "from_address"
                ],
                "transactions": [
                    "receipt_gas_used",
                    "gas_price",
                    "block_number",
                    "miner",
                    "from_address"
                ],
                "blocks": [
                    "number",
                    "block_timestamp"
                ]
            }
        }
    },
    "bq037": {
        "query": "WITH A AS (     SELECT         reference_bases,         start_position     FROM         `bigquery-public-data.human_genome_variants.1000_genomes_phase_3_optimized_schema_variants_20150220`     WHERE         reference_bases IN ('AT', 'TA') ), B AS (     SELECT         reference_bases,         MIN(start_position) AS min_start_position,         MAX(start_position) AS max_start_position,         COUNT(1) AS total_count     FROM         A     GROUP BY         reference_bases ), min_counts AS (     SELECT         reference_bases,         start_position AS min_start_position,         COUNT(1) AS min_count     FROM         A     GROUP BY         reference_bases, start_position     HAVING         start_position = (SELECT MIN(start_position) FROM A AS sub WHERE sub.reference_bases = A.reference_bases) ), max_counts AS (     SELECT         reference_bases,         start_position AS max_start_position,         COUNT(1) AS max_count     FROM         A     GROUP BY         reference_bases, start_position     HAVING         start_position = (SELECT MAX(start_position) FROM A AS sub WHERE sub.reference_bases = A.reference_bases) ) SELECT     B.reference_bases,     B.min_start_position,     CAST(min_counts.min_count AS FLOAT64) / B.total_count AS min_position_ratio,     B.max_start_position,     CAST(max_counts.max_count AS FLOAT64) / B.total_count AS max_position_ratio FROM     B LEFT JOIN     min_counts ON B.reference_bases = min_counts.reference_bases AND B.min_start_position = min_counts.min_start_position LEFT JOIN     max_counts ON B.reference_bases = max_counts.reference_bases AND B.max_start_position = max_counts.max_start_position ORDER BY     B.reference_bases;",
        "schema": {
            "bigquery-public-data.human_genome_variants": {
                "1000_genomes_phase_3_optimized_schema_variants_20150220": [
                    "reference_bases",
                    "start_position"
                ]
            }
        }
    },
    "bq135": {
        "query": "WITH all_transactions AS (   SELECT block_timestamp, amount   FROM `spider2-public-data.crypto_zilliqa.transactions`   UNION ALL   SELECT block_timestamp, amount   FROM `spider2-public-data.crypto_zilliqa.transitions`  ) SELECT    DATE(block_timestamp) AS date FROM all_transactions WHERE block_timestamp < TIMESTAMP('2022-01-01') GROUP BY date ORDER BY SUM(amount) / 1e12 DESC LIMIT 1;",
        "schema": {
            "spider2-public-data.crypto_zilliqa": {
                "transactions": [
                    "block_timestamp",
                    "amount"
                ],
                "transitions": [
                    "block_timestamp",
                    "amount"
                ]
            }
        }
    },
    "bq065": {
        "query": "WITH parsed_aggregator_oracle_requests AS (     SELECT ARRAY(         SELECT JSON_EXTRACT_SCALAR(symbol_as_json, '$')         FROM UNNEST(JSON_EXTRACT_ARRAY(decoded_result.calldata, \"$.symbols\")) AS symbol_as_json     ) AS symbols,     CAST(JSON_EXTRACT_SCALAR(decoded_result.calldata, \"$.multiplier\") AS FLOAT64) AS multiplier,     ARRAY(         SELECT CAST(JSON_EXTRACT_SCALAR(rate_as_json, '$') AS FLOAT64)         FROM UNNEST(JSON_EXTRACT_ARRAY(decoded_result.result, \"$.rates\")) AS rate_as_json     ) AS rates,     block_timestamp,     oracle_request_id,     FROM `public-data-finance.crypto_band.oracle_requests`     WHERE request.oracle_script_id = 3 ), -- zip symbols and rates zipped_rates AS (     SELECT block_timestamp,         oracle_request_id,         struct(symbol, rates[OFFSET(off)] AS rate) AS zipped,         multiplier,     FROM parsed_aggregator_oracle_requests,         UNNEST(symbols) AS symbol WITH OFFSET off ), -- adjust for multiplier adjusted_rates AS (     SELECT          block_timestamp,         oracle_request_id,         struct(zipped.symbol, IEEE_DIVIDE(zipped.rate, multiplier) AS rate) AS zipped,     FROM zipped_rates ) SELECT      block_timestamp,     oracle_request_id,     zipped.symbol,     zipped.rate, FROM adjusted_rates ORDER BY block_timestamp DESC LIMIT 10",
        "schema": {
            "public-data-finance.crypto_band": {
                "oracle_requests": [
                    "decoded_result.calldata",
                    "decoded_result.result",
                    "block_timestamp",
                    "oracle_request_id",
                    "request.oracle_script_id"
                ]
            }
        }
    },
    "bq038": {
        "query": "WITH grouped_trips AS (   SELECT     end_station_id,     COUNTIF(group_size = 1) AS single_trips,     COUNTIF(group_size != 1) AS group_trips   FROM (     SELECT       end_station_id,       COUNT(*) AS group_size     FROM (       SELECT         ROUND(UNIX_SECONDS(starttime) / 120) AS start_round,         ROUND(UNIX_SECONDS(stoptime) / 120) AS stop_round,         start_station_id,         end_station_id       FROM         `bigquery-public-data.new_york.citibike_trips`       GROUP BY         start_round, stop_round, start_station_id, end_station_id     )     GROUP BY       end_station_id   )   GROUP BY     end_station_id ), top_stations AS (   SELECT     end_station_id,     group_trips / (single_trips + group_trips) AS percent_groups   FROM     grouped_trips   ORDER BY     percent_groups DESC   LIMIT 10 )  SELECT DISTINCT   ct.end_station_name FROM   top_stations ts JOIN   `bigquery-public-data.new_york.citibike_trips` ct ON   ts.end_station_id = ct.end_station_id",
        "schema": {
            "bigquery-public-data.new_york": {
                "citibike_trips": [
                    "starttime",
                    "stoptime",
                    "start_station_id",
                    "end_station_id",
                    "end_station_name"
                ]
            }
        }
    },
    "bq040": {
        "query": "WITH t2 AS ( SELECT      t.*,     t.pickup_location_id as pickup_zone_id,     tz.borough as pickup_borough FROM ( SELECT *,     TIMESTAMP_DIFF(dropoff_datetime,pickup_datetime,SECOND) as time_duration_in_secs,     (CASE WHEN total_amount=0 THEN 0     ELSE (tip_amount*100/total_amount) END) as tip_rate FROM `bigquery-public-data.new_york_taxi_trips.tlc_yellow_trips_2016` ) t INNER JOIN `bigquery-public-data.new_york_taxi_trips.taxi_zone_geom` tz ON t.pickup_location_id = tz.zone_id WHERE      pickup_datetime BETWEEN '2016-01-01' AND '2016-01-07'      AND dropoff_datetime BETWEEN '2016-01-01' AND '2016-01-07'     AND TIMESTAMP_DIFF(dropoff_datetime,pickup_datetime,SECOND) > 0     AND passenger_count > 0     AND trip_distance >= 0      AND tip_amount >= 0      AND tolls_amount >= 0      AND mta_tax >= 0      AND fare_amount >= 0     AND total_amount >= 0 ), t3 AS (SELECT  pickup_borough, (CASE      WHEN tip_rate = 0 THEN 'no tip'     WHEN tip_rate <= 5 THEN 'Less than 5%'     WHEN tip_rate <= 10 THEN '5% to 10%'     WHEN tip_rate <= 15 THEN '10% to 15%'     WHEN tip_rate <= 20 THEN '15% to 20%'     WHEN tip_rate <= 25 THEN '20% to 25%'     ELSE 'More than 25%' END)as tip_category, COUNT(*) as no_of_trips FROM t2 GROUP BY 1,2 ORDER BY pickup_borough ASC), INFO AS ( SELECT pickup_borough      , tip_category      , Sum(no_of_trips) as no_of_trips,      (CASE            WHEN pickup_borough is null THEN (select sum(no_of_trips)           FROM t3)                      WHEN pickup_borough is not null and tip_category is null THEN (select sum(no_of_trips)           FROM t3)                      WHEN pickup_borough is not null and tip_category is not null THEN (select sum(no_of_trips)           FROM t3           WHERE pickup_borough = m.pickup_borough)           END) as parent_sum,        (           Sum(no_of_trips)             /           (             CASE            WHEN pickup_borough is null THEN (select sum(no_of_trips)           FROM t3)                      WHEN pickup_borough is not null and tip_category is null THEN (select sum(no_of_trips)           FROM t3)                      WHEN pickup_borough is not null and tip_category is not null THEN (select sum(no_of_trips)           FROM t3           WHERE pickup_borough = m.pickup_borough)           END           )         ) as percentage FROM t3 m GROUP BY ROLLUP(pickup_borough, tip_category) order by 1, 2 )  SELECT pickup_borough, tip_category, percentage FROM INFO WHERE pickup_borough is not null and tip_category is not null AND pickup_borough not in ('EWR','Staten Island')",
        "schema": {
            "bigquery-public-data.new_york_taxi_trips": {
                "tlc_yellow_trips_2016": [
                    "pickup_datetime",
                    "dropoff_datetime",
                    "pickup_location_id",
                    "total_amount",
                    "tip_amount"
                ],
                "taxi_zone_geom": [
                    "zone_id",
                    "borough"
                ]
            }
        }
    },
    "bq040_1": {
        "query": "WITH t2 AS ( SELECT      t.*,     t.pickup_location_id as pickup_zone_id,     tz.borough as pickup_borough FROM ( SELECT *,     TIMESTAMP_DIFF(dropoff_datetime,pickup_datetime,SECOND) as time_duration_in_secs,     (CASE WHEN total_amount=0 THEN 0     ELSE (tip_amount*100/total_amount) END) as tip_rate FROM `bigquery-public-data.new_york_taxi_trips.tlc_yellow_trips_2016` ) t INNER JOIN `bigquery-public-data.new_york_taxi_trips.taxi_zone_geom` tz ON t.pickup_location_id = tz.zone_id WHERE      pickup_datetime BETWEEN '2016-01-01' AND '2016-01-07'      AND dropoff_datetime BETWEEN '2016-01-01' AND '2016-01-07'     AND TIMESTAMP_DIFF(dropoff_datetime,pickup_datetime,SECOND) > 0     AND passenger_count > 0     AND trip_distance >= 0      AND tip_amount >= 0      AND tolls_amount >= 0      AND mta_tax >= 0      AND fare_amount >= 0     AND total_amount >= 0 ), t3 AS (SELECT  pickup_borough, (CASE      WHEN tip_rate = 0 THEN 'no tip'     WHEN tip_rate <= 5 THEN 'Less than 5%'     WHEN tip_rate <= 10 THEN '5% to 10%'     WHEN tip_rate <= 15 THEN '10% to 15%'     WHEN tip_rate <= 20 THEN '15% to 20%'     WHEN tip_rate <= 25 THEN '20% to 25%'     ELSE 'More than 25%' END)as tip_category, COUNT(*) as no_of_trips FROM t2 GROUP BY 1,2 ORDER BY pickup_borough ASC), INFO AS ( SELECT pickup_borough      , tip_category      , Sum(no_of_trips) as no_of_trips,      (CASE            WHEN pickup_borough is null THEN (select sum(no_of_trips)           FROM t3)                      WHEN pickup_borough is not null and tip_category is null THEN (select sum(no_of_trips)           FROM t3)                      WHEN pickup_borough is not null and tip_category is not null THEN (select sum(no_of_trips)           FROM t3           WHERE pickup_borough = m.pickup_borough)           END) as parent_sum,        (           Sum(no_of_trips)             /           (             CASE            WHEN pickup_borough is null THEN (select sum(no_of_trips)           FROM t3)                      WHEN pickup_borough is not null and tip_category is null THEN (select sum(no_of_trips)           FROM t3)                      WHEN pickup_borough is not null and tip_category is not null THEN (select sum(no_of_trips)           FROM t3           WHERE pickup_borough = m.pickup_borough)           END           )         ) as percentage FROM t3 m GROUP BY ROLLUP(pickup_borough, tip_category) order by 1, 2 )  SELECT      pickup_borough,     (SUM(CASE WHEN tip_category = 'no tip' THEN no_of_trips ELSE 0 END) * 100.0 / SUM(no_of_trips)) AS percentage_no_tip FROM t3 GROUP BY pickup_borough ORDER BY pickup_borough;",
        "schema": {
            "bigquery-public-data.new_york_taxi_trips.tlc_yellow_trips_2016": {
                "tlc_yellow_trips_2016": [
                    "pickup_datetime",
                    "dropoff_datetime",
                    "pickup_location_id",
                    "total_amount",
                    "tip_amount"
                ]
            },
            "bigquery-public-data.new_york_taxi_trips.taxi_zone_geom": {
                "taxi_zone_geom": [
                    "zone_id",
                    "borough"
                ]
            }
        }
    },
    "bq039": {
        "query": "SELECT      tz.zone_name AS pickup_zone,     tz1.zone_name AS dropoff_zone,      time_duration_in_secs,     driving_speed_miles_per_hour,     tip_rate FROM ( SELECT *,     TIMESTAMP_DIFF(dropoff_datetime,pickup_datetime,SECOND) as time_duration_in_secs,     ROUND(trip_distance / (TIMESTAMP_DIFF(dropoff_datetime, pickup_datetime, SECOND) / 3600), 2) AS driving_speed_miles_per_hour,     (CASE WHEN total_amount=0 THEN 0           ELSE (tip_amount*100/total_amount) END) as tip_rate FROM `bigquery-public-data.new_york_taxi_trips.tlc_yellow_trips_2016` ) t INNER JOIN `bigquery-public-data.new_york_taxi_trips.taxi_zone_geom` tz ON t.pickup_location_id = tz.zone_id INNER JOIN `bigquery-public-data.new_york_taxi_trips.taxi_zone_geom` tz1 ON t.dropoff_location_id = tz1.zone_id WHERE      pickup_datetime BETWEEN '2016-07-01' AND '2016-07-07'      AND dropoff_datetime BETWEEN '2016-07-01' AND '2016-07-07'     AND TIMESTAMP_DIFF(dropoff_datetime,pickup_datetime,SECOND) > 0     AND passenger_count > 5     AND trip_distance >= 10     AND tip_amount >= 0      AND tolls_amount >= 0      AND mta_tax >= 0      AND fare_amount >= 0     AND total_amount >= 0 ORDER BY total_amount DESC LIMIT 10;",
        "schema": {
            "bigquery-public-data.new_york_taxi_trips": {
                "tlc_yellow_trips_2016": [
                    "dropoff_datetime",
                    "pickup_datetime",
                    "trip_distance",
                    "total_amount",
                    "tip_amount",
                    "pickup_location_id",
                    "dropoff_location_id",
                    "passenger_count"
                ],
                "taxi_zone_geom": [
                    "zone_name",
                    "zone_id"
                ]
            }
        }
    },
    "bq054": {
        "query": "#standardsql SELECT   IFNULL(a.upper_latin, b.upper_latin) as upper_latin,   IFNULL(count_2015, 0) as count_2015,   IFNULL(count_1995, 0) as count_1995,   (IFNULL(count_2015, 0)-IFNULL(count_1995, 0)) AS count_growth,   (IFNULL(alive_2015, 0)-IFNULL(alive_1995, 0)) as alive_growth,   (IFNULL(dead_2015, 0)-IFNULL(dead_1995, 0)) as dead_growth FROM (   SELECT     UPPER(spc_latin) AS upper_latin,     spc_common,     COUNT(*) AS count_2015,     COUNTIF(status=\"Alive\") AS alive_2015,     COUNTIF(status=\"Dead\") AS dead_2015   FROM     `bigquery-public-data.new_york.tree_census_2015`   WHERE spc_latin != \"\"   GROUP BY     spc_latin,     spc_common)a FULL OUTER JOIN (   SELECT     UPPER(spc_latin) AS upper_latin,     COUNT(*) AS count_1995,     COUNTIF(status!=\"Dead\") AS alive_1995,     COUNTIF(status=\"Dead\") AS dead_1995   FROM     `bigquery-public-data.new_york.tree_census_1995`   GROUP BY     spc_latin)b ON   a.upper_latin=b.upper_latin ORDER BY   count_growth DESC LIMIT 10",
        "schema": {
            "bigquery-public-data.new_york": {
                "tree_census_2015": [
                    "spc_latin",
                    "spc_common",
                    "status"
                ],
                "tree_census_1995": [
                    "spc_latin",
                    "status"
                ]
            }
        }
    },
    "bq186": {
        "query": "WITH aaa AS (     SELECT *,                          CONCAT(CAST(EXTRACT(YEAR FROM start_date) AS STRING),                LPAD(CAST(EXTRACT(MONTH FROM start_date) AS STRING), 2, '0')) AS trip_date     FROM `bigquery-public-data.san_francisco.bikeshare_trips` AS bt     -- WHERE EXTRACT(YEAR FROM start_date) = 2015 ), bbb AS (     SELECT          trip_date AS date,          FIRST_VALUE(duration_sec) OVER (             PARTITION BY trip_date             ORDER BY trip_date         ) / 60.0 AS open,         LAST_VALUE(duration_sec) OVER (             PARTITION BY trip_date             ORDER BY trip_date         ) / 60.0 AS close,         MAX(duration_sec) OVER (             PARTITION BY trip_date             ORDER BY trip_date         ) / 60.0 AS high,         MIN(duration_sec) OVER (             PARTITION BY trip_date             ORDER BY trip_date         ) / 60.0 AS low     FROM aaa     ORDER BY start_date ) SELECT date, open, high, close, low FROM bbb GROUP BY date, open, high, close, low ORDER BY date;",
        "schema": {
            "bigquery-public-data.san_francisco": {
                "bikeshare_trips": [
                    "start_date",
                    "duration_sec"
                ]
            }
        }
    },
    "bq339": {
        "query": "WITH monthly_totals AS (   SELECT     SUM(CASE WHEN subscriber_type = 'Customer' THEN duration_sec / 60 ELSE NULL END) AS customer_minutes_sum,     SUM(CASE WHEN subscriber_type = 'Subscriber' THEN duration_sec / 60 ELSE NULL END) AS subscriber_minutes_sum,     EXTRACT(MONTH FROM end_date) AS end_month   FROM     `bigquery-public-data.san_francisco_bikeshare.bikeshare_trips`   WHERE     EXTRACT(YEAR FROM end_date) = 2017   GROUP BY     end_month ),  cumulative_totals AS (   SELECT     end_month,     SUM(customer_minutes_sum) OVER (ORDER BY end_month ROWS UNBOUNDED PRECEDING) / 1000 AS cumulative_minutes_cust,     SUM(subscriber_minutes_sum) OVER (ORDER BY end_month ROWS UNBOUNDED PRECEDING) / 1000 AS cumulative_minutes_sub   FROM     monthly_totals ),  differences AS (   SELECT     end_month,     ABS(cumulative_minutes_cust - cumulative_minutes_sub) AS abs_diff   FROM     cumulative_totals )  SELECT   end_month FROM   differences ORDER BY   abs_diff DESC LIMIT 1;",
        "schema": {
            "bigquery-public-data.san_francisco_bikeshare": {
                "bikeshare_trips": [
                    "subscriber_type",
                    "duration_sec",
                    "end_date"
                ]
            }
        }
    },
    "bq059": {
        "query": "WITH stations AS (   SELECT station_id   FROM     `bigquery-public-data.san_francisco_bikeshare.bikeshare_station_info` AS stainfo   WHERE stainfo.region_id = (     SELECT region.region_id     FROM `bigquery-public-data.san_francisco_bikeshare.bikeshare_regions` AS region     WHERE region.name = \"Berkeley\"   ) ), meta_data AS (     SELECT         round(st_distance(start_station_geom, end_station_geom), 1) as distancia_metros,         round(st_distance(start_station_geom, end_station_geom) / duration_sec, 1) as velocidade_media     FROM         `bigquery-public-data.san_francisco_bikeshare.bikeshare_trips` AS trips     WHERE         cast(trips.start_station_id as string) IN (SELECT station_id FROM stations)         AND cast(trips.end_station_id as string) IN (SELECT station_id FROM stations)         AND start_station_latitude IS NOT NULL         AND start_station_longitude IS NOT NULL         AND end_station_latitude IS NOT NULL         AND end_station_longitude IS NOT NULL         AND st_distance(start_station_geom, end_station_geom) > 1000     ORDER BY         velocidade_media DESC     LIMIT 1 )  SELECT velocidade_media as max_velocity FROM meta_data;",
        "schema": {
            "bigquery-public-data.san_francisco_bikeshare": {
                "bikeshare_station_info": [
                    "station_id",
                    "region_id"
                ],
                "bikeshare_regions": [
                    "region_id",
                    "name"
                ],
                "bikeshare_trips": [
                    "start_station_id",
                    "end_station_id",
                    "start_station_geom",
                    "end_station_geom",
                    "duration_sec",
                    "start_station_latitude",
                    "start_station_longitude",
                    "end_station_latitude",
                    "end_station_longitude"
                ]
            }
        }
    },
    "bq006": {
        "query": "WITH incident_stats AS (   SELECT      COUNT(descript) AS total_pub_intox   FROM      `bigquery-public-data.austin_incidents.incidents_2016`    WHERE      descript = 'PUBLIC INTOXICATION'    GROUP BY      date ), average_and_stddev AS (   SELECT      AVG(total_pub_intox) AS avg,      STDDEV(total_pub_intox) AS stddev    FROM      incident_stats ), daily_z_scores AS (   SELECT      date,      COUNT(descript) AS total_pub_intox,      ROUND((COUNT(descript) - a.avg) / a.stddev, 2) AS z_score   FROM      `bigquery-public-data.austin_incidents.incidents_2016`,     (SELECT avg, stddev FROM average_and_stddev) AS a   WHERE      descript = 'PUBLIC INTOXICATION'   GROUP BY      date, avg, stddev )  SELECT    date FROM    daily_z_scores ORDER BY    z_score DESC LIMIT 1 OFFSET 1",
        "schema": {
            "bigquery-public-data.austin_incidents": {
                "incidents_2016": [
                    "descript",
                    "date"
                ]
            }
        }
    },
    "bq187": {
        "query": "WITH tokenInfo AS (     SELECT address     FROM `bigquery-public-data.ethereum_blockchain.tokens`     WHERE name = 'BNB' ),  receivedTx AS (     SELECT tx.to_address as addr,             tokens.name as name,             SUM(CAST(tx.value AS float64) / POWER(10, 18)) as amount_received     FROM `bigquery-public-data.ethereum_blockchain.token_transfers` as tx     JOIN tokenInfo ON tx.token_address = tokenInfo.address,          `bigquery-public-data.ethereum_blockchain.tokens` as tokens     WHERE tx.token_address = tokens.address          AND tx.to_address <> '0x0000000000000000000000000000000000000000'     GROUP BY 1, 2 ),  sentTx AS (     SELECT tx.from_address as addr,             tokens.name as name,             SUM(CAST(tx.value AS float64) / POWER(10, 18)) as amount_sent     FROM `bigquery-public-data.ethereum_blockchain.token_transfers` as tx     JOIN tokenInfo ON tx.token_address = tokenInfo.address,          `bigquery-public-data.ethereum_blockchain.tokens` as tokens     WHERE tx.token_address = tokens.address          AND tx.from_address <> '0x0000000000000000000000000000000000000000'     GROUP BY 1, 2 ),  walletBalances AS (     SELECT r.addr,            COALESCE(SUM(r.amount_received), 0) - COALESCE(SUM(s.amount_sent), 0) as balance     FROM          receivedTx as r     LEFT JOIN          sentTx as s     ON          r.addr = s.addr     GROUP BY          r.addr )  SELECT      SUM(balance) as circulating_supply FROM      walletBalances;",
        "schema": {
            "bigquery-public-data.ethereum_blockchain": {
                "tokens": [
                    "address",
                    "name"
                ],
                "token_transfers": [
                    "to_address",
                    "token_address",
                    "value",
                    "from_address"
                ]
            }
        }
    },
    "bq014": {
        "query": "WITH first_orders AS (   SELECT     o.order_id,     o.user_id,     ROW_NUMBER() OVER (PARTITION BY o.user_id ORDER BY o.created_at ASC) order_sequence   FROM     `bigquery-public-data.thelook_ecommerce.orders` o   WHERE     o.status NOT IN ('Cancelled', 'Returned')   QUALIFY order_sequence = 1 ),  category_stats AS (   SELECT     p.category,     SUM(oi.sale_price) AS revenue,     COUNT(DISTINCT fo.user_id) AS user_count   FROM     first_orders fo   LEFT JOIN     `bigquery-public-data.thelook_ecommerce.order_items` oi ON oi.order_id = fo.order_id   LEFT JOIN     `bigquery-public-data.thelook_ecommerce.products` p ON p.id = oi.product_id   GROUP BY     p.category ),  top_category AS (   SELECT     category   FROM     category_stats   ORDER BY     user_count DESC   LIMIT 1 )  SELECT   c.revenue FROM   category_stats c JOIN   top_category t ON c.category = t.category;",
        "schema": {
            "bigquery-public-data.thelook_ecommerce": {
                "orders": [
                    "order_id",
                    "user_id",
                    "created_at",
                    "status"
                ],
                "order_items": [
                    "order_id",
                    "sale_price",
                    "product_id"
                ],
                "products": [
                    "id",
                    "category"
                ]
            }
        }
    },
    "bq188": {
        "query": "WITH table1 AS (   SELECT     created_at,     session_id,     sequence_number,     CASE WHEN event_type = 'product' THEN CAST(REPLACE(uri, '/product/', '') AS INT) ELSE NULL END product_uri_id,     LEAD(created_at) OVER (PARTITION BY session_id ORDER BY sequence_number) next_event   FROM `bigquery-public-data.thelook_ecommerce.events`  ),  table2 AS (   SELECT      p.category,     COUNT(o.id) times_bought   FROM `bigquery-public-data.thelook_ecommerce.products` p   LEFT JOIN `bigquery-public-data.thelook_ecommerce.order_items` o     ON p.id = o.product_id   GROUP BY 1 ),  category_stats AS (   SELECT      p.category,       COUNT(table1.product_uri_id) number_of_visits,     ROUND(AVG(DATE_DIFF(table1.next_event, table1.created_at, SECOND) / 60), 2) avg_time_spent,     table2.times_bought total_quantity_bought   FROM table1   LEFT JOIN bigquery-public-data.thelook_ecommerce.products p     ON table1.product_uri_id = p.id   LEFT JOIN table2     ON p.category = table2.category   WHERE table1.product_uri_id IS NOT NULL   GROUP BY 1, 4 )  SELECT    CAST(avg_time_spent AS STRING)  FROM category_stats ORDER BY category_stats.total_quantity_bought DESC LIMIT 1",
        "schema": {
            "bigquery-public-data.thelook_ecommerce": {
                "events": [
                    "created_at",
                    "session_id",
                    "sequence_number",
                    "event_type",
                    "uri"
                ],
                "products": [
                    "category",
                    "id"
                ],
                "order_items": [
                    "id",
                    "product_id"
                ]
            }
        }
    },
    "bq258": {
        "query": "WITH monthly_summary AS (   SELECT      FORMAT_DATE('%m', oi.delivered_at) AS Month,     FORMAT_DATE('%Y', oi.delivered_at) AS Year,     p.category AS Product_category,     SUM(oi.sale_price) AS TPV,     COUNT(DISTINCT oi.order_id) AS TPO   FROM      bigquery-public-data.thelook_ecommerce.order_items oi   JOIN      bigquery-public-data.thelook_ecommerce.products p ON oi.product_id = p.id   JOIN      bigquery-public-data.thelook_ecommerce.orders o ON oi.order_id = o.order_id   WHERE      oi.status ='Complete'   AND     FORMAT_DATE('%Y', oi.delivered_at) < '2023'   GROUP BY     Month, Year, Product_category   ORDER BY      Year, Month ),  lagged_summary AS (   SELECT      month,     year,     Product_category,     TPV,     TPO,     LAG(TPV) OVER(PARTITION BY Product_category ORDER BY year, month) AS Lagged_TPV,     LAG(TPO) OVER(PARTITION BY Product_category ORDER BY year, month) AS Lagged_TPO   FROM      monthly_summary )  SELECT    month,   year,   Product_category,   TPV,   TPO,   Lagged_TPV,   Lagged_TPO,   ROUND((TPV - Lagged_TPV) / NULLIF(Lagged_TPV, 0) * 100, 2) AS Revenue_growth,   ROUND((TPO - Lagged_TPO) / NULLIF(Lagged_TPO, 0) * 100, 2) AS Order_growth,   ROUND(SUM(p.cost), 2) AS Total_cost,   ROUND(TPV - SUM(p.cost), 2) AS Total_profit,   ROUND(TPV / NULLIF(SUM(p.cost), 0) * 100, 2) AS Profit_to_cost_ratio FROM    lagged_summary ls JOIN    bigquery-public-data.thelook_ecommerce.products p ON ls.Product_category = p.category  GROUP BY    month, year, Product_category, TPV, TPO, Lagged_TPV, Lagged_TPO;",
        "schema": {
            "bigquery-public-data.thelook_ecommerce": {
                "order_items": [
                    "delivered_at",
                    "sale_price",
                    "order_id",
                    "product_id",
                    "status"
                ],
                "products": [
                    "id",
                    "category",
                    "cost"
                ],
                "orders": [
                    "order_id"
                ]
            }
        }
    },
    "bq259": {
        "query": "with a as(   select     user_id,     format_date('%Y-%m',first_purchase_date) as cohort_date,     created_at,     (extract(year from created_at) - extract(year from first_purchase_date))*12     + (extract(month from created_at) - extract(month from first_purchase_date)) + 1 as index   from (   select     user_id,     min(created_at) over(partition by user_id) as first_purchase_date,     created_at,     from bigquery-public-data.thelook_ecommerce.order_items     where created_at < TIMESTAMP \"2024-01-01 00:00:00 UTC\"   ) b ),  xxx as (   select          cohort_date,         index,         count(distinct user_id) as total_user,   from a    group by cohort_date, index ),   user_cohort as( select   cohort_date,   sum(case when index=1 then total_user else 0 end) as index_0,   sum(case when index=2 then total_user else 0 end) as index_1,   sum(case when index=3 then total_user else 0 end) as index_2,   sum(case when index=4 then total_user else 0 end) as index_3, from xxx group by cohort_date order by cohort_date)  select cohort_date, 100.00 * index_1 / index_0 as First, 100.00 * index_2 / index_0 as Second, 100.00 * index_3 / index_0 as Third, from user_cohort",
        "schema": {
            "bigquery-public-data.thelook_ecommerce": {
                "order_items": [
                    "user_id",
                    "created_at"
                ]
            }
        }
    },
    "bq189": {
        "query": "WITH  monthly_summary AS (   SELECT      FORMAT_DATE('%m', oi.delivered_at) AS Month,     FORMAT_DATE('%Y', oi.delivered_at) AS Year,     p.category AS Product_category,     SUM(oi.sale_price) AS TPV,     COUNT(DISTINCT oi.order_id) AS TPO   FROM      `bigquery-public-data.thelook_ecommerce.order_items` oi   JOIN      `bigquery-public-data.thelook_ecommerce.products` p ON oi.product_id = p.id   JOIN      `bigquery-public-data.thelook_ecommerce.orders` o ON oi.order_id = o.order_id   WHERE     oi.status = 'Complete'   GROUP BY     Month, Year, Product_category   ORDER BY      Year, Month ),  lagged_summary AS (   SELECT      month,     year,     Product_category,     TPV,     TPO,     LAG(TPV) OVER(PARTITION BY Product_category ORDER BY year, month) AS Lagged_TPV,     LAG(TPO) OVER(PARTITION BY Product_category ORDER BY year, month) AS Lagged_TPO   FROM      monthly_summary ),  growth_summary AS (   SELECT      month,     year,     Product_category,     TPV,     TPO,     Lagged_TPV,     Lagged_TPO,     ROUND((TPV - Lagged_TPV) / NULLIF(Lagged_TPV, 0) * 100, 2) AS Revenue_growth,     ROUND((TPO - Lagged_TPO) / NULLIF(Lagged_TPO, 0) * 100, 2) AS Order_growth   FROM      lagged_summary ),  max_order_growth AS (   SELECT      Product_category,     AVG(Order_growth) AS avg_order_growth   FROM      growth_summary   GROUP BY      Product_category   ORDER BY      avg_order_growth DESC   LIMIT 1 )  SELECT    AVG(gs.Revenue_growth) AS average_revenue_growth FROM    growth_summary gs JOIN    max_order_growth mog ON gs.Product_category = mog.Product_category;",
        "schema": {
            "bigquery-public-data.thelook_ecommerce": {
                "order_items": [
                    "delivered_at",
                    "sale_price",
                    "order_id",
                    "product_id",
                    "status"
                ],
                "products": [
                    "id",
                    "category"
                ],
                "orders": [
                    "order_id"
                ]
            }
        }
    },
    "bq260": {
        "query": "WITH filtered_users AS (     SELECT          first_name,          last_name,          gender,          age,         created_at     FROM          bigquery-public-data.thelook_ecommerce.users     WHERE          created_at BETWEEN '2019-01-01' AND '2022-04-30' ), youngest_ages AS (     SELECT          gender,          MIN(age) AS age     FROM          filtered_users     GROUP BY          gender ), oldest_ages AS (     SELECT          gender,          MAX(age) AS age     FROM          filtered_users     GROUP BY          gender ), youngest_oldest AS (     SELECT          u.first_name,          u.last_name,          u.gender,          u.age,          'youngest' AS tag     FROM          filtered_users u     JOIN          youngest_ages y     ON          u.gender = y.gender AND u.age = y.age     UNION ALL     SELECT          u.first_name,          u.last_name,          u.gender,          u.age,          'oldest' AS tag     FROM          filtered_users u     JOIN          oldest_ages o     ON          u.gender = o.gender AND u.age = o.age ) SELECT COUNT(*) AS num  FROM youngest_oldest GROUP BY tag, gender",
        "schema": {
            "bigquery-public-data.thelook_ecommerce": {
                "users": [
                    "first_name",
                    "last_name",
                    "gender",
                    "age",
                    "created_at"
                ]
            }
        }
    },
    "bq261": {
        "query": "WITH product_sales AS (     SELECT          FORMAT_TIMESTAMP('%Y-%m', i.created_at) AS month_year,         p.id AS product_id,         p.name AS product_name,         SUM(i.sale_price) AS sales,         SUM(p.cost) AS cost,         SUM(i.sale_price - p.cost) AS profit     FROM          bigquery-public-data.thelook_ecommerce.order_items AS i     JOIN          bigquery-public-data.thelook_ecommerce.products AS p      ON          i.product_id = p.id     WHERE created_at < TIMESTAMP \"2024-01-01 00:00:00 UTC\"     GROUP BY          month_year, product_id, product_name ),  ranked_products AS (     SELECT          month_year,         product_id,         product_name,         sales,         cost,         profit,         RANK() OVER (PARTITION BY month_year ORDER BY profit DESC) AS rank_per_month     FROM          product_sales )  SELECT      month_year,     product_id,     product_name,     sales,     cost,     profit FROM      ranked_products WHERE      rank_per_month = 1 ORDER BY      month_year;",
        "schema": {
            "bigquery-public-data.thelook_ecommerce": {
                "order_items": [
                    "created_at",
                    "sale_price",
                    "product_id"
                ],
                "products": [
                    "id",
                    "name",
                    "cost"
                ]
            }
        }
    },
    "bq262": {
        "query": "WITH orders_data AS (     SELECT         FORMAT_TIMESTAMP('%Y-%m', o.created_at) AS month,         i.product_id,         COUNT(o.order_id) AS order_count,         SUM(i.sale_price) AS total_sales     FROM          bigquery-public-data.thelook_ecommerce.orders AS o     JOIN          bigquery-public-data.thelook_ecommerce.order_items AS i      ON         o.order_id = i.order_id     WHERE         o.created_at BETWEEN TIMESTAMP('2019-06-01') AND TIMESTAMP('2019-12-31')     GROUP BY          month, i.product_id ), product_data AS (     SELECT          p.id AS product_id,         p.category AS product_category,         p.cost     FROM          bigquery-public-data.thelook_ecommerce.products AS p ), monthly_metrics AS (     SELECT          o.month,         p.product_category,         SUM(o.order_count) AS total_order,         SUM(o.total_sales) AS total_revenue,          SUM(o.total_sales - (p.cost * o.order_count)) AS total_profit      FROM          orders_data AS o     JOIN          product_data AS p     ON          o.product_id = p.product_id     GROUP BY          o.month, p.product_category ), growth_metrics AS (     SELECT          month,         product_category,         total_order,         (total_order - LAG(total_order) OVER (PARTITION BY product_category ORDER BY month)) / LAG(total_order) OVER (PARTITION BY product_category ORDER BY month) * 100 AS order_growth,         total_revenue,         (total_revenue - LAG(total_revenue) OVER (PARTITION BY product_category ORDER BY month)) / LAG(total_revenue) OVER (PARTITION BY product_category ORDER BY month) * 100 AS revenue_growth,         total_profit,         (total_profit - LAG(total_profit) OVER (PARTITION BY product_category ORDER BY month)) / LAG(total_profit) OVER (PARTITION BY product_category ORDER BY month) * 100 AS profit_growth     FROM          monthly_metrics )  SELECT     * FROM      growth_metrics WHERE     month <> '2019-06' ORDER BY     month, product_category ASC;",
        "schema": {
            "bigquery-public-data.thelook_ecommerce": {
                "orders": [
                    "created_at",
                    "order_id"
                ],
                "order_items": [
                    "order_id",
                    "product_id",
                    "sale_price"
                ],
                "products": [
                    "id",
                    "category",
                    "cost"
                ]
            }
        }
    },
    "bq190": {
        "query": "WITH  female_age AS (   SELECT      MIN(age) AS min_age,      MAX(age) AS max_age   FROM      `bigquery-public-data.thelook_ecommerce.users`   WHERE      gender = 'F'      AND created_at BETWEEN '2019-01-01 00:00:00' AND '2022-05-01 00:00:00' ), male_age AS (   SELECT      MIN(age) AS min_age,      MAX(age) AS max_age   FROM      `bigquery-public-data.thelook_ecommerce.users`   WHERE      gender = 'M'      AND created_at BETWEEN '2019-01-01 00:00:00' AND '2022-05-01 00:00:00' ), young_old_group AS (   SELECT t1.first_name, t1.last_name, t1.gender, t1.age   FROM `bigquery-public-data.thelook_ecommerce.users` AS t1   JOIN female_age AS t2 ON t1.age = t2.min_age OR t1.age = t2.max_age   WHERE t1.gender = 'F' AND t1.created_at BETWEEN '2019-01-01 00:00:00' AND '2022-05-01 00:00:00'   UNION ALL   SELECT t3.first_name, t3.last_name, t3.gender, t3.age   FROM `bigquery-public-data.thelook_ecommerce.users` AS t3   JOIN male_age AS t4 ON t3.age = t4.min_age OR t3.age = t4.max_age   WHERE t3.gender = 'M' AND t3.created_at BETWEEN '2019-01-01 00:00:00' AND '2022-05-01 00:00:00' ), age_tag AS (   SELECT *,      CASE        WHEN age IN (SELECT MIN(age)                     FROM `bigquery-public-data.thelook_ecommerce.users`                    WHERE gender = 'F' AND created_at BETWEEN '2019-01-01 00:00:00' AND '2022-05-01 00:00:00')             OR age IN (SELECT MIN(age)                        FROM `bigquery-public-data.thelook_ecommerce.users`                       WHERE gender = 'M' AND created_at BETWEEN '2019-01-01 00:00:00' AND '2022-05-01 00:00:00')             THEN 'Youngest'       ELSE 'Oldest'     END AS tag   FROM young_old_group  ), count_summary AS (   SELECT      gender,      tag,      COUNT(*) AS user_count   FROM      age_tag   GROUP BY      gender, tag ) SELECT    gender,    tag,    user_count FROM    count_summary ORDER BY    gender, tag;",
        "schema": {
            "bigquery-public-data.thelook_ecommerce": {
                "users": [
                    "age",
                    "created_at",
                    "first_name",
                    "gender",
                    "last_name"
                ]
            }
        }
    },
    "bq263": {
        "query": "with d as(     select         a.order_id,          format_date('%Y-%m', a.created_at) as month,         format_date('%Y', a.created_at) as year,         b.product_id, b.sale_price, c.category, c.cost     from bigquery-public-data.thelook_ecommerce.orders as a     JOIN         bigquery-public-data.thelook_ecommerce.order_items as b     on a.order_id = b.order_id     JOIN bigquery-public-data.thelook_ecommerce.products as c     on b.order_id = c.id     where a.status = 'Complete'     and a.created_at BETWEEN TIMESTAMP('2023-01-01') AND TIMESTAMP('2023-12-31')     and c.category = 'Sleep & Lounge' ),  e as (     select month, year, sale_price, category, cost,         sum(sale_price) over(partition by month, category) as TPV,         sum(cost) over(partition by month, category) as total_cost,         count(distinct order_id) over(partition by month, category) as TPO,         sum(sale_price-cost) over(partition by month, category) as total_profit,         sum((sale_price-cost)/cost) over(partition by month, category) as Profit_to_cost_ratio     from d )  select distinct month, category, TPV, total_cost, TPO, total_profit, Profit_to_cost_ratio from e order by month",
        "schema": {
            "bigquery-public-data.thelook_ecommerce": {
                "orders": [
                    "order_id",
                    "created_at",
                    "status"
                ],
                "order_items": [
                    "order_id",
                    "product_id",
                    "sale_price"
                ],
                "products": [
                    "id",
                    "category",
                    "cost"
                ]
            }
        }
    },
    "bq264": {
        "query": "with youngest as (SELECT         gender, id,         first_name,         last_name,         age,         'youngest' AS tag,   FROM `bigquery-public-data.thelook_ecommerce.users`   WHERE age = (SELECT MIN(age) FROM `bigquery-public-data.thelook_ecommerce.users`)         AND (created_at BETWEEN '2019-01-01' AND '2022-04-30')   GROUP BY gender, id, first_name, last_name, age   order by gender),    oldest as (SELECT         gender, id,         first_name,         last_name,         age,         'oldest' AS tag   FROM `bigquery-public-data.thelook_ecommerce.users`   WHERE age = (SELECT MAX(age) FROM `bigquery-public-data.thelook_ecommerce.users`)         AND (created_at BETWEEN '2019-01-01' AND '2022-04-30')   GROUP BY gender, id, first_name, last_name, age   order by gender),    TEMP_record as (   select *   from youngest    union all    select *   from oldest)   select        sum( CASE         WHEN age = (SELECT MAX(age) FROM `bigquery-public-data.thelook_ecommerce.users`) THEN 1       END)- sum( CASE         WHEN age = (SELECT MIN(age) FROM `bigquery-public-data.thelook_ecommerce.users`) THEN 1       END) as diff  from TEMP_record",
        "schema": {
            "bigquery-public-data.thelook_ecommerce": {
                "users": [
                    "gender",
                    "id",
                    "first_name",
                    "last_name",
                    "age",
                    "created_at"
                ]
            }
        }
    },
    "bq197": {
        "query": "WITH  report_monthly_orders_product_agg AS ( SELECT      p.name AS product_name,     p.brand,     p.category,     FORMAT_TIMESTAMP('%Y-%m', o.created_at) AS month,     o.status,     COUNT(o.product_id) AS total_sales,     SUM(o.sale_price) AS total_revenue  FROM      `bigquery-public-data.thelook_ecommerce.products` p LEFT JOIN      `bigquery-public-data.thelook_ecommerce.order_items` o ON      p.id = o.product_id WHERE     o.status = 'Complete'     AND o.created_at < TIMESTAMP('2024-07-01')  GROUP BY      product_name,      month,     o.status,     p.brand,     p.category         HAVING     month IS NOT NULL AND total_revenue IS NOT NULL AND p.brand IS NOT NULL )  SELECT      month,      product_name,      brand,     category,     total_sales,     ROUND(total_revenue, 2) AS total_revenue,     status     FROM      (         SELECT              month,              product_name,             brand,             category,              total_sales,             total_revenue,             status,             ROW_NUMBER() OVER (PARTITION BY month ORDER BY total_sales DESC, total_revenue DESC) as row_num         FROM             report_monthly_orders_product_agg     )  WHERE      row_num = 1 ORDER BY month ASC;",
        "schema": {
            "bigquery-public-data.thelook_ecommerce": {
                "products": [
                    "name",
                    "brand",
                    "category",
                    "id"
                ],
                "order_items": [
                    "created_at",
                    "status",
                    "product_id",
                    "sale_price"
                ]
            }
        }
    },
    "bq265": {
        "query": "WITH   main AS (   SELECT     id AS user_id,     email,     gender,     country,     traffic_source   FROM     `bigquery-public-data.thelook_ecommerce.users`    WHERE     created_at BETWEEN '2019-01-01' AND '2019-12-31'),    daate AS (   SELECT     user_id,     order_id,     EXTRACT (date     FROM       created_at) AS order_date,     num_of_item   FROM     `bigquery-public-data.thelook_ecommerce.orders`    WHERE     created_at BETWEEN '2019-01-01' AND '2019-12-31' ),    orders AS (   SELECT     user_id,     order_id,     product_id,     sale_price,     status   FROM     `bigquery-public-data.thelook_ecommerce.order_items`    WHERE      created_at BETWEEN '2019-01-01' AND '2019-12-31' ),    nest AS (   SELECT     o.user_id,     o.order_id,     o.product_id,     d.order_date,     d.num_of_item,     ROUND(o.sale_price,2)AS sale_price,     ROUND(d.num_of_item*o.sale_price,2) AS total_sale,   FROM     orders o   INNER JOIN     daate d   ON     o.order_id = d.order_id   ORDER BY     o.user_id ),    type AS (   SELECT     user_id,     MIN(nest.order_date) AS cohort_date,     MAX(nest.order_date) AS latest_shopping_date,     DATE_DIFF(MAX(nest.order_date),MIN(nest.order_date),month) AS lifespan_months,     ROUND(SUM(total_sale),2) AS ltv,     COUNT(order_id) AS no_of_order   FROM     nest   GROUP BY     user_id ),    kite AS (   SELECT     m.user_id,     m.email,     m.gender,     m.country,     m.traffic_source,     extract(year from n.cohort_date) as cohort_year,     n.latest_shopping_date,     n.lifespan_months,     n.ltv,     n.no_of_order,     ROUND(n.ltv/n.no_of_order, 2) as avg_order_value   FROM     main m   INNER JOIN     type n   ON     m.user_id = n.user_id )  SELECT   email FROM   kite ORDER BY avg_order_value DESC LIMIT 10",
        "schema": {
            "bigquery-public-data.thelook_ecommerce": {
                "users": [
                    "id",
                    "email",
                    "gender",
                    "country",
                    "traffic_source",
                    "created_at"
                ],
                "orders": [
                    "user_id",
                    "order_id",
                    "created_at",
                    "num_of_item"
                ],
                "order_items": [
                    "user_id",
                    "order_id",
                    "product_id",
                    "sale_price",
                    "status",
                    "created_at"
                ]
            }
        }
    },
    "bq266": {
        "query": "WITH cte AS (   SELECT      t1.id AS product_id,     t1.name,     t1.cost,     t1.retail_price,     t2.created_at,    CONCAT(EXTRACT(YEAR FROM t2.created_at), '-', LPAD(CAST(EXTRACT(MONTH FROM t2.created_at) AS STRING), 2, '0')) AS year_month,     (t1.retail_price - t1.cost) AS profit   FROM      `bigquery-public-data.thelook_ecommerce.products` AS t1   LEFT JOIN      `bigquery-public-data.thelook_ecommerce.order_items` AS t2   ON      t1.id = t2.product_id   WHERE     t2.created_at BETWEEN '2020-01-01' AND '2020-12-31' ),  ranked_cte AS (   SELECT     year_month,     product_id,     name,     cost,     retail_price AS sale,     profit,     DENSE_RANK() OVER (PARTITION BY year_month ORDER BY profit asc) AS rank   FROM      cte ) SELECT   name FROM    ranked_cte WHERE    rank = 1 and year_month is not null ORDER BY year_month",
        "schema": {
            "bigquery-public-data.thelook_ecommerce": {
                "products": [
                    "id",
                    "name",
                    "cost",
                    "retail_price"
                ],
                "order_items": [
                    "product_id",
                    "created_at"
                ]
            }
        }
    },
    "bq271": {
        "query": "WITH orders_x_order_items AS (   SELECT orders.*,          order_items.inventory_item_id,          order_items.sale_price   FROM `bigquery-public-data.thelook_ecommerce.orders` AS orders   LEFT JOIN `bigquery-public-data.thelook_ecommerce.order_items` AS order_items   ON orders.order_id = order_items.order_id   WHERE orders.created_at BETWEEN '2021-01-01' AND '2021-12-31' ),  orders_x_inventory AS (   SELECT orders_x_order_items.*,          inventory_items.product_category,          inventory_items.product_department,          inventory_items.product_retail_price,          inventory_items.product_distribution_center_id,          inventory_items.cost,          distribution_centers.name   FROM orders_x_order_items   LEFT JOIN `bigquery-public-data.thelook_ecommerce.inventory_items` AS inventory_items   ON orders_x_order_items.inventory_item_id = inventory_items.id   LEFT JOIN `bigquery-public-data.thelook_ecommerce.distribution_centers` AS distribution_centers   ON inventory_items.product_distribution_center_id = distribution_centers.id   WHERE inventory_items.created_at BETWEEN '2021-01-01' AND '2021-12-31' ),  orders_x_users AS (   SELECT orders_x_inventory.*,          users.country AS users_country,   FROM orders_x_inventory    LEFT JOIN `bigquery-public-data.thelook_ecommerce.users` AS users   ON orders_x_inventory.user_id = users.id   WHERE users.created_at BETWEEN '2021-01-01' AND '2021-12-31' ),  monthly_order_product_category AS (   SELECT DATE_TRUNC(DATE(created_at),MONTH) AS reporting_month,          users_country,          product_department,          product_category,          COUNT(DISTINCT order_id) AS n_order,          COUNT(DISTINCT user_id) AS n_purchasers,          SUM(product_retail_price) AS total_product_retail_price,          SUM(cost) AS total_cost   FROM orders_x_users   GROUP BY 1,2,3,4   ORDER BY 1,2,3,4 )  SELECT users_country, total_product_retail_price - total_cost AS profit FROM monthly_order_product_category ORDER BY profit DESC LIMIT 1;",
        "schema": {
            "bigquery-public-data.thelook_ecommerce": {
                "orders": [
                    "order_id",
                    "user_id",
                    "created_at"
                ],
                "order_items": [
                    "order_id",
                    "inventory_item_id",
                    "sale_price"
                ],
                "inventory_items": [
                    "id",
                    "product_category",
                    "product_department",
                    "product_retail_price",
                    "product_distribution_center_id",
                    "cost",
                    "created_at"
                ],
                "distribution_centers": [
                    "id",
                    "name"
                ],
                "users": [
                    "id",
                    "country",
                    "created_at"
                ]
            }
        }
    },
    "bq272": {
        "query": "WITH product_profit AS (   SELECT     DATE(DATE_TRUNC(oi.created_at, month)) AS month,     oi.product_id,     p.name,     p.category,     ROUND(SUM(oi.sale_price), 2) AS sum_sales,     ROUND(SUM(p.cost),2) AS sum_cost,     ROUND(SUM(oi.sale_price)-SUM(p.cost),2) AS profit   FROM     `bigquery-public-data.thelook_ecommerce.order_items` oi     LEFT JOIN `bigquery-public-data.thelook_ecommerce.products` p ON oi.product_id = p.id   WHERE     DATE(oi.created_at) BETWEEN '2019-01-01' AND '2022-09-30'     AND oi.status NOT IN ('Cancelled', 'Returned')   GROUP BY     month,     product_id,     name,     category ),   profit_rank AS (   SELECT   month,   product_id,   name,   category,   sum_sales,   sum_cost,   profit,   RANK() OVER(PARTITION BY month ORDER BY profit DESC) AS profit_rank_per_month FROM    product_profit QUALIFY   profit_rank_per_month <= 3 ORDER BY    month,   profit DESC )  SELECT name FROM profit_rank",
        "schema": {
            "bigquery-public-data.thelook_ecommerce": {
                "order_items": [
                    "created_at",
                    "product_id",
                    "sale_price",
                    "status"
                ],
                "products": [
                    "id",
                    "name",
                    "category",
                    "cost"
                ]
            }
        }
    },
    "bq273": {
        "query": "with  orders as (   select     order_id,      user_id,      created_at,     date_trunc(delivered_at, MONTH) as delivery_month,     status    from bigquery-public-data.thelook_ecommerce.orders  ),  order_items as (   select      order_id,      product_id,      sale_price    from bigquery-public-data.thelook_ecommerce.order_items  ),  products as (   select      id,      cost   from bigquery-public-data.thelook_ecommerce.products ),  users as (   select     id,      traffic_source    from bigquery-public-data.thelook_ecommerce.users  ),  filter_join as (   select      orders.order_id,     orders.user_id,     order_items.product_id,     orders.delivery_month,     orders.status,     order_items.sale_price,     products.cost,     users.traffic_source   from orders   join order_items on orders.order_id = order_items.order_id   join products on order_items.product_id = products.id   join users on orders.user_id = users.id   where orders.status = 'Complete'        and users.traffic_source = 'Facebook'       and orders.created_at between '2022-01-01' and '2023-06-30' ),  monthly_sales as (  select      delivery_month,     traffic_source,     sum(sale_price) as total_revenue,     sum(sale_price) - sum(cost) as total_profit,     count(distinct product_id) as product_quantity,     count(distinct order_id) as orders_quantity,     count(distinct user_id) as users_quantity   from filter_join   group by delivery_month, traffic_source ) select    monthly_sales.delivery_month,   monthly_sales.total_profit - lag(monthly_sales.total_profit, 1) over(partition by monthly_sales.traffic_source order by monthly_sales.delivery_month)      as profit_vs_prior_month from monthly_sales order by profit_vs_prior_month DESC limit 5;",
        "schema": {
            "bigquery-public-data.thelook_ecommerce": {
                "orders": [
                    "order_id",
                    "user_id",
                    "created_at",
                    "delivered_at",
                    "status"
                ],
                "order_items": [
                    "order_id",
                    "product_id",
                    "sale_price"
                ],
                "products": [
                    "id",
                    "cost"
                ],
                "users": [
                    "id",
                    "traffic_source"
                ]
            }
        }
    },
    "bq020_1": {
        "query": "SELECT   reference_name FROM (   SELECT     reference_name,     COUNT(reference_name) / r.length AS variant_density,     COUNT(reference_name) AS variant_count,     r.length AS reference_length   FROM     `bigquery-public-data.genomics_cannabis.MNPR01_201703` v,     `bigquery-public-data.genomics_cannabis.MNPR01_reference_201703` r   WHERE     v.reference_name = r.name     AND EXISTS (     SELECT       1     FROM       UNNEST(v.call) AS call     WHERE       EXISTS (       SELECT         1       FROM         UNNEST(call.genotype) AS gt       WHERE         gt > 0))   GROUP BY     reference_name,     r.length ) AS d ORDER BY   variant_density DESC LIMIT    1;",
        "schema": {
            "bigquery-public-data.genomics_cannabis": {
                "MNPR01_201703": [
                    "reference_name",
                    "call.genotype"
                ],
                "MNPR01_reference_201703": [
                    "name",
                    "length"
                ]
            }
        }
    },
    "bq020_2": {
        "query": "WITH density_data AS (   SELECT      reference_name,      COUNT(reference_name) / r.length AS variant_density,      COUNT(reference_name) AS variant_count,      r.length AS reference_length    FROM      `bigquery-public-data.genomics_cannabis.MNPR01_201703` v,      `bigquery-public-data.genomics_cannabis.MNPR01_reference_201703` r    WHERE      v.reference_name= r.name      AND EXISTS (        SELECT          1        FROM          UNNEST(v.call) AS call        WHERE          EXISTS (            SELECT              1            FROM              UNNEST(call.genotype) AS gt            WHERE              gt > 0))    GROUP BY      reference_name,      r.length )  SELECT    * FROM   density_data ORDER BY    reference_length DESC,    reference_name LIMIT 1;",
        "schema": {
            "bigquery-public-data.genomics_cannabis": {
                "MNPR01_201703": [
                    "reference_name",
                    "call.genotype"
                ],
                "MNPR01_reference_201703": [
                    "name",
                    "length"
                ]
            }
        }
    },
    "bq025": {
        "query": "SELECT   age.country_name,   SUM(age.population) AS under_25,   pop.midyear_population AS total,   ROUND((SUM(age.population) / pop.midyear_population) * 100,2) AS pct_under_25 FROM (   SELECT     country_name,     population,     country_code   FROM     `bigquery-public-data.census_bureau_international.midyear_population_agespecific`   WHERE     year =2020     AND age < 20) age INNER JOIN (   SELECT     midyear_population,     country_code   FROM     `bigquery-public-data.census_bureau_international.midyear_population`   WHERE     year = 2020) pop ON   age.country_code = pop.country_code GROUP BY   1,   3 ORDER BY   4 DESC /* Remove limit for visualization */ LIMIT   10",
        "schema": {
            "bigquery-public-data.census_bureau_international": {
                "midyear_population_agespecific": [
                    "country_name",
                    "population",
                    "country_code",
                    "year",
                    "age"
                ],
                "midyear_population": [
                    "midyear_population",
                    "country_code",
                    "year"
                ]
            }
        }
    },
    "bq025_1": {
        "query": "SELECT country_name FROM (SELECT   age.country_name,   SUM(age.population) AS under_25,   pop.midyear_population AS total,   ROUND((SUM(age.population) / pop.midyear_population) * 100,2) AS pct_under_25 FROM (   SELECT     country_name,     population,     country_code   FROM     `bigquery-public-data.census_bureau_international.midyear_population_agespecific`   WHERE     year =2017     AND age < 25) age INNER JOIN (   SELECT     midyear_population,     country_code   FROM     `bigquery-public-data.census_bureau_international.midyear_population`   WHERE     year = 2017) pop ON   age.country_code = pop.country_code GROUP BY   1,   3 ORDER BY   4 DESC ) LIMIT 1",
        "schema": {
            "bigquery-public-data.census_bureau_international": {
                "midyear_population_agespecific": [
                    "country_name",
                    "population",
                    "country_code",
                    "year",
                    "age"
                ],
                "midyear_population": [
                    "midyear_population",
                    "country_code",
                    "year"
                ]
            }
        }
    },
    "bq338": {
        "query": "WITH acs_2017 AS (   SELECT geo_id, median_income AS median_income_2017   FROM `bigquery-public-data.census_bureau_acs.censustract_2017_5yr`     WHERE geo_id LIKE '36047%' --Selecting Brooklyn ),  acs_2010 AS (   SELECT geo_id, median_income AS median_income_2010   FROM `bigquery-public-data.census_bureau_acs.censustract_2010_5yr`    WHERE geo_id LIKE '36047%' --Selecting Brooklyn ),  acs_diff AS (   SELECT     a17.geo_id,      a17.median_income_2017,      a10.median_income_2010,     (a17.median_income_2017 - a10.median_income_2010) AS median_income_diff,      geo.tract_geom AS tract_geom   FROM acs_2017 a17   JOIN acs_2010 a10     ON a17.geo_id = a10.geo_id   JOIN `bigquery-public-data.geo_census_tracts.census_tracts_new_york`geo     ON a17.geo_id = geo.geo_id )  SELECT     geo_id FROM     acs_diff  WHERE     median_income_diff IS NOT NULL ORDER BY     median_income_diff DESC LIMIT 1;",
        "schema": {
            "bigquery-public-data.census_bureau_acs": {
                "censustract_2017_5yr": [
                    "geo_id",
                    "median_income"
                ],
                "censustract_2010_5yr": [
                    "geo_id",
                    "median_income"
                ]
            },
            "bigquery-public-data.geo_census_tracts": {
                "census_tracts_new_york": [
                    "geo_id",
                    "tract_geom"
                ]
            }
        }
    },
    "bq086": {
        "query": "WITH   country_pop AS (   SELECT     country_code AS iso_3166_1_alpha_3,     year_2018 AS population_2018   FROM     `bigquery-public-data.world_bank_global_population.population_by_country`) SELECT   country_code,   country_name,   cumulative_confirmed AS june_confirmed_cases,   population_2018,   ROUND(cumulative_confirmed/population_2018 * 100,2) AS case_percent FROM   `bigquery-public-data.covid19_open_data.covid19_open_data` JOIN   country_pop USING   (iso_3166_1_alpha_3) WHERE   date = '2020-06-30'   AND aggregation_level = 0 ORDER BY   case_percent DESC",
        "schema": {
            "bigquery-public-data.world_bank_global_population": {
                "population_by_country": [
                    "country_code",
                    "year_2018"
                ]
            },
            "bigquery-public-data.covid19_open_data": {
                "covid19_open_data": [
                    "country_code",
                    "country_name",
                    "cumulative_confirmed",
                    "iso_3166_1_alpha_3",
                    "date",
                    "aggregation_level"
                ]
            }
        }
    },
    "bq089": {
        "query": "WITH   num_vaccine_sites_per_county AS (   SELECT     facility_sub_region_1 AS us_state,     facility_sub_region_2 AS us_county,     facility_sub_region_2_code AS us_county_fips,     COUNT(DISTINCT facility_place_id) AS num_vaccine_sites   FROM     bigquery-public-data.covid19_vaccination_access.facility_boundary_us_all   WHERE     STARTS_WITH(facility_sub_region_2_code, \"06\")   GROUP BY     facility_sub_region_1,     facility_sub_region_2,     facility_sub_region_2_code ),   total_population_per_county AS (   SELECT     LEFT(geo_id, 5) AS us_county_fips,     ROUND(SUM(total_pop)) AS total_population   FROM     bigquery-public-data.census_bureau_acs.censustract_2018_5yr   WHERE     STARTS_WITH(LEFT(geo_id, 5), \"06\")   GROUP BY     LEFT(geo_id, 5) ) SELECT   * EXCEPT(us_county_fips),   ROUND((num_vaccine_sites * 1000) / total_population, 2) AS sites_per_1k_ppl FROM   num_vaccine_sites_per_county INNER JOIN   total_population_per_county USING   (us_county_fips) ORDER BY   sites_per_1k_ppl ASC LIMIT   100;",
        "schema": {
            "bigquery-public-data.covid19_vaccination_access": {
                "facility_boundary_us_all": [
                    "facility_sub_region_1",
                    "facility_sub_region_2",
                    "facility_sub_region_2_code",
                    "facility_place_id"
                ]
            },
            "bigquery-public-data.census_bureau_acs": {
                "censustract_2018_5yr": [
                    "geo_id",
                    "total_pop"
                ]
            }
        }
    },
    "bq088": {
        "query": "SELECT   table_2019.avg_symptom_Anxiety_2019,   table_2020.avg_symptom_Anxiety_2020,   ((table_2020.avg_symptom_Anxiety_2020 - table_2019.avg_symptom_Anxiety_2019)/table_2019.avg_symptom_Anxiety_2019) * 100 AS percent_increase_anxiety,   table_2019.avg_symptom_Depression_2019,   table_2020.avg_symptom_Depression_2020,   ((table_2020.avg_symptom_Depression_2020 - table_2019.avg_symptom_Depression_2019)/table_2019.avg_symptom_Depression_2019) * 100 AS percent_increase_depression FROM (   SELECT     AVG(CAST(symptom_Anxiety AS FLOAT64)) AS avg_symptom_Anxiety_2020,     AVG(CAST(symptom_Depression AS FLOAT64)) AS avg_symptom_Depression_2020,   FROM     `bigquery-public-data.covid19_symptom_search.symptom_search_country_weekly`   WHERE     country_region_code = \"US\"     AND date >= '2020-01-01'     AND date <'2021-01-01') AS table_2020,   (   SELECT     AVG(CAST(symptom_Anxiety AS FLOAT64)) AS avg_symptom_Anxiety_2019,     AVG(CAST(symptom_Depression AS FLOAT64)) AS avg_symptom_Depression_2019,   FROM     `bigquery-public-data.covid19_symptom_search.symptom_search_country_weekly`   WHERE     country_region_code = \"US\"     AND date >= '2019-01-01'     AND date <'2020-01-01') AS table_2019",
        "schema": {
            "bigquery-public-data.covid19_symptom_search": {
                "symptom_search_country_weekly": [
                    "symptom_Anxiety",
                    "symptom_Depression",
                    "country_region_code",
                    "date"
                ]
            }
        }
    },
    "bq137": {
        "query": "with zip_pop AS (   SELECT     zip_census.zipcode AS zipcode,     population   FROM     `bigquery-public-data.census_bureau_usa.population_by_zip_2010` AS zip_census   WHERE     (gender LIKE 'male'       OR gender LIKE 'female')     AND minimum_age IS NULL     AND maximum_age IS NULL ) SELECT   zip_area.zipcode_geom AS zipcode_polygon,   zip_area.zipcode AS zipcode,   area_land_meters,   area_water_meters,   ST_GeogPoint(longitude,     latitude) AS lat_lon,   state_code,   state_name,   city,   county,   population FROM   `bigquery-public-data.utility_us.zipcode_area` AS zip_area JOIN   zip_pop ON   zip_area.zipcode = zip_pop.zipcode WHERE   ST_DWITHIN(ST_GeogPoint(longitude,latitude),   ST_GeogPoint(-122.3321,47.6062),10000)",
        "schema": {
            "bigquery-public-data.census_bureau_usa": {
                "population_by_zip_2010": [
                    "zipcode",
                    "population",
                    "gender",
                    "minimum_age",
                    "maximum_age"
                ]
            },
            "bigquery-public-data.utility_us": {
                "zipcode_area": [
                    "zipcode_geom",
                    "zipcode",
                    "area_land_meters",
                    "area_water_meters",
                    "longitude",
                    "latitude",
                    "state_code",
                    "state_name",
                    "city",
                    "county"
                ]
            }
        }
    },
    "bq023": {
        "query": "with median_income_by_geo as (     select         geo_id         , median_income      from `bigquery-public-data.census_bureau_acs.censustract_2018_5yr` )  , donations_by_zip as (     select         zip_code         , transaction_amt     from `bigquery-public-data.fec.indiv20`      where state = 'NY' )  , zip_to_geo as (     select         zip_code         , census_tract_geoid      from `bigquery-public-data.hud_zipcode_crosswalk.zipcode_to_census_tracts` )  , avg_donations_by_geo_id as (     select         zip_to_geo.census_tract_geoid as geo_id         , sum(donations_by_zip.transaction_amt) as average_donation     from donations_by_zip     join zip_to_geo     on zip_to_geo.zip_code = donations_by_zip.zip_code     group by 1 )  , census_tracts_kings as (     select          geo_id         , tract_ce         , tract_geom     from `bigquery-public-data.geo_census_tracts.census_tracts_new_york`     where county_fips_code = '047'     and state_fips_code = '36' )  select      census_tracts_kings.tract_ce as census_tract     , avg_donations_by_geo_id.average_donation     , median_income_by_geo.median_income from      census_tracts_kings     LEFT JOIN avg_donations_by_geo_id       ON census_tracts_kings.geo_id = avg_donations_by_geo_id.geo_id     LEFT join median_income_by_geo     on census_tracts_kings.geo_id = median_income_by_geo.geo_id order by census_tract;",
        "schema": {
            "bigquery-public-data.census_bureau_acs.censustract_2018_5yr": {
                "censustract_2018_5yr": [
                    "geo_id",
                    "median_income"
                ]
            },
            "bigquery-public-data.fec.indiv20": {
                "indiv20": [
                    "zip_code",
                    "transaction_amt",
                    "state"
                ]
            },
            "bigquery-public-data.hud_zipcode_crosswalk.zipcode_to_census_tracts": {
                "zipcode_to_census_tracts": [
                    "zip_code",
                    "census_tract_geoid"
                ]
            },
            "bigquery-public-data.geo_census_tracts.census_tracts_new_york": {
                "census_tracts_new_york": [
                    "geo_id",
                    "tract_ce",
                    "tract_geom",
                    "county_fips_code",
                    "state_fips_code"
                ]
            }
        }
    },
    "bq060": {
        "query": "WITH results AS (     SELECT         growth.country_name,         growth.net_migration,         CAST(area.country_area as INT64) as country_area     FROM (         SELECT             country_name,             net_migration,             country_code         FROM             `bigquery-public-data.census_bureau_international.birth_death_growth_rates`         WHERE             year = 2017     ) growth     INNER JOIN (         SELECT             country_area,             country_code         FROM             `bigquery-public-data.census_bureau_international.country_names_area`         WHERE             country_area > 500     ) area     ON         growth.country_code = area.country_code     ORDER BY         net_migration DESC     LIMIT 3 ) SELECT country_name, net_migration FROM results;",
        "schema": {
            "bigquery-public-data.census_bureau_international": {
                "birth_death_growth_rates": [
                    "country_name",
                    "net_migration",
                    "country_code",
                    "year"
                ],
                "country_names_area": [
                    "country_area",
                    "country_code"
                ]
            }
        }
    },
    "bq061": {
        "query": "WITH acs_2018 AS (     SELECT       geo_id,       median_income AS median_income_2018     FROM       `bigquery-public-data.census_bureau_acs.censustract_2018_5yr`  ), acs_2015 AS (     SELECT       geo_id,       median_income AS median_income_2015     FROM       `bigquery-public-data.census_bureau_acs.censustract_2015_5yr` ), acs_diff AS (     SELECT       a18.geo_id,       a18.median_income_2018,       a15.median_income_2015,       (a18.median_income_2018 - a15.median_income_2015) AS median_income_diff,     FROM       acs_2018 a18     JOIN       acs_2015 a15     ON       a18.geo_id = a15.geo_id ), max_geo_id AS (     SELECT       geo_id     FROM       acs_diff     WHERE       median_income_diff IS NOT NULL       AND acs_diff.geo_id in (         SELECT           geo_id         FROM           `bigquery-public-data.geo_census_tracts.census_tracts_california`       )     ORDER BY       median_income_diff DESC     LIMIT 1 ) SELECT     tracts.tract_ce as tract_code FROM     max_geo_id JOIN     `bigquery-public-data.geo_census_tracts.census_tracts_california` AS tracts ON     max_geo_id.geo_id = tracts.geo_id;",
        "schema": {
            "bigquery-public-data.census_bureau_acs.censustract_2018_5yr": {
                "censustract_2018_5yr": [
                    "geo_id",
                    "median_income"
                ]
            },
            "bigquery-public-data.census_bureau_acs.censustract_2015_5yr": {
                "censustract_2015_5yr": [
                    "geo_id",
                    "median_income"
                ]
            },
            "bigquery-public-data.geo_census_tracts.census_tracts_california": {
                "census_tracts_california": [
                    "geo_id",
                    "tract_ce"
                ]
            }
        }
    },
    "bq064": {
        "query": "WITH all_zip_tract_join AS (   SELECT      zips.zip_code,      zips.functional_status as zip_functional_status,     tracts.tract_ce,      tracts.geo_id as tract_geo_id,      tracts.functional_status as tract_functional_status,     ST_Area(ST_Intersection(tracts.tract_geom, zips.zip_code_geom))         / ST_Area(tracts.tract_geom) as tract_pct_in_zip_code   FROM       `bigquery-public-data.geo_census_tracts.us_census_tracts_national` tracts,     `bigquery-public-data.geo_us_boundaries.zip_codes` zips   WHERE      ST_Intersects(tracts.tract_geom, zips.zip_code_geom) ), zip_tract_join AS (   SELECT * FROM all_zip_tract_join WHERE tract_pct_in_zip_code > 0 ), census_totals AS (   -- convert averages to additive totals   SELECT      geo_id,     total_pop,     total_pop * income_per_capita AS total_income    FROM      `bigquery-public-data.census_bureau_acs.censustract_2017_5yr`  ), joined AS (    -- join with precomputed census/zip pairs,   -- compute zip's share of tract   SELECT      zip_code,      total_pop * tract_pct_in_zip_code    AS zip_pop,     total_income * tract_pct_in_zip_code AS zip_income   FROM census_totals c   JOIN zip_tract_join ztj   ON c.geo_id = ztj.tract_geo_id ), sums AS (    -- aggregate all \"pieces\" of zip code   SELECT     zip_code,      SUM(zip_pop) AS zip_pop,     SUM(zip_income) AS zip_total_inc   FROM joined    GROUP BY zip_code ), zip_pop_income AS (     SELECT          zip_code, zip_pop,          -- convert to averages         zip_total_inc / zip_pop AS income_per_capita     FROM sums ), zipcodes_within_distance as (     SELECT          zip_code, zip_code_geom     FROM          `bigquery-public-data.geo_us_boundaries.zip_codes`     WHERE         ST_DWithin(             ST_GeogPoint(-122.191667, 47.685833),             zip_code_geom,             1609 * 5         ) ) select    stats.zip_code,   ROUND(stats.zip_pop, 1) as zip_population,   ROUND(stats.income_per_capita, 1) as average_income from    zipcodes_within_distance area join    zip_pop_income stats on area.zip_code = stats.zip_code ORDER BY     average_income DESC;",
        "schema": {
            "bigquery-public-data.census_bureau_acs.censustract_2017_5yr": {
                "censustract_2017_5yr": [
                    "geo_id",
                    "total_pop",
                    "income_per_capita"
                ]
            },
            "bigquery-public-data.geo_census_tracts.us_census_tracts_national": {
                "us_census_tracts_national": [
                    "tract_ce",
                    "tract_geo_id",
                    "functional_status",
                    "tract_geom"
                ]
            },
            "bigquery-public-data.geo_us_boundaries.zip_codes": {
                "zip_codes": [
                    "zip_code",
                    "functional_status",
                    "zip_code_geom"
                ]
            }
        }
    },
    "bq198": {
        "query": "SELECT   team_name,   COUNT(*) AS top_performer_count FROM (   SELECT     DISTINCT c2.season,     c2.market AS team_name   FROM (     SELECT       season AS a,       MAX(wins) AS win_max     FROM       `bigquery-public-data.ncaa_basketball.mbb_historical_teams_seasons`     WHERE       season<=2000       AND season >=1900     GROUP BY       season ),     `bigquery-public-data.ncaa_basketball.mbb_historical_teams_seasons` c2   WHERE     win_max = c2.wins     AND a = c2.season     AND c2.market IS NOT NULL   ORDER BY     c2.season) GROUP BY   team_name ORDER BY   top_performer_count DESC,   team_name LIMIT   5",
        "schema": {
            "bigquery-public-data.ncaa_basketball": {
                "mbb_historical_teams_seasons": [
                    "season",
                    "wins",
                    "market"
                ]
            }
        }
    },
    "bq055": {
        "query": "WITH google_data AS (     SELECT         'Google Hiring' AS data_source,         race_asian,         race_black,         race_hispanic_latinx,         race_native_american,         race_white,     FROM `bigquery-public-data.google_dei.dar_non_intersectional_hiring`     WHERE         workforce = 'overall'         AND report_year = 2023 ),  bls_data AS (     SELECT         percent_asian AS race_asian,         percent_black_or_african_american AS race_black,         percent_hispanic_or_latino AS race_hispanic_latinx,         NULL AS race_native_american,         percent_white AS race_white,     FROM `bigquery-public-data.bls.cpsaat18`     WHERE year = 2022           AND ((subsector IN (                   'Internet publishing and broadcasting and web search portals',                   'Software publishers',                   'Data processing, hosting, and related services')                 AND industry_group IS NULL                 AND industry IS NULL)               OR (industry_group = 'Computer systems design and related services'                 AND industry IS NULL)) ),  bls_averages AS (     SELECT         AVG(race_asian) AS avg_race_asian,         AVG(race_black) AS avg_race_black,         AVG(race_hispanic_latinx) AS avg_race_hispanic_latinx,         AVG(race_native_american) AS avg_race_native_american,         AVG(race_white) AS avg_race_white     FROM bls_data ),  google_bl_difference AS (     SELECT         'asian' AS race,         ABS(google.race_asian - bls.avg_race_asian) AS diff     FROM google_data google, bls_averages bls     UNION ALL     SELECT         'black' AS race,         ABS(google.race_black - bls.avg_race_black) AS diff     FROM google_data google, bls_averages bls     UNION ALL     SELECT         'hispanic_latinx' AS race,         ABS(google.race_hispanic_latinx - bls.avg_race_hispanic_latinx) AS diff     FROM google_data google, bls_averages bls     UNION ALL     SELECT         'native_american' AS race,         ABS(google.race_native_american - bls.avg_race_native_american) AS diff     FROM google_data google, bls_averages bls     UNION ALL     SELECT         'white' AS race,         ABS(google.race_white - bls.avg_race_white) AS diff     FROM google_data google, bls_averages bls )  SELECT     race,     diff FROM google_bl_difference ORDER BY diff DESC LIMIT 3;",
        "schema": {
            "bigquery-public-data.google_dei": {
                "dar_non_intersectional_hiring": [
                    "race_asian",
                    "race_black",
                    "race_hispanic_latinx",
                    "race_native_american",
                    "race_white",
                    "workforce",
                    "report_year"
                ]
            },
            "bigquery-public-data.bls": {
                "cpsaat18": [
                    "percent_asian",
                    "percent_black_or_african_american",
                    "percent_hispanic_or_latino",
                    "percent_white",
                    "year",
                    "subsector",
                    "industry_group",
                    "industry"
                ]
            }
        }
    },
    "bq268": {
        "query": "WITH   visit AS ( SELECT fullvisitorid, MIN(date) AS date_first_visit, MAX(date) AS date_last_visit  FROM `bigquery-public-data.google_analytics_sample.ga_sessions_*` GROUP BY fullvisitorid),  device_visit AS ( SELECT DISTINCT fullvisitorid, date, device.deviceCategory FROM `bigquery-public-data.google_analytics_sample.ga_sessions_*`),  transactions AS ( SELECT fullvisitorid, MIN(date) AS date_transactions, 1 AS transaction FROM `bigquery-public-data.google_analytics_sample.ga_sessions_*` AS ga, UNNEST(ga.hits) AS hits WHERE  hits.transaction.transactionId IS NOT NULL GROUP BY fullvisitorid),  device_transactions AS ( SELECT DISTINCT fullvisitorid, date, device.deviceCategory FROM `bigquery-public-data.google_analytics_sample.ga_sessions_*` AS ga, UNNEST(ga.hits) AS hits WHERE hits.transaction.transactionId IS NOT NULL),  visits_transactions AS ( SELECT visit.fullvisitorid, date_first_visit, date_transactions, date_last_visit ,         device_visit.deviceCategory AS device_last_visit, device_transactions.deviceCategory AS device_transaction,         IFNULL(transactions.transaction,0) AS transaction FROM visit LEFT JOIN transactions ON visit.fullvisitorid = transactions.fullvisitorid LEFT JOIN device_visit ON visit.fullvisitorid = device_visit.fullvisitorid  AND visit.date_last_visit = device_visit.date  LEFT JOIN device_transactions ON visit.fullvisitorid = device_transactions.fullvisitorid  AND transactions.date_transactions = device_transactions.date ),  mortality_table AS ( SELECT fullvisitorid, date_first_visit,         CASE WHEN date_transactions IS NULL THEN date_last_visit ELSE date_transactions  END AS date_event,         CASE WHEN device_transaction IS NULL THEN device_last_visit ELSE device_transaction END AS device, transaction FROM visits_transactions )  SELECT DATE_DIFF(PARSE_DATE('%Y%m%d',date_event), PARSE_DATE('%Y%m%d', date_first_visit),DAY) AS time  FROM mortality_table WHERE device = 'mobile' ORDER BY DATE_DIFF(PARSE_DATE('%Y%m%d',date_event), PARSE_DATE('%Y%m%d', date_first_visit),DAY) DESC LIMIT 1",
        "schema": {
            "bigquery-public-data.google_analytics_sample": {
                "ga_sessions_*": [
                    "fullvisitorid",
                    "date",
                    "device.deviceCategory",
                    "hits.transaction.transactionId"
                ]
            }
        }
    },
    "bq269": {
        "query": "WITH    cte1 AS     (SELECT       CONCAT(EXTRACT(YEAR FROM (PARSE_DATE('%Y%m%d', date))),'0',             EXTRACT(MONTH FROM (PARSE_DATE('%Y%m%d', date)))) AS month,       SUM(totals.pageviews)/COUNT(DISTINCT fullVisitorId) AS avg_pageviews_non_purchase     FROM `bigquery-public-data.google_analytics_sample.ga_sessions_2017*`,       UNNEST (hits) AS hits,       UNNEST (hits.product) AS product     WHERE _table_suffix BETWEEN '0601' AND '0731'       AND totals.transactions IS NULL       AND product.productRevenue IS NULL     GROUP BY month),   cte2 AS     (SELECT       CONCAT(EXTRACT(YEAR FROM (PARSE_DATE('%Y%m%d', date))),'0',             EXTRACT(MONTH FROM (PARSE_DATE('%Y%m%d', date)))) AS month,       SUM(totals.pageviews)/COUNT(DISTINCT fullVisitorId) AS avg_pageviews_purchase     FROM `bigquery-public-data.google_analytics_sample.ga_sessions_2017*`,       UNNEST (hits) AS hits,       UNNEST (hits.product) AS product     WHERE _table_suffix BETWEEN '0601' AND '0731'       AND totals.transactions >= 1       AND product.productRevenue IS NOT NULL     GROUP BY month) SELECT month, avg_pageviews_purchase, avg_pageviews_non_purchase FROM cte1 INNER JOIN cte2 USING(month) ORDER BY month;",
        "schema": {
            "bigquery-public-data.google_analytics_sample": {
                "ga_sessions_2017*": [
                    "date",
                    "totals.pageviews",
                    "fullVisitorId",
                    "totals.transactions",
                    "hits.product.productRevenue"
                ]
            }
        }
    },
    "bq270": {
        "query": "WITH   cte1 AS     (SELECT       CONCAT(EXTRACT(YEAR FROM (PARSE_DATE('%Y%m%d', date))),'0',                 EXTRACT(MONTH FROM (PARSE_DATE('%Y%m%d', date)))) AS month,       COUNT(hits.eCommerceAction.action_type) AS num_product_view     FROM `bigquery-public-data.google_analytics_sample.ga_sessions_2017*`,       UNNEST(hits) AS hits     WHERE _table_suffix BETWEEN '0101' AND '0331'       AND hits.eCommerceAction.action_type = '2'     GROUP BY month),   cte2 AS     (SELECT       CONCAT(EXTRACT(YEAR FROM (PARSE_DATE('%Y%m%d', date))),'0',                 EXTRACT(MONTH FROM (PARSE_DATE('%Y%m%d', date)))) AS month,       COUNT(hits.eCommerceAction.action_type) AS num_addtocart     FROM `bigquery-public-data.google_analytics_sample.ga_sessions_2017*`,       UNNEST(hits) AS hits     WHERE _table_suffix BETWEEN '0101' AND '0331'       AND hits.eCommerceAction.action_type = '3'     GROUP BY month),   cte3 AS     (SELECT       CONCAT(EXTRACT(YEAR FROM (PARSE_DATE('%Y%m%d', date))),'0',                 EXTRACT(MONTH FROM (PARSE_DATE('%Y%m%d', date)))) AS month,       COUNT(hits.eCommerceAction.action_type) AS num_purchase     FROM `bigquery-public-data.google_analytics_sample.ga_sessions_2017*`,       UNNEST(hits) AS hits,       UNNEST(hits.product) AS product     WHERE _table_suffix BETWEEN '0101' AND '0331'       AND hits.eCommerceAction.action_type = '6'       AND product.productRevenue IS NOT NULL     GROUP BY month) SELECT    ROUND((num_addtocart/num_product_view * 100),2) AS add_to_cart_rate,   ROUND((num_purchase/num_product_view * 100),2) AS purchase_rate FROM cte1   LEFT JOIN cte2   USING(month)    LEFT JOIN cte3   USING(month) ORDER BY month;",
        "schema": {
            "bigquery-public-data.google_analytics_sample": {
                "ga_sessions_2017*": [
                    "date",
                    "hits.eCommerceAction.action_type",
                    "hits.product.productRevenue",
                    "_table_suffix"
                ]
            }
        }
    },
    "bq275": {
        "query": "WITH    visit AS (     SELECT fullvisitorid, MIN(date) AS date_first_visit     FROM `bigquery-public-data.google_analytics_sample.ga_sessions_*`      GROUP BY fullvisitorid   ),      transactions AS (     SELECT fullvisitorid, MIN(date) AS date_transactions, 1 AS transaction     FROM `bigquery-public-data.google_analytics_sample.ga_sessions_*` AS ga,      UNNEST(ga.hits) AS hits      WHERE hits.transaction.transactionId IS NOT NULL      GROUP BY fullvisitorid   ),    device_transactions AS (     SELECT DISTINCT fullvisitorid, date, device.deviceCategory AS device_transaction     FROM `bigquery-public-data.google_analytics_sample.ga_sessions_*` AS ga,      UNNEST(ga.hits) AS hits      WHERE hits.transaction.transactionId IS NOT NULL   ),    visits_transactions AS (     SELECT visit.fullvisitorid, date_first_visit, date_transactions, device_transaction     FROM visit      LEFT JOIN transactions ON visit.fullvisitorid = transactions.fullvisitorid     LEFT JOIN device_transactions ON visit.fullvisitorid = device_transactions.fullvisitorid      AND transactions.date_transactions = device_transactions.date   )  SELECT fullvisitorid  FROM visits_transactions WHERE DATE_DIFF(PARSE_DATE('%Y%m%d', date_transactions), PARSE_DATE('%Y%m%d', date_first_visit), DAY) > 0 AND device_transaction = \"mobile\";",
        "schema": {
            "bigquery-public-data.google_analytics_sample": {
                "ga_sessions_*": [
                    "fullvisitorid",
                    "date",
                    "hits.transaction.transactionId",
                    "device.deviceCategory"
                ]
            }
        }
    },
    "bq016": {
        "query": "DECLARE     Sys STRING DEFAULT 'PYPI';  WITH HighestReleases AS (     SELECT         Name,         Version,     FROM (         SELECT             Name,             Version,             ROW_NUMBER() OVER (                 PARTITION BY Name                 ORDER BY VersionInfo.Ordinal DESC             ) AS RowNumber         FROM             `spider2-public-data.deps_dev_v1.PackageVersions`         WHERE             System = Sys             AND VersionInfo.IsRelease     )     WHERE RowNumber = 1 )  SELECT     D.Dependency.Name,     D.Dependency.Version FROM     `spider2-public-data.deps_dev_v1.Dependencies` AS D JOIN     HighestReleases AS H USING     (Name, Version) WHERE     D.System = Sys GROUP BY     D.Dependency.Name,     D.Dependency.Version ORDER BY     COUNT(*) DESC LIMIT 1;",
        "schema": {
            "spider2-public-data.deps_dev_v1": {
                "PackageVersions": [
                    "Name",
                    "Version",
                    "VersionInfo.Ordinal",
                    "VersionInfo.IsRelease",
                    "System"
                ],
                "Dependencies": [
                    "Dependency.Name",
                    "Dependency.Version",
                    "System"
                ]
            }
        }
    },
    "bq062": {
        "query": "WITH Counts AS (     SELECT         System,         License,         COUNT(DISTINCT Name) AS NPackages     FROM         `spider2-public-data.deps_dev_v1.PackageVersions`     CROSS JOIN         UNNEST(Licenses) AS License     GROUP BY         System,         License ), Ranked AS (     SELECT         System,         License,         NPackages,         ROW_NUMBER() OVER (PARTITION BY System ORDER BY NPackages DESC) AS LicenseRank     FROM Counts ) SELECT     System,     License FROM     Ranked WHERE     LicenseRank <= 1 ORDER BY     System,     LicenseRank;",
        "schema": {
            "spider2-public-data.deps_dev_v1": {
                "PackageVersions": [
                    "System",
                    "Name",
                    "Licenses"
                ]
            }
        }
    },
    "bq063": {
        "query": "DECLARE     Sys STRING DEFAULT 'NPM';  WITH HighestReleases AS (     SELECT         Name,         Version,     FROM (         SELECT             Name,             Version,             ROW_NUMBER() OVER (                 PARTITION BY Name                 ORDER BY VersionInfo.Ordinal DESC             ) AS RowNumber         FROM             `bigquery-public-data.deps_dev_v1.PackageVersions`         WHERE             System = Sys             AND VersionInfo.IsRelease)     WHERE RowNumber = 1 ),  TopDependencies AS (     SELECT         D.Name,         D.Version,         COUNT(*) AS NDependencies     FROM         `spider2-public-data.deps_dev_v1.Dependencies` AS D     JOIN         HighestReleases AS H     ON         D.Name = H.Name AND D.Version = H.Version     WHERE         D.System = Sys     GROUP BY         Name,         Version     ORDER BY         NDependencies DESC     LIMIT 100 )  SELECT     lnk.URL FROM      `spider2-public-data.deps_dev_v1.PackageVersions` AS P,     unnest(Links) as lnk JOIN      TopDependencies AS T ON     T.Name = P.Name AND T.Version = P.Version WHERE     P.System = Sys     AND P.Name NOT LIKE '%@%'     AND lnk.Label = 'SOURCE_REPO'     AND lower(lnk.URL) LIKE '%github.com%' ORDER BY T.NDependencies DESC LIMIT 1;",
        "schema": {
            "bigquery-public-data.deps_dev_v1": {
                "PackageVersions": [
                    "Name",
                    "Version",
                    "System",
                    "VersionInfo.Ordinal",
                    "VersionInfo.IsRelease",
                    "Links"
                ],
                "Dependencies": [
                    "Name",
                    "Version",
                    "System"
                ]
            },
            "spider2-public-data.deps_dev_v1": {
                "Dependencies": [
                    "Name",
                    "Version"
                ],
                "PackageVersions": [
                    "Name",
                    "Version",
                    "System",
                    "URL",
                    "Label"
                ]
            }
        }
    },
    "bq028": {
        "query": "DECLARE     Sys STRING DEFAULT 'NPM';  WITH HighestReleases AS (     SELECT         Name,         Version     FROM (         SELECT             Name,             Version,             ROW_NUMBER() OVER (                 PARTITION BY Name                 ORDER BY VersionInfo.Ordinal DESC             ) AS RowNumber         FROM             `spider2-public-data.deps_dev_v1.PackageVersions`         WHERE             System = Sys             AND VersionInfo.IsRelease     )     WHERE RowNumber = 1 ), PVP AS (     SELECT         Name, Version, ProjectType, ProjectName     FROM         `spider2-public-data.deps_dev_v1.PackageVersionToProject`     JOIN         HighestReleases AS HR     USING (Name, Version)     WHERE         System = Sys         AND ProjectType = 'GITHUB' ) SELECT PVP.Name, PVP.Version FROM     PVP JOIN     `spider2-public-data.deps_dev_v1.Projects` AS P ON     PVP.ProjectType = P.Type AND PVP.ProjectName = P.Name ORDER BY P.StarsCount DESC LIMIT 3;",
        "schema": {
            "spider2-public-data.deps_dev_v1": {
                "PackageVersions": [
                    "Name",
                    "Version",
                    "System",
                    "VersionInfo.Ordinal",
                    "VersionInfo.IsRelease"
                ],
                "PackageVersionToProject": [
                    "Name",
                    "Version",
                    "ProjectType",
                    "ProjectName",
                    "System"
                ],
                "Projects": [
                    "Type",
                    "Name",
                    "StarsCount"
                ]
            }
        }
    },
    "bq022": {
        "query": "SELECT   FORMAT('%02.0fm to %02.0fm', min_minutes, max_minutes) AS minutes_range,   SUM(trips) AS total_trips,   FORMAT('%3.2f', SUM(total_fare) / SUM(trips)) AS average_fare FROM (   SELECT     MIN(duration_in_minutes) OVER (quantiles) AS min_minutes,     MAX(duration_in_minutes) OVER (quantiles) AS max_minutes,     SUM(trips) AS trips,     SUM(total_fare) AS total_fare   FROM (     SELECT       ROUND(trip_seconds / 60) AS duration_in_minutes,       NTILE(6) OVER (ORDER BY trip_seconds / 60) AS quantile,       COUNT(1) AS trips,       SUM(fare) AS total_fare     FROM       `bigquery-public-data.chicago_taxi_trips.taxi_trips`     WHERE       trip_seconds BETWEEN 0 AND 3600     GROUP BY       trip_seconds,       duration_in_minutes )   GROUP BY     duration_in_minutes,     quantile   WINDOW quantiles AS (PARTITION BY quantile)   ) GROUP BY   minutes_range ORDER BY   minutes_range",
        "schema": {
            "bigquery-public-data.chicago_taxi_trips": {
                "taxi_trips": [
                    "trip_seconds",
                    "fare"
                ]
            }
        }
    },
    "bq076": {
        "query": "SELECT   incidents AS highest_monthly_thefts FROM (   SELECT     year,     EXTRACT(MONTH FROM date) AS month,     COUNT(1) AS incidents,     RANK() OVER (PARTITION BY year ORDER BY COUNT(1) DESC) AS ranking   FROM     `bigquery-public-data.chicago_crime.crime`   WHERE     primary_type = 'MOTOR VEHICLE THEFT'     AND year = 2016   GROUP BY     year,     month ) WHERE   ranking = 1 ORDER BY   year DESC LIMIT 1;",
        "schema": {
            "bigquery-public-data.chicago_crime": {
                "crime": [
                    "date",
                    "primary_type",
                    "year"
                ]
            }
        }
    },
    "bq077": {
        "query": "SELECT   year,   incidents FROM (   SELECT     year,     EXTRACT(MONTH     FROM       date) AS month,     COUNT(1) AS incidents,     RANK() OVER (PARTITION BY year ORDER BY COUNT(1) DESC) AS ranking   FROM     `bigquery-public-data.chicago_crime.crime`   WHERE     primary_type = 'MOTOR VEHICLE THEFT'     AND year BETWEEN 2010 AND 2016   GROUP BY     year,     month ) WHERE   ranking = 1 ORDER BY   year ASC",
        "schema": {
            "bigquery-public-data.chicago_crime": {
                "crime": [
                    "year",
                    "date",
                    "primary_type"
                ]
            }
        }
    },
    "bq350": {
        "query": "DECLARE   my_drug_list ARRAY<STRING>; SET   my_drug_list = [   'Keytruda',   'Vioxx',   'Humira',   'Premarin' ];  SELECT   id AS drug_id,   tradeNameList.element AS drug_trade_name,   drugType AS drug_type,   hasBeenWithdrawn AS drug_withdrawn FROM   `open-targets-prod.platform.molecule`,   UNNEST (tradeNames.list) AS tradeNameList WHERE   tradeNameList.element IN UNNEST(my_drug_list)   AND isApproved = TRUE   AND blackBoxWarning = TRUE   AND drugType != 'Unknown';",
        "schema": {
            "open-targets-prod.platform": {
                "molecule": [
                    "id",
                    "tradeNames.list",
                    "drugType",
                    "hasBeenWithdrawn",
                    "isApproved",
                    "blackBoxWarning"
                ]
            }
        }
    },
    "bq351_1": {
        "query": "WITH AvgScore AS (   SELECT     AVG(associations.score) AS avg_score   FROM     `open-targets-prod.platform.associationByOverallDirect` AS associations   JOIN     `open-targets-prod.platform.diseases` AS diseases   ON     associations.diseaseId = diseases.id   WHERE     diseases.name = 'psoriasis' ) SELECT   targets.approvedSymbol AS target_approved_symbol FROM   `open-targets-prod.platform.associationByOverallDirect` AS associations JOIN   `open-targets-prod.platform.diseases` AS diseases ON   associations.diseaseId = diseases.id JOIN   `open-targets-prod.platform.targets` AS targets ON   associations.targetId = targets.id CROSS JOIN   AvgScore WHERE   diseases.name = 'psoriasis' ORDER BY   ABS(associations.score - AvgScore.avg_score) ASC LIMIT 1",
        "schema": {
            "open-targets-prod.platform": {
                "associationByOverallDirect": [
                    "score",
                    "diseaseId",
                    "targetId"
                ],
                "diseases": [
                    "id",
                    "name"
                ],
                "targets": [
                    "id",
                    "approvedSymbol"
                ]
            }
        }
    },
    "bq109": {
        "query": "WITH coloc_stats AS (   SELECT     coloc.coloc_log2_h4_h3,     coloc.right_study AS qtl_source   FROM     `open-targets-genetics.genetics.variant_disease_coloc` AS coloc   JOIN     `open-targets-genetics.genetics.studies` AS studies   ON     coloc.left_study = studies.study_id   WHERE     coloc.right_gene_id = \"ENSG00000169174\"     AND coloc.coloc_h4 > 0.8     AND coloc.coloc_h3 < 0.02     AND studies.trait_reported LIKE \"%lesterol levels%\"     AND coloc.right_bio_feature = 'IPSC'     AND CONCAT(coloc.left_chrom, '_', coloc.left_pos, '_', coloc.left_ref, '_', coloc.left_alt) = '1_55029009_C_T' ), max_value AS (   SELECT     MAX(coloc_log2_h4_h3) AS max_log2_h4_h3   FROM     coloc_stats )  SELECT   AVG(coloc_log2_h4_h3) AS average,   VAR_SAMP(coloc_log2_h4_h3) AS variance,   MAX(coloc_log2_h4_h3) - MIN(coloc_log2_h4_h3) AS max_min_difference,   (SELECT qtl_source FROM coloc_stats WHERE coloc_log2_h4_h3 = (SELECT max_log2_h4_h3 FROM max_value)) AS qtl_source_of_max FROM   coloc_stats;",
        "schema": {
            "open-targets-genetics.genetics": {
                "variant_disease_coloc": [
                    "coloc_log2_h4_h3",
                    "right_study",
                    "left_study",
                    "right_gene_id",
                    "coloc_h4",
                    "coloc_h3",
                    "right_bio_feature",
                    "left_chrom",
                    "left_pos",
                    "left_ref",
                    "left_alt"
                ],
                "studies": [
                    "study_id",
                    "trait_reported"
                ]
            }
        }
    },
    "bq084": {
        "query": "SELECT   COUNT(*) AS TXN_COUNT_PER_MONTH,   COUNT(*) /      CASE        WHEN EXTRACT(MONTH FROM MIN(txn.block_timestamp)) IN (1, 3, 5, 7, 8, 10, 12) THEN 2678400       WHEN EXTRACT(MONTH FROM MIN(txn.block_timestamp)) = 2 THEN          CASE            WHEN MOD(EXTRACT(YEAR FROM MIN(txn.block_timestamp)), 4) = 0 AND (MOD(EXTRACT(YEAR FROM MIN(txn.block_timestamp)), 100) != 0 OR MOD(EXTRACT(YEAR FROM MIN(txn.block_timestamp)), 400) = 0) THEN 2505600           ELSE 2419200         END       ELSE 2592000     END AS TXN_PER_SECOND,   EXTRACT(YEAR FROM MIN(txn.block_timestamp)) AS YEAR,   EXTRACT(MONTH FROM MIN(txn.block_timestamp)) AS MONTH FROM   `bigquery-public-data.goog_blockchain_polygon_mainnet_us.transactions` AS txn WHERE EXTRACT(YEAR FROM txn.block_timestamp) = 2023 GROUP BY   EXTRACT(YEAR FROM txn.block_timestamp),   EXTRACT(MONTH FROM txn.block_timestamp) ORDER BY TXN_COUNT_PER_MONTH DESC;",
        "schema": {
            "bigquery-public-data.goog_blockchain_polygon_mainnet_us": {
                "transactions": [
                    "block_timestamp"
                ]
            }
        }
    },
    "bq278": {
        "query": "SELECT   #name of state   state_name,      #number of buildings in Google Map suitable for solar   SUM(count_qualified) Google_Maps_Buildings_Avail_for_Solar,      #percent of buildings in Google Maps covered by Project Sunroof   ROUND(CAST(AVG(percent_covered) AS numeric), 1) Percent_GMap_Covered_by_Proj_Sunroof,      #percent of buildings covered by Project Sunroof that are suitable for solar   ROUND(CAST(AVG(percent_qualified)AS numeric), 1) Percent_Covered_that_Suitable_for_Solar,      #total number of available buildings for solar   ROUND(SUM(count_qualified) * (ROUND(CAST(AVG(percent_covered)AS numeric), 1)/100) * (ROUND(CAST(AVG(percent_qualified)AS numeric), 1)/100), 0) Available_Buildings,      #number of solar panels potential for all roof space in the region, assuming 1.650m .992m panels   SUM(number_of_panels_total) Total_Panels_Potential,      #number of kW of solar potential for all roof types in region (assuming 250 watts per panel)   SUM(kw_total) Kw_total_all_panel_250w,      #total solar energy generation potential for all roof space in region   SUM(yearly_sunlight_kwh_total) Total_Energy_Potential,      #potential carbon dioxide abatement (The calculation uses eGRID subregion CO2 equivalent non-baseload output emission rates. https://www.epa.gov/sites/production/files/2015 10/documents/egrid2012_summarytables_0.pdf)   ROUND(CAST(SUM(carbon_offset_metric_tons)AS numeric),0) Carbon_Offset,      #number of existing buildings with solar installation   SUM(existing_installs_count) Current_Buildings_with_Solar_Panel,      #number of buildings without solar that potential for solar install   ROUND(SUM(count_qualified) * (ROUND(CAST(AVG(percent_covered)AS numeric), 1)/100) * (ROUND(CAST(AVG(percent_qualified)AS numeric), 1)/100), 0) - SUM(existing_installs_count) Building_Gap FROM   `bigquery-public-data.sunroof_solar.solar_potential_by_postal_code` sp GROUP BY   sp.state_name ORDER BY   SUM(sp.count_qualified) DESC LIMIT 1;",
        "schema": {
            "bigquery-public-data.sunroof_solar": {
                "solar_potential_by_postal_code": [
                    "state_name",
                    "count_qualified",
                    "percent_covered",
                    "percent_qualified",
                    "number_of_panels_total",
                    "kw_total",
                    "yearly_sunlight_kwh_total",
                    "carbon_offset_metric_tons",
                    "existing_installs_count"
                ]
            }
        }
    },
    "bq067": {
        "query": "SELECT   CASE     WHEN COUNTIF(injury_severity = 4) > 1 -- 4 = Fatal injury       then 1       else 0   END AS label,   a.state_number AS feature1,   c.body_type AS feature2,   a.number_of_drunk_drivers AS feature3,   a.day_of_week AS feature4,   a.hour_of_crash AS feature5,   CASE     WHEN a.work_zone = \"None\" THEN 0     ELSE 1   END AS feature6,   CASE WHEN avg_diff_speed >= 0 AND avg_diff_speed < 20 THEN 0       WHEN avg_diff_speed >= 20 AND avg_diff_speed < 40 THEN 1       WHEN avg_diff_speed >= 40 AND avg_diff_speed < 60 THEN 2       WHEN avg_diff_speed >= 60 AND avg_diff_speed < 80 THEN 3       ELSE 4   END AS feature7 FROM    `bigquery-public-data.nhtsa_traffic_fatalities.accident_2016` a,   `bigquery-public-data.nhtsa_traffic_fatalities.person_2016` b,   `bigquery-public-data.nhtsa_traffic_fatalities.vehicle_2016` c,   (     SELECT        consecutive_number,        AVG(ABS(travel_speed - speed_limit)) avg_diff_speed     FROM        `bigquery-public-data.nhtsa_traffic_fatalities.vehicle_2016`      -- travel_speed bounded because codes: 997 = speed greater than 96, 998 = speed greater than 151, 999 = unknown     -- Speed_limit bounded because codes: 98= not reported 99= unknown     WHERE        travel_speed <= 151 AND speed_limit <= 80     GROUP BY        consecutive_number   ) d WHERE   a.consecutive_number = b.consecutive_number   AND b.consecutive_number = c.consecutive_number   AND c.consecutive_number = d.consecutive_number   AND a.consecutive_number IN   (     SELECT        accident.consecutive_number     FROM        `bigquery-public-data.nhtsa_traffic_fatalities.person_2016` person, `bigquery-public-data.nhtsa_traffic_fatalities.accident_2016` accident     WHERE       person.consecutive_number = accident.consecutive_number     GROUP BY        accident.consecutive_number     HAVING COUNT(DISTINCT person.person_number) <> 1   ) GROUP BY   a.consecutive_number, a.state_number, c.body_type, a.number_of_drunk_drivers, a.day_of_week, a.hour_of_crash, a.work_zone, avg_diff_speed",
        "schema": {
            "bigquery-public-data.nhtsa_traffic_fatalities": {
                "accident_2016": [
                    "injury_severity",
                    "state_number",
                    "number_of_drunk_drivers",
                    "day_of_week",
                    "hour_of_crash",
                    "work_zone",
                    "consecutive_number"
                ],
                "person_2016": [
                    "consecutive_number",
                    "person_number"
                ],
                "vehicle_2016": [
                    "body_type",
                    "consecutive_number",
                    "travel_speed",
                    "speed_limit"
                ]
            }
        }
    },
    "bq352": {
        "query": "WITH natality_2018 AS (   SELECT County_of_Residence_FIPS AS FIPS, Ave_Number_of_Prenatal_Wks AS Vist_Ave, County_of_Residence   FROM `bigquery-public-data.sdoh_cdc_wonder_natality.county_natality`    WHERE SUBSTR(County_of_Residence_FIPS, 0, 2) = \"55\" AND Year = '2018-01-01' ),  acs_2017 AS (   SELECT geo_id, commute_45_59_mins, employed_pop   FROM `bigquery-public-data.census_bureau_acs.county_2017_5yr` ),  corr_tbl AS (   SELECT     n.County_of_Residence,     ROUND((a.commute_45_59_mins / a.employed_pop) * 100, 2) AS percent_high_travel,     n.Vist_Ave   FROM acs_2017 a   JOIN natality_2018 n   ON a.geo_id = n.FIPS )  SELECT County_of_Residence, Vist_Ave FROM corr_tbl WHERE percent_high_travel > 5",
        "schema": {
            "bigquery-public-data.sdoh_cdc_wonder_natality": {
                "county_natality": [
                    "County_of_Residence_FIPS",
                    "Ave_Number_of_Prenatal_Wks",
                    "County_of_Residence",
                    "Year"
                ]
            },
            "bigquery-public-data.census_bureau_acs": {
                "county_2017_5yr": [
                    "geo_id",
                    "commute_45_59_mins",
                    "employed_pop"
                ]
            }
        }
    },
    "bq352_1": {
        "query": "WITH ranked_data AS (   SELECT     ROUND((commute_45_59_mins/employed_pop)*100, 2) AS percent_high_travel,     Ave_Number_of_Prenatal_Wks AS Vist_Ave   FROM `bigquery-public-data.sdoh_cdc_wonder_natality.county_natality` n   JOIN `bigquery-public-data.census_bureau_acs.county_2017_5yr` a   ON n.County_of_Residence_FIPS = a.geo_id   WHERE SUBSTR(n.County_of_Residence_FIPS, 0, 2) = \"55\" AND n.Year = '2018-01-01' ), top_3 AS (   SELECT percent_high_travel   FROM ranked_data   ORDER BY Vist_Ave DESC   LIMIT 3 ), bottom_3 AS (   SELECT percent_high_travel   FROM ranked_data   ORDER BY Vist_Ave ASC   LIMIT 3 )  SELECT    (SELECT AVG(percent_high_travel) FROM top_3) -   (SELECT AVG(percent_high_travel) FROM bottom_3) AS difference",
        "schema": {
            "bigquery-public-data.sdoh_cdc_wonder_natality": {
                "county_natality": [
                    "commute_45_59_mins",
                    "employed_pop",
                    "Ave_Number_of_Prenatal_Wks",
                    "County_of_Residence_FIPS",
                    "Year"
                ]
            },
            "bigquery-public-data.census_bureau_acs": {
                "county_2017_5yr": [
                    "geo_id"
                ]
            }
        }
    },
    "bq074": {
        "query": "WITH acs_2018 AS (   SELECT geo_id, unemployed_pop AS unemployed_2018     FROM `bigquery-public-data.census_bureau_acs.county_2018_1yr`  ),   acs_2015 AS (   SELECT geo_id, unemployed_pop AS unemployed_2015     FROM `bigquery-public-data.census_bureau_acs.county_2015_1yr`  ),   unemployed_change AS (   SELECT     u18.unemployed_2018, u18.geo_id, u15.unemployed_2015,     (u18.unemployed_2018 - u15.unemployed_2015) AS u_change   FROM acs_2018 u18   JOIN acs_2015 u15   ON u18.geo_id = u15.geo_id ),   duals_Jan_2018 AS (   SELECT Public_Total AS duals_2018, County_Name, FIPS    FROM `bigquery-public-data.sdoh_cms_dual_eligible_enrollment.dual_eligible_enrollment_by_county_and_program`    WHERE Date = '2018-12-01' ),  duals_Jan_2015 AS (   SELECT Public_Total AS duals_2015, County_Name, FIPS   FROM `bigquery-public-data.sdoh_cms_dual_eligible_enrollment.dual_eligible_enrollment_by_county_and_program`    WHERE Date = '2015-12-01' ),  duals_change AS (   SELECT     d18.FIPS, d18.County_Name, d18.duals_2018, d15.duals_2015,     (d18.duals_2018 - d15.duals_2015) AS total_duals_diff   FROM duals_Jan_2018 d18   JOIN duals_Jan_2015 d15   ON d18.FIPS = d15.FIPS ),   corr_tbl AS (   SELECT unemployed_change.geo_id, duals_change.County_Name, unemployed_change.u_change, duals_change.total_duals_diff   FROM unemployed_change   JOIN duals_change   ON unemployed_change.geo_id = duals_change.FIPS )   SELECT COUNT(*) FROM corr_tbl WHERE u_change >0 AND corr_tbl.total_duals_diff < 0",
        "schema": {
            "bigquery-public-data.census_bureau_acs.county_2018_1yr": {
                "county_2018_1yr": [
                    "geo_id",
                    "unemployed_pop"
                ]
            },
            "bigquery-public-data.census_bureau_acs.county_2015_1yr": {
                "county_2015_1yr": [
                    "geo_id",
                    "unemployed_pop"
                ]
            },
            "bigquery-public-data.sdoh_cms_dual_eligible_enrollment.dual_eligible_enrollment_by_county_and_program": {
                "dual_eligible_enrollment_by_county_and_program": [
                    "Public_Total",
                    "County_Name",
                    "FIPS",
                    "Date"
                ]
            }
        }
    },
    "bq066": {
        "query": "WITH morbidity_2018 AS (   SELECT County_of_Residence_FIPS AS FIPS, Births AS Morbidity_Births, County_of_Residence   FROM `bigquery-public-data.sdoh_cdc_wonder_natality.county_natality_by_maternal_morbidity`    WHERE Maternal_Morbidity_YN = 0 AND Year = '2018-01-01' ),  births_2018 AS (   SELECT County_of_Residence_FIPS AS FIPS, Births   FROM `bigquery-public-data.sdoh_cdc_wonder_natality.county_natality`   WHERE Year = '2018-01-01' ),  acs_2017 AS (   SELECT geo_id, poverty, total_pop   FROM `bigquery-public-data.census_bureau_acs.county_2017_5yr` ),   maternal_morbidity AS (   SELECT morbidity_2018.FIPS, ROUND((Morbidity_Births/Births)*100,2) AS Mbdy_pcnt, County_of_Residence   FROM morbidity_2018   JOIN births_2018   ON morbidity_2018.FIPS = births_2018.FIPS ),   corr_tbl AS (   SELECT    acs_2017.geo_id, ROUND((poverty/total_pop)*100,2) AS percent_poverty,     Mbdy_pcnt, County_of_Residence    FROM acs_2017    JOIN maternal_morbidity    ON acs_2017.geo_id = maternal_morbidity.FIPS )    SELECT CORR(percent_poverty, Mbdy_pcnt) AS pearson_correlation FROM corr_tbl;",
        "schema": {
            "bigquery-public-data.sdoh_cdc_wonder_natality.county_natality_by_maternal_morbidity": {
                "county_natality_by_maternal_morbidity": [
                    "County_of_Residence_FIPS",
                    "Births",
                    "County_of_Residence",
                    "Maternal_Morbidity_YN",
                    "Year"
                ]
            },
            "bigquery-public-data.sdoh_cdc_wonder_natality.county_natality": {
                "county_natality": [
                    "County_of_Residence_FIPS",
                    "Births",
                    "Year"
                ]
            },
            "bigquery-public-data.census_bureau_acs.county_2017_5yr": {
                "county_2017_5yr": [
                    "geo_id",
                    "poverty",
                    "total_pop"
                ]
            }
        }
    },
    "bq114": {
        "query": "SELECT   aq.city,   (epa.arithmetic_mean - aq.value) FROM   `bigquery-public-data.openaq.global_air_quality` AS aq JOIN   `bigquery-public-data.epa_historical_air_quality.air_quality_annual_summary` AS epa ON   ROUND(aq.latitude, 1) = ROUND(epa.latitude, 1)   AND ROUND(aq.longitude, 1) = ROUND(epa.longitude, 1) WHERE   epa.units_of_measure = \"Micrograms/cubic meter (LC)\"   AND epa.parameter_name = \"Acceptable PM2.5 AQI & Speciation Mass\"   AND epa.year = 1990   AND aq.pollutant = \"pm25\" ORDER BY   (epa.arithmetic_mean - aq.value) DESC LIMIT   2",
        "schema": {
            "bigquery-public-data.openaq.global_air_quality": {
                "global_air_quality": [
                    "city",
                    "latitude",
                    "longitude",
                    "value",
                    "pollutant"
                ]
            },
            "bigquery-public-data.epa_historical_air_quality.air_quality_annual_summary": {
                "air_quality_annual_summary": [
                    "arithmetic_mean",
                    "latitude",
                    "longitude",
                    "units_of_measure",
                    "parameter_name",
                    "year"
                ]
            }
        }
    },
    "bq116": {
        "query": "SELECT   SUM(QuickSummary.revenue) / 1e9 AS revenue_per_state_in_billions FROM (   SELECT     submission_number,     MAX(value) AS revenue   FROM `bigquery-public-data.sec_quarterly_financials.quick_summary`   WHERE     measure_tag IN ('Revenues', 'SalesRevenueNet',                     'SalesRevenueGoodsNet')     AND fiscal_year = 2016     AND fiscal_period_focus = 'FY'     AND number_of_quarters = 4   GROUP BY     submission_number) QuickSummary  INNER JOIN (    SELECT      submission_number,      MAX(stprba) AS state    FROM      `bigquery-public-data.sec_quarterly_financials.submission`    WHERE      stprba IS NOT NULL      AND stprba != ''      AND countryba = 'US'    GROUP BY      submission_number) Submission  ON    QuickSummary.submission_number = Submission.submission_number GROUP BY   state ORDER BY   revenue_per_state_in_billions DESC LIMIT 1;",
        "schema": {
            "bigquery-public-data.sec_quarterly_financials": {
                "quick_summary": [
                    "submission_number",
                    "value",
                    "measure_tag",
                    "fiscal_year",
                    "fiscal_period_focus",
                    "number_of_quarters"
                ],
                "submission": [
                    "submission_number",
                    "stprba",
                    "countryba"
                ]
            }
        }
    },
    "bq015": {
        "query": "SELECT      tag,      SUM(c) AS c  FROM (     SELECT          CONCAT('stackoverflow.com/questions/', CAST(b.id AS STRING)) AS url,         title,          c,          answer_count,          favorite_count,          view_count,          score,          SPLIT(tags, '|') AS tags      FROM          `bigquery-public-data.stackoverflow.posts_questions` AS a      JOIN (         SELECT              CAST(REGEXP_EXTRACT(text, r'stackoverflow.com/questions/([0-9]+)/') AS INT64) AS id,             COUNT(*) AS c          FROM              `fh-bigquery.hackernews.comments`          WHERE              text LIKE '%stackoverflow.com/questions/%'              AND EXTRACT(YEAR FROM time_ts) >= 2014          GROUP BY              1          ORDER BY              2 DESC     ) AS b ON a.id = b.id ), UNNEST(tags) AS tag  GROUP BY      1  ORDER BY      2 DESC  LIMIT 10",
        "schema": {
            "bigquery-public-data.stackoverflow": {
                "posts_questions": [
                    "id",
                    "title",
                    "tags"
                ]
            },
            "fh-bigquery.hackernews": {
                "comments": [
                    "text",
                    "time_ts"
                ]
            }
        }
    },
    "bq041": {
        "query": "DECLARE yr, conversion_window INT64; SET (yr, conversion_window) = (2021, 30);  WITH users AS (   SELECT *   FROM `bigquery-public-data.stackoverflow.users`   WHERE EXTRACT(YEAR FROM creation_date) = yr ),  users_questions AS (   SELECT      u.display_name,      u.id AS user_id,      u.creation_date AS signup,      COUNT(q.id) AS questions,      MIN(q.creation_date) AS first_question   FROM users u   LEFT JOIN `bigquery-public-data.stackoverflow.posts_questions` q      ON q.owner_user_id = u.id      AND DATE_DIFF(q.creation_date, u.creation_date, DAY) <= conversion_window   GROUP BY      u.display_name,      u.id,      u.creation_date ),  users_questions_answers AS (   SELECT      display_name,      user_id,      signup,      questions,      first_question,      COUNT(a.id) AS answers_after_question   FROM users_questions uq   LEFT JOIN `bigquery-public-data.stackoverflow.posts_answers` a      ON a.owner_user_id = uq.user_id      AND a.creation_date > uq.first_question     AND DATE_DIFF(a.creation_date, uq.first_question, DAY) <= conversion_window   GROUP BY      display_name,      user_id,      signup,      questions,      first_question )  SELECT    EXTRACT(MONTH FROM signup) AS month,   COUNT(user_id) AS new_users,   COUNT(DISTINCT CASE WHEN questions > 0 THEN user_id ELSE NULL END) AS asked,   ROUND(COUNT(DISTINCT CASE WHEN questions > 0 THEN user_id ELSE NULL END) / COUNT(user_id) * 100, 2) AS pct_asked,   COUNT(DISTINCT CASE WHEN answers_after_question > 0 THEN user_id ELSE NULL END) AS then_answered,   ROUND(COUNT(DISTINCT CASE WHEN answers_after_question > 0 THEN user_id ELSE NULL END) / COUNT(user_id) * 100, 2) AS pct_then_answered FROM users_questions_answers GROUP BY    EXTRACT(MONTH FROM signup) ORDER BY    month ASC;",
        "schema": {
            "bigquery-public-data.stackoverflow": {
                "users": [
                    "creation_date",
                    "display_name",
                    "id"
                ],
                "posts_questions": [
                    "id",
                    "owner_user_id",
                    "creation_date"
                ],
                "posts_answers": [
                    "id",
                    "owner_user_id",
                    "creation_date"
                ]
            }
        }
    },
    "bq121": {
        "query": "SELECT User_Tenure,        COUNT(1) AS Num_Users,        ROUND(AVG(reputation)) AS Avg_Reputation,        ROUND(AVG(num_badges)) AS Avg_Num_Badges FROM (   SELECT users.id AS user,          ROUND(TIMESTAMP_DIFF(CURRENT_TIMESTAMP(), ANY_VALUE(users.creation_date), DAY)/365) AS user_tenure,          ANY_VALUE(users.reputation) AS reputation,          SUM(IF(badges.user_id IS NULL, 0, 1)) AS num_badges   FROM `bigquery-public-data.stackoverflow.users` users   LEFT JOIN `bigquery-public-data.stackoverflow.badges` badges   ON users.id = badges.user_id   GROUP BY user ) GROUP BY User_Tenure ORDER BY User_Tenure",
        "schema": {
            "bigquery-public-data.stackoverflow": {
                "users": [
                    "id",
                    "creation_date",
                    "reputation"
                ],
                "badges": [
                    "user_id"
                ]
            }
        }
    },
    "bq123": {
        "query": "WITH question_answer_stats AS (   SELECT     EXTRACT(DAYOFWEEK FROM q.creation_date) AS question_day,     COUNT(DISTINCT a.id) AS count_answers,     COUNT(DISTINCT q.id) AS count_questions,     ROUND(COUNT(DISTINCT a.id) * 1.0 / COUNT(DISTINCT q.id) * 100, 2) AS percent_questions   FROM      `bigquery-public-data.stackoverflow.posts_questions` q   LEFT JOIN     `bigquery-public-data.stackoverflow.posts_answers` a    ON      q.id = a.parent_id      AND a.creation_date < TIMESTAMP_ADD(q.creation_date, INTERVAL 1 HOUR)    GROUP BY     EXTRACT(DAYOFWEEK FROM q.creation_date)   ORDER BY      percent_questions DESC )  SELECT    question_day,    percent_questions FROM    question_answer_stats ORDER BY    percent_questions DESC LIMIT 1 OFFSET 2;",
        "schema": {
            "bigquery-public-data.stackoverflow": {
                "posts_questions": [
                    "creation_date",
                    "id"
                ],
                "posts_answers": [
                    "id",
                    "parent_id",
                    "creation_date"
                ]
            }
        }
    },
    "bq280": {
        "query": "WITH UserAnswers AS (   SELECT     owner_user_id AS answer_owner_id,     COUNT(id) AS answer_count   FROM bigquery-public-data.stackoverflow.posts_answers   WHERE owner_user_id IS NOT NULL   GROUP BY owner_user_id ), DetailedUsers AS (   SELECT     id AS user_id,     display_name AS user_display_name,     reputation   FROM bigquery-public-data.stackoverflow.users   WHERE display_name IS NOT NULL AND reputation > 10 ), RankedUsers AS (   SELECT     u.user_display_name,     u.reputation,     a.answer_count,     ROW_NUMBER() OVER (ORDER BY a.answer_count DESC) AS rank   FROM DetailedUsers u   JOIN UserAnswers a ON u.user_id = a.answer_owner_id ) SELECT   user_display_name, FROM RankedUsers WHERE rank = 1;",
        "schema": {
            "bigquery-public-data.stackoverflow": {
                "posts_answers": [
                    "owner_user_id",
                    "id"
                ],
                "users": [
                    "id",
                    "display_name",
                    "reputation"
                ]
            }
        }
    },
    "bq300": {
        "query": "WITH   python2_questions AS (     SELECT       q.id AS question_id,       q.title,       q.body AS question_body,       q.tags     FROM       `bigquery-public-data.stackoverflow.posts_questions` q     WHERE       (LOWER(q.tags) LIKE '%python-2%'       OR LOWER(q.tags) LIKE '%python-2.x%'       OR (         LOWER(q.title) LIKE '%python 2%'         OR LOWER(q.body) LIKE '%python 2%'         OR LOWER(q.title) LIKE '%python2%'         OR LOWER(q.body) LIKE '%python2%'       ))       AND (         LOWER(q.title) NOT LIKE '%python 3%'         AND LOWER(q.body) NOT LIKE '%python 3%'         AND LOWER(q.title) NOT LIKE '%python3%'         AND LOWER(q.body) NOT LIKE '%python3%'       )   )  SELECT   COUNT(*) AS count_number FROM   python2_questions q LEFT JOIN   `bigquery-public-data.stackoverflow.posts_answers` a ON   q.question_id = a.parent_id GROUP BY q.question_id ORDER BY count_number DESC LIMIT 1",
        "schema": {
            "bigquery-public-data.stackoverflow": {
                "posts_questions": [
                    "id",
                    "title",
                    "body",
                    "tags"
                ],
                "posts_answers": [
                    "parent_id"
                ]
            }
        }
    },
    "bq301": {
        "query": "SELECT     answer.id AS a_id,     (SELECT users.reputation FROM `bigquery-public-data.stackoverflow.users` users         WHERE users.id = answer.owner_user_id) AS a_user_reputation,     answer.score AS a_score,     answer.comment_count AS answer_comment_count,     questions.tags as q_tags,     questions.score AS q_score,       questions.answer_count AS answer_count,      (SELECT users.reputation FROM `bigquery-public-data.stackoverflow.users` users         WHERE users.id = questions.owner_user_id) AS q_user_reputation,     questions.view_count AS q_view_count,     questions.comment_count AS q_comment_count FROM    `bigquery-public-data.stackoverflow.posts_answers` AS answer  LEFT JOIN    `bigquery-public-data.stackoverflow.posts_questions` AS questions       ON answer.parent_id = questions.id WHERE     answer.id = questions.accepted_answer_id     AND      (         questions.tags LIKE '%javascript%' AND         (questions.tags LIKE '%xss%' OR         questions.tags LIKE '%cross-site%' OR         questions.tags LIKE '%exploit%' OR         questions.tags LIKE '%cybersecurity%')     )     AND DATE(questions.creation_date) BETWEEN '2016-01-01' AND '2016-01-31'     AND DATE(answer.creation_date) BETWEEN '2016-01-01' AND '2016-01-31'",
        "schema": {
            "bigquery-public-data.stackoverflow": {
                "posts_answers": [
                    "id",
                    "owner_user_id",
                    "score",
                    "comment_count",
                    "parent_id",
                    "creation_date"
                ],
                "posts_questions": [
                    "tags",
                    "score",
                    "answer_count",
                    "owner_user_id",
                    "view_count",
                    "comment_count",
                    "id",
                    "accepted_answer_id",
                    "creation_date"
                ],
                "users": [
                    "id",
                    "reputation"
                ]
            }
        }
    },
    "bq302": {
        "query": "WITH -- Get recent data RecentData AS (     SELECT         FORMAT_TIMESTAMP('%Y%m', creation_date) AS month_index,         tags     FROM         `bigquery-public-data.stackoverflow.posts_questions`     WHERE         EXTRACT(YEAR FROM DATE(creation_date)) = 2022 ),  -- Monthly number of questions posted MonthlyQuestions AS (     SELECT         month_index,         COUNT(*) AS num_questions     FROM         RecentData     GROUP BY         month_index ),  -- Monthly number of questions posted with specific tags TaggedQuestions AS (     SELECT         month_index,         tag,         COUNT(*) AS num_tags     FROM         RecentData,         UNNEST(SPLIT(tags, '|')) AS tag     WHERE         tag IN ('python')     GROUP BY         month_index, tag )  SELECT     a.month_index,     a.num_tags / b.num_questions AS proportion FROM     TaggedQuestions a LEFT JOIN     MonthlyQuestions b ON a.month_index = b.month_index ORDER BY     a.month_index, proportion DESC;",
        "schema": {
            "bigquery-public-data.stackoverflow": {
                "posts_questions": [
                    "creation_date",
                    "tags"
                ]
            }
        }
    },
    "bq303": {
        "query": "SELECT u_id, tags FROM (     -- select comments with tags from the post     SELECT cm.u_id, cm.creation_date, cm.text, pq.tags, \"comment\" as type     FROM (             SELECT a.parent_id as q_id, c.user_id as u_id, c.creation_date as creation_date, c.text as text             FROM `bigquery-public-data.stackoverflow.comments` as c             INNER JOIN `bigquery-public-data.stackoverflow.posts_answers` as a ON (a.id = c.post_id)             WHERE c.user_id BETWEEN 16712208 AND 18712208               AND DATE(c.creation_date) BETWEEN '2019-07-01' AND '2019-12-31'                          UNION ALL                           SELECT q.id as q_id, c.user_id as u_id, c.creation_date as creation_date, c.text as text             FROM `bigquery-public-data.stackoverflow.comments` as c             INNER JOIN `bigquery-public-data.stackoverflow.posts_questions` as q ON (q.id = c.post_id)             WHERE c.user_id BETWEEN 16712208 AND 18712208               AND DATE(c.creation_date) BETWEEN '2019-07-01' AND '2019-12-31'         ) as cm     INNER JOIN `bigquery-public-data.stackoverflow.posts_questions` as pq ON (pq.id = cm.q_id)              UNION ALL     -- select answers with tags related to the post     SELECT pa.owner_user_id as u_id, pa.creation_date as creation_date, pa.body as text, pq.tags as tags, \"answer\" as type     FROM `bigquery-public-data.stackoverflow.posts_answers` as pa     LEFT OUTER JOIN `bigquery-public-data.stackoverflow.posts_questions` as pq ON pq.id = pa.parent_id     WHERE pa.owner_user_id BETWEEN 16712208 AND 18712208       AND DATE(pa.creation_date) BETWEEN '2019-07-01' AND '2019-12-31'          UNION ALL     -- select posts     SELECT pq.owner_user_id as u_id, pq.creation_date as creation_date, pq.body as text, pq.tags as tags, \"question\" as type     FROM `bigquery-public-data.stackoverflow.posts_questions` as pq     WHERE pq.owner_user_id BETWEEN 16712208 AND 18712208       AND DATE(pq.creation_date) BETWEEN '2019-07-01' AND '2019-12-31' ) ORDER BY u_id, creation_date;",
        "schema": {
            "bigquery-public-data.stackoverflow": {
                "comments": [
                    "user_id",
                    "parent_id",
                    "creation_date",
                    "text",
                    "post_id"
                ],
                "posts_answers": [
                    "id",
                    "parent_id",
                    "owner_user_id",
                    "creation_date",
                    "body",
                    "tags"
                ],
                "posts_questions": [
                    "id",
                    "owner_user_id",
                    "creation_date",
                    "body",
                    "tags"
                ]
            }
        }
    },
    "bq304": {
        "query": "WITH tags_to_use AS (     SELECT tag, idx     FROM UNNEST([         'android-layout',          'android-activity',          'android-intent',          'android-edittext',          'android-fragments',          'android-recyclerview',          'listview',          'android-actionbar',          'google-maps',          'android-asynctask'     ]) AS tag WITH OFFSET idx ), android_how_to_questions AS (     SELECT         PQ.*     FROM         bigquery-public-data.stackoverflow.posts_questions PQ     WHERE         EXISTS (             SELECT 1             FROM UNNEST(SPLIT(PQ.tags, '|')) tag             WHERE tag IN (SELECT tag FROM tags_to_use)         )         AND (LOWER(PQ.title) LIKE '%how%' OR LOWER(PQ.body) LIKE '%how%')         AND NOT (LOWER(PQ.title) LIKE '%fail%' OR LOWER(PQ.title) LIKE '%problem%' OR LOWER(PQ.title) LIKE '%error%'                  OR LOWER(PQ.title) LIKE '%wrong%' OR LOWER(PQ.title) LIKE '%fix%' OR LOWER(PQ.title) LIKE '%bug%'                  OR LOWER(PQ.title) LIKE '%issue%' OR LOWER(PQ.title) LIKE '%solve%' OR LOWER(PQ.title) LIKE '%trouble%')         AND NOT (LOWER(PQ.body) LIKE '%fail%' OR LOWER(PQ.body) LIKE '%problem%' OR LOWER(PQ.body) LIKE '%error%'                  OR LOWER(PQ.body) LIKE '%wrong%' OR LOWER(PQ.body) LIKE '%fix%' OR LOWER(PQ.body) LIKE '%bug%'                  OR LOWER(PQ.body) LIKE '%issue%' OR LOWER(PQ.body) LIKE '%solve%' OR LOWER(PQ.body) LIKE '%trouble%') ), questions_with_tag_rankings AS (     SELECT         T.id AS tag_id,         TTU.idx AS tag_offset,         T.tag_name,         T.wiki_post_id AS tag_wiki_post_id,         Q.id AS question_id,         Q.title,         Q.tags,         Q.view_count,         RANK() OVER (PARTITION BY T.id ORDER BY Q.view_count DESC) AS question_view_count_rank,         COUNT(*) OVER (PARTITION BY T.id) AS total_valid_questions     FROM         bigquery-public-data.stackoverflow.tags T     INNER JOIN         tags_to_use TTU ON T.tag_name = TTU.tag     INNER JOIN         android_how_to_questions Q ON T.tag_name IN UNNEST(SPLIT(Q.tags, '|')) ) SELECT     question_id FROM     questions_with_tag_rankings WHERE     question_view_count_rank <= 50 AND total_valid_questions >= 50 ORDER BY     tag_offset ASC, question_view_count_rank ASC;",
        "schema": {
            "bigquery-public-data.stackoverflow": {
                "posts_questions": [
                    "id",
                    "tags",
                    "title",
                    "body",
                    "view_count"
                ],
                "tags": [
                    "id",
                    "tag_name",
                    "wiki_post_id"
                ]
            }
        }
    },
    "bq304_1": {
        "query": "WITH tags_to_use AS (     SELECT tag, idx     FROM UNNEST([         'android-layout',          'android-activity',          'android-intent',          'android-edittext',          'android-fragments',          'android-recyclerview',          'listview',          'android-actionbar',          'google-maps',          'android-asynctask'     ]) AS tag WITH OFFSET idx ), android_how_to_questions AS (     SELECT         PQ.*     FROM         `bigquery-public-data.stackoverflow.posts_questions` PQ     WHERE         EXISTS (             SELECT 1             FROM UNNEST(SPLIT(PQ.tags, '|')) tag             WHERE tag IN (SELECT tag FROM tags_to_use)         )         AND (LOWER(PQ.title) LIKE '%how%' OR LOWER(PQ.body) LIKE '%how%') ), most_viewed_question AS (     SELECT         T.id AS tag_id,         T.tag_name,         Q.id AS question_id,         Q.title,         Q.tags,         Q.view_count     FROM         `bigquery-public-data.stackoverflow.tags` T     INNER JOIN         tags_to_use TTU ON T.tag_name = TTU.tag     INNER JOIN         android_how_to_questions Q ON T.tag_name IN UNNEST(SPLIT(Q.tags, '|'))     ORDER BY Q.view_count DESC     LIMIT 1 ) SELECT     title FROM     most_viewed_question;",
        "schema": {
            "bigquery-public-data.stackoverflow": {
                "posts_questions": [
                    "tags",
                    "title",
                    "body",
                    "id",
                    "view_count"
                ],
                "tags": [
                    "id",
                    "tag_name"
                ]
            }
        }
    },
    "bq305": {
        "query": "",
        "schema": {
            "analytics_123456789.raw": {
                "events": [
                    "event_timestamp",
                    "event_name",
                    "user_pseudo_id",
                    "event_params.key",
                    "event_params.value.string_value",
                    "event_params.value.int_value",
                    "event_params.value.float_value",
                    "event_params.value.double_value"
                ]
            }
        }
    },
    "bq306": {
        "query": "SELECT   votes.tag AS vote_tag,   (votes.count * 10 + accepts.count * 15) AS reputation,   votes.count AS vote_count,   accepts.count AS accept_count FROM (   SELECT     tag,     COUNT(tag) AS count   FROM (     SELECT SPLIT(q.tags, '|') AS tag     FROM `bigquery-public-data.stackoverflow.votes` v       LEFT JOIN `bigquery-public-data.stackoverflow.posts_answers` a         ON v.post_id = a.id       LEFT JOIN `bigquery-public-data.stackoverflow.posts_questions` q         ON a.parent_id = q.id     WHERE a.owner_user_id = 1908967       AND v.vote_type_id = 2       AND DATE(v.creation_date) < DATE('2018-06-07')   ), UNNEST(tag) AS tag   GROUP BY tag   ORDER BY count DESC ) AS votes FULL OUTER JOIN (   SELECT     tag,     COUNT(tag) AS count   FROM (     SELECT SPLIT(q.tags, '|') AS tag     FROM `bigquery-public-data.stackoverflow.votes` v       LEFT JOIN `bigquery-public-data.stackoverflow.posts_answers` a         ON v.post_id = a.id       LEFT JOIN `bigquery-public-data.stackoverflow.posts_questions` q         ON a.parent_id = q.id     WHERE a.owner_user_id = 1908967       AND v.vote_type_id = 1       AND DATE(v.creation_date) < DATE('2018-06-07')   ), UNNEST(tag) AS tag   GROUP BY tag   ORDER BY count DESC ) AS accepts ON votes.tag = accepts.tag ORDER BY reputation DESC LIMIT 10",
        "schema": {
            "bigquery-public-data.stackoverflow": {
                "votes": [
                    "post_id",
                    "vote_type_id",
                    "creation_date",
                    "tag"
                ],
                "posts_answers": [
                    "id",
                    "parent_id",
                    "owner_user_id"
                ],
                "posts_questions": [
                    "id",
                    "tags"
                ]
            }
        }
    },
    "bq307": {
        "query": "SELECT badge_name AS First_Gold_Badge,        COUNT(1) AS Num_Users,        ROUND(AVG(tenure_in_days)) AS Avg_Num_Days FROM (   SELECT     badges.user_id AS user_id,     badges.name AS badge_name,     TIMESTAMP_DIFF(badges.date, users.creation_date, DAY) AS tenure_in_days,     ROW_NUMBER() OVER (PARTITION BY badges.user_id                        ORDER BY badges.date) AS row_number   FROM     `bigquery-public-data.stackoverflow.badges` badges   JOIN     `bigquery-public-data.stackoverflow.users` users   ON badges.user_id = users.id   WHERE badges.class = 1 ) WHERE row_number = 1 GROUP BY First_Gold_Badge ORDER BY Num_Users DESC LIMIT 10;",
        "schema": {
            "bigquery-public-data.stackoverflow": {
                "badges": [
                    "user_id",
                    "name",
                    "date",
                    "class"
                ],
                "users": [
                    "id",
                    "creation_date"
                ]
            }
        }
    },
    "bq308": {
        "query": "SELECT   Day_of_Week,   COUNT(1) AS Num_Questions,   SUM(answered_in_1h) AS Num_Answered_in_1H,   ROUND(100 * SUM(answered_in_1h) / COUNT(1),1) AS Percent_Answered_in_1H FROM (   SELECT     q.id AS question_id,     EXTRACT(DAYOFWEEK FROM q.creation_date) AS day_of_week,     MAX(IF(a.parent_id IS NOT NULL AND            (UNIX_SECONDS(a.creation_date)-UNIX_SECONDS(q.creation_date))/(60*60) <= 1, 1, 0)) AS answered_in_1h   FROM     `bigquery-public-data.stackoverflow.posts_questions` q   LEFT JOIN     `bigquery-public-data.stackoverflow.posts_answers` a   ON q.id = a.parent_id   WHERE EXTRACT(YEAR FROM a.creation_date) = 2020     AND EXTRACT(YEAR FROM q.creation_date) = 2020   GROUP BY question_id, day_of_week ) GROUP BY   Day_of_Week ORDER BY   Day_of_Week;",
        "schema": {
            "bigquery-public-data.stackoverflow": {
                "posts_questions": [
                    "id",
                    "creation_date"
                ],
                "posts_answers": [
                    "parent_id",
                    "creation_date"
                ]
            }
        }
    },
    "bq309": {
        "query": "WITH badge_counts AS (   SELECT     c.id,     COUNT(DISTINCT d.id) AS badge_number   FROM     `bigquery-public-data.stackoverflow.users` AS c   JOIN     `bigquery-public-data.stackoverflow.badges` AS d   ON     c.id = d.user_id   GROUP BY     c.id ), labeled_questions AS (   SELECT     a.id,     IF(       a.id IN (         SELECT DISTINCT b.id         FROM           `bigquery-public-data.stackoverflow.posts_answers` AS a         JOIN           `bigquery-public-data.stackoverflow.posts_questions` AS b         ON           a.parent_id = b.id         WHERE           b.accepted_answer_id IS NULL           AND a.score / b.view_count > 0.01       ) OR accepted_answer_id IS NOT NULL,       1,       0     ) AS label,     a.owner_user_id,     LENGTH(a.body) AS body_length   FROM     `bigquery-public-data.stackoverflow.posts_questions` AS a ) SELECT   lq.id,   b.reputation,   b.up_votes - b.down_votes AS net_votes,   e.badge_number FROM   labeled_questions AS lq JOIN   `bigquery-public-data.stackoverflow.users` AS b ON   lq.owner_user_id = b.id JOIN   badge_counts AS e ON   b.id = e.id WHERE   lq.label = 1 ORDER BY   lq.body_length DESC LIMIT   10;",
        "schema": {
            "bigquery-public-data.stackoverflow": {
                "users": [
                    "id",
                    "reputation",
                    "up_votes",
                    "down_votes"
                ],
                "badges": [
                    "id",
                    "user_id"
                ],
                "posts_answers": [
                    "parent_id",
                    "score",
                    "id"
                ],
                "posts_questions": [
                    "id",
                    "accepted_answer_id",
                    "view_count",
                    "owner_user_id",
                    "body"
                ]
            }
        }
    },
    "bq124": {
        "query": "With INFO AS ( SELECT    MR.patientId,    P.last_name,   ARRAY_TO_STRING(P.first_name, \" \") AS First_name,   Condition.Codes,    Condition.Conditions,   MR.med_count AS COUNT_NUMBER FROM   (SELECT      id,      name[safe_offset(0)].family as last_name,      name[safe_offset(0)].given as first_name,      TIMESTAMP(deceased.dateTime) AS deceased_datetime    FROM `bigquery-public-data.fhir_synthea.patient`) AS P JOIN   (SELECT  subject.patientId as patientId,             COUNT(DISTINCT medication.codeableConcept.coding[safe_offset(0)].code) AS med_count    FROM    `bigquery-public-data.fhir_synthea.medication_request`    WHERE   status = 'active'    GROUP BY 1    ) AS MR ON MR.patientId = P.id  JOIN   (SELECT    PatientId,    STRING_AGG(DISTINCT condition_desc, \", \") AS Conditions,    STRING_AGG(DISTINCT condition_code, \", \") AS Codes   FROM(     SELECT        subject.patientId as PatientId,                code.coding[safe_offset(0)].code condition_code,               code.coding[safe_offset(0)].display condition_desc        FROM `bigquery-public-data.fhir_synthea.condition`        WHERE           code.coding[safe_offset(0)].display = 'Diabetes'          OR           code.coding[safe_offset(0)].display = 'Hypertension'      )   GROUP BY PatientId   ) AS Condition ON MR.patientId = Condition.PatientId WHERE med_count >= 7  AND P.deceased_datetime is NULL /*only alive patients*/ GROUP BY patientId, last_name, first_name, Condition.Codes, Condition.Conditions, MR.med_count ORDER BY last_name )  SELECT COUNT(*) FROM INFO",
        "schema": {
            "bigquery-public-data.fhir_synthea": {
                "patient": [
                    "id",
                    "name",
                    "deceased.dateTime"
                ],
                "medication_request": [
                    "subject.patientId",
                    "medication.codeableConcept.coding",
                    "status"
                ],
                "condition": [
                    "subject.patientId",
                    "code.coding"
                ]
            }
        }
    },
    "bq126": {
        "query": "SELECT   o.artist_display_name,   o.title,   o.object_end_date,   o.medium,   i.original_image_url FROM (   SELECT     object_id,     title,     artist_display_name,     object_end_date,     medium   FROM     `bigquery-public-data.the_met.objects`   WHERE     department = \"Photographs\"     AND object_name LIKE \"%Photograph%\"     AND artist_display_name != \"Unknown\"     AND object_end_date <= 1839 ) o INNER JOIN (   SELECT     original_image_url,     object_id   FROM     `bigquery-public-data.the_met.images` ) i ON   o.object_id = i.object_id ORDER BY   o.object_end_date ;",
        "schema": {
            "bigquery-public-data.the_met": {
                "objects": [
                    "object_id",
                    "title",
                    "artist_display_name",
                    "object_end_date",
                    "medium",
                    "department",
                    "object_name"
                ],
                "images": [
                    "original_image_url",
                    "object_id"
                ]
            }
        }
    },
    "bq200": {
        "query": "SELECT      _pitcher FROM (     -- #rank of the player by his speed (ignoring ties)     SELECT _team         ,_pitcher         ,_speed         ,row_number() OVER (             PARTITION BY _team ORDER BY _speed DESC             ) _rnk     FROM (         -- #finalizing the table with player-team link         SELECT _team             ,_pitcher             ,max(_speed) _speed         FROM (             -- #glueing tables with players and teams             SELECT _pitcher                 ,coalesce(_home_team, _away_team) _team                 ,_speed             FROM (                 -- #setting up the table with players                 SELECT venueId                     ,pitcherId                     ,pitcherFirstName || ' ' || pitcherLastName AS _pitcher                     ,max(pitchSpeed) _speed                 FROM (                     -- #full table comprising all seasons                     SELECT venueId                         ,pitcherId                         ,pitcherFirstName                         ,pitcherLastName                         ,pitchSpeed                     FROM `bigquery-public-data.baseball.games_wide`                                          UNION ALL                                          SELECT venueId                         ,pitcherId                         ,pitcherFirstName                         ,pitcherLastName                         ,pitchSpeed                     FROM `bigquery-public-data.baseball.games_post_wide`                     ) _all                 WHERE pitchSpeed != 0                 GROUP BY venueId                     ,pitcherId                     ,pitcherFirstName || ' ' || pitcherLastName                 ) _grp             -- #joining table with player-team links             LEFT JOIN (                 SELECT pitcherId                     ,venueId                     -- we need to check here if the pitcher is in the list of the homing team                     ,CASE                          WHEN pitcherId IN unnest(                                                 [homeFielder1\t\t                                                 ,homeFielder2\t\t\t                                                 ,homeFielder3\t\t\t                                                 ,homeFielder4\t\t\t                                                 ,homeFielder5\t\t\t                                                 ,homeFielder6\t\t\t                                                 ,homeFielder7\t\t\t                                                 ,homeFielder8\t\t\t                                                 ,homeFielder9\t\t\t                                                 ,homeFielder10\t\t\t                                                 ,homeFielder11\t\t\t                                                 ,homeFielder12\t\t\t                                                 ,homeBatter1\t\t\t                                                 ,homeBatter2\t\t\t                                                 ,homeBatter3\t\t\t                                                 ,homeBatter4\t\t\t                                                 ,homeBatter5\t\t\t                                                 ,homeBatter6\t\t\t                                                 ,homeBatter7\t\t\t                                                 ,homeBatter8\t\t\t                                                 ,homeBatter9]                             )                             THEN homeTeamName                         ELSE NULL                         END _home_team                     -- we need to check here if the pitcher is in the list of the guest team                     ,CASE                          WHEN pitcherId IN unnest(                                                 [awayFielder1\t\t                                                 ,awayFielder2\t\t                                                 ,awayFielder3\t\t                                                 ,awayFielder4\t\t                                                 ,awayFielder5\t\t                                                 ,awayFielder6\t\t                                                 ,awayFielder7\t\t                                                 ,awayFielder8\t\t                                                 ,awayFielder9\t\t                                                 ,awayFielder10\t\t                                                 ,awayFielder11\t\t                                                 ,awayFielder12\t\t                                                 ,awayBatter1\t\t                                                 ,awayBatter2\t\t                                                 ,awayBatter3\t\t                                                 ,awayBatter4\t\t                                                 ,awayBatter5\t\t                                                 ,awayBatter6\t\t                                                 ,awayBatter7\t\t                                                 ,awayBatter8\t\t                                                 ,awayBatter9]                             )                             THEN awayTeamName                         ELSE NULL                         END _away_team                 FROM (                     SELECT *                     FROM `bigquery-public-data.baseball.games_wide`                                          UNION ALL                                          SELECT *                     FROM `bigquery-public-data.baseball.games_post_wide`                     ) t                 ) _team ON _team.pitcherId = _grp.pitcherId                 AND _team.venueId = _grp.venueId             ) _total         GROUP BY _team             ,_pitcher         ) _filter     WHERE 1 = 1         AND _team IS NOT NULL         AND _pitcher IS NOT NULL         AND _pitcher != ''         AND _speed != 0     ) _rank WHERE 1 = 1     AND _rnk = 1 ORDER BY _speed DESC",
        "schema": {
            "bigquery-public-data.baseball": {
                "games_wide": [
                    "venueId",
                    "pitcherId",
                    "pitcherFirstName",
                    "pitcherLastName",
                    "pitchSpeed",
                    "homeFielder1",
                    "homeFielder2",
                    "homeFielder3",
                    "homeFielder4",
                    "homeFielder5",
                    "homeFielder6",
                    "homeFielder7",
                    "homeFielder8",
                    "homeFielder9",
                    "homeFielder10",
                    "homeFielder11",
                    "homeFielder12",
                    "homeBatter1",
                    "homeBatter2",
                    "homeBatter3",
                    "homeBatter4",
                    "homeBatter5",
                    "homeBatter6",
                    "homeBatter7",
                    "homeBatter8",
                    "homeBatter9",
                    "awayFielder1",
                    "awayFielder2",
                    "awayFielder3",
                    "awayFielder4",
                    "awayFielder5",
                    "awayFielder6",
                    "awayFielder7",
                    "awayFielder8",
                    "awayFielder9",
                    "awayFielder10",
                    "awayFielder11",
                    "awayFielder12",
                    "awayBatter1",
                    "awayBatter2",
                    "awayBatter3",
                    "awayBatter4",
                    "awayBatter5",
                    "awayBatter6",
                    "awayBatter7",
                    "awayBatter8",
                    "awayBatter9",
                    "homeTeamName",
                    "awayTeamName"
                ],
                "games_post_wide": [
                    "venueId",
                    "pitcherId",
                    "pitcherFirstName",
                    "pitcherLastName",
                    "pitchSpeed",
                    "homeFielder1",
                    "homeFielder2",
                    "homeFielder3",
                    "homeFielder4",
                    "homeFielder5",
                    "homeFielder6",
                    "homeFielder7",
                    "homeFielder8",
                    "homeFielder9",
                    "homeFielder10",
                    "homeFielder11",
                    "homeFielder12",
                    "homeBatter1",
                    "homeBatter2",
                    "homeBatter3",
                    "homeBatter4",
                    "homeBatter5",
                    "homeBatter6",
                    "homeBatter7",
                    "homeBatter8",
                    "homeBatter9",
                    "awayFielder1",
                    "awayFielder2",
                    "awayFielder3",
                    "awayFielder4",
                    "awayFielder5",
                    "awayFielder6",
                    "awayFielder7",
                    "awayFielder8",
                    "awayFielder9",
                    "awayFielder10",
                    "awayFielder11",
                    "awayFielder12",
                    "awayBatter1",
                    "awayBatter2",
                    "awayBatter3",
                    "awayBatter4",
                    "awayBatter5",
                    "awayBatter6",
                    "awayBatter7",
                    "awayBatter8",
                    "awayBatter9",
                    "homeTeamName",
                    "awayTeamName"
                ]
            }
        }
    },
    "bq204": {
        "query": "SELECT user FROM ( Select user       From `bigquery-public-data.eclipse_megamovie.photos_v_0_1`       UNION ALL       Select user       From`bigquery-public-data.eclipse_megamovie.photos_v_0_2`       UNION ALL       Select user       From`bigquery-public-data.eclipse_megamovie.photos_v_0_3` )  GROUP BY user  HAVING COUNT (user)=(  SELECT MAX(mycount)  FROM (  SELECT user, COUNT(user) mycount  FROM ( Select user       From `bigquery-public-data.eclipse_megamovie.photos_v_0_1`       UNION ALL       Select user       From`bigquery-public-data.eclipse_megamovie.photos_v_0_2`       UNION ALL       Select user       From`bigquery-public-data.eclipse_megamovie.photos_v_0_3` ) GROUP BY user)) ORDER BY COUNT(user)  LIMIT 1",
        "schema": {
            "bigquery-public-data.eclipse_megamovie": {
                "photos_v_0_1": [
                    "user"
                ],
                "photos_v_0_2": [
                    "user"
                ],
                "photos_v_0_3": [
                    "user"
                ]
            }
        }
    },
    "bq360": {
        "query": "WITH specialist_counts AS (   SELECT     healthcare_provider_taxonomy_1_specialization,     COUNT(DISTINCT npi) AS number_specialist   FROM     `bigquery-public-data.nppes.npi_optimized`   WHERE     provider_business_practice_location_address_city_name = \"MOUNTAIN VIEW\"     AND provider_business_practice_location_address_state_name = \"CA\"     AND healthcare_provider_taxonomy_1_specialization > \"\"   GROUP BY     healthcare_provider_taxonomy_1_specialization ), top_10_specialists AS (   SELECT     healthcare_provider_taxonomy_1_specialization,     number_specialist   FROM     specialist_counts   ORDER BY     number_specialist DESC   LIMIT 10 ), average_value AS (   SELECT     AVG(number_specialist) AS average_specialist   FROM     top_10_specialists ), closest_to_average AS (   SELECT     healthcare_provider_taxonomy_1_specialization,     number_specialist,     ABS(number_specialist - (SELECT average_specialist FROM average_value)) AS difference   FROM     top_10_specialists ) SELECT   healthcare_provider_taxonomy_1_specialization FROM   closest_to_average ORDER BY   difference LIMIT 1;",
        "schema": {
            "bigquery-public-data.nppes": {
                "npi_optimized": [
                    "healthcare_provider_taxonomy_1_specialization",
                    "npi",
                    "provider_business_practice_location_address_city_name",
                    "provider_business_practice_location_address_state_name"
                ]
            }
        }
    },
    "bq286": {
        "query": "SELECT   a.name AS name FROM   `bigquery-public-data.usa_names.usa_1910_current` a JOIN (   SELECT     name,     gender,     year,     SUM(number) AS total_number   FROM     `bigquery-public-data.usa_names.usa_1910_current`   GROUP BY     name,     gender,     year) b ON   a.name = b.name   AND a.gender = b.gender   AND a.year = b.year WHERE      a.gender = 'F' AND     a.state = 'WY' AND     a.year = 2021 ORDER BY (a.number / b.total_number) DESC LIMIT 1",
        "schema": {
            "bigquery-public-data.usa_names": {
                "usa_1910_current": [
                    "name",
                    "gender",
                    "year",
                    "number",
                    "state"
                ]
            }
        }
    },
    "bq043": {
        "query": "SELECT   genex.case_barcode AS case_barcode,   genex.sample_barcode AS sample_barcode,   genex.aliquot_barcode AS aliquot_barcode,   genex.HGNC_gene_symbol AS HGNC_gene_symbol,   clinical_info.Variant_Type AS Variant_Type,   genex.gene_id AS gene_id,   genex.normalized_count AS normalized_count,   genex.project_short_name AS project_short_name,   clinical_info.demo__gender AS gender,   clinical_info.demo__vital_status AS vital_status,   clinical_info.demo__days_to_death AS days_to_death FROM ( /* This will get the clinical information for the cases*/   SELECT     case_list.Variant_Type AS Variant_Type,     case_list.case_barcode AS case_barcode,     clinical.demo__gender,     clinical.demo__vital_status,     clinical.demo__days_to_death   FROM     /* this will get the unique list of cases having the CDKN2A gene mutation in bladder cancer BLCA cases*/     (SELECT       mutation.case_barcode,       mutation.Variant_Type     FROM       `isb-cgc-bq.TCGA_versioned.somatic_mutation_hg19_DCC_2017_02` AS mutation     WHERE       mutation.Hugo_Symbol = 'CDKN2A'       AND project_short_name = 'TCGA-BLCA'     GROUP BY       mutation.case_barcode,       mutation.Variant_Type     ORDER BY       mutation.case_barcode       ) AS case_list /* end case_list */   INNER JOIN     `isb-cgc-bq.TCGA.clinical_gdc_current` AS clinical   ON     case_list.case_barcode = clinical.submitter_id /* end clinical annotation */ ) AS clinical_info INNER JOIN   `isb-cgc-bq.TCGA_versioned.RNAseq_hg19_gdc_2017_02` AS genex ON   genex.case_barcode = clinical_info.case_barcode WHERE   genex.HGNC_gene_symbol IN ('MDM2', 'TP53', 'CDKN1A','CCNE1') ORDER BY   case_barcode,   HGNC_gene_symbol",
        "schema": {
            "isb-cgc-bq.TCGA_versioned": {
                "somatic_mutation_hg19_DCC_2017_02": [
                    "case_barcode",
                    "Variant_Type",
                    "Hugo_Symbol",
                    "project_short_name"
                ],
                "RNAseq_hg19_gdc_2017_02": [
                    "case_barcode",
                    "HGNC_gene_symbol",
                    "gene_id",
                    "normalized_count",
                    "project_short_name"
                ]
            },
            "isb-cgc-bq.TCGA": {
                "clinical_gdc_current": [
                    "submitter_id",
                    "demo__gender",
                    "demo__vital_status",
                    "demo__days_to_death"
                ]
            }
        }
    },
    "bq042": {
        "query": "SELECT   -- Create a timestamp from the date components.   TIMESTAMP(CONCAT(year,\"-\",mo,\"-\",da)) AS timestamp,   -- Replace numerical null values with actual null   AVG(IF (temp=9999.9,       null,       temp)) AS temperature,   AVG(IF (wdsp=\"999.9\",       null,       CAST(wdsp AS Float64))) AS wind_speed,   AVG(IF (prcp=99.99,       0,       prcp)) AS precipitation FROM   `bigquery-public-data.noaa_gsod.gsod20*` WHERE   CAST(YEAR AS INT64) > 2010   AND CAST(YEAR AS INT64) < 2021   AND CAST(MO AS INT64) = 6   AND CAST(DA AS INT64) = 12   AND stn = \"725030\" -- La Guardia GROUP BY   timestamp ORDER BY   timestamp ASC;",
        "schema": {
            "bigquery-public-data.noaa_gsod": {
                "gsod20*": [
                    "year",
                    "mo",
                    "da",
                    "temp",
                    "wdsp",
                    "prcp",
                    "stn"
                ]
            }
        }
    },
    "bq047": {
        "query": "WITH nyc_weather AS (     SELECT     -- Create a timestamp from the date components.     timestamp(concat(year, \"-\", mo, \"-\", da)) as timestamp,     -- Replace numerical null values with actual nulls     AVG(IF (temp=9999.9, null, temp)) AS temperature     FROM         `bigquery-public-data.noaa_gsod.gsod20*`     WHERE         CAST(YEAR AS INT64) BETWEEN 2008 AND 2018     AND (stn=\"725030\" OR  -- La Guardia         stn=\"744860\")    -- JFK     GROUP BY timestamp ) SELECT     complaint_type,     sum(complaint_count) as total_complaint_count,     count(temperature) as data_count,     ROUND(corr(temperature, avg_count), 4) AS corr_count,     ROUND(corr(temperature, avg_pct_count), 4) AS corr_pct From (     SELECT         avg(pct_count) as avg_pct_count,         avg(day_count) as avg_count,         sum(day_count) as complaint_count,         complaint_type,         temperature     FROM (         SELECT             DATE(timestamp) AS date,             temperature         FROM             nyc_weather ) a     JOIN (         SELECT x.date, complaint_type, day_count, day_count / all_calls_count as pct_count         FROM (             SELECT                 DATE(created_date) AS date,                 complaint_type,                 COUNT(*) AS day_count             FROM                 `bigquery-public-data.new_york.311_service_requests`             GROUP BY                 date,                 complaint_type) x         JOIN (             SELECT                 DATE(timestamp) AS date,                 COUNT(*) AS all_calls_count             FROM nyc_weather             GROUP BY date         ) y         ON x.date = y.date     ) b     ON a.date = b.date     GROUP BY         complaint_type,         temperature ) GROUP BY complaint_type HAVING     ABS(corr_pct) > 0.5 AND     total_complaint_count > 5000 ORDER BY     ABS(corr_pct) DESC",
        "schema": {
            "bigquery-public-data.noaa_gsod.gsod20*": {
                "gsod20*": [
                    "year",
                    "mo",
                    "da",
                    "temp",
                    "stn"
                ]
            },
            "bigquery-public-data.new_york.311_service_requests": {
                "311_service_requests": [
                    "created_date",
                    "complaint_type"
                ]
            }
        }
    },
    "bq048": {
        "query": "WITH nyc_weather AS (     SELECT     -- Create a timestamp from the date components.     timestamp(concat(year, \"-\", mo, \"-\", da)) as timestamp,     -- Replace numerical null values with actual nulls     AVG(IF (wdsp=\"999.9\", null, CAST(wdsp AS Float64))) AS wind_speed     FROM         `bigquery-public-data.noaa_gsod.gsod20*`     WHERE         CAST(YEAR AS INT64) BETWEEN 2011 AND 2020     AND stn = \"744860\" -- JFK Airport     GROUP BY timestamp ), complaint_correlations AS (     SELECT         complaint_type,         sum(complaint_count) as total_complaint_count,         count(wind_speed) as data_count,         ROUND(corr(wind_speed, avg_count), 4) AS corr_count,         ROUND(corr(wind_speed, avg_pct_count), 4) AS corr_pct     From (         SELECT             avg(pct_count) as avg_pct_count,             avg(day_count) as avg_count,             sum(day_count) as complaint_count,             complaint_type,             wind_speed         FROM (             SELECT                 DATE(timestamp) AS date,                 wind_speed             FROM                 nyc_weather) a         JOIN (             SELECT x.date, complaint_type, day_count, day_count / all_calls_count as pct_count             FROM (                 SELECT                         DATE(created_date) AS date,                         complaint_type,                         COUNT(*) AS day_count                 FROM                     `bigquery-public-data.new_york.311_service_requests`                 GROUP BY                     date,                     complaint_type) x             JOIN (                 SELECT                     DATE(timestamp) AS date,                     COUNT(*) AS all_calls_count                 FROM nyc_weather                 GROUP BY date             ) y             ON x.date=y.date         ) b         ON             a.date = b.date         GROUP BY             complaint_type,             wind_speed     )     GROUP BY complaint_type     HAVING         total_complaint_count > 3000     ORDER BY     corr_pct DESC ) SELECT     'Positive' AS correlation_type,     complaint_type,     corr_pct AS correlation FROM     complaint_correlations WHERE     corr_pct = (SELECT MAX(corr_pct) FROM complaint_correlations) UNION ALL SELECT     'Negative' AS correlation_type,     complaint_type,     corr_pct AS correlation FROM     complaint_correlations WHERE     corr_pct = (SELECT MIN(corr_pct) FROM complaint_correlations);",
        "schema": {
            "bigquery-public-data.noaa_gsod": {
                "gsod20*": [
                    "year",
                    "mo",
                    "da",
                    "wdsp",
                    "stn"
                ]
            },
            "bigquery-public-data.new_york": {
                "311_service_requests": [
                    "created_date",
                    "complaint_type"
                ]
            }
        }
    },
    "bq158": {
        "query": "WITH table1 AS (     SELECT         histological_type AS data1,         bcr_patient_barcode AS ParticipantBarcode     FROM pancancer-atlas.Filtered.clinical_PANCAN_patient_with_followup_filtered     WHERE acronym = 'BRCA' AND histological_type IS NOT NULL       ), table2 AS (     SELECT         Hugo_Symbol AS symbol,          ParticipantBarcode     FROM pancancer-atlas.Filtered.MC3_MAF_V5_one_per_tumor_sample     WHERE Study = 'BRCA' AND Hugo_Symbol = 'CDH1'           AND FILTER = 'PASS'       GROUP BY         ParticipantBarcode, symbol ), summ_table AS (     SELECT          n1.data1,         IF(n2.ParticipantBarcode IS NULL, 'NO', 'YES') AS data2,         COUNT(*) AS Nij     FROM         table1 AS n1     LEFT JOIN         table2 AS n2 ON n1.ParticipantBarcode = n2.ParticipantBarcode     GROUP BY         n1.data1, data2 ), percentages AS (     SELECT         data1,         SUM(CASE WHEN data2 = 'YES' THEN Nij ELSE 0 END) AS mutation_count,         SUM(Nij) AS total,         SUM(CASE WHEN data2 = 'YES' THEN Nij ELSE 0 END) / SUM(Nij) AS mutation_percentage     FROM summ_table     GROUP BY data1 ) SELECT data1 AS Histological_Type FROM percentages ORDER BY mutation_percentage DESC LIMIT 1;",
        "schema": {
            "pancancer-atlas.Filtered": {
                "clinical_PANCAN_patient_with_followup_filtered": [
                    "histological_type",
                    "bcr_patient_barcode",
                    "acronym"
                ],
                "MC3_MAF_V5_one_per_tumor_sample": [
                    "Hugo_Symbol",
                    "ParticipantBarcode",
                    "Study",
                    "FILTER"
                ]
            }
        }
    },
    "bq159": {
        "query": "WITH table1 AS ( SELECT    symbol,    avgdata AS data,    ParticipantBarcode FROM (    SELECT       'histological_type' AS symbol,        histological_type AS avgdata,       bcr_patient_barcode AS ParticipantBarcode    FROM `pancancer-atlas.Filtered.clinical_PANCAN_patient_with_followup_filtered`    WHERE acronym = 'BRCA'   AND histological_type IS NOT NULL          ) ) ,table2 AS ( SELECT    symbol,    ParticipantBarcode FROM (    SELECT       Hugo_Symbol AS symbol,        ParticipantBarcode AS ParticipantBarcode    FROM `pancancer-atlas.Filtered.MC3_MAF_V5_one_per_tumor_sample`    WHERE Study = 'BRCA' AND Hugo_Symbol = 'CDH1'          AND FILTER = 'PASS'      GROUP BY       ParticipantBarcode, symbol    ) ) ,summ_table AS ( SELECT     n1.data as data1,    IF( n2.ParticipantBarcode is null, 'NO', 'YES') as data2,    COUNT(*) as Nij FROM    table1 AS n1 LEFT JOIN    table2 AS n2 ON    n1.ParticipantBarcode = n2.ParticipantBarcode GROUP BY   data1, data2 )  ,expected_table AS ( SELECT data1, data2 FROM (          SELECT data1, SUM(Nij) as Ni        FROM summ_table     GROUP BY data1 )  CROSS JOIN (      SELECT data2, SUM(Nij) as Nj     FROM summ_table     GROUP BY data2 )      WHERE Ni > 10 AND Nj > 10 ) ,contingency_table AS ( SELECT    T1.data1,    T1.data2,    IF( Nij IS NULL, 0, Nij) as Nij,    (SUM(Nij) OVER (PARTITION BY T1.data1))*(SUM(Nij) OVER (PARTITION BY T1.data2))/ SUM(Nij) OVER () AS  E_nij      FROM    expected_table AS T1 LEFT JOIN    summ_table AS T2 ON    T1.data1 = T2.data1 AND T1.data2 = T2.data2 )     SELECT      SUM( (Nij - E_nij)*(Nij - E_nij) / E_nij ) as Chi2        FROM contingency_table",
        "schema": {
            "pancancer-atlas.Filtered": {
                "clinical_PANCAN_patient_with_followup_filtered": [
                    "histological_type",
                    "bcr_patient_barcode",
                    "acronym"
                ],
                "MC3_MAF_V5_one_per_tumor_sample": [
                    "Hugo_Symbol",
                    "ParticipantBarcode",
                    "Study",
                    "FILTER"
                ]
            }
        }
    },
    "bq279": {
        "query": "SELECT     t.year,     CASE          WHEN t.year = 2013 THEN (                                   SELECT                                      COUNT(DISTINCT station_id)                                   FROM                                      `bigquery-public-data.austin_bikeshare.bikeshare_trips` t                                   INNER JOIN                                      `bigquery-public-data.austin_bikeshare.bikeshare_stations` s                                   ON                                      t.start_station_id = s.station_id                                   WHERE                                      s.status = 'active' AND EXTRACT(YEAR FROM start_time) = 2013                                  )          WHEN t.year = 2014 THEN (                                   SELECT                                      COUNT(DISTINCT station_id)                                   FROM                                      `bigquery-public-data.austin_bikeshare.bikeshare_trips` t                                   INNER JOIN                                      `bigquery-public-data.austin_bikeshare.bikeshare_stations` s                                   ON                                      t.start_station_id = s.station_id                                   WHERE                                      s.status = 'active' AND EXTRACT(YEAR FROM start_time) = 2014                                  )     END     AS number_status_active,     CASE          WHEN t.year = 2013 THEN (                                   SELECT                                     COUNT(DISTINCT station_id)                                   FROM                                    `bigquery-public-data.austin_bikeshare.bikeshare_trips` t                                   INNER JOIN                                    `bigquery-public-data.austin_bikeshare.bikeshare_stations` s                                   ON                                     t.start_station_id = s.station_id                                   WHERE                                     s.status = 'closed' AND EXTRACT(YEAR FROM start_time) = 2013                                  )          WHEN t.year = 2014 THEN (                                   SELECT                                    COUNT(DISTINCT station_id)                                   FROM                                      `bigquery-public-data.austin_bikeshare.bikeshare_trips` t                                   INNER JOIN                                      `bigquery-public-data.austin_bikeshare.bikeshare_stations` s                                   ON                                      t.start_station_id = s.station_id                                   WHERE                                      s.status = 'closed' AND EXTRACT(YEAR FROM start_time) = 2014                                  )     END     AS number_status_closed FROM     (       SELECT           EXTRACT(YEAR FROM start_time) AS year,          start_station_id       FROM          `bigquery-public-data.austin_bikeshare.bikeshare_trips`     )      AS t INNER JOIN     `bigquery-public-data.austin_bikeshare.bikeshare_stations` s ON     t.start_station_id = s.station_id WHERE     t.year BETWEEN 2013 AND 2014 GROUP BY     t.year ORDER BY     t.year;",
        "schema": {
            "bigquery-public-data.austin_bikeshare": {
                "bikeshare_trips": [
                    "year",
                    "start_station_id",
                    "start_time"
                ],
                "bikeshare_stations": [
                    "station_id",
                    "status"
                ]
            }
        }
    },
    "bq281": {
        "query": "SELECT   COUNT(1) AS num_rides FROM   `bigquery-public-data.austin_bikeshare.bikeshare_trips`  WHERE  start_station_name      NOT IN ('Mobile Station', 'Repair Shop') AND end_station_name      NOT IN ('Mobile Station', 'Repair Shop') AND  subscriber_type = 'Student Membership' AND bike_type = 'electric' AND duration_minutes > 10 GROUP BY      EXTRACT(YEAR from start_time),      EXTRACT(MONTH from start_time),      EXTRACT(DAY from start_time) ORDER BY num_rides DESC LIMIT 1",
        "schema": {
            "bigquery-public-data.austin_bikeshare": {
                "bikeshare_trips": [
                    "start_station_name",
                    "end_station_name",
                    "subscriber_type",
                    "bike_type",
                    "duration_minutes",
                    "start_time"
                ]
            }
        }
    },
    "bq282": {
        "query": "SELECT    district FROM (   SELECT     S.starting_district AS district,     T.start_station_id,     T.end_station_id   FROM     `bigquery-public-data.austin_bikeshare.bikeshare_trips` AS T   INNER JOIN (     SELECT       station_id,       council_district AS starting_district     FROM       `bigquery-public-data.austin_bikeshare.bikeshare_stations`     WHERE       status = \"active\"   ) AS S ON T.start_station_id = S.station_id   WHERE     S.starting_district IN (       SELECT council_district       FROM `bigquery-public-data.austin_bikeshare.bikeshare_stations`       WHERE         status = \"active\" AND         station_id = SAFE_CAST(T.end_station_id AS INT64)     )     AND T.start_station_id != SAFE_CAST(T.end_station_id AS INT64) )  GROUP BY district ORDER BY COUNT(*) DESC LIMIT 1;",
        "schema": {
            "bigquery-public-data.austin_bikeshare": {
                "bikeshare_trips": [
                    "starting_district",
                    "start_station_id",
                    "end_station_id"
                ],
                "bikeshare_stations": [
                    "station_id",
                    "council_district",
                    "status"
                ]
            }
        }
    },
    "bq283": {
        "query": "WITH StationStats AS (   SELECT     BT.start_station_id,     COUNT(BT.trip_id) AS total_trips,     RANK() OVER (ORDER BY COUNT(BT.trip_id) DESC) AS station_rank,     ROUND((COUNT(BT.trip_id) / SUM(COUNT(BT.trip_id)) OVER ()) * 100, 2) AS percentage_of_total_trips   FROM `bigquery-public-data.austin_bikeshare.bikeshare_trips` BT   JOIN `bigquery-public-data.austin_bikeshare.bikeshare_stations` BS   ON BT.start_station_id = BS.station_id    WHERE BS.status = 'active'   GROUP BY BT.start_station_id ) , Top15 as(   SELECT     start_station_id,     total_trips,     station_rank,     percentage_of_total_trips   FROM StationStats   WHERE station_rank <= 15    ORDER BY station_rank ASC )  SELECT SUM(T.percentage_of_total_trips) FROM Top15 T;",
        "schema": {
            "bigquery-public-data.austin_bikeshare": {
                "bikeshare_trips": [
                    "start_station_id",
                    "trip_id"
                ],
                "bikeshare_stations": [
                    "station_id",
                    "status"
                ]
            }
        }
    },
    "bq329": {
        "query": "WITH bikeshare_stations AS (   SELECT *   FROM      `bigquery-public-data.austin_bikeshare.bikeshare_stations` ),  bikeshare_trips AS (   SELECT      start_station_id,     SAFE_CAST(end_station_id AS INT64) AS end_station_id,     duration_minutes   FROM      `bigquery-public-data.austin_bikeshare.bikeshare_trips` ), average_duration AS (   SELECT      start_station_id,     AVG(duration_minutes) AS avg_duration_minutes   FROM      bikeshare_trips   GROUP BY      start_station_id ) SELECT    ad.start_station_id FROM    average_duration ad JOIN bikeshare_stations st ON ad.start_station_id = st.station_id ORDER BY    ad.avg_duration_minutes ASC LIMIT 1;",
        "schema": {
            "bigquery-public-data.austin_bikeshare": {
                "bikeshare_stations": [
                    "station_id",
                    "*"
                ],
                "bikeshare_trips": [
                    "start_station_id",
                    "end_station_id",
                    "duration_minutes"
                ]
            }
        }
    },
    "bq284": {
        "query": "SELECT    category,   COUNT(*) AS number_total_by_category,     CASE      WHEN category = 'tech' THEN            (SELECT count(*)                 FROM `bigquery-public-data.bbc_news.fulltext`                 WHERE (body LIKE '%Education%') AND category = 'tech') * 100 /                 (SELECT count(*)                 FROM `bigquery-public-data.bbc_news.fulltext`                 WHERE category = 'tech')     WHEN category = 'sport' THEN            (SELECT count(*)                 FROM `bigquery-public-data.bbc_news.fulltext`                 WHERE (body LIKE '%Education%') AND category = 'sport') * 100 /                 (SELECT count(*)                 FROM `bigquery-public-data.bbc_news.fulltext`                 WHERE category = 'sport')     WHEN category = 'business' THEN            (SELECT count(*)                 FROM `bigquery-public-data.bbc_news.fulltext`                 WHERE (body LIKE '%Education%') AND category = 'business') * 100 /                 (SELECT count(*)                 FROM `bigquery-public-data.bbc_news.fulltext`                 WHERE category = 'business')     WHEN category = 'politics' THEN            (SELECT count(*)                 FROM `bigquery-public-data.bbc_news.fulltext`                 WHERE (body LIKE '%Education%') AND category = 'politics') * 100 /                 (SELECT count(*)                 FROM `bigquery-public-data.bbc_news.fulltext`                 WHERE category = 'politics')     WHEN category = 'entertainment' THEN            (SELECT count(*)                 FROM `bigquery-public-data.bbc_news.fulltext`                 WHERE (body LIKE '%Education%') AND category = 'entertainment') * 100 /                 (SELECT count(*)                 FROM `bigquery-public-data.bbc_news.fulltext`                 WHERE category = 'entertainment')   END AS percent_education FROM `bigquery-public-data.bbc_news.fulltext` GROUP BY   category;",
        "schema": {
            "bigquery-public-data.bbc_news": {
                "fulltext": [
                    "category",
                    "body"
                ]
            }
        }
    },
    "bq355": {
        "query": "WITH quinapril_concept AS (     SELECT concept_id     FROM `bigquery-public-data.cms_synthetic_patient_data_omop.concept`     WHERE concept_code = \"35208\" AND vocabulary_id = \"RxNorm\" ), quinapril_related_medications AS (     SELECT DISTINCT descendant_concept_id AS concept_id     FROM `bigquery-public-data.cms_synthetic_patient_data_omop.concept_ancestor`     WHERE ancestor_concept_id IN (SELECT concept_id FROM quinapril_concept) ), participants_with_quinapril AS (     SELECT COUNT(DISTINCT person_id) AS count     FROM `bigquery-public-data.cms_synthetic_patient_data_omop.drug_exposure`     WHERE drug_concept_id IN (SELECT concept_id FROM quinapril_related_medications) ), total_participants AS (     SELECT COUNT(DISTINCT person_id) AS count     FROM `bigquery-public-data.cms_synthetic_patient_data_omop.person` ) SELECT     100 - (100 * participants_with_quinapril.count / total_participants.count) AS without_quinapril FROM     participants_with_quinapril, total_participants",
        "schema": {
            "bigquery-public-data.cms_synthetic_patient_data_omop": {
                "concept": [
                    "concept_id",
                    "concept_code",
                    "vocabulary_id"
                ],
                "concept_ancestor": [
                    "descendant_concept_id",
                    "ancestor_concept_id"
                ],
                "drug_exposure": [
                    "person_id",
                    "drug_concept_id"
                ],
                "person": [
                    "person_id"
                ]
            }
        }
    },
    "bq285": {
        "query": "with _fips AS     (         SELECT             state_fips_code         FROM             `bigquery-public-data.census_utility.fips_codes_states`         WHERE             state_name = \"Florida\"     )      ,_zip AS     (         SELECT             z.zip_code,             z.zip_code_geom,         FROM             `bigquery-public-data.geo_us_boundaries.zip_codes` z, _fips u         WHERE             z.state_fips_code = u.state_fips_code     )      ,locations AS     (         SELECT             COUNT(i.institution_name) AS count_locations,             l.zip_code         FROM             `bigquery-public-data.fdic_banks.institutions` i         JOIN             `bigquery-public-data.fdic_banks.locations` l          USING (fdic_certificate_number)         WHERE             l.state IS NOT NULL         AND              l.state_name IS NOT NULL         GROUP BY 2     )      SELECT         z.zip_code     FROM         _zip z     JOIN         locations l      USING (zip_code)     GROUP BY         z.zip_code     ORDER BY         SUM(l.count_locations) DESC     LIMIT 1;",
        "schema": {
            "bigquery-public-data.census_utility": {
                "fips_codes_states": [
                    "state_fips_code",
                    "state_name"
                ]
            },
            "bigquery-public-data.geo_us_boundaries": {
                "zip_codes": [
                    "zip_code",
                    "zip_code_geom",
                    "state_fips_code"
                ]
            },
            "bigquery-public-data.fdic_banks": {
                "institutions": [
                    "institution_name",
                    "fdic_certificate_number"
                ],
                "locations": [
                    "fdic_certificate_number",
                    "zip_code",
                    "state",
                    "state_name"
                ]
            }
        }
    },
    "bq287": {
        "query": "with utah_fips AS    (         SELECT             state_fips_code         FROM             `bigquery-public-data.census_utility.fips_codes_states`         WHERE             state_name = \"Utah\"     ),  utah_zip AS     (         SELECT             z.zip_code         FROM             `bigquery-public-data.geo_us_boundaries.zip_codes` z, utah_fips u         WHERE             z.state_fips_code = u.state_fips_code     ),  locations AS     (         SELECT             COUNT(i.institution_name) AS count_locations,             l.zip_code         FROM             utah_zip z         JOIN             `bigquery-public-data.fdic_banks.locations` l USING (zip_code)         JOIN             `bigquery-public-data.fdic_banks.institutions` i USING (fdic_certificate_number)         WHERE             l.state IS NOT NULL             AND l.state_name IS NOT NULL             AND l.zip_code = z.zip_code         GROUP BY 2     ),      acs_2017 AS          (             SELECT                 CAST(geo_id as STRING) AS zip_code,                 ROUND(SAFE_DIVIDE(employed_pop, pop_16_over), 4) AS rate_employment,             FROM                 `bigquery-public-data.census_bureau_acs.zip_codes_2017_5yr`             JOIN                 utah_zip              ON                  geo_id = zip_code         )  SELECT     rate_employment FROM   utah_zip z JOIN   locations l USING (zip_code) JOIN   acs_2017 acs USING (zip_code) ORDER BY   l.count_locations ASC LIMIT 1;",
        "schema": {
            "bigquery-public-data.census_utility": {
                "fips_codes_states": [
                    "state_fips_code",
                    "state_name"
                ]
            },
            "bigquery-public-data.geo_us_boundaries": {
                "zip_codes": [
                    "zip_code",
                    "state_fips_code"
                ]
            },
            "bigquery-public-data.fdic_banks": {
                "locations": [
                    "zip_code",
                    "state",
                    "state_name",
                    "fdic_certificate_number"
                ],
                "institutions": [
                    "fdic_certificate_number",
                    "institution_name"
                ]
            },
            "bigquery-public-data.census_bureau_acs": {
                "zip_codes_2017_5yr": [
                    "geo_id",
                    "employed_pop",
                    "pop_16_over"
                ]
            }
        }
    },
    "bq288": {
        "query": "WITH state_counts AS (         SELECT              DISTINCT state_name,             COUNT(1) AS count_institutions         FROM             `bigquery-public-data.fdic_banks.institutions`         GROUP BY             state_name         ),          detailed_info AS (             SELECT                 DISTINCT state_name AS state,                 SUM(total_assets) AS sum_assets,             FROM                 `bigquery-public-data.fdic_banks.institutions`             WHERE                 established_date BETWEEN '1900-01-01' AND '2000-12-31'             AND                  (institution_name LIKE 'Bank%')             GROUP BY                 state_name         ) SELECT     s.count_institutions AS count_institutions_in_state FROM     detailed_info d JOIN     state_counts s  ON      d.state = s.state_name ORDER BY     d.sum_assets DESC LIMIT 1;",
        "schema": {
            "bigquery-public-data.fdic_banks": {
                "institutions": [
                    "state_name",
                    "total_assets",
                    "established_date",
                    "institution_name"
                ]
            }
        }
    },
    "bq289": {
        "query": "WITH philadelphia AS (     SELECT          *      FROM          `bigquery-public-data.geo_us_census_places.places_pennsylvania`      WHERE          place_name = 'Philadelphia' ), amenities AS (     SELECT *,             (                 SELECT                      tags.value                  FROM                      UNNEST(all_tags) AS tags                  WHERE                      tags.key = 'amenity'            ) AS amenity     FROM          `bigquery-public-data.geo_openstreetmap.planet_features_points` AS features     CROSS JOIN philadelphia     WHERE ST_CONTAINS(philadelphia.place_geom, features.geometry)     AND      (         EXISTS (             SELECT 1              FROM UNNEST(all_tags) AS tags              WHERE tags.key = 'amenity'              AND tags.value IN ('library', 'place_of_worship', 'community_centre')         )     ) ), joiin AS (     SELECT          a1.*,          a2.osm_id AS nearest_osm_id,          ST_DISTANCE(a1.geometry, a2.geometry) AS distance,          ROW_NUMBER() OVER (PARTITION BY a1.osm_id ORDER BY ST_Distance(a1.geometry, a2.geometry)) AS row_num     FROM amenities a1     CROSS JOIN amenities a2     WHERE a1.osm_id < a2.osm_id     ORDER BY a1.osm_id, distance )  SELECT distance FROM joiin   WHERE row_num = 1 ORDER BY distance ASC LIMIT 1;",
        "schema": {
            "bigquery-public-data.geo_us_census_places.places_pennsylvania": {
                "places_pennsylvania": [
                    "place_name",
                    "place_geom"
                ]
            },
            "bigquery-public-data.geo_openstreetmap.planet_features_points": {
                "planet_features_points": [
                    "all_tags",
                    "geometry",
                    "osm_id"
                ]
            }
        }
    },
    "bq226": {
        "query": "SELECT     CONCAT(\"https://cronoscan.com/address/\", t.from_address) AS cronoscan_link, FROM     `bigquery-public-data.goog_blockchain_cronos_mainnet_us.transactions` AS t INNER JOIN     `bigquery-public-data.goog_blockchain_cronos_mainnet_us.blocks` AS b ON     b.block_hash = t.block_hash WHERE     t.to_address IS NOT NULL AND     b.size > 4096 AND     b.block_timestamp > TIMESTAMP(\"2023-01-01 00:00:00\") AND     t.block_timestamp > TIMESTAMP(\"2023-01-01 00:00:00\") GROUP BY     t.from_address ORDER BY     COUNT(*)  DESC LIMIT 1;",
        "schema": {
            "bigquery-public-data.goog_blockchain_cronos_mainnet_us": {
                "transactions": [
                    "from_address",
                    "to_address",
                    "block_hash",
                    "block_timestamp"
                ],
                "blocks": [
                    "block_hash",
                    "size",
                    "block_timestamp"
                ]
            }
        }
    },
    "bq320": {
        "query": "SELECT   COUNT(*) AS total_count FROM   `bigquery-public-data.idc_v11.dicom_pivot_v11` dicom_pivot_v11 WHERE   StudyInstanceUID IN (     SELECT       StudyInstanceUID     FROM       `bigquery-public-data.idc_v11.dicom_pivot_v11` dicom_pivot_v11     WHERE       StudyInstanceUID IN (         SELECT           StudyInstanceUID         FROM           `bigquery-public-data.idc_v11.dicom_pivot_v11` dicom_pivot_v11         WHERE           (             LOWER(               dicom_pivot_v11.SegmentedPropertyTypeCodeSequence             ) LIKE LOWER('80891009:SCT')           )         GROUP BY           StudyInstanceUID         INTERSECT DISTINCT         SELECT           StudyInstanceUID         FROM           `bigquery-public-data.idc_v11.dicom_pivot_v11` dicom_pivot_v11         WHERE           (             dicom_pivot_v11.collection_id IN ('Community', 'nsclc_radiomics')           )         GROUP BY           StudyInstanceUID       )     GROUP BY       StudyInstanceUID   );",
        "schema": {
            "bigquery-public-data.idc_v11": {
                "dicom_pivot_v11": [
                    "StudyInstanceUID",
                    "SegmentedPropertyTypeCodeSequence",
                    "collection_id"
                ]
            }
        }
    },
    "bq321": {
        "query": "WITH relevant_series AS (   SELECT      DISTINCT StudyInstanceUID   FROM      `bigquery-public-data.idc_v14.dicom_all`   WHERE      collection_id = 'qin_prostate_repeatability'     AND           SeriesDescription IN (             'DWI',             'T2 Weighted Axial',             'Apparent Diffusion Coefficient',             'T2 Weighted Axial Segmentations',             'Apparent Diffusion Coefficient Segmentations'     )     ), t2_seg_lesion_series AS (   SELECT      DISTINCT StudyInstanceUID   FROM      `bigquery-public-data.idc_v14.dicom_all`   CROSS JOIN UNNEST(SegmentSequence) AS segSeq   WHERE      collection_id = 'qin_prostate_repeatability'     AND SeriesDescription = 'T2 Weighted Axial Segmentations' )  SELECT      COUNT(DISTINCT StudyInstanceUID) AS total_count FROM (   SELECT      StudyInstanceUID    FROM relevant_series   UNION ALL   SELECT      StudyInstanceUID   FROM t2_seg_lesion_series );",
        "schema": {
            "bigquery-public-data.idc_v14": {
                "dicom_all": [
                    "StudyInstanceUID",
                    "collection_id",
                    "SeriesDescription",
                    "SegmentSequence"
                ]
            }
        }
    },
    "bq322": {
        "query": "WITH modality_counts AS (   SELECT     Modality,     COUNT(*) AS frequency   FROM     `bigquery-public-data.idc_v15.dicom_pivot` dicom_pivot   WHERE     StudyInstanceUID IN (       SELECT         StudyInstanceUID       FROM         `bigquery-public-data.idc_v15.dicom_pivot` dicom_pivot       WHERE         collection_id IN ('Community', 'nsclc_radiomics')       GROUP BY         StudyInstanceUID     )   GROUP BY     Modality )  SELECT   Modality FROM   modality_counts ORDER BY   frequency DESC LIMIT 1;",
        "schema": {
            "bigquery-public-data.idc_v15": {
                "dicom_pivot": [
                    "Modality",
                    "StudyInstanceUID",
                    "collection_id"
                ]
            }
        }
    },
    "bq227_1": {
        "query": "WITH top5_vs_other_minor_cat AS (   SELECT year, month, minor_category,        CASE          WHEN minor_category IN (SELECT minor_category                                   FROM (SELECT minor_category, SUM(value) AS total                                     FROM bigquery-public-data.london_crime.crime_by_lsoa                                     GROUP BY 1                                     ORDER BY 2 DESC                                     LIMIT 5))                             THEN 'Top 5'          ELSE 'Other Minor Categories'-- Dividing the data into 'Top 5' and 'Other Minor Categories'        END AS division,        SUM(value) AS total   FROM bigquery-public-data.london_crime.crime_by_lsoa     GROUP BY 1,2,3     ORDER BY 3 DESC ), top5_percentage AS (   SELECT      year,      division,      year_total / SUM(year_total) OVER (PARTITION BY year) * 100 AS percentage    FROM      (       SELECT          year, division, SUM(total) AS year_total       FROM          top5_vs_other_minor_cat       GROUP BY 1,2       ORDER BY 1     ) ) SELECT   year,   percentage FROM    top5_percentage WHERE division = 'Top 5' ORDER BY year;",
        "schema": {
            "bigquery-public-data.london_crime": {
                "crime_by_lsoa": [
                    "year",
                    "month",
                    "minor_category",
                    "value"
                ]
            }
        }
    },
    "bq227_2": {
        "query": "WITH borough_data AS (     SELECT          year,          month,          borough,          major_category,          minor_category,          SUM(value) AS total,     CASE          WHEN              major_category = 'Theft and Handling'          THEN              'Theft and Handling'         ELSE              'Other'      END AS major_division,     CASE          WHEN              minor_category = 'Other Theft' THEN minor_category         ELSE              'Other'     END AS minor_division,     FROM          bigquery-public-data.london_crime.crime_by_lsoa     GROUP BY 1,2,3,4,5     ORDER BY 1,2 )  SELECT year, SUM(total) AS year_total FROM borough_data WHERE      borough = 'Westminster' AND     major_division != 'Other' AND      minor_division != 'Other' GROUP BY year, major_division, minor_division ORDER BY year;",
        "schema": {
            "bigquery-public-data.london_crime": {
                "crime_by_lsoa": [
                    "year",
                    "month",
                    "borough",
                    "major_category",
                    "minor_category",
                    "value"
                ]
            }
        }
    },
    "bq228": {
        "query": "WITH ranked_crimes AS (     SELECT         borough,         major_category,         RANK() OVER(PARTITION BY borough ORDER BY SUM(value) DESC) AS rank_per_borough,         SUM(value) AS no_of_incidents     FROM         `bigquery-public-data.london_crime.crime_by_lsoa`     GROUP BY         borough,         major_category )  SELECT     borough,     major_category,     rank_per_borough,     no_of_incidents FROM     ranked_crimes WHERE     rank_per_borough <= 3 AND      borough = 'Barking and Dagenham' ORDER BY     borough,     rank_per_borough;",
        "schema": {
            "bigquery-public-data.london_crime": {
                "crime_by_lsoa": [
                    "borough",
                    "major_category",
                    "value"
                ]
            }
        }
    },
    "bq229": {
        "query": "WITH all_images_and_labels AS (   SELECT i.original_url, l.label_name, l.confidence   FROM `bigquery-public-data.open_images.images` i   JOIN `bigquery-public-data.open_images.labels` l   ON i.image_id = l.image_id ), urls_with_labels AS (     SELECT original_url, label     FROM     (     SELECT DISTINCT original_url, 'cat' as label     FROM all_images_and_labels     WHERE confidence = 1     AND label_name LIKE '/m/01yrx'     UNION ALL     (         SELECT DISTINCT all_images.original_url, 'other' as label         FROM all_images_and_labels all_images         LEFT JOIN         (         SELECT original_url         FROM all_images_and_labels         WHERE confidence = 1         AND NOT (label_name LIKE '/m/01yrx')         ) not_cat         ON all_images.original_url = not_cat.original_url         WHERE not_cat.original_url IS NULL     )     ) )  SELECT label, COUNT(*) AS url_num FROM urls_with_labels GROUP BY label",
        "schema": {
            "bigquery-public-data.open_images": {
                "images": [
                    "original_url",
                    "image_id"
                ],
                "labels": [
                    "image_id",
                    "label_name",
                    "confidence"
                ]
            }
        }
    },
    "bq325": {
        "query": "WITH ranked_genes AS (     SELECT          locus2gene.study_id,          genes.gene_name,          lead_variants.pval,         ROW_NUMBER() OVER (             PARTITION BY locus2gene.study_id, genes.gene_name              ORDER BY lead_variants.pval         ) AS rn     FROM          `bigquery-public-data.open_targets_genetics.locus2gene` AS locus2gene     INNER JOIN          `bigquery-public-data.open_targets_genetics.studies` AS study_metadata         ON locus2gene.study_id = study_metadata.study_id     INNER JOIN          `bigquery-public-data.open_targets_genetics.genes` AS genes         ON locus2gene.gene_id = genes.gene_id     INNER JOIN          `bigquery-public-data.open_targets_genetics.variant_disease` AS lead_variants         ON locus2gene.pos = lead_variants.lead_pos         AND locus2gene.chrom = lead_variants.lead_chrom         AND locus2gene.study_id = lead_variants.study_id ) SELECT      gene_name FROM      ranked_genes WHERE      rn = 1 ORDER BY      pval ASC LIMIT 10;",
        "schema": {
            "bigquery-public-data.open_targets_genetics": {
                "locus2gene": [
                    "study_id",
                    "gene_id",
                    "pos",
                    "chrom"
                ],
                "studies": [
                    "study_id"
                ],
                "genes": [
                    "gene_id",
                    "gene_name"
                ],
                "variant_disease": [
                    "lead_pos",
                    "lead_chrom",
                    "study_id",
                    "pval"
                ]
            }
        }
    },
    "bq230": {
        "query": "WITH    temp_table AS   (SELECT     state_name,     commodity_desc,     SUM(value) AS total_produce,     TIMESTAMP_TRUNC(load_time, YEAR) AS year_load,   FROM      `bigquery-public-data.usda_nass_agriculture.crops`   WHERE     group_desc='FIELD CROPS' AND     statisticcat_desc='PRODUCTION' AND     agg_level_desc='STATE' AND     value IS NOT NULL AND     unit_desc='BU'   GROUP BY     commodity_desc,     year_load,     state_name   ORDER BY     state_name,     commodity_desc,     total_produce DESC) SELECT   state_name,   MAX(total_produce) AS total_prod FROM   temp_table WHERE   year_load='2018-01-01 00:00:00 UTC' AND   commodity_desc='CORN' GROUP BY   state_name,   commodity_desc ORDER BY   state_name",
        "schema": {
            "bigquery-public-data.usda_nass_agriculture": {
                "crops": [
                    "state_name",
                    "commodity_desc",
                    "value",
                    "load_time"
                ]
            }
        }
    },
    "bq231": {
        "query": "WITH   temp_table AS   (SELECT     state_name,     commodity_desc,     SUM(value) as total_produce,     TIMESTAMP_TRUNC(load_time, YEAR) AS year_load,   FROM      `bigquery-public-data.usda_nass_agriculture.crops`   WHERE     group_desc='HORTICULTURE' AND     statisticcat_desc='PRODUCTION' AND     agg_level_desc='STATE' AND     commodity_desc='MUSHROOMS' AND     value IS NOT NULL   GROUP BY     state_name,     commodity_desc,     year_load), state_with_prod AS ( SELECT   state_name,   MAX(total_produce) AS total_prod FROM   temp_table WHERE   year_load='2022-01-01 00:00:00 UTC' GROUP BY   state_name,   commodity_desc )  SELECT state_name FROM state_with_prod ORDER BY total_prod DESC LIMIT 1",
        "schema": {
            "bigquery-public-data.usda_nass_agriculture": {
                "crops": [
                    "state_name",
                    "commodity_desc",
                    "value",
                    "load_time",
                    "group_desc",
                    "statisticcat_desc",
                    "agg_level_desc"
                ]
            }
        }
    },
    "bq327": {
        "query": "WITH russia_Data AS (   SELECT DISTINCT      id.country_name,     id.value, -- Format in DataStudio     id.indicator_name   FROM (     SELECT       country_code,       region     FROM       bigquery-public-data.world_bank_intl_debt.country_summary     WHERE       region != \"\" -- Aggregated countries do not have a region   ) cs -- Aggregated countries do not have a region   INNER JOIN (     SELECT       country_code,       country_name,       value,        indicator_name     FROM       bigquery-public-data.world_bank_intl_debt.international_debt     WHERE       country_code = 'RUS'   ) id   ON     cs.country_code = id.country_code   WHERE value IS NOT NULL ) -- Count the number of indicators with a value of 0 for Russia SELECT    COUNT(*) AS number_of_indicators_with_zero FROM    russia_Data WHERE    value = 0;",
        "schema": {
            "bigquery-public-data.world_bank_intl_debt": {
                "country_summary": [
                    "country_code",
                    "region"
                ],
                "international_debt": [
                    "country_code",
                    "country_name",
                    "value",
                    "indicator_name"
                ]
            }
        }
    },
    "bq328": {
        "query": "WITH country_data AS (   -- CTE for country descriptive data   SELECT      country_code,      short_name AS country,     region,      income_group    FROM      `bigquery-public-data.world_bank_wdi.country_summary` ),  gdp_data AS (   -- Filter data to only include GDP values   SELECT      data.country_code,      country,     region,     value AS gdp_value   FROM      `bigquery-public-data.world_bank_wdi.indicators_data` data   LEFT JOIN country_data     ON data.country_code = country_data.country_code   WHERE indicator_code = \"NY.GDP.MKTP.KD\" -- GDP Indicator     AND country_data.region IS NOT NULL     AND country_data.income_group IS NOT NULL ),  cal_median_gdp AS (   -- Calculate the median GDP value for each region   SELECT      region,     APPROX_QUANTILES(gdp_value, 2)[OFFSET(1)] AS median_gdp   FROM gdp_data   GROUP BY region ) -- Select the regions with their median GDP values SELECT    region FROM    cal_median_gdp ORDER BY median_gdp DESC LIMIT 1;",
        "schema": {
            "bigquery-public-data.world_bank_wdi": {
                "country_summary": [
                    "country_code",
                    "short_name",
                    "region",
                    "income_group"
                ],
                "indicators_data": [
                    "country_code",
                    "value",
                    "indicator_code"
                ]
            }
        }
    },
    "bq370": {
        "query": "WITH CustomerOrderData AS (     SELECT OrderID,            InvoiceID,            CustomerID,            COUNT(CustomerOrderCost) AS TotalNbOrders,            SUM(CustomerOrderCost) AS OrdersTotalValue,            COUNT(CustomerOrderInvoice) AS TotalNbInvoices,            SUM(CustomerOrderInvoice) AS InvoicesTotalValue     FROM (            SELECT Orders.*,                   Invoices.CustomerOrderInvoice            FROM (                   SELECT o.OrderID,                          Inv.InvoiceID,                          ol.StockItemID,                          cu.CustomerID,                          ol.Quantity * ol.UnitPrice AS CustomerOrderCost                   FROM `spider2-public-data.wide_world_importers.sales_Customers` cu                   INNER JOIN `spider2-public-data.wide_world_importers.sales_Orders` o                            ON cu.CustomerID = o.CustomerID                   INNER JOIN `spider2-public-data.wide_world_importers.sales_OrderLines` ol                            ON o.OrderID = ol.OrderID                   INNER JOIN `spider2-public-data.wide_world_importers.sales_Invoices` Inv                            ON ol.OrderID = Inv.OrderID                 ) Orders            INNER JOIN (                   SELECT Inv.OrderID,                          Invl.InvoiceID,                          Invl.StockItemID,                          Quantity * UnitPrice AS CustomerOrderInvoice                   FROM `spider2-public-data.wide_world_importers.sales_InvoiceLines` Invl                   INNER JOIN `spider2-public-data.wide_world_importers.sales_Invoices` Inv                            ON Invl.InvoiceID = Inv.InvoiceID                 ) Invoices             ON Orders.OrderID = Invoices.OrderID             AND Orders.InvoiceID = Invoices.InvoiceID             AND Orders.StockItemID = Invoices.StockItemID          ) A     GROUP BY OrderID,              InvoiceID,              CustomerID ), CustomerSummary AS (     SELECT CustomerID,            COUNT(TotalNbOrders) AS TotalNbOrders,            COUNT(TotalNbInvoices) AS TotalNbInvoices,            SUM(OrdersTotalValue) AS OrdersTotalValue,            SUM(InvoicesTotalValue) AS InvoicesTotalValue,            (SUM(OrdersTotalValue) - SUM(InvoicesTotalValue)) AS AbsoluteValueDifference     FROM CustomerOrderData     GROUP BY CustomerID ) SELECT COUNT(*) AS NumberOfCustomersWithNoDifference FROM CustomerSummary WHERE TotalNbOrders = TotalNbInvoices   AND OrdersTotalValue = InvoicesTotalValue;",
        "schema": {
            "spider2-public-data.wide_world_importers": {
                "sales_Customers": [
                    "CustomerID"
                ],
                "sales_Orders": [
                    "OrderID",
                    "CustomerID"
                ],
                "sales_OrderLines": [
                    "OrderID",
                    "StockItemID",
                    "Quantity",
                    "UnitPrice"
                ],
                "sales_Invoices": [
                    "OrderID",
                    "InvoiceID"
                ],
                "sales_InvoiceLines": [
                    "InvoiceID",
                    "StockItemID",
                    "Quantity",
                    "UnitPrice"
                ]
            }
        }
    },
    "bq371": {
        "query": "WITH CustomerQuarterlyData AS (     SELECT             CUS.CustomerName,            COALESCE(INVL.unitprice * INVL.quantity, 0) AS InvoicesTotalValue,            CASE                WHEN EXTRACT(QUARTER FROM CAST(INV.invoicedate AS TIMESTAMP)) = 1 THEN 'Q1'                WHEN EXTRACT(QUARTER FROM CAST(INV.invoicedate AS TIMESTAMP)) = 2 THEN 'Q2'                WHEN EXTRACT(QUARTER FROM CAST(INV.invoicedate AS TIMESTAMP)) = 3 THEN 'Q3'                WHEN EXTRACT(QUARTER FROM CAST(INV.invoicedate AS TIMESTAMP)) = 4 THEN 'Q4'            END AS QuarterInvoiceDate     FROM           `spider2-public-data.wide_world_importers.sales_InvoiceLines` AS INVL     INNER JOIN `spider2-public-data.wide_world_importers.sales_Invoices` AS INV             ON INVL.InvoiceID = INV.InvoiceID     INNER JOIN `spider2-public-data.wide_world_importers.sales_Customers` AS CUS             ON CUS.CustomerID = INV.CustomerID     WHERE EXTRACT(YEAR FROM CAST(INV.invoicedate AS TIMESTAMP)) = 2013 ), QuarterlyAverages AS (     SELECT             QuarterInvoiceDate,            AVG(InvoicesTotalValue) AS AvgInvoiceValue     FROM           CustomerQuarterlyData     GROUP BY QuarterInvoiceDate ), MaxMinAverages AS (     SELECT             MAX(AvgInvoiceValue) AS MaxAvgValue,            MIN(AvgInvoiceValue) AS MinAvgValue     FROM           QuarterlyAverages ) SELECT       MaxAvgValue - MinAvgValue AS DifferenceBetweenMaxAndMinAvg FROM MaxMinAverages;",
        "schema": {
            "spider2-public-data.wide_world_importers": {
                "sales_InvoiceLines": [
                    "unitprice",
                    "quantity",
                    "InvoiceID"
                ],
                "sales_Invoices": [
                    "InvoiceID",
                    "CustomerID",
                    "invoicedate"
                ],
                "sales_Customers": [
                    "CustomerID",
                    "CustomerName"
                ]
            }
        }
    },
    "bq372": {
        "query": "WITH MaxLossPerCategory AS (     -- Calculate the maximum loss for each category     SELECT             CustomerCategoryName,            MAX(OrderValueLost) AS MaxLoss     FROM (         SELECT                 cc.CustomerCategoryName,                SUM(ol.Quantity * ol.UnitPrice) AS OrderValueLost         FROM                 `spider2-public-data.wide_world_importers.sales_Customers` cu         INNER JOIN `spider2-public-data.wide_world_importers.sales_Orders` o             ON cu.CustomerID = o.CustomerID         INNER JOIN `spider2-public-data.wide_world_importers.sales_CustomerCategories` cc             ON cu.CustomerCategoryID = cc.CustomerCategoryID         INNER JOIN `spider2-public-data.wide_world_importers.sales_OrderLines` ol             ON o.OrderID = ol.OrderID         WHERE o.OrderID NOT IN (             SELECT                   I.OrderID             FROM                   `spider2-public-data.wide_world_importers.sales_Invoices` I         )         GROUP BY cc.CustomerCategoryName, cu.CustomerID     ) A     GROUP BY A.CustomerCategoryName ), AvgMaxLoss AS (     -- Calculate the average of the maximum losses across all categories     SELECT           AVG(MaxLoss) AS AvgLoss     FROM           MaxLossPerCategory ), ClosestToAvg AS (     -- Find the category with the maximum loss closest to the average     SELECT             ml.CustomerCategoryName,            ABS(ml.MaxLoss - al.AvgLoss) AS DiffFromAvg     FROM             MaxLossPerCategory ml     CROSS JOIN AvgMaxLoss al     ORDER BY DiffFromAvg ASC     LIMIT 1 ) -- Final selection of the category name SELECT       CustomerCategoryName FROM       ClosestToAvg;",
        "schema": {
            "spider2-public-data.wide_world_importers": {
                "sales_Customers": [
                    "CustomerID",
                    "CustomerCategoryID"
                ],
                "sales_Orders": [
                    "CustomerID",
                    "OrderID"
                ],
                "sales_CustomerCategories": [
                    "CustomerCategoryID",
                    "CustomerCategoryName"
                ],
                "sales_OrderLines": [
                    "OrderID",
                    "Quantity",
                    "UnitPrice"
                ],
                "sales_Invoices": [
                    "OrderID"
                ]
            }
        }
    },
    "bq373": {
        "query": "WITH MonthlyAverageSpending AS (     SELECT          AVG(Jan + Feb + Mar + Apr + May + Jun + Jul + Aug + Sep + Oct + Nov + Dec) AS AvgMonthlySpending     FROM (         SELECT              CustomerName,             IFNULL(SUM(CASE WHEN MonthInvoiceDate = 'Jan' THEN InvoicesTotalValue ELSE 0.00 END), 0.00) AS Jan,             IFNULL(SUM(CASE WHEN MonthInvoiceDate = 'Feb' THEN InvoicesTotalValue ELSE 0.00 END), 0.00) AS Feb,             IFNULL(SUM(CASE WHEN MonthInvoiceDate = 'Mar' THEN InvoicesTotalValue ELSE 0.00 END), 0.00) AS Mar,             IFNULL(SUM(CASE WHEN MonthInvoiceDate = 'Apr' THEN InvoicesTotalValue ELSE 0.00 END), 0.00) AS Apr,             IFNULL(SUM(CASE WHEN MonthInvoiceDate = 'May' THEN InvoicesTotalValue ELSE 0.00 END), 0.00) AS May,             IFNULL(SUM(CASE WHEN MonthInvoiceDate = 'Jun' THEN InvoicesTotalValue ELSE 0.00 END), 0.00) AS Jun,             IFNULL(SUM(CASE WHEN MonthInvoiceDate = 'Jul' THEN InvoicesTotalValue ELSE 0.00 END), 0.00) AS Jul,             IFNULL(SUM(CASE WHEN MonthInvoiceDate = 'Aug' THEN InvoicesTotalValue ELSE 0.00 END), 0.00) AS Aug,             IFNULL(SUM(CASE WHEN MonthInvoiceDate = 'Sep' THEN InvoicesTotalValue ELSE 0.00 END), 0.00) AS Sep,             IFNULL(SUM(CASE WHEN MonthInvoiceDate = 'Oct' THEN InvoicesTotalValue ELSE 0.00 END), 0.00) AS Oct,             IFNULL(SUM(CASE WHEN MonthInvoiceDate = 'Nov' THEN InvoicesTotalValue ELSE 0.00 END), 0.00) AS Nov,             IFNULL(SUM(CASE WHEN MonthInvoiceDate = 'Dec' THEN InvoicesTotalValue ELSE 0.00 END), 0.00) AS Dec         FROM (             SELECT                  cu.CustomerName,                 COALESCE(invl.UnitPrice * invl.Quantity, 0) AS InvoicesTotalValue,                 FORMAT_DATE('%b', DATE(inv.InvoiceDate)) AS MonthInvoiceDate             FROM                  `spider2-public-data.wide_world_importers.sales_InvoiceLines` invl             INNER JOIN                  `spider2-public-data.wide_world_importers.sales_Invoices` inv                 ON invl.InvoiceID = inv.InvoiceID             INNER JOIN                  `spider2-public-data.wide_world_importers.sales_Customers` cu                 ON cu.CustomerID = inv.CustomerID             WHERE                  EXTRACT(YEAR FROM CAST(INV.invoicedate AS TIMESTAMP)) = 2014         ) AS SourceTable         GROUP BY              CustomerName     ) AS MonthlySpend     GROUP BY          CustomerName ), MedianSpending AS (     SELECT          PERCENTILE_CONT(AvgMonthlySpending, 0.5) OVER() AS MedianOfAvgMonthlySpending     FROM          MonthlyAverageSpending ) -- Final output of the median spending SELECT DISTINCT MedianOfAvgMonthlySpending FROM MedianSpending;",
        "schema": {
            "spider2-public-data.wide_world_importers": {
                "sales_InvoiceLines": [
                    "UnitPrice",
                    "Quantity",
                    "InvoiceID"
                ],
                "sales_Invoices": [
                    "InvoiceID",
                    "CustomerID",
                    "InvoiceDate"
                ],
                "sales_Customers": [
                    "CustomerID",
                    "CustomerName"
                ]
            }
        }
    },
    "bq398": {
        "query": "WITH russia_Data as ( SELECT distinct    id.country_name,   id.value, --format in DataStudio   id.indicator_name FROM (   SELECT     country_code,     region   FROM     bigquery-public-data.world_bank_intl_debt.country_summary   WHERE     region != \"\" ) cs --aggregated countries do not have a region INNER JOIN (   SELECT     country_code,     country_name,     value,      indicator_name   FROM     bigquery-public-data.world_bank_intl_debt.international_debt   WHERE true     and country_code = 'RUS'        ) id ON   cs.country_code = id.country_code WHERE value is not null ORDER BY   id.value DESC ) SELECT      indicator_name FROM russia_data LIMIT 3;",
        "schema": {
            "bigquery-public-data.world_bank_intl_debt": {
                "country_summary": [
                    "country_code",
                    "region"
                ],
                "international_debt": [
                    "country_code",
                    "country_name",
                    "value",
                    "indicator_name"
                ]
            }
        }
    },
    "ga001": {
        "query": "WITH   Params AS (     SELECT 'Google Navy Speckled Tee' AS selected_product   ),   PurchaseEvents AS (     SELECT       user_pseudo_id,       items     FROM       `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*`     WHERE       _TABLE_SUFFIX BETWEEN '20201201' AND '20201231'       AND event_name = 'purchase'   ),   ProductABuyers AS (     SELECT DISTINCT       user_pseudo_id     FROM       Params,       PurchaseEvents,       UNNEST(items) AS items     WHERE       items.item_name = selected_product   ) SELECT   items.item_name AS item_name,   SUM(items.quantity) AS item_quantity FROM   Params,   PurchaseEvents,   UNNEST(items) AS items WHERE   user_pseudo_id IN (SELECT user_pseudo_id FROM ProductABuyers)   AND items.item_name != selected_product GROUP BY 1 ORDER BY item_quantity DESC LIMIT 1;",
        "schema": {
            "bigquery-public-data.ga4_obfuscated_sample_ecommerce": {
                "events_*": [
                    "user_pseudo_id",
                    "items",
                    "event_name"
                ]
            }
        }
    },
    "ga001_1": {
        "query": "WITH Params AS (   SELECT 'Google Red Speckled Tee' AS selected_product ), DateRanges AS (   SELECT '20201101' AS start_date, '20201130' AS end_date, '202011' AS period UNION ALL   SELECT '20201201', '20201231', '202012' UNION ALL   SELECT '20210101', '20210131', '202101' ), PurchaseEvents AS (   SELECT     period,     user_pseudo_id,     items   FROM     DateRanges   JOIN     `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*`     ON _TABLE_SUFFIX BETWEEN start_date AND end_date   WHERE     event_name = 'purchase' ), ProductABuyers AS (   SELECT DISTINCT     period,     user_pseudo_id   FROM     Params,     PurchaseEvents,     UNNEST(items) AS items   WHERE     items.item_name = selected_product ), TopProducts AS (   SELECT     pe.period,     items.item_name AS item_name,     SUM(items.quantity) AS item_quantity   FROM     Params,     PurchaseEvents pe,     UNNEST(items) AS items   WHERE     user_pseudo_id IN (SELECT user_pseudo_id FROM ProductABuyers pb WHERE pb.period = pe.period)     AND items.item_name != selected_product   GROUP BY     pe.period, items.item_name ), TopProductPerPeriod AS (   SELECT     period,     item_name,     item_quantity   FROM (     SELECT       period,       item_name,       item_quantity,       RANK() OVER (PARTITION BY period ORDER BY item_quantity DESC) AS rank     FROM       TopProducts   )   WHERE     rank = 1 ) SELECT   period,   item_name,   item_quantity FROM   TopProductPerPeriod ORDER BY   period;",
        "schema": {
            "bigquery-public-data.ga4_obfuscated_sample_ecommerce": {
                "events_*": [
                    "_TABLE_SUFFIX",
                    "event_name",
                    "user_pseudo_id",
                    "items.item_name",
                    "items.quantity",
                    "period"
                ]
            }
        }
    },
    "ga003": {
        "query": "WITH EventData AS (     SELECT          user_pseudo_id,          event_timestamp,          param     FROM          `firebase-public-project.analytics_153293282.events_20180915`,         UNNEST(event_params) AS param     WHERE          event_name = \"level_complete_quickplay\"         AND (param.key = \"value\" OR param.key = \"board\") ), ProcessedData AS (     SELECT          user_pseudo_id,          event_timestamp,          MAX(IF(param.key = \"value\", param.value.int_value, NULL)) AS score,         MAX(IF(param.key = \"board\", param.value.string_value, NULL)) AS board_type     FROM          EventData     GROUP BY          user_pseudo_id,          event_timestamp ) SELECT      ANY_VALUE(board_type) AS board,      AVG(score) AS average_score FROM      ProcessedData GROUP BY      board_type",
        "schema": {
            "firebase-public-project.analytics_153293282": {
                "events_20180915": [
                    "user_pseudo_id",
                    "event_timestamp",
                    "event_name",
                    "event_params"
                ]
            }
        }
    },
    "ga004": {
        "query": "WITH   UserInfo AS (     SELECT       user_pseudo_id,       COUNTIF(event_name = 'page_view') AS page_view_count,       COUNTIF(event_name IN ('in_app_purchase', 'purchase')) AS purchase_event_count     FROM `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*`     WHERE _TABLE_SUFFIX BETWEEN '20201201' AND '20201231'     GROUP BY 1   ),   Averages AS (     SELECT       (purchase_event_count > 0) AS purchaser,       COUNT(*) AS user_count,       SUM(page_view_count) AS total_page_views,       SUM(page_view_count) / COUNT(*) AS avg_page_views     FROM UserInfo     GROUP BY 1   )  SELECT   MAX(CASE WHEN purchaser THEN avg_page_views ELSE 0 END) -   MAX(CASE WHEN NOT purchaser THEN avg_page_views ELSE 0 END) AS avg_page_views_difference FROM Averages;",
        "schema": {
            "bigquery-public-data.ga4_obfuscated_sample_ecommerce": {
                "events_*": [
                    "user_pseudo_id",
                    "event_name",
                    "_TABLE_SUFFIX"
                ]
            }
        }
    },
    "ga004_1": {
        "query": "WITH   UserInfo AS (     SELECT       user_pseudo_id,       PARSE_DATE('%Y%m%d', event_date) AS event_date,       COUNTIF(event_name = 'page_view') AS page_view_count,       COUNTIF(event_name IN ('in_app_purchase', 'purchase')) AS purchase_event_count     FROM `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*`     WHERE _TABLE_SUFFIX BETWEEN '20201101' AND '20201130'     GROUP BY 1, 2   ) SELECT   event_date,   SUM(page_view_count) / COUNT(*) AS avg_page_views,   SUM(page_view_count) FROM UserInfo WHERE purchase_event_count > 0 GROUP BY event_date ORDER BY event_date;",
        "schema": {
            "bigquery-public-data.ga4_obfuscated_sample_ecommerce": {
                "events_*": [
                    "user_pseudo_id",
                    "event_date",
                    "event_name"
                ]
            }
        }
    },
    "ga017": {
        "query": "WITH unnested_events AS (   SELECT     MAX(CASE WHEN event_params.key = 'page_title' THEN event_params.value.string_value END) AS page_title,     user_pseudo_id,     event_timestamp   FROM     `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*`,     UNNEST(event_params) AS event_params   WHERE     _TABLE_SUFFIX BETWEEN '20210101' AND '20210131'     AND event_name = 'page_view'   GROUP BY user_pseudo_id,event_timestamp ), temp AS (     SELECT     page_title,     COUNT(*) AS event_count,     COUNT(DISTINCT user_pseudo_id) AS users     FROM     unnested_events     GROUP BY page_title     ORDER BY event_count DESC )  SELECT users  FROM temp LIMIT 1",
        "schema": {
            "bigquery-public-data.ga4_obfuscated_sample_ecommerce": {
                "events_*": [
                    "event_params.key",
                    "event_params.value.string_value",
                    "user_pseudo_id",
                    "event_timestamp",
                    "_TABLE_SUFFIX",
                    "event_name"
                ]
            }
        }
    },
    "ga007": {
        "query": "WITH base_table AS ( -- pulls relevant columns from relevant dates to decrease the size of data scanned   SELECT     event_name,     event_date,     event_timestamp,     user_pseudo_id,     user_id,     device,     geo,     traffic_source,     event_params,     user_properties   FROM     `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*`   WHERE     _table_suffix = '20210101'   AND event_name IN ('page_view') ) , unnested_events AS ( -- unnests event parameters to get to relevant keys and values   SELECT     event_date AS date,     event_timestamp AS event_timestamp_microseconds,     user_pseudo_id,     MAX(CASE WHEN c.key = 'ga_session_id' THEN c.value.int_value END) AS visitID,     MAX(CASE WHEN c.key = 'ga_session_number' THEN c.value.int_value END) AS visitNumber,     MAX(CASE WHEN c.key = 'page_title' THEN c.value.string_value END) AS page_title,     MAX(CASE WHEN c.key = 'page_location' THEN c.value.string_value END) AS page_location   FROM      base_table,     UNNEST (event_params) c   GROUP BY 1,2,3 ) ,unnested_events_categorised AS ( -- categorizing Page Titles into PDPs and PLPs   SELECT   *,   CASE WHEN ARRAY_LENGTH(SPLIT(page_location, '/')) >= 5              AND             CONTAINS_SUBSTR(ARRAY_REVERSE(SPLIT(page_location, '/'))[SAFE_OFFSET(0)], '+')             AND (LOWER(SPLIT(page_location, '/')[SAFE_OFFSET(4)]) IN                                          ('accessories','apparel','brands','campus+collection','drinkware',                                           'electronics','google+redesign',                                           'lifestyle','nest','new+2015+logo','notebooks+journals',                                           'office','shop+by+brand','small+goods','stationery','wearables'                                           )                   OR                   LOWER(SPLIT(page_location, '/')[SAFE_OFFSET(3)]) IN                                          ('accessories','apparel','brands','campus+collection','drinkware',                                           'electronics','google+redesign',                                           'lifestyle','nest','new+2015+logo','notebooks+journals',                                           'office','shop+by+brand','small+goods','stationery','wearables'                                           )             )             THEN 'PDP'             WHEN NOT(CONTAINS_SUBSTR(ARRAY_REVERSE(SPLIT(page_location, '/'))[SAFE_OFFSET(0)], '+'))             AND (LOWER(SPLIT(page_location, '/')[SAFE_OFFSET(4)]) IN                                          ('accessories','apparel','brands','campus+collection','drinkware',                                           'electronics','google+redesign',                                           'lifestyle','nest','new+2015+logo','notebooks+journals',                                           'office','shop+by+brand','small+goods','stationery','wearables'                                           )                   OR                    LOWER(SPLIT(page_location, '/')[SAFE_OFFSET(3)]) IN                                            ('accessories','apparel','brands','campus+collection','drinkware',                                             'electronics','google+redesign',                                             'lifestyle','nest','new+2015+logo','notebooks+journals',                                             'office','shop+by+brand','small+goods','stationery','wearables'                                             )             )             THEN 'PLP'         ELSE page_title         END AS page_title_adjusted     FROM      unnested_events )  SELECT (SELECT COUNT(*) FROM unnested_events_categorised WHERE page_title_adjusted='PDP') / (SELECT COUNT(*) FROM unnested_events_categorised);",
        "schema": {
            "bigquery-public-data.ga4_obfuscated_sample_ecommerce": {
                "events_*": [
                    "event_name",
                    "event_date",
                    "event_timestamp",
                    "user_pseudo_id",
                    "user_id",
                    "device",
                    "geo",
                    "traffic_source",
                    "event_params",
                    "user_properties",
                    "_table_suffix",
                    "event_params.key",
                    "event_params.value.int_value",
                    "event_params.value.string_value"
                ]
            }
        }
    },
    "ga007_1": {
        "query": "WITH base_table AS ( -- pulls relevant columns from relevant dates to decrease the size of data scanned   SELECT     event_name,     event_date,     event_timestamp,     user_pseudo_id,     user_id,     device,     geo,     traffic_source,     event_params,     user_properties   FROM     `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*`   WHERE     _table_suffix ='20210102'   AND user_pseudo_id='1402138.5184246691'   AND event_name IN ('page_view') ) , unnested_events AS ( -- unnests event parameters to get to relevant keys and values   SELECT     event_date AS date,     event_timestamp AS event_timestamp_microseconds,     user_pseudo_id,     MAX(CASE WHEN c.key = 'ga_session_id' THEN c.value.int_value END) AS visitID,     MAX(CASE WHEN c.key = 'ga_session_number' THEN c.value.int_value END) AS visitNumber,     MAX(CASE WHEN c.key = 'page_title' THEN c.value.string_value END) AS page_title,     MAX(CASE WHEN c.key = 'page_location' THEN c.value.string_value END) AS page_location   FROM      base_table,     UNNEST (event_params) c   GROUP BY 1,2,3 )     SELECT   *,   CASE WHEN ARRAY_LENGTH(SPLIT(page_location, '/')) >= 5              AND             CONTAINS_SUBSTR(ARRAY_REVERSE(SPLIT(page_location, '/'))[SAFE_OFFSET(0)], '+')             AND (LOWER(SPLIT(page_location, '/')[SAFE_OFFSET(4)]) IN                                          ('accessories','apparel','brands','campus+collection','drinkware',                                           'electronics','google+redesign',                                           'lifestyle','nest','new+2015+logo','notebooks+journals',                                           'office','shop+by+brand','small+goods','stationery','wearables'                                           )                   OR                   LOWER(SPLIT(page_location, '/')[SAFE_OFFSET(3)]) IN                                          ('accessories','apparel','brands','campus+collection','drinkware',                                           'electronics','google+redesign',                                           'lifestyle','nest','new+2015+logo','notebooks+journals',                                           'office','shop+by+brand','small+goods','stationery','wearables'                                           )             )             THEN 'PDP'             WHEN NOT(CONTAINS_SUBSTR(ARRAY_REVERSE(SPLIT(page_location, '/'))[SAFE_OFFSET(0)], '+'))             AND (LOWER(SPLIT(page_location, '/')[SAFE_OFFSET(4)]) IN                                          ('accessories','apparel','brands','campus+collection','drinkware',                                           'electronics','google+redesign',                                           'lifestyle','nest','new+2015+logo','notebooks+journals',                                           'office','shop+by+brand','small+goods','stationery','wearables'                                           )                   OR                    LOWER(SPLIT(page_location, '/')[SAFE_OFFSET(3)]) IN                                            ('accessories','apparel','brands','campus+collection','drinkware',                                             'electronics','google+redesign',                                             'lifestyle','nest','new+2015+logo','notebooks+journals',                                             'office','shop+by+brand','small+goods','stationery','wearables'                                             )             )             THEN 'PLP'         ELSE page_title         END AS page_title_adjusted     FROM      unnested_events",
        "schema": {
            "bigquery-public-data.ga4_obfuscated_sample_ecommerce": {
                "events_*": [
                    "event_name",
                    "event_date",
                    "event_timestamp",
                    "user_pseudo_id",
                    "user_id",
                    "device",
                    "geo",
                    "traffic_source",
                    "event_params",
                    "user_properties",
                    "_table_suffix",
                    "event_params.key",
                    "event_params.value.int_value",
                    "event_params.value.string_value"
                ]
            }
        }
    },
    "ga018": {
        "query": "-- pulling user page views from GA4 events WITH base_table AS ( -- pulls relevant columns from relevant dates to decrease the size of data scanned   SELECT     event_name,     event_date,     event_timestamp,     user_pseudo_id,     user_id,     device,     geo,     traffic_source,     event_params,     user_properties   FROM     `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*`   WHERE     _table_suffix = '20210102'   AND event_name IN ('page_view') ) , unnested_events AS ( -- unnests event parameters to get to relevant keys and values   SELECT     event_date AS date,     event_timestamp AS event_timestamp_microseconds,     user_pseudo_id,     MAX(CASE WHEN c.key = 'ga_session_id' THEN c.value.int_value END) AS visitID,     MAX(CASE WHEN c.key = 'ga_session_number' THEN c.value.int_value END) AS visitNumber,     MAX(CASE WHEN c.key = 'page_title' THEN c.value.string_value END) AS page_title,     MAX(CASE WHEN c.key = 'page_location' THEN c.value.string_value END) AS page_location   FROM      base_table,     UNNEST (event_params) c   GROUP BY 1,2,3 )  , unnested_events_categorised AS ( -- categorizing Page Titles into PDPs and PLPs   SELECT   *,   CASE WHEN ARRAY_LENGTH(SPLIT(page_location, '/')) >= 5              AND             CONTAINS_SUBSTR(ARRAY_REVERSE(SPLIT(page_location, '/'))[SAFE_OFFSET(0)], '+')             AND (LOWER(SPLIT(page_location, '/')[SAFE_OFFSET(4)]) IN                                          ('accessories','apparel','brands','campus+collection','drinkware',                                           'electronics','google+redesign',                                           'lifestyle','nest','new+2015+logo','notebooks+journals',                                           'office','shop+by+brand','small+goods','stationery','wearables'                                           )                   OR                   LOWER(SPLIT(page_location, '/')[SAFE_OFFSET(3)]) IN                                          ('accessories','apparel','brands','campus+collection','drinkware',                                           'electronics','google+redesign',                                           'lifestyle','nest','new+2015+logo','notebooks+journals',                                           'office','shop+by+brand','small+goods','stationery','wearables'                                           )             )             THEN 'PDP'             WHEN NOT(CONTAINS_SUBSTR(ARRAY_REVERSE(SPLIT(page_location, '/'))[SAFE_OFFSET(0)], '+'))             AND (LOWER(SPLIT(page_location, '/')[SAFE_OFFSET(4)]) IN                                          ('accessories','apparel','brands','campus+collection','drinkware',                                           'electronics','google+redesign',                                           'lifestyle','nest','new+2015+logo','notebooks+journals',                                           'office','shop+by+brand','small+goods','stationery','wearables'                                           )                   OR                    LOWER(SPLIT(page_location, '/')[SAFE_OFFSET(3)]) IN                                            ('accessories','apparel','brands','campus+collection','drinkware',                                             'electronics','google+redesign',                                             'lifestyle','nest','new+2015+logo','notebooks+journals',                                             'office','shop+by+brand','small+goods','stationery','wearables'                                             )             )             THEN 'PLP'         ELSE page_title         END AS page_title_adjusted     FROM      unnested_events )   , ranked_screens AS (   SELECT     *,     LAG(page_title_adjusted,1) OVER (PARTITION BY  user_pseudo_id, visitID ORDER BY event_timestamp_microseconds ASC) previous_page,     LEAD(page_title_adjusted,1) OVER (PARTITION BY  user_pseudo_id, visitID ORDER BY event_timestamp_microseconds ASC)  next_page   FROM      unnested_events_categorised  )  ,PLPtoPDPTransitions AS (   SELECT     user_pseudo_id,     visitID   FROM     ranked_screens   WHERE     page_title_adjusted = 'PLP' AND next_page = 'PDP' )  ,TotalPLPViews AS (   SELECT     COUNT(*) AS total_plp_views   FROM     ranked_screens   WHERE     page_title_adjusted = 'PLP' )  ,TotalTransitions AS (   SELECT     COUNT(*) AS total_transitions   FROM     PLPtoPDPTransitions )  SELECT   (total_transitions * 100.0) / total_plp_views AS percentage FROM   TotalTransitions, TotalPLPViews;",
        "schema": {
            "bigquery-public-data.ga4_obfuscated_sample_ecommerce": {
                "events_*": [
                    "event_name",
                    "event_date",
                    "event_timestamp",
                    "user_pseudo_id",
                    "user_id",
                    "device",
                    "geo",
                    "traffic_source",
                    "event_params",
                    "user_properties",
                    "_table_suffix",
                    "event_params.key",
                    "event_params.value.int_value",
                    "event_params.value.string_value"
                ]
            }
        }
    },
    "ga031": {
        "query": "WITH base_table AS (   SELECT     event_name,     event_date,     event_timestamp,     user_pseudo_id,     user_id,     device,     geo,     traffic_source,     event_params,     user_properties   FROM     `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*`   WHERE     _table_suffix = '20210102'     AND event_name IN ('page_view') ), unnested_events AS (   SELECT     event_date AS date,     event_timestamp AS event_timestamp_microseconds,     user_pseudo_id,     MAX(CASE WHEN c.key = 'ga_session_id' THEN c.value.int_value END) AS visitID,     MAX(CASE WHEN c.key = 'ga_session_number' THEN c.value.int_value END) AS visitNumber,     MAX(CASE WHEN c.key = 'page_title' THEN c.value.string_value END) AS page_title,     MAX(CASE WHEN c.key = 'page_location' THEN c.value.string_value END) AS page_location   FROM      base_table,     UNNEST (event_params) c   GROUP BY 1,2,3 ), home_visits AS (   SELECT     user_pseudo_id,     visitID   FROM     unnested_events   WHERE     page_title = 'Home' ), checkout_visits AS (   SELECT     user_pseudo_id,     visitID   FROM     unnested_events   WHERE     page_title = 'Checkout Confirmation' ), home_to_checkout AS (   SELECT     h.user_pseudo_id,     h.visitID   FROM     home_visits h   JOIN     checkout_visits c ON h.user_pseudo_id = c.user_pseudo_id AND h.visitID = c.visitID ), total_home_visits AS (   SELECT     COUNT(*) AS total_home   FROM     home_visits ), total_checkout_visits AS (   SELECT     COUNT(*) AS total_checkout   FROM     home_to_checkout )  SELECT   (total_checkout * 100.0) / total_home AS conversion_rate FROM   total_home_visits,   total_checkout_visits;",
        "schema": {
            "bigquery-public-data.ga4_obfuscated_sample_ecommerce": {
                "events_*": [
                    "event_name",
                    "event_date",
                    "event_timestamp",
                    "user_pseudo_id",
                    "user_id",
                    "device",
                    "geo",
                    "traffic_source",
                    "event_params",
                    "user_properties",
                    "_table_suffix",
                    "event_params.key",
                    "event_params.value.int_value",
                    "event_params.value.string_value"
                ]
            }
        }
    },
    "ga032": {
        "query": "WITH base_table AS ( -- pulls relevant columns from relevant dates to decrease the size of data scanned   SELECT     event_name,     event_date,     event_timestamp,     user_pseudo_id,     user_id,     device,     geo,     traffic_source,     event_params,     user_properties   FROM     `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*`   WHERE     _table_suffix = '20210128'    AND event_name IN ('page_view') ) , unnested_events AS ( -- unnests event parameters to get to relevant keys and values   SELECT     event_date AS date,     event_timestamp AS event_timestamp_microseconds,     user_pseudo_id,     MAX(CASE WHEN c.key = 'ga_session_id' THEN c.value.int_value END) AS visitID,     MAX(CASE WHEN c.key = 'ga_session_number' THEN c.value.int_value END) AS visitNumber,     MAX(CASE WHEN c.key = 'page_title' THEN c.value.string_value END) AS page_title,     MAX(CASE WHEN c.key = 'page_location' THEN c.value.string_value END) AS page_location   FROM      base_table,     UNNEST (event_params) c   WHERE user_pseudo_id='1362228.4966015575'   GROUP BY 1,2,3 )  , unnested_events_categorised AS ( -- categorizing Page Titles into PDPs and PLPs   SELECT   *,   CASE WHEN ARRAY_LENGTH(SPLIT(page_location, '/')) >= 5              AND             CONTAINS_SUBSTR(ARRAY_REVERSE(SPLIT(page_location, '/'))[SAFE_OFFSET(0)], '+')             AND (LOWER(SPLIT(page_location, '/')[SAFE_OFFSET(4)]) IN                                          ('accessories','apparel','brands','campus+collection','drinkware',                                           'electronics','google+redesign',                                           'lifestyle','nest','new+2015+logo','notebooks+journals',                                           'office','shop+by+brand','small+goods','stationery','wearables'                                           )                   OR                   LOWER(SPLIT(page_location, '/')[SAFE_OFFSET(3)]) IN                                          ('accessories','apparel','brands','campus+collection','drinkware',                                           'electronics','google+redesign',                                           'lifestyle','nest','new+2015+logo','notebooks+journals',                                           'office','shop+by+brand','small+goods','stationery','wearables'                                           )             )             THEN 'PDP'             WHEN NOT(CONTAINS_SUBSTR(ARRAY_REVERSE(SPLIT(page_location, '/'))[SAFE_OFFSET(0)], '+'))             AND (LOWER(SPLIT(page_location, '/')[SAFE_OFFSET(4)]) IN                                          ('accessories','apparel','brands','campus+collection','drinkware',                                           'electronics','google+redesign',                                           'lifestyle','nest','new+2015+logo','notebooks+journals',                                           'office','shop+by+brand','small+goods','stationery','wearables'                                           )                   OR                    LOWER(SPLIT(page_location, '/')[SAFE_OFFSET(3)]) IN                                            ('accessories','apparel','brands','campus+collection','drinkware',                                             'electronics','google+redesign',                                             'lifestyle','nest','new+2015+logo','notebooks+journals',                                             'office','shop+by+brand','small+goods','stationery','wearables'                                             )             )             THEN 'PLP'         ELSE page_title         END AS page_title_adjusted     FROM      unnested_events )  , ranked_screens AS ( -- prepares additional data points for analytics to understand transitions between the previous, current and following pages   SELECT     *,     DENSE_RANK() OVER (PARTITION BY  user_pseudo_id, visitID ORDER BY event_timestamp_microseconds ASC) page_rank,     LAG(page_title_adjusted,1) OVER (PARTITION BY  user_pseudo_id, visitID ORDER BY event_timestamp_microseconds ASC) previous_page,     LEAD(page_title_adjusted,1) OVER (PARTITION BY  user_pseudo_id, visitID ORDER BY event_timestamp_microseconds ASC)  next_page   FROM      unnested_events_categorised  ) , screen_summary AS ( -- another layer of analytics: check the last page number viewed on a session -- aggregate all screens per session, which will be helpful in identifying power users   SELECT     *,     MAX(page_rank) OVER (PARTITION BY  user_pseudo_id, visitID) last_page_rank,     ARRAY_AGG(page_title_adjusted) OVER (PARTITION BY  user_pseudo_id, visitID) pages_on_a_visit   FROM      ranked_screens )   SELECT    distinct ARRAY_TO_STRING(ARRAY(SELECT DISTINCT * FROM UNNEST(pages_on_a_visit) ORDER BY 1 ASC), '>>') AS screens_on_a_visit FROM    screen_summary;",
        "schema": {
            "bigquery-public-data.ga4_obfuscated_sample_ecommerce": {
                "events_*": [
                    "event_name",
                    "event_date",
                    "event_timestamp",
                    "user_pseudo_id",
                    "user_id",
                    "device",
                    "geo",
                    "traffic_source",
                    "event_params",
                    "user_properties",
                    "_table_suffix",
                    "event_params.key",
                    "event_params.value.int_value",
                    "event_params.value.string_value"
                ]
            }
        }
    },
    "ga006": {
        "query": "WITH   events AS (     SELECT       session.value.int_value AS session_id,       COALESCE(spend.value.int_value, spend.value.float_value, spend.value.double_value, 0.0)         AS spend_value,       event.*      -- Replace table name     FROM `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*` AS event     LEFT JOIN UNNEST(event.event_params) AS session       ON session.key = 'ga_session_id'     LEFT JOIN UNNEST(event.event_params) AS spend       ON spend.key = 'value'      -- Replace date range     WHERE _TABLE_SUFFIX BETWEEN '20201101' and '20201130'   ),  SESSTION_INFO AS (   SELECT     user_pseudo_id,     COUNT(DISTINCT session_id) AS session_count,     SUM(spend_value) / COUNT(DISTINCT session_id) AS avg_spend_per_session_by_user   FROM events   WHERE event_name = 'purchase' and session_id IS NOT NULL   GROUP BY user_pseudo_id )  SELECT user_pseudo_id, avg_spend_per_session_by_user FROM SESSTION_INFO WHERE session_count > 1",
        "schema": {
            "bigquery-public-data.ga4_obfuscated_sample_ecommerce": {
                "events_*": [
                    "session.value.int_value",
                    "spend.value.int_value",
                    "spend.value.float_value",
                    "spend.value.double_value",
                    "event_params",
                    "event_name",
                    "_TABLE_SUFFIX",
                    "user_pseudo_id"
                ]
            }
        }
    },
    "ga009": {
        "query": "SELECT   engaged_sessions_number / user_number AS engaged_sessions_per_user FROM (   SELECT     COUNT(       DISTINCT CASE         WHEN (SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'session_engaged') = '1' THEN           CONCAT(             user_pseudo_id,              CAST(               (SELECT value.int_value FROM UNNEST(event_params) WHERE key = 'ga_session_id') AS STRING             )           )       END     ) AS engaged_sessions_number,     COUNT(DISTINCT user_pseudo_id) AS user_number   FROM     `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*`   WHERE     _TABLE_SUFFIX BETWEEN '20201201' and '20201231' ) AS summary",
        "schema": {
            "bigquery-public-data.ga4_obfuscated_sample_ecommerce": {
                "events_*": [
                    "user_pseudo_id",
                    "event_params.key",
                    "event_params.value.string_value",
                    "event_params.value.int_value",
                    "_TABLE_SUFFIX"
                ]
            }
        }
    },
    "ga010": {
        "query": "WITH prep AS (   SELECT     user_pseudo_id,     (SELECT value.int_value FROM UNNEST(event_params) WHERE key = 'ga_session_id') AS session_id,     ARRAY_AGG((SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'source') IGNORE NULLS                ORDER BY event_timestamp)[SAFE_OFFSET(0)] AS source,     ARRAY_AGG((SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'medium') IGNORE NULLS                ORDER BY event_timestamp)[SAFE_OFFSET(0)] AS medium,     ARRAY_AGG((SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'campaign') IGNORE NULLS                ORDER BY event_timestamp)[SAFE_OFFSET(0)] AS campaign   FROM     `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*`   WHERE     _TABLE_SUFFIX BETWEEN '20201201' AND '20201231'   GROUP BY     user_pseudo_id,     session_id ) SELECT   -- session default channel grouping (dimension | the channel group associated with a session)    CASE      WHEN source = '(direct)' AND (medium IN ('(not set)','(none)')) THEN 'Direct'     WHEN REGEXP_CONTAINS(campaign, 'cross-network') THEN 'Cross-network'     WHEN (REGEXP_CONTAINS(source,'alibaba|amazon|google shopping|shopify|etsy|ebay|stripe|walmart')         OR REGEXP_CONTAINS(campaign, '^(.*(([^a-df-z]|^)shop|shopping).*)$'))         AND REGEXP_CONTAINS(medium, '^(.*cp.*|ppc|paid.*)$') THEN 'Paid Shopping'     WHEN REGEXP_CONTAINS(source,'baidu|bing|duckduckgo|ecosia|google|yahoo|yandex')         AND REGEXP_CONTAINS(medium,'^(.*cp.*|ppc|paid.*)$') THEN 'Paid Search'     WHEN REGEXP_CONTAINS(source,'badoo|facebook|fb|instagram|linkedin|pinterest|tiktok|twitter|whatsapp')         AND REGEXP_CONTAINS(medium,'^(.*cp.*|ppc|paid.*)$') THEN 'Paid Social'     WHEN REGEXP_CONTAINS(source,'dailymotion|disneyplus|netflix|youtube|vimeo|twitch|vimeo|youtube')         AND REGEXP_CONTAINS(medium,'^(.*cp.*|ppc|paid.*)$') THEN 'Paid Video'     WHEN medium IN ('display', 'banner', 'expandable', 'interstitial', 'cpm') THEN 'Display'     WHEN REGEXP_CONTAINS(source,'alibaba|amazon|google shopping|shopify|etsy|ebay|stripe|walmart')         OR REGEXP_CONTAINS(campaign, '^(.*(([^a-df-z]|^)shop|shopping).*)$') THEN 'Organic Shopping'     WHEN REGEXP_CONTAINS(source,'badoo|facebook|fb|instagram|linkedin|pinterest|tiktok|twitter|whatsapp')         OR medium IN ('social','social-network','social-media','sm','social network','social media') THEN 'Organic Social'     WHEN REGEXP_CONTAINS(source,'dailymotion|disneyplus|netflix|youtube|vimeo|twitch|vimeo|youtube')         OR REGEXP_CONTAINS(medium,'^(.*video.*)$') THEN 'Organic Video'     WHEN REGEXP_CONTAINS(source,'baidu|bing|duckduckgo|ecosia|google|yahoo|yandex')         OR medium = 'organic' THEN 'Organic Search'     WHEN REGEXP_CONTAINS(source,'email|e-mail|e_mail|e mail')         OR REGEXP_CONTAINS(medium,'email|e-mail|e_mail|e mail') THEN 'Email'     WHEN medium = 'affiliate' THEN 'Affiliates'     WHEN medium = 'referral' THEN 'Referral'     WHEN medium = 'audio' THEN 'Audio'     WHEN medium = 'sms' THEN 'SMS'     WHEN medium LIKE '%push'         OR REGEXP_CONTAINS(medium,'mobile|notification') THEN 'Mobile Push Notifications'     ELSE 'Unassigned'    END AS channel_grouping_session FROM   prep GROUP BY   channel_grouping_session ORDER BY   COUNT(DISTINCT CONCAT(user_pseudo_id, session_id)) DESC LIMIT 1 OFFSET 3",
        "schema": {
            "bigquery-public-data.ga4_obfuscated_sample_ecommerce": {
                "events_*": [
                    "user_pseudo_id",
                    "event_params.key",
                    "event_params.value.int_value",
                    "event_params.value.string_value",
                    "event_timestamp",
                    "_TABLE_SUFFIX"
                ]
            }
        }
    },
    "ga010_1": {
        "query": "WITH prep AS (   SELECT     user_pseudo_id,     (SELECT value.int_value FROM UNNEST(event_params) WHERE key = 'ga_session_id') AS session_id,     ARRAY_AGG((SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'source') IGNORE NULLS                ORDER BY event_timestamp)[SAFE_OFFSET(0)] AS source,     ARRAY_AGG((SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'medium') IGNORE NULLS                ORDER BY event_timestamp)[SAFE_OFFSET(0)] AS medium,     ARRAY_AGG((SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'campaign') IGNORE NULLS                ORDER BY event_timestamp)[SAFE_OFFSET(0)] AS campaign   FROM     `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*`   WHERE     _TABLE_SUFFIX BETWEEN '20201201' AND '20201231'   GROUP BY     user_pseudo_id,     session_id ) SELECT   -- session default channel grouping (dimension | the channel group associated with a session)    CASE      WHEN source = '(direct)' AND (medium IN ('(not set)','(none)')) THEN 'Direct'     WHEN REGEXP_CONTAINS(campaign, 'cross-network') THEN 'Cross-network'     WHEN (REGEXP_CONTAINS(source,'alibaba|amazon|google shopping|shopify|etsy|ebay|stripe|walmart')         OR REGEXP_CONTAINS(campaign, '^(.*(([^a-df-z]|^)shop|shopping).*)$'))         AND REGEXP_CONTAINS(medium, '^(.*cp.*|ppc|paid.*)$') THEN 'Paid Shopping'     WHEN REGEXP_CONTAINS(source,'baidu|bing|duckduckgo|ecosia|google|yahoo|yandex')         AND REGEXP_CONTAINS(medium,'^(.*cp.*|ppc|paid.*)$') THEN 'Paid Search'     WHEN REGEXP_CONTAINS(source,'badoo|facebook|fb|instagram|linkedin|pinterest|tiktok|twitter|whatsapp')         AND REGEXP_CONTAINS(medium,'^(.*cp.*|ppc|paid.*)$') THEN 'Paid Social'     WHEN REGEXP_CONTAINS(source,'dailymotion|disneyplus|netflix|youtube|vimeo|twitch|vimeo|youtube')         AND REGEXP_CONTAINS(medium,'^(.*cp.*|ppc|paid.*)$') THEN 'Paid Video'     WHEN medium IN ('display', 'banner', 'expandable', 'interstitial', 'cpm') THEN 'Display'     WHEN REGEXP_CONTAINS(source,'alibaba|amazon|google shopping|shopify|etsy|ebay|stripe|walmart')         OR REGEXP_CONTAINS(campaign, '^(.*(([^a-df-z]|^)shop|shopping).*)$') THEN 'Organic Shopping'     WHEN REGEXP_CONTAINS(source,'badoo|facebook|fb|instagram|linkedin|pinterest|tiktok|twitter|whatsapp')         OR medium IN ('social','social-network','social-media','sm','social network','social media') THEN 'Organic Social'     WHEN REGEXP_CONTAINS(source,'dailymotion|disneyplus|netflix|youtube|vimeo|twitch|vimeo|youtube')         OR REGEXP_CONTAINS(medium,'^(.*video.*)$') THEN 'Organic Video'     WHEN REGEXP_CONTAINS(source,'baidu|bing|duckduckgo|ecosia|google|yahoo|yandex')         OR medium = 'organic' THEN 'Organic Search'     WHEN REGEXP_CONTAINS(source,'email|e-mail|e_mail|e mail')         OR REGEXP_CONTAINS(medium,'email|e-mail|e_mail|e mail') THEN 'Email'     WHEN medium = 'affiliate' THEN 'Affiliates'     WHEN medium = 'referral' THEN 'Referral'     WHEN medium = 'audio' THEN 'Audio'     WHEN medium = 'sms' THEN 'SMS'     WHEN medium LIKE '%push'         OR REGEXP_CONTAINS(medium,'mobile|notification') THEN 'Mobile Push Notifications'     ELSE 'Unassigned'    END AS channel_grouping_session,   COUNT(DISTINCT CONCAT(user_pseudo_id, session_id)) AS sessions FROM   prep GROUP BY   channel_grouping_session",
        "schema": {
            "bigquery-public-data.ga4_obfuscated_sample_ecommerce": {
                "events_*": [
                    "user_pseudo_id",
                    "event_params.key",
                    "event_params.value.int_value",
                    "event_params.value.string_value",
                    "event_timestamp"
                ]
            }
        }
    },
    "ga011": {
        "query": "SELECT  page_views FROM ( SELECT     CASE          WHEN SPLIT(SPLIT((SELECT value.string_value                            FROM UNNEST(event_params)                            WHERE event_name = 'page_view' AND key = 'page_location'),'/')[SAFE_ORDINAL(4)],'?')[SAFE_ORDINAL(1)] = ''          THEN NULL          ELSE CONCAT('/', SPLIT(SPLIT((SELECT value.string_value                                        FROM UNNEST(event_params)                                        WHERE event_name = 'page_view' AND key = 'page_location'),'/')[SAFE_ORDINAL(4)],'?')[SAFE_ORDINAL(1)])      END AS pagepath_level_1,     CASE          WHEN SPLIT(SPLIT((SELECT value.string_value                            FROM UNNEST(event_params)                            WHERE event_name = 'page_view' AND key = 'page_location'),'/')[SAFE_ORDINAL(5)],'?')[SAFE_ORDINAL(1)] = ''          THEN NULL          ELSE CONCAT('/', SPLIT(SPLIT((SELECT value.string_value                                        FROM UNNEST(event_params)                                        WHERE event_name = 'page_view' AND key = 'page_location'),'/')[SAFE_ORDINAL(5)],'?')[SAFE_ORDINAL(1)])      END AS pagepath_level_2,     CASE          WHEN SPLIT(SPLIT((SELECT value.string_value                            FROM UNNEST(event_params)                            WHERE event_name = 'page_view' AND key = 'page_location'),'/')[SAFE_ORDINAL(6)],'?')[SAFE_ORDINAL(1)] = ''          THEN NULL          ELSE CONCAT('/', SPLIT(SPLIT((SELECT value.string_value                                        FROM UNNEST(event_params)                                        WHERE event_name = 'page_view' AND key = 'page_location'),'/')[SAFE_ORDINAL(6)],'?')[SAFE_ORDINAL(1)])      END AS pagepath_level_3,     COUNTIF(event_name = 'page_view') AS page_views FROM     `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*` WHERE     _table_suffix BETWEEN '20201201' and '20201231' GROUP BY     pagepath_level_1,     pagepath_level_2,     pagepath_level_3 ) ORDER BY     page_views DESC LIMIT 1",
        "schema": {
            "bigquery-public-data.ga4_obfuscated_sample_ecommerce": {
                "events_*": [
                    "event_params.value.string_value",
                    "event_name",
                    "key",
                    "page_views",
                    "_table_suffix"
                ]
            }
        }
    },
    "ga012": {
        "query": "WITH top_category AS (   SELECT     product.item_category,     SUM(ecommerce.tax_value_in_usd) / SUM(ecommerce.purchase_revenue_in_usd) AS tax_rate   FROM     bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_20201130,     UNNEST(items) AS product   WHERE     event_name = 'purchase'   GROUP BY     product.item_category   ORDER BY     tax_rate DESC   LIMIT 1 )  SELECT     ecommerce.transaction_id,     SUM(ecommerce.total_item_quantity) AS total_item_quantity,     SUM(ecommerce.purchase_revenue_in_usd) AS purchase_revenue_in_usd,     SUM(ecommerce.purchase_revenue) AS purchase_revenue FROM     bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_20201130,      UNNEST(items) AS product JOIN top_category ON product.item_category = top_category.item_category WHERE     event_name = 'purchase' GROUP BY     ecommerce.transaction_id;",
        "schema": {
            "bigquery-public-data.ga4_obfuscated_sample_ecommerce": {
                "events_20201130": [
                    "event_name",
                    "items",
                    "ecommerce.tax_value_in_usd",
                    "ecommerce.purchase_revenue_in_usd",
                    "ecommerce.transaction_id",
                    "ecommerce.total_item_quantity",
                    "ecommerce.purchase_revenue"
                ]
            }
        }
    },
    "ga019": {
        "query": "WITH --List of users who installed sept_cohort AS (   SELECT DISTINCT user_pseudo_id,   FORMAT_DATE('%Y-%m-%d', PARSE_DATE('%Y%m%d', event_date)) AS date_first_open,   FROM `firebase-public-project.analytics_153293282.events_*`   WHERE event_name = 'first_open'   AND _TABLE_SUFFIX BETWEEN '20180801' and '20180930' ), --Get the list of users who uninstalled uninstallers AS (   SELECT DISTINCT user_pseudo_id,   FORMAT_DATE('%Y-%m-%d', PARSE_DATE('%Y%m%d', event_date)) AS date_app_remove,   FROM `firebase-public-project.analytics_153293282.events_*`   WHERE event_name = 'app_remove'   AND _TABLE_SUFFIX BETWEEN '20180801' and '20180930' ), --Join the 2 tables and compute for # of days to uninstall joined AS (   SELECT a.*,   b.date_app_remove,   DATE_DIFF(DATE(b.date_app_remove), DATE(a.date_first_open), DAY) AS days_to_uninstall   FROM sept_cohort a   LEFT JOIN uninstallers b   ON a.user_pseudo_id = b.user_pseudo_id ) --Compute for the percentage SELECT COUNT(DISTINCT CASE WHEN days_to_uninstall > 7 OR days_to_uninstall IS NULL THEN user_pseudo_id END) / COUNT(DISTINCT user_pseudo_id) AS percent_users_7_days FROM joined",
        "schema": {
            "firebase-public-project.analytics_153293282": {
                "events_*": [
                    "user_pseudo_id",
                    "event_date",
                    "event_name"
                ]
            }
        }
    },
    "ga030": {
        "query": "WITH dates AS (     SELECT          DATE('2018-07-02') AS start_date,         DATE('2018-10-02') AS end_date,         DATE_ADD(DATE_TRUNC(DATE('2018-10-02'), WEEK(MONDAY)), INTERVAL -4 WEEK) AS min_date ),  date_table AS (     SELECT DISTINCT          PARSE_DATE('%Y%m%d', `event_date`) AS event_date,         user_pseudo_id,         CASE              WHEN DATE_DIFF(PARSE_DATE('%Y%m%d', `event_date`), DATE(TIMESTAMP_MICROS(user_first_touch_timestamp)), DAY) = 0              THEN 1              ELSE 0          END AS is_new_user     FROM `firebase-public-project.analytics_153293282.events_*`      WHERE event_name = 'session_start'     AND PARSE_DATE('%Y%m%d', `event_date`) >= DATE('2018-07-02') ),  new_user_list AS (     SELECT DISTINCT          user_pseudo_id,         event_date     FROM date_table     WHERE is_new_user = 1 ),  days_since_start_table AS (     SELECT DISTINCT          is_new_user,         nu.event_date AS date_cohort,         dt.user_pseudo_id,         dt.event_date,         DATE_DIFF(dt.event_date, nu.event_date, DAY) AS days_since_start     FROM date_table dt     JOIN new_user_list nu ON dt.user_pseudo_id = nu.user_pseudo_id ),  weeks_retention AS (     SELECT          date_cohort,         DATE_TRUNC(date_cohort, WEEK(MONDAY)) AS week_cohort,         user_pseudo_id,         days_since_start,         CASE              WHEN days_since_start = 0 THEN 0              ELSE CEIL(days_since_start / 7)          END AS weeks_since_start     FROM days_since_start_table ),  retention_counts AS (     SELECT          week_cohort,         weeks_since_start,         COUNT(DISTINCT user_pseudo_id) AS retained_users     FROM weeks_retention     WHERE week_cohort >= DATE('2018-07-02') AND week_cohort <= (SELECT min_date FROM dates)      GROUP BY          week_cohort,         weeks_since_start )  SELECT      initial.week_cohort FROM      retention_counts AS initial LEFT JOIN      retention_counts AS four_week ON initial.week_cohort = four_week.week_cohort AND four_week.weeks_since_start = 4 WHERE      initial.weeks_since_start = 0 ORDER BY      IFNULL(four_week.retained_users / initial.retained_users, 0) DESC LIMIT 1 ;",
        "schema": {
            "firebase-public-project.analytics_153293282": {
                "events_*": [
                    "event_date",
                    "user_pseudo_id",
                    "user_first_touch_timestamp",
                    "event_name"
                ]
            }
        }
    },
    "ga030_1": {
        "query": "WITH dates AS (     SELECT          DATE('2018-07-09') AS start_date,         DATE('2018-10-02') AS end_date,         DATE_ADD(DATE_TRUNC(DATE('2018-10-02'), WEEK(MONDAY)), INTERVAL -2 WEEK) AS min_date ),  date_table AS (     SELECT DISTINCT          PARSE_DATE('%Y%m%d', `event_date`) AS event_date,         user_pseudo_id,         CASE              WHEN DATE_DIFF(PARSE_DATE('%Y%m%d', `event_date`), DATE(TIMESTAMP_MICROS(user_first_touch_timestamp)), DAY) = 0              THEN 1              ELSE 0          END AS is_new_user     FROM `firebase-public-project.analytics_153293282.events_*`      WHERE event_name = 'session_start'     AND PARSE_DATE('%Y%m%d', `event_date`) >= DATE('2018-07-09') ),  new_user_list AS (     SELECT DISTINCT          user_pseudo_id,         event_date     FROM date_table     WHERE is_new_user = 1 ),  days_since_start_table AS (     SELECT DISTINCT          is_new_user,         nu.event_date AS date_cohort,         dt.user_pseudo_id,         dt.event_date,         DATE_DIFF(dt.event_date, nu.event_date, DAY) AS days_since_start     FROM date_table dt     JOIN new_user_list nu ON dt.user_pseudo_id = nu.user_pseudo_id ),  weeks_retention AS (     SELECT          date_cohort,         DATE_TRUNC(date_cohort, WEEK(MONDAY)) AS week_cohort,         user_pseudo_id,         days_since_start,         CASE              WHEN days_since_start = 0 THEN 0              ELSE CEIL(days_since_start / 7)          END AS weeks_since_start     FROM days_since_start_table ),  retention_counts AS (     SELECT          week_cohort,         weeks_since_start,         COUNT(DISTINCT user_pseudo_id) AS retained_users     FROM weeks_retention     WHERE week_cohort >= DATE('2018-07-02') AND week_cohort <= (SELECT min_date FROM dates)      GROUP BY          week_cohort,         weeks_since_start )  SELECT      initial.week_cohort,     IFNULL(four_week.retained_users / initial.retained_users, 0) AS retention_rate FROM      retention_counts AS initial LEFT JOIN      retention_counts AS four_week ON initial.week_cohort = four_week.week_cohort AND four_week.weeks_since_start = 2 WHERE      initial.weeks_since_start = 0 ORDER BY week_cohort",
        "schema": {
            "firebase-public-project.analytics_153293282": {
                "events_*": [
                    "event_date",
                    "user_pseudo_id",
                    "user_first_touch_timestamp",
                    "event_name"
                ]
            }
        }
    },
    "ga028": {
        "query": "WITH dates AS (     SELECT          DATE('2018-07-02') AS start_date,         DATE('2018-10-02') AS end_date,         DATE_ADD(DATE_TRUNC(DATE('2018-10-02'), WEEK(TUESDAY)), INTERVAL -4 WEEK) AS min_date ),  date_table AS (     SELECT DISTINCT          PARSE_DATE('%Y%m%d', `event_date`) AS event_date,         user_pseudo_id,         CASE              WHEN DATE_DIFF(PARSE_DATE('%Y%m%d', `event_date`), DATE(TIMESTAMP_MICROS(user_first_touch_timestamp)), DAY) = 0              THEN 1              ELSE 0          END AS is_new_user     FROM          `firebase-public-project.analytics_153293282.events_*`      WHERE          event_name = 'session_start' ),  new_user_list AS (     SELECT DISTINCT          user_pseudo_id,         event_date     FROM          date_table     WHERE          is_new_user = 1 ),  days_since_start_table AS (     SELECT DISTINCT          is_new_user,         nu.event_date AS date_cohort,         dt.user_pseudo_id,         dt.event_date,         DATE_DIFF(dt.event_date, nu.event_date, DAY) AS days_since_start     FROM          date_table dt     JOIN          new_user_list nu ON dt.user_pseudo_id = nu.user_pseudo_id ),  weeks_retention AS (     SELECT          date_cohort,         DATE_TRUNC(date_cohort, WEEK(MONDAY)) AS week_cohort,         user_pseudo_id,         days_since_start,         CASE              WHEN days_since_start = 0              THEN 0              ELSE CEIL(days_since_start / 7)          END AS weeks_since_start     FROM          days_since_start_table ), RETENTION_INFO AS (   SELECT        week_cohort,       weeks_since_start,       COUNT(DISTINCT user_pseudo_id) AS retained_users   FROM        weeks_retention   WHERE        week_cohort <= (SELECT min_date FROM dates)   GROUP BY        week_cohort,       weeks_since_start   HAVING        weeks_since_start <= 4   ORDER BY        week_cohort,       weeks_since_start )  SELECT weeks_since_start, retained_users FROM RETENTION_INFO WHERE week_cohort = DATE('2018-07-02')",
        "schema": {
            "firebase-public-project.analytics_153293282": {
                "events_*": [
                    "event_date",
                    "user_pseudo_id",
                    "user_first_touch_timestamp",
                    "event_name"
                ]
            }
        }
    },
    "ga020": {
        "query": "-- Define the date range and calculate the minimum date for filtering results WITH dates AS (     SELECT          DATE('2018-08-01') AS start_date,         DATE('2018-08-15') AS end_date ), -- Create a table of active dates for each user within the specified date range dates_active_table AS (     SELECT         user_pseudo_id,         PARSE_DATE('%Y%m%d', `event_date`) AS user_active_date     FROM          `firebase-public-project.analytics_153293282.events_*`      WHERE          event_name = 'session_start'         AND PARSE_DATE('%Y%m%d', `event_date`) BETWEEN (SELECT start_date FROM dates) AND (SELECT end_date FROM dates)     GROUP BY          user_pseudo_id, user_active_date ), -- Create a table of the earliest quickplay event date for each user within the specified date range event_table AS (     SELECT          user_pseudo_id,         event_name,         MIN(PARSE_DATE('%Y%m%d', `event_date`)) AS event_cohort_date     FROM          `firebase-public-project.analytics_153293282.events_*`      WHERE          event_name IN ('level_start_quickplay', 'level_end_quickplay', 'level_complete_quickplay',                         'level_fail_quickplay', 'level_reset_quickplay', 'level_retry_quickplay')         AND PARSE_DATE('%Y%m%d', `event_date`) BETWEEN (SELECT start_date FROM dates) AND (SELECT end_date FROM dates)     GROUP BY          user_pseudo_id, event_name ), -- Calculate the number of days since each user's initial quickplay event days_since_event_table AS (     SELECT         events.user_pseudo_id,         events.event_name AS event_cohort,         events.event_cohort_date,         days.user_active_date,         DATE_DIFF(days.user_active_date, events.event_cohort_date, DAY) AS days_since_event     FROM          event_table events     LEFT JOIN          dates_active_table days ON events.user_pseudo_id = days.user_pseudo_id     WHERE          events.event_cohort_date <= days.user_active_date ), -- Calculate the weeks since each user's initial quickplay event and count the active days in each week weeks_retention AS (     SELECT         event_cohort,         user_pseudo_id,         CAST(CASE WHEN days_since_event = 0 THEN 0 ELSE CEIL(days_since_event / 7) END AS INTEGER) AS weeks_since_event,         COUNT(DISTINCT days_since_event) AS days_active_since_event -- Count Days Active in Week     FROM          days_since_event_table     GROUP BY          event_cohort, user_pseudo_id, weeks_since_event ), -- Aggregate the weekly retention data aggregated_weekly_retention_table AS (     SELECT         event_cohort,         weeks_since_event,         SUM(days_active_since_event) AS weekly_days_active,         COUNT(DISTINCT user_pseudo_id) AS retained_users     FROM          weeks_retention     GROUP BY          event_cohort, weeks_since_event ), RETENTION_INFO AS ( -- Select and calculate the weekly retention rate for each event cohort SELECT     event_cohort,     weeks_since_event,     weekly_days_active,     retained_users,     (retained_users / MAX(retained_users) OVER (PARTITION BY event_cohort)) AS retention_rate FROM      aggregated_weekly_retention_table ORDER BY      event_cohort, weeks_since_event )  SELECT event_cohort FROM RETENTION_INFO WHERE weeks_since_event = 2 ORDER BY retention_rate LIMIT 1",
        "schema": {
            "firebase-public-project.analytics_153293282": {
                "events_*": [
                    "user_pseudo_id",
                    "event_date",
                    "event_name"
                ]
            }
        }
    },
    "ga020_1": {
        "query": "-- Define the date range and calculate the minimum date for filtering results WITH dates AS (     SELECT          DATE('2018-07-02') AS start_date,         DATE('2018-07-16') AS end_date ), -- Create a table of active dates for each user within the specified date range dates_active_table AS (     SELECT         user_pseudo_id,         PARSE_DATE('%Y%m%d', `event_date`) AS user_active_date     FROM          `firebase-public-project.analytics_153293282.events_*`      WHERE          event_name = 'session_start'         AND PARSE_DATE('%Y%m%d', `event_date`) BETWEEN (SELECT start_date FROM dates) AND (SELECT end_date FROM dates)     GROUP BY          user_pseudo_id, user_active_date ), -- Create a table of the earliest quickplay event date for each user within the specified date range event_table AS (     SELECT          user_pseudo_id,         event_name,         MIN(PARSE_DATE('%Y%m%d', `event_date`)) AS event_cohort_date     FROM          `firebase-public-project.analytics_153293282.events_*`      WHERE          event_name IN ('level_start_quickplay', 'level_end_quickplay', 'level_complete_quickplay',                         'level_fail_quickplay', 'level_reset_quickplay', 'level_retry_quickplay')         AND PARSE_DATE('%Y%m%d', `event_date`) BETWEEN (SELECT start_date FROM dates) AND (SELECT end_date FROM dates)     GROUP BY          user_pseudo_id, event_name ), -- Calculate the number of days since each user's initial quickplay event days_since_event_table AS (     SELECT         events.user_pseudo_id,         events.event_name AS event_cohort,         events.event_cohort_date,         days.user_active_date,         DATE_DIFF(days.user_active_date, events.event_cohort_date, DAY) AS days_since_event     FROM          event_table events     LEFT JOIN          dates_active_table days ON events.user_pseudo_id = days.user_pseudo_id     WHERE          events.event_cohort_date <= days.user_active_date ), -- Calculate the weeks since each user's initial quickplay event and count the active days in each week weeks_retention AS (     SELECT         event_cohort,         user_pseudo_id,         CAST(CASE WHEN days_since_event = 0 THEN 0 ELSE CEIL(days_since_event / 7) END AS INTEGER) AS weeks_since_event,         COUNT(DISTINCT days_since_event) AS days_active_since_event -- Count Days Active in Week     FROM          days_since_event_table     GROUP BY          event_cohort, user_pseudo_id, weeks_since_event ), -- Aggregate the weekly retention data aggregated_weekly_retention_table AS (     SELECT         event_cohort,         weeks_since_event,         SUM(days_active_since_event) AS weekly_days_active,         COUNT(DISTINCT user_pseudo_id) AS retained_users     FROM          weeks_retention     GROUP BY          event_cohort, weeks_since_event ), RETENTION_INFO AS ( SELECT     event_cohort,     weeks_since_event,     weekly_days_active,     retained_users,     (retained_users / MAX(retained_users) OVER (PARTITION BY event_cohort)) AS retention_rate FROM      aggregated_weekly_retention_table ORDER BY      event_cohort, weeks_since_event )  SELECT event_cohort, retention_rate FROM RETENTION_INFO WHERE weeks_since_event = 2",
        "schema": {
            "firebase-public-project.analytics_153293282": {
                "events_*": [
                    "user_pseudo_id",
                    "event_date",
                    "event_name"
                ]
            }
        }
    },
    "ga025": {
        "query": "WITH -- List of users who installed in Sept sept_cohort AS (     SELECT DISTINCT          user_pseudo_id,         FORMAT_DATE('%Y-%m-%d', PARSE_DATE('%Y%m%d', event_date)) AS date_first_open     FROM          `firebase-public-project.analytics_153293282.events_*`     WHERE          event_name = 'first_open'         AND _TABLE_SUFFIX BETWEEN '20180901' AND '20180930' ), -- Get the list of users who uninstalled uninstallers AS (     SELECT DISTINCT          user_pseudo_id,         FORMAT_DATE('%Y-%m-%d', PARSE_DATE('%Y%m%d', event_date)) AS date_app_remove     FROM          `firebase-public-project.analytics_153293282.events_*`     WHERE          event_name = 'app_remove'         AND _TABLE_SUFFIX BETWEEN '20180901' AND '20181007' ), -- Get the list of users who experienced crashes users_crashes AS (     SELECT DISTINCT          user_pseudo_id,         FORMAT_DATE('%Y-%m-%d', PARSE_DATE('%Y%m%d', event_date)) AS date_crash     FROM          `firebase-public-project.analytics_153293282.events_*`,         UNNEST(event_params) e     WHERE          event_name = 'app_exception'         AND _TABLE_SUFFIX BETWEEN '20180901' AND '20181007' ), -- Join the 3 tables joined AS (     SELECT          a.user_pseudo_id,         a.date_first_open,         b.date_app_remove,         DATE_DIFF(DATE(b.date_app_remove), DATE(a.date_first_open), DAY) AS days_to_uninstall,         c.date_crash     FROM          sept_cohort a     LEFT JOIN          uninstallers b ON a.user_pseudo_id = b.user_pseudo_id     LEFT JOIN          users_crashes c ON a.user_pseudo_id = c.user_pseudo_id ) -- Compute the percentage SELECT     COUNT(DISTINCT CASE WHEN days_to_uninstall <= 7 AND date_crash IS NOT NULL THEN user_pseudo_id END) /      COUNT(DISTINCT CASE WHEN days_to_uninstall <= 7 THEN user_pseudo_id END) AS percent_users_crashes FROM      joined;",
        "schema": {
            "firebase-public-project.analytics_153293282": {
                "events_*": [
                    "user_pseudo_id",
                    "event_date",
                    "event_name",
                    "_TABLE_SUFFIX",
                    "event_params"
                ]
            }
        }
    },
    "local002": {
        "query": "WITH DailySalesPerCategory AS (     SELECT         DATE(order_purchase_timestamp) AS date,         -- Days since 2017-01-01         CAST(JULIANDAY(order_purchase_timestamp) - JULIANDAY('2017-01-01') AS INTEGER) AS day,         product_category_name_english AS category,         SUM(price) AS sales     FROM         orders         JOIN order_items USING (order_id)         JOIN products USING (product_id)         JOIN product_category_name_translation USING (product_category_name)     WHERE         order_purchase_timestamp BETWEEN '2017-01-01' AND '2018-08-29'         AND category = 'toys'     GROUP BY         day,         product_category_name_english ), LmPerCategory AS (     SELECT         category,         -- Slope         (COUNT(*) * SUM(day * sales) - SUM(day) * SUM(sales)) /              (COUNT(*) * SUM(day * day) - SUM(day) * SUM(day))             AS slope,         -- Intercept         (SUM(sales) -             ((COUNT(*) * SUM(day * sales) - SUM(day) * SUM(sales)) /              (COUNT(*) * SUM(day * day) - SUM(day) * SUM(day))) *             SUM(day)) / COUNT(*)             AS intercept     FROM         DailySalesPerCategory     GROUP BY         category ), ForecastedSales AS (     SELECT         DATE(date, '+1 year') AS date,         category,         -- Increase in predicted sales * sales 1 year ago         (intercept + slope * (day + CAST(JULIANDAY('2018-12-31') - JULIANDAY('2017-12-31') AS INTEGER)))             / (intercept + slope * day) * sales             AS forecasted_sales     FROM DailySalesPerCategory         JOIN LmPerCategory USING (category)     -- Filter for days of December 2018     WHERE day + CAST(JULIANDAY('2018-12-31') - JULIANDAY('2017-12-31') AS INTEGER)         BETWEEN CAST(JULIANDAY('2018-12-01') - JULIANDAY('2017-01-01') AS INTEGER)         AND CAST(JULIANDAY('2018-12-31') - JULIANDAY('2017-01-01') AS INTEGER) ), AVGForecastedSales AS (   SELECT     -- 5-day moving average     AVG(forecasted_sales)       OVER (PARTITION BY category ORDER BY date ROWS BETWEEN 2 PRECEDING AND 2 FOLLOWING) AS moving_avg_sales,     date   FROM ForecastedSales   WHERE date IN ('2018-12-05', '2018-12-06', '2018-12-07') )  SELECT SUM(moving_avg_sales) AS total_sales FROM AVGForecastedSales",
        "schema": {
            "orders": {
                "orders": [
                    "order_purchase_timestamp",
                    "order_id"
                ],
                "order_items": [
                    "order_id"
                ],
                "products": [
                    "product_id"
                ],
                "product_category_name_translation": [
                    "product_category_name"
                ]
            }
        }
    },
    "local029": {
        "query": "WITH customer_orders AS (     SELECT         c.customer_unique_id,         COUNT(o.order_id) AS Total_Orders_By_Customers,         AVG(p.payment_value) AS Average_Payment_By_Customer,         c.customer_city,         c.customer_state     FROM olist_customers c     JOIN olist_orders o ON c.customer_id = o.customer_id     JOIN olist_order_payments p ON o.order_id = p.order_id     WHERE o.order_status = 'delivered'     GROUP BY c.customer_unique_id, c.customer_city, c.customer_state )  SELECT      Average_Payment_By_Customer,     customer_city,     customer_state FROM customer_orders ORDER BY Total_Orders_By_Customers DESC LIMIT 3;",
        "schema": {
            "olist_customers": {
                "c": [
                    "customer_unique_id",
                    "customer_city",
                    "customer_state"
                ]
            },
            "olist_orders": {
                "o": [
                    "order_id",
                    "customer_id",
                    "order_status"
                ]
            },
            "olist_order_payments": {
                "p": [
                    "order_id",
                    "payment_value"
                ]
            }
        }
    },
    "local030": {
        "query": "WITH bottom_five_cities AS (     SELECT          c.customer_city,         SUM(p.payment_value) AS Total_Payment_By_Customers,         COUNT(o.order_id) AS Total_Number_Of_Orders     FROM olist_customers c     JOIN olist_orders o ON c.customer_id = o.customer_id     JOIN olist_order_payments p ON o.order_id = p.order_id     WHERE o.order_status = 'delivered'     GROUP BY c.customer_city     ORDER BY Total_Payment_By_Customers ASC     LIMIT 5 ) SELECT      AVG(Total_Payment_By_Customers) AS Average_Total_Payment,     AVG(Total_Number_Of_Orders) AS Average_Total_Orders FROM bottom_five_cities;",
        "schema": {
            "olist_customers": {
                "olist_customers": [
                    "customer_city",
                    "customer_id"
                ]
            },
            "olist_orders": {
                "olist_orders": [
                    "order_id",
                    "customer_id",
                    "order_status"
                ]
            },
            "olist_order_payments": {
                "olist_order_payments": [
                    "order_id",
                    "payment_value"
                ]
            }
        }
    },
    "local194": {
        "query": "WITH     actor_count AS (         SELECT              f.film_id,             f.title,             COUNT(fa.actor_id) AS num_actors         FROM              film f         JOIN              film_actor fa ON fa.film_id = f.film_id         GROUP BY              f.film_id, f.title         ORDER BY              f.film_id     ),     film_revenue AS (         SELECT              i.film_id,             SUM(p.amount) AS gross_revenue         FROM              payment p         JOIN              rental r ON r.rental_id = p.rental_id         JOIN              inventory i ON i.inventory_id = r.inventory_id         GROUP BY              i.film_id         ORDER BY              i.film_id     ),     film_rev_per_actor AS (         SELECT              ac.title,             ROUND(fr.gross_revenue / ac.num_actors, 2) AS rev_per_actor         FROM              actor_count ac         JOIN              film_revenue fr ON fr.film_id = ac.film_id     ) SELECT      * FROM      film_rev_per_actor ORDER BY      rev_per_actor DESC LIMIT      3;",
        "schema": {
            "sakila": {
                "film": [
                    "film_id",
                    "title"
                ],
                "film_actor": [
                    "actor_id",
                    "film_id"
                ],
                "payment": [
                    "amount",
                    "rental_id"
                ],
                "rental": [
                    "rental_id",
                    "inventory_id"
                ],
                "inventory": [
                    "inventory_id",
                    "film_id"
                ]
            }
        }
    },
    "local202": {
        "query": "WITH alien_aggression AS (     SELECT         state,         SUM(CASE WHEN aggressive = 1 THEN 1 ELSE 0 END) AS n_hostile_aliens,         SUM(CASE WHEN aggressive = 0 THEN 1 ELSE 0 END) AS n_friendly_aliens     FROM alien_data     GROUP BY state ), alien_stats AS (     SELECT         alien_data.state,         COUNT(*) AS alien_population_total,         ROUND(AVG(age)) AS avg_alien_age,         alien_aggression.n_friendly_aliens,         alien_aggression.n_hostile_aliens     FROM alien_data     JOIN alien_aggression ON alien_data.state = alien_aggression.state     GROUP BY alien_data.state, alien_aggression.n_friendly_aliens, alien_aggression.n_hostile_aliens ), top_states AS (     SELECT state     FROM alien_stats     ORDER BY alien_population_total DESC     LIMIT 10 ) SELECT     COUNT(*) AS number_of_states FROM     alien_stats WHERE     state IN (SELECT state FROM top_states)     AND ROUND((CAST(n_friendly_aliens AS REAL) / CAST(alien_population_total AS REAL)) * 100, 2) >     ROUND((CAST(n_hostile_aliens AS REAL) / CAST(alien_population_total AS REAL)) * 100, 2)     AND avg_alien_age > 200;",
        "schema": {
            "alien_data": {
                "alien_data": [
                    "state",
                    "aggressive",
                    "age"
                ],
                "alien_aggression": [
                    "state",
                    "n_friendly_aliens",
                    "n_hostile_aliens"
                ],
                "alien_stats": [
                    "state",
                    "alien_population_total",
                    "avg_alien_age"
                ],
                "top_states": [
                    "state"
                ]
            }
        }
    },
    "local329_3": {
        "query": "",
        "schema": {
            "dp-dwh-prod.dwh_web": {
                "fct_session_hit": [
                    "session_id",
                    "hit_type",
                    "event_list",
                    "product_list",
                    "hit_ts",
                    "date_key"
                ]
            },
            "dp-dwh-prod.dwh_presentation": {
                "dim_date": [
                    "date_key",
                    "day_of_week"
                ]
            }
        }
    },
    "local334": {
        "query": "WITH login_status AS (   SELECT     session,     user_id,     action,     CASE       WHEN COALESCE(user_id, ' ') <> ' ' THEN 'login'       ELSE 'guest'     END AS login_status   FROM action_log ), action_counts AS (   SELECT     action,     login_status,     COUNT(*) AS action_count   FROM login_status   GROUP BY action, login_status ), most_frequent_action AS (   SELECT     login_status,     action,     action_count,     ROW_NUMBER() OVER (PARTITION BY login_status ORDER BY action_count DESC) AS rank   FROM action_counts ) SELECT   action_count FROM   most_frequent_action WHERE   rank = 1;",
        "schema": {
            "action_log": {
                "action_log": [
                    "session",
                    "user_id",
                    "action"
                ]
            }
        }
    },
    "local334_1": {
        "query": "WITH login_status AS (   SELECT     session,     user_id,     action,     CASE       WHEN COALESCE(user_id, ' ') <> ' ' THEN 'login'       ELSE 'guest'     END AS login_status   FROM action_log ), action_counts AS (   SELECT     action,     login_status,     COUNT(*) AS action_count   FROM login_status   GROUP BY action, login_status ), max_min_counts AS (   SELECT     MAX(action_count) AS max_action_count,     MIN(action_count) AS min_action_count   FROM action_counts ) SELECT   max_action_count - min_action_count AS action_count_difference FROM   max_min_counts;",
        "schema": {
            "action_log": {
                "action_log": [
                    "session",
                    "user_id",
                    "action"
                ]
            }
        }
    },
    "bq295": {
        "query": "WITH watched_repos AS (     SELECT         repo.name AS repo     FROM          `githubarchive.month.2017*`     WHERE         type = \"WatchEvent\" ), repo_watch_counts AS (     SELECT         repo,         COUNT(*) AS watch_count     FROM         watched_repos     GROUP BY         repo )  SELECT     r.repo,     r.watch_count FROM     `bigquery-public-data.github_repos.sample_files` AS f JOIN     `bigquery-public-data.github_repos.sample_contents` AS c ON     f.id = c.id JOIN      repo_watch_counts AS r ON     f.repo_name = r.repo WHERE     f.path LIKE '%.py'      AND c.size < 15000      AND REGEXP_CONTAINS(c.content, r'def ') GROUP BY     r.repo, r.watch_count ORDER BY     r.watch_count DESC LIMIT      3;",
        "schema": {
            "githubarchive.month": {
                "2017*": [
                    "repo.name",
                    "type"
                ]
            },
            "bigquery-public-data.github_repos": {
                "sample_files": [
                    "id",
                    "repo_name",
                    "path"
                ],
                "sample_contents": [
                    "id",
                    "size",
                    "content"
                ]
            }
        }
    },
    "bq250": {
        "query": "WITH country_name AS (   SELECT 'Singapore' AS value ),  last_updated AS (   SELECT     MAX(last_updated) AS value   FROM `bigquery-public-data.worldpop.population_grid_1km` AS pop     INNER JOIN country_name ON (pop.country_name = country_name.value)   WHERE last_updated < '2023-01-01' ),  population AS (   SELECT     SUM(sum_population) AS sum_population,     ST_CONVEXHULL(st_union_agg(centr)) AS boundingbox   FROM (     SELECT       SUM(population) AS sum_population,       ST_CENTROID_AGG(ST_GEOGPOINT(longitude_centroid, latitude_centroid)) AS centr     FROM       `bigquery-public-data.worldpop.population_grid_1km` AS pop       INNER JOIN country_name ON (pop.country_name = country_name.value)       INNER JOIN last_updated ON (pop.last_updated = last_updated.value)     GROUP BY geo_id   ) ),  hospitals AS (   SELECT     layer.geometry   FROM     `bigquery-public-data.geo_openstreetmap.planet_layers` AS layer     INNER JOIN population ON ST_INTERSECTS(population.boundingbox, layer.geometry)   WHERE     layer.layer_code in (2110, 2120) ),  distances AS (   SELECT     pop.geo_id,     pop.population,     MIN(ST_DISTANCE(pop.geog, hospitals.geometry)) AS distance   FROM     `bigquery-public-data.worldpop.population_grid_1km` AS pop       INNER JOIN country_name ON pop.country_name = country_name.value       INNER JOIN last_updated ON pop.last_updated = last_updated.value         CROSS JOIN hospitals   WHERE pop.population > 0   GROUP BY geo_id, population )  SELECT   SUM(pd.population) AS population FROM   distances pd CROSS JOIN population p GROUP BY distance ORDER BY distance DESC LIMIT 1",
        "schema": {
            "bigquery-public-data.worldpop": {
                "population_grid_1km": [
                    "country_name",
                    "last_updated",
                    "sum_population",
                    "longitude_centroid",
                    "latitude_centroid",
                    "geo_id",
                    "population",
                    "geog"
                ]
            },
            "bigquery-public-data.geo_openstreetmap": {
                "planet_layers": [
                    "geometry",
                    "layer_code"
                ]
            }
        }
    },
    "bq326": {
        "query": "--Transposing data in the yearly columns to rows in a new table.  WITH base AS (     SELECT country,     country_code,     unpivotted     FROM `bigquery-public-data.world_bank_global_population.population_by_country` a        , UNNEST(fhoffa.x.unpivot(a, 'year')) unpivotted ),  pop AS (SELECT country,   country_code,  --unpivot the returned data in the first CTE  CAST (RIGHT(unpivotted.key,4) AS INT64) AS as_of_year,  CASE WHEN unpivotted.value = 'null' THEN '0' ELSE unpivotted.value END AS population  FROM base  --selecting years from 2010 and beyond WHERE CAST (RIGHT(unpivotted.key,4) AS INT64)  >= 2010 ),  ----New CTE to change population data type pop_1 AS (    SELECT     country,    country_code,    as_of_year,   CAST (population as FLOAT64) AS population, --using lag function to calculate previous population by country_code   COALESCE (LAG (CAST (population AS FLOAT64), 1)   OVER (PARTITION BY country_code ORDER BY as_of_year), 0) AS prev_population    from pop ),  --New CTE to calculate change in population and filter for year 2018  Number1 as (   SELECT *,  --used Coalesce to get rid of null. from division --Used Nullif to handle error by diving by zero.   COALESCE (ROUND ( population /NULLIF(prev_population,0), 2 ), 0) AS change_in_population     FROM pop_1 --filter for 2018 where pop_1.as_of_year = 2018), --New CTE to return required columns and filter for PPP(SH.XPD.CHEX.PP.CD RETURNS PPP) A AS (  SELECT   country_name,   country_code,   indicator_name,   value as PPP,   year, --using lag function to calculate previous PPP by country_code ordered by year  LAG(value) over (partition by country_code order by year) as prePPP  FROM `bigquery-public-data.world_bank_health_population.health_nutrition_population` -- filter for SH.XPD.CHEX.PP.CD  WHERE   indicator_code = \"SH.XPD.CHEX.PP.CD\"), --CTE to calculate chane in population B AS (   SELECT    *, --used Coalesce to get rid of null. from division --Used Nullif to handle error by diving by zero.    COALESCE (ROUND ( A.PPP /NULLIF(prePPP,0), 2 ), 0) AS change_in_PPP   FROM A  --filter for 2018   WHERE year = 2018) --join change in population table and change in PPP into one table based on the country code SELECT   COUNT(country) AS country_count FROM Number1  left join B   ON Number1.country_code = B.country_code WHERE  B.change_in_PPP > 1 AND Number1.change_in_population > 1;",
        "schema": {
            "bigquery-public-data.world_bank_global_population": {
                "population_by_country": [
                    "country",
                    "country_code",
                    "year"
                ]
            },
            "bigquery-public-data.world_bank_health_population": {
                "health_nutrition_population": [
                    "country_name",
                    "country_code",
                    "indicator_name",
                    "value",
                    "year",
                    "indicator_code"
                ]
            }
        }
    },
    "local028_1": {
        "query": "WITH monthly_order_counts AS (     SELECT         strftime('%Y', order_delivered_customer_date) AS Year,         strftime('%m', order_delivered_customer_date) AS Month,         COUNT(*) AS MonthlyOrderCount     FROM olist_orders     WHERE order_status = 'delivered'       AND order_delivered_customer_date IS NOT NULL     GROUP BY Year, Month ), yearly_order_counts AS (     SELECT         Year,         SUM(MonthlyOrderCount) AS TotalOrderCount     FROM monthly_order_counts     WHERE Year IN ('2016', '2017', '2018')     GROUP BY Year ), min_order_year AS (     SELECT         Year     FROM yearly_order_counts     ORDER BY TotalOrderCount ASC     LIMIT 1 ) SELECT     MAX(MonthlyOrderCount) AS max_monthly_order_count FROM monthly_order_counts WHERE Year = (SELECT Year FROM min_order_year);",
        "schema": {
            "olist_orders": {
                "olist_orders": [
                    "order_delivered_customer_date",
                    "order_status"
                ]
            }
        }
    },
    "local157": {
        "query": "WITH cte_adjusted_prices AS (   SELECT     ticker,     market_date,     CASE       WHEN substr(volume, -1) = 'K' THEN cast(substr(volume, 1, length(volume) - 1) AS REAL) * 1000       WHEN substr(volume, -1) = 'M' THEN cast(substr(volume, 1, length(volume) - 1) AS REAL) * 1000000       WHEN volume = '-' THEN 0       ELSE cast(volume AS REAL)     END AS volume   FROM prices ), cte_previous_volume AS (   SELECT     ticker,     market_date,     volume,     LAG(volume) OVER (       PARTITION BY ticker       ORDER BY strftime('%Y-%m-%d', substr(market_date, 7, 4) || '-' || substr(market_date, 4, 2) || '-' || substr(market_date, 1, 2))     ) AS previous_volume   FROM cte_adjusted_prices   WHERE volume != 0 ) SELECT   ticker,   market_date,   volume,   previous_volume,   ROUND(     100.0 * (volume - previous_volume) / previous_volume,     2   ) AS daily_change FROM cte_previous_volume WHERE strftime('%Y-%m-%d', substr(market_date, 7, 4) || '-' || substr(market_date, 4, 2) || '-' || substr(market_date, 1, 2))   BETWEEN '2021-08-01' AND '2021-08-10' ORDER BY ticker, market_date;",
        "schema": {
            "prices": {
                "prices": [
                    "ticker",
                    "market_date",
                    "volume"
                ]
            }
        }
    },
    "local297": {
        "query": "WITH customer_balance AS (     SELECT *,            SUM(txn_amount) OVER (PARTITION BY customer_id ORDER BY month_ ASC) AS balance     FROM (         SELECT customer_id, strftime('%Y-%m-01', txn_date) AS month_, SUM(txn_group) AS txn_amount          FROM (             SELECT *,                    CASE WHEN txn_type = 'deposit' THEN txn_amount                         ELSE -1 * txn_amount END AS txn_group             FROM Customer_Transactions             ORDER BY customer_id, txn_date         ) AS update_txn_amount         GROUP BY customer_id, strftime('%Y-%m-01', txn_date)     ) AS monthly_totals ), growth_rates AS (     SELECT customer_id, month_, balance, previous_month_balance,             CASE WHEN previous_month_balance IS NULL THEN NULL                 WHEN previous_month_balance = 0 THEN balance * 100                 ELSE ROUND(((balance - previous_month_balance) * 1.0 / ABS(previous_month_balance)) * 100, 1) END AS growth_rate,            ROW_NUMBER() OVER (PARTITION BY customer_id ORDER BY month_ DESC) AS balance_index     FROM (         SELECT *,                LAG(balance) OVER (PARTITION BY customer_id ORDER BY month_) AS previous_month_balance         FROM customer_balance     ) AS add_previous_month_balance ), cust_last_balance AS (     SELECT customer_id, month_, growth_rate,            CASE WHEN growth_rate > 5 THEN 1 ELSE 0 END AS growth_rate_check      FROM growth_rates     WHERE balance_index = 1 ) SELECT ROUND((SUM(growth_rate_check) * 1.0 / COUNT(*) * 100), 2) || '%' AS percentage_growth_check FROM cust_last_balance;",
        "schema": {
            "Customer_Transactions": {
                "update_txn_amount": [
                    "customer_id",
                    "txn_date",
                    "txn_amount",
                    "txn_type",
                    "txn_group"
                ],
                "customer_balance": [
                    "customer_id",
                    "month_",
                    "txn_amount",
                    "balance"
                ],
                "growth_rates": [
                    "customer_id",
                    "month_",
                    "balance",
                    "previous_month_balance",
                    "growth_rate",
                    "balance_index"
                ],
                "cust_last_balance": [
                    "customer_id",
                    "month_",
                    "growth_rate",
                    "growth_rate_check"
                ]
            }
        }
    },
    "local003": {
        "query": "WITH RecencyScore AS (     SELECT customer_unique_id,            MAX(order_purchase_timestamp) AS last_purchase,            NTILE(5) OVER (ORDER BY MAX(order_purchase_timestamp) DESC) AS recency     FROM orders         JOIN customers USING (customer_id)     WHERE order_status = 'delivered'     GROUP BY customer_unique_id ), FrequencyScore AS (     SELECT customer_unique_id,            COUNT(order_id) AS total_orders,            NTILE(5) OVER (ORDER BY COUNT(order_id) DESC) AS frequency     FROM orders         JOIN customers USING (customer_id)     WHERE order_status = 'delivered'     GROUP BY customer_unique_id ), MonetaryScore AS (     SELECT customer_unique_id,            SUM(price) AS total_spent,            NTILE(5) OVER (ORDER BY SUM(price) DESC) AS monetary     FROM orders         JOIN order_items USING (order_id)         JOIN customers USING (customer_id)     WHERE order_status = 'delivered'     GROUP BY customer_unique_id ),  -- 2. Assign each customer to a group RFM AS (     SELECT last_purchase, total_orders, total_spent,         CASE             WHEN recency = 1 AND frequency + monetary IN (1, 2, 3, 4) THEN \"Champions\"             WHEN recency IN (4, 5) AND frequency + monetary IN (1, 2) THEN \"Can't Lose Them\"             WHEN recency IN (4, 5) AND frequency + monetary IN (3, 4, 5, 6) THEN \"Hibernating\"             WHEN recency IN (4, 5) AND frequency + monetary IN (7, 8, 9, 10) THEN \"Lost\"             WHEN recency IN (2, 3) AND frequency + monetary IN (1, 2, 3, 4) THEN \"Loyal Customers\"             WHEN recency = 3 AND frequency + monetary IN (5, 6) THEN \"Needs Attention\"             WHEN recency = 1 AND frequency + monetary IN (7, 8) THEN \"Recent Users\"             WHEN recency = 1 AND frequency + monetary IN (5, 6) OR                 recency = 2 AND frequency + monetary IN (5, 6, 7, 8) THEN \"Potentital Loyalists\"             WHEN recency = 1 AND frequency + monetary IN (9, 10) THEN \"Price Sensitive\"             WHEN recency = 2 AND frequency + monetary IN (9, 10) THEN \"Promising\"             WHEN recency = 3 AND frequency + monetary IN (7, 8, 9, 10) THEN \"About to Sleep\"         END AS RFM_Bucket     FROM RecencyScore         JOIN FrequencyScore USING (customer_unique_id)         JOIN MonetaryScore USING (customer_unique_id) )  SELECT RFM_Bucket,         AVG(total_spent / total_orders) AS avg_sales_per_customer FROM RFM GROUP BY RFM_Bucket",
        "schema": {
            "public": {
                "orders": [
                    "customer_id",
                    "order_purchase_timestamp",
                    "order_id",
                    "order_status",
                    "price"
                ],
                "customers": [
                    "customer_id",
                    "customer_unique_id"
                ],
                "order_items": [
                    "order_id"
                ],
                "RecencyScore": [
                    "customer_unique_id",
                    "last_purchase",
                    "recency"
                ],
                "FrequencyScore": [
                    "customer_unique_id",
                    "total_orders",
                    "frequency"
                ],
                "MonetaryScore": [
                    "customer_unique_id",
                    "total_spent",
                    "monetary"
                ],
                "RFM": [
                    "last_purchase",
                    "total_orders",
                    "total_spent",
                    "RFM_Bucket"
                ]
            }
        }
    },
    "local004": {
        "query": "WITH CustomerData AS (     SELECT         customer_unique_id,         COUNT(DISTINCT orders.order_id) AS order_count,         SUM(payment_value) AS total_payment,         JULIANDAY(MIN(order_purchase_timestamp)) AS first_order_day,         JULIANDAY(MAX(order_purchase_timestamp)) AS last_order_day     FROM customers         JOIN orders USING (customer_id)         JOIN order_payments USING (order_id)     GROUP BY customer_unique_id ) SELECT     customer_unique_id,     order_count AS PF,     ROUND(total_payment / order_count, 2) AS AOV,     CASE         WHEN (last_order_day - first_order_day) < 7 THEN             1         ELSE             (last_order_day - first_order_day) / 7         END AS ACL FROM CustomerData ORDER BY AOV DESC LIMIT 3",
        "schema": {
            "public": {
                "customers": [
                    "customer_unique_id",
                    "customer_id"
                ],
                "orders": [
                    "order_id",
                    "customer_id",
                    "order_purchase_timestamp"
                ],
                "order_payments": [
                    "order_id",
                    "payment_value"
                ],
                "CustomerData": [
                    "customer_unique_id",
                    "order_count",
                    "total_payment",
                    "first_order_day",
                    "last_order_day"
                ]
            }
        }
    },
    "local007": {
        "query": "with player_career_span as (     select          b.player_name,         b.debut,         b.final_game,         round(b.year, 2) + round(round(b.month, 2) / round(12, 2), 2) + round(round(b.day, 2) / round(365, 2), 2) as career_span     from (         select             a.player_name,             a.debut,             a.final_game,             case when a.year > 0 then a.year else -a.year end as year,             case when a.month > 0 then a.month else -a.month end as month,             case when a.days > 0 then a.days else -a.days end as day         from (             select                  name_given as player_name,                 debut,                 final_game,                 (strftime('%Y', final_game) - strftime('%Y', debut)) as year,                 (strftime('%m', final_game) - strftime('%m', debut)) as month,                 (strftime('%d', final_game) - strftime('%d', debut)) as days             from player         ) a     ) b )  select      avg(career_span) as average_career_span from      player_career_span;",
        "schema": {
            "public": {
                "player": [
                    "name_given",
                    "debut",
                    "final_game"
                ],
                "player_career_span": [
                    "player_name",
                    "debut",
                    "final_game",
                    "career_span"
                ]
            }
        }
    },
    "local009": {
        "query": "WITH FLIGHT_INFO AS (     SELECT             flights.flight_id,         json_extract(departure.city, '$.en') AS from_city,         CAST(SUBSTR(departure.coordinates, 2, INSTR(departure.coordinates, ',') - 2) AS REAL) AS from_longitude,         CAST(SUBSTR(departure.coordinates, INSTR(departure.coordinates, ',') + 1, LENGTH(departure.coordinates) - INSTR(departure.coordinates, ',') - 2) AS REAL) AS from_latitude,         json_extract(arrival.city, '$.en') AS to_city,         CAST(SUBSTR(arrival.coordinates, 2, INSTR(arrival.coordinates, ',') - 2) AS REAL) AS to_longitude,         CAST(SUBSTR(arrival.coordinates, INSTR(arrival.coordinates, ',') + 1, LENGTH(arrival.coordinates) - INSTR(arrival.coordinates, ',') - 2) AS REAL) AS to_latitude     FROM         flights      LEFT JOIN airports_data AS departure ON flights.departure_airport = departure.airport_code     LEFT JOIN airports_data AS arrival ON flights.arrival_airport = arrival.airport_code ), DISTANCES AS (     SELECT         flight_id,         from_city,         to_city,         CASE             WHEN from_city < to_city THEN from_city ELSE to_city END AS city1,             CASE             WHEN from_city < to_city THEN to_city ELSE from_city END AS city2,         2 * 6371 * ASIN(SQRT(             POWER(SIN(RADIANS((to_latitude - from_latitude) / 2)), 2) +             COS(RADIANS(from_latitude)) * COS(RADIANS(to_latitude)) *             POWER(SIN(RADIANS((to_longitude - from_longitude) / 2)), 2)         )) AS distance_km     FROM FLIGHT_INFO ), ALL_Route AS (     SELECT         city1,         city2,         distance_km,         COUNT(*) AS number_of_flights -- Count flights for both directions     FROM DISTANCES     WHERE (city1 = 'Abakan' OR city2 = 'Abakan')     GROUP BY city1, city2 ) SELECT      distance_km FROM ALL_Route ORDER BY distance_km DESC LIMIT 1;",
        "schema": {
            "public": {
                "flights": [
                    "flight_id",
                    "departure_airport",
                    "arrival_airport"
                ],
                "airports_data": [
                    "airport_code",
                    "city.en",
                    "coordinates"
                ],
                "FLIGHT_INFO": [
                    "flight_id",
                    "from_city",
                    "from_longitude",
                    "from_latitude",
                    "to_city",
                    "to_longitude",
                    "to_latitude"
                ],
                "DISTANCES": [
                    "flight_id",
                    "from_city",
                    "to_city",
                    "city1",
                    "city2",
                    "distance_km"
                ],
                "ALL_Route": [
                    "city1",
                    "city2",
                    "distance_km",
                    "number_of_flights"
                ]
            }
        }
    },
    "local010": {
        "query": "WITH FLIGHT_INFO AS (     SELECT             flights.flight_id,         json_extract(departure.city, '$.en') AS from_city,         CAST(SUBSTR(departure.coordinates, 2, INSTR(departure.coordinates, ',') - 2) AS REAL) AS from_longitude,         CAST(SUBSTR(departure.coordinates, INSTR(departure.coordinates, ',') + 1, LENGTH(departure.coordinates) - INSTR(departure.coordinates, ',') - 2) AS REAL) AS from_latitude,         json_extract(arrival.city, '$.en') AS to_city,         CAST(SUBSTR(arrival.coordinates, 2, INSTR(arrival.coordinates, ',') - 2) AS REAL) AS to_longitude,         CAST(SUBSTR(arrival.coordinates, INSTR(arrival.coordinates, ',') + 1, LENGTH(arrival.coordinates) - INSTR(arrival.coordinates, ',') - 2) AS REAL) AS to_latitude     FROM         flights      LEFT JOIN airports_data AS departure ON flights.departure_airport = departure.airport_code     LEFT JOIN airports_data AS arrival ON flights.arrival_airport = arrival.airport_code )   -- Create a histogram distribution of average_distance_km SELECT group_count FROM ( SELECT     FLOOR(average_distance_km / 1000) * 1000 AS distance_range,     COUNT(*) AS group_count FROM (     -- Calculate the average distance for each unique combination of from_city and to_city     SELECT         from_city,         to_city,         AVG(distance_km) AS average_distance_km     FROM (         -- Subquery to calculate the distances as before         SELECT             from_city,             to_city,             -- Calculate the distance using the Haversine formula             2 * 6371 * ASIN(SQRT(                 POWER(SIN(RADIANS((to_latitude - from_latitude) / 2)), 2) +                 COS(RADIANS(from_latitude)) * COS(RADIANS(to_latitude)) *                 POWER(SIN(RADIANS((to_longitude - from_longitude) / 2)), 2)             )) AS distance_km         FROM FLIGHT_INFO     ) AS subquery     GROUP BY from_city, to_city ) AS distances GROUP BY distance_range ORDER BY group_count LIMIT 1 )",
        "schema": {
            "public": {
                "flights": [
                    "flight_id",
                    "departure_airport",
                    "arrival_airport"
                ],
                "airports_data": [
                    "airport_code",
                    "city",
                    "coordinates"
                ],
                "FLIGHT_INFO": [
                    "flight_id",
                    "from_city",
                    "from_longitude",
                    "from_latitude",
                    "to_city",
                    "to_longitude",
                    "to_latitude"
                ]
            }
        }
    },
    "local026": {
        "query": "WITH combined_runs AS (     SELECT match_id, over_id, ball_id, innings_no, runs_scored AS runs     FROM batsman_scored     UNION ALL     SELECT match_id, over_id, ball_id, innings_no, extra_runs AS runs     FROM extra_runs ), over_runs AS (     SELECT match_id, innings_no, over_id, SUM(runs) AS runs_scored     FROM combined_runs     GROUP BY match_id, innings_no, over_id ), max_over_runs AS (     SELECT match_id, MAX(runs_scored) AS max_runs     FROM over_runs     GROUP BY match_id ), top_overs AS (     SELECT o.match_id, o.innings_no, o.over_id, o.runs_scored     FROM over_runs o     JOIN max_over_runs m ON o.match_id = m.match_id AND o.runs_scored = m.max_runs ), top_bowlers AS (     SELECT         bb.match_id,         t.runs_scored AS maximum_runs,         bb.bowler     FROM ball_by_ball bb     JOIN top_overs t ON bb.match_id = t.match_id     AND bb.innings_no = t.innings_no     AND bb.over_id = t.over_id     GROUP BY bb.match_id, t.runs_scored, bb.bowler ) SELECT     b.match_id,     p.player_name FROM (     SELECT *     FROM top_bowlers     ORDER BY maximum_runs DESC     LIMIT 3 ) b JOIN player p ON p.player_id = b.bowler ORDER BY b.maximum_runs DESC, b.match_id, p.player_name;",
        "schema": {
            "public": {
                "batsman_scored": [
                    "match_id",
                    "over_id",
                    "ball_id",
                    "innings_no",
                    "runs_scored"
                ],
                "extra_runs": [
                    "match_id",
                    "over_id",
                    "ball_id",
                    "innings_no",
                    "extra_runs"
                ],
                "combined_runs": [
                    "match_id",
                    "over_id",
                    "ball_id",
                    "innings_no",
                    "runs"
                ],
                "over_runs": [
                    "match_id",
                    "innings_no",
                    "over_id",
                    "runs_scored"
                ],
                "max_over_runs": [
                    "match_id",
                    "max_runs"
                ],
                "top_overs": [
                    "match_id",
                    "innings_no",
                    "over_id",
                    "runs_scored"
                ],
                "ball_by_ball": [
                    "match_id",
                    "bowler",
                    "innings_no",
                    "over_id"
                ],
                "top_bowlers": [
                    "match_id",
                    "maximum_runs",
                    "bowler"
                ],
                "player": [
                    "player_id",
                    "player_name"
                ]
            }
        }
    },
    "local026_1": {
        "query": "WITH runs_and_wickets AS (     SELECT          bowler,         SUM(CASE WHEN wt.match_id IS NOT NULL THEN 1 ELSE 0 END) AS wickets_taken,         SUM(COALESCE(er.extra_runs, 0) + COALESCE(bs.runs_scored, 0)) AS total_runs_given     FROM          ball_by_ball bb     LEFT JOIN          wicket_taken wt ON bb.match_id = wt.match_id              AND bb.over_id = wt.over_id              AND bb.ball_id = wt.ball_id              AND bb.innings_no = wt.innings_no     LEFT JOIN          extra_runs er ON bb.match_id = er.match_id              AND bb.over_id = er.over_id              AND bb.ball_id = er.ball_id              AND bb.innings_no = er.innings_no     LEFT JOIN          batsman_scored bs ON bb.match_id = bs.match_id              AND bb.over_id = bs.over_id              AND bb.ball_id = bs.ball_id              AND bb.innings_no = bs.innings_no     GROUP BY          bowler ), bowling_averages AS (     SELECT          bowler AS player_id,          ROUND(total_runs_given / NULLIF(wickets_taken, 0), 3) AS bowling_avg,         ROW_NUMBER() OVER (ORDER BY total_runs_given / NULLIF(wickets_taken, 0)) AS rn     FROM          runs_and_wickets     WHERE          wickets_taken > 0 ) SELECT      p.player_name  FROM      player p JOIN      bowling_averages ba ON p.player_id = ba.player_id  WHERE      ba.rn = 1 ORDER BY      p.player_name;",
        "schema": {
            "public": {
                "ball_by_ball": [
                    "match_id",
                    "over_id",
                    "ball_id",
                    "innings_no",
                    "bowler"
                ],
                "wicket_taken": [
                    "match_id",
                    "over_id",
                    "ball_id",
                    "innings_no"
                ],
                "extra_runs": [
                    "match_id",
                    "over_id",
                    "ball_id",
                    "innings_no",
                    "extra_runs"
                ],
                "batsman_scored": [
                    "match_id",
                    "over_id",
                    "ball_id",
                    "innings_no",
                    "runs_scored"
                ],
                "runs_and_wickets": [
                    "bowler",
                    "wickets_taken",
                    "total_runs_given"
                ],
                "bowling_averages": [
                    "player_id",
                    "bowling_avg",
                    "rn"
                ],
                "player": [
                    "player_id",
                    "player_name"
                ]
            }
        }
    },
    "local026_2": {
        "query": "WITH derived AS (     SELECT          bbb.match_id,          bbb.over_id,          bbb.ball_id,          bbb.innings_no,          bbb.striker,          bs.runs_scored AS runs      FROM          ball_by_ball bbb     JOIN          batsman_scored bs     ON          bbb.match_id = bs.match_id          AND bbb.over_id = bs.over_id          AND bbb.ball_id = bs.ball_id          AND bbb.innings_no = bs.innings_no ), fifty_plus_scorers AS (     SELECT          striker AS player_id      FROM          derived      GROUP BY          match_id, striker      HAVING          SUM(runs) > 50 ), total_runs AS (     SELECT          striker AS player_id,          SUM(runs) AS total_runs      FROM          derived      GROUP BY          striker ), qualified_scorers AS (     SELECT          tr.player_id,          tr.total_runs      FROM          total_runs tr     JOIN          fifty_plus_scorers fps     ON          tr.player_id = fps.player_id ) SELECT      AVG(total_runs) AS average_runs  FROM      qualified_scorers;",
        "schema": {
            "public": {
                "ball_by_ball": [
                    "match_id",
                    "over_id",
                    "ball_id",
                    "innings_no",
                    "striker"
                ],
                "batsman_scored": [
                    "match_id",
                    "over_id",
                    "ball_id",
                    "innings_no",
                    "runs_scored"
                ],
                "derived": [
                    "match_id",
                    "over_id",
                    "ball_id",
                    "innings_no",
                    "striker",
                    "runs"
                ],
                "fifty_plus_scorers": [
                    "player_id"
                ],
                "total_runs": [
                    "player_id",
                    "total_runs"
                ],
                "qualified_scorers": [
                    "player_id",
                    "total_runs"
                ]
            }
        }
    },
    "local026_6": {
        "query": "WITH consolidated_runs AS (     SELECT         match_id,         over_id,         innings_no,         runs_scored AS runs     FROM         batsman_scored     UNION ALL     SELECT         match_id,         over_id,         innings_no,         extra_runs AS runs     FROM         extra_runs ), summarized_runs AS (     SELECT         match_id,         innings_no,         over_id,         SUM(runs) AS total_runs     FROM         consolidated_runs     GROUP BY         match_id, innings_no, over_id ), max_runs_per_match AS (     SELECT         match_id,         MAX(total_runs) AS max_runs     FROM         summarized_runs     GROUP BY         match_id ), over_details AS (     SELECT         sr.match_id,         sr.innings_no,         sr.over_id,         sr.total_runs,         bb.bowler     FROM         summarized_runs sr     JOIN         max_runs_per_match mr ON sr.match_id = mr.match_id AND sr.total_runs = mr.max_runs     JOIN         ball_by_ball bb ON sr.match_id = bb.match_id AND sr.innings_no = bb.innings_no AND sr.over_id = bb.over_id     GROUP BY         sr.match_id, sr.innings_no, sr.over_id, sr.total_runs, bb.bowler ), final_result AS (     SELECT         od.match_id,         od.total_runs AS maximum_runs,         p.player_name     FROM         over_details od     JOIN         player p ON od.bowler = p.player_id     ORDER BY         od.match_id,         od.over_id,         p.player_name ) SELECT     AVG(maximum_runs) AS average_maximum_runs FROM     final_result;",
        "schema": {
            "public": {
                "batsman_scored": [
                    "match_id",
                    "over_id",
                    "innings_no",
                    "runs_scored"
                ],
                "extra_runs": [
                    "match_id",
                    "over_id",
                    "innings_no",
                    "extra_runs"
                ],
                "consolidated_runs": [
                    "match_id",
                    "over_id",
                    "innings_no",
                    "runs"
                ],
                "summarized_runs": [
                    "match_id",
                    "innings_no",
                    "over_id",
                    "total_runs"
                ],
                "max_runs_per_match": [
                    "match_id",
                    "max_runs"
                ],
                "ball_by_ball": [
                    "match_id",
                    "innings_no",
                    "over_id",
                    "bowler"
                ],
                "over_details": [
                    "match_id",
                    "innings_no",
                    "over_id",
                    "total_runs",
                    "bowler"
                ],
                "player": [
                    "player_id",
                    "player_name"
                ],
                "final_result": [
                    "match_id",
                    "maximum_runs"
                ]
            }
        }
    },
    "local038": {
        "query": "SELECT     actor.first_name || ' ' || actor.last_name AS full_name FROM     actor INNER JOIN film_actor ON actor.actor_id = film_actor.actor_id INNER JOIN film ON film_actor.film_id = film.film_id INNER JOIN film_category ON film.film_id = film_category.film_id INNER JOIN category ON film_category.category_id = category.category_id -- Join with the language table INNER JOIN language ON film.language_id = language.language_id WHERE     category.name = 'Children' AND     film.release_year BETWEEN 2000 AND 2010 AND     film.rating IN ('G', 'PG') AND     language.name = 'English' AND     film.length <= 120 GROUP BY     actor.actor_id, actor.first_name, actor.last_name ORDER BY     COUNT(film.film_id) DESC LIMIT 1;",
        "schema": {
            "public": {
                "actor": [
                    "actor_id",
                    "first_name",
                    "last_name"
                ],
                "film_actor": [
                    "actor_id",
                    "film_id"
                ],
                "film": [
                    "film_id",
                    "release_year",
                    "rating",
                    "language_id",
                    "length"
                ],
                "film_category": [
                    "film_id",
                    "category_id"
                ],
                "category": [
                    "category_id",
                    "name"
                ],
                "language": [
                    "language_id",
                    "name"
                ]
            }
        }
    },
    "local039": {
        "query": "SELECT     category.name FROM     category INNER JOIN film_category USING (category_id) INNER JOIN film USING (film_id) INNER JOIN inventory USING (film_id) INNER JOIN rental USING (inventory_id) INNER JOIN customer USING (customer_id) INNER JOIN address USING (address_id) INNER JOIN city USING (city_id) WHERE     LOWER(city.city) LIKE 'a%' OR city.city LIKE '%-%' GROUP BY     category.name ORDER BY     SUM(CAST((julianday(rental.return_date) - julianday(rental.rental_date)) * 24 AS INTEGER)) DESC LIMIT     1;",
        "schema": {
            "public": {
                "category": [
                    "name",
                    "category_id"
                ],
                "film_category": [
                    "category_id",
                    "film_id"
                ],
                "film": [
                    "film_id"
                ],
                "inventory": [
                    "film_id",
                    "inventory_id"
                ],
                "rental": [
                    "inventory_id",
                    "rental_date",
                    "return_date",
                    "customer_id"
                ],
                "customer": [
                    "customer_id",
                    "address_id"
                ],
                "address": [
                    "address_id",
                    "city_id"
                ],
                "city": [
                    "city_id",
                    "city"
                ]
            }
        }
    },
    "local041": {
        "query": "WITH Borough_Health_Tree_Counts AS (     SELECT         t.health,         COUNT(*) AS tree_count     FROM trees t     WHERE t.boroname = 'Bronx' AND t.health IS NOT NULL AND t.health != ''     GROUP BY t.health ), Borough_Health_Total_Trees AS (     SELECT         COUNT(*) AS total_trees     FROM trees t     WHERE t.boroname = 'Bronx' )  SELECT     ROUND(         (             SELECT tree_count              FROM Borough_Health_Tree_Counts             WHERE health = 'Good'         ) * 100.0 /          (             SELECT total_trees              FROM Borough_Health_Total_Trees         ), 2     ) AS Percentage ;",
        "schema": {
            "public": {
                "trees": [
                    "health",
                    "boroname"
                ],
                "Borough_Health_Tree_Counts": [
                    "tree_count"
                ],
                "Borough_Health_Total_Trees": [
                    "total_trees"
                ]
            }
        }
    },
    "local053_1": {
        "query": "WITH top_industry AS (     SELECT i.industry     FROM industries AS i     INNER JOIN dates AS d         ON i.company_id = d.company_id     WHERE strftime('%Y', d.date_joined) IN ('2019', '2020', '2021')     GROUP BY i.industry     ORDER BY COUNT(*) DESC     LIMIT 1 ),  yearly_counts AS (     SELECT strftime('%Y', d.date_joined) AS year,            COUNT(*) AS num_unicorns     FROM industries AS i     INNER JOIN dates AS d         ON i.company_id = d.company_id     WHERE strftime('%Y', d.date_joined) IN ('2019', '2020', '2021')       AND i.industry = (SELECT industry FROM top_industry)     GROUP BY year )  SELECT ROUND(AVG(num_unicorns), 2) AS average_new_unicorns FROM yearly_counts;",
        "schema": {
            "public": {
                "industries": [
                    "industry",
                    "company_id"
                ],
                "dates": [
                    "company_id",
                    "date_joined"
                ],
                "top_industry": [
                    "industry"
                ],
                "yearly_counts": [
                    "year",
                    "num_unicorns"
                ]
            }
        }
    },
    "local054_2": {
        "query": "WITH ARTIST_SALES AS (     SELECT          ARTISTS.ARTISTID AS ARTIST_ID,          ARTISTS.NAME AS ARTIST_NAME,         SUM(INVOICE_ITEMS.UNITPRICE * INVOICE_ITEMS.QUANTITY) AS TOTAL_SALES     FROM          INVOICE_ITEMS     JOIN          TRACKS ON TRACKS.TRACKID = INVOICE_ITEMS.TRACKID     JOIN          ALBUMS ON ALBUMS.ALBUMID = TRACKS.ALBUMID     JOIN          ARTISTS ON ARTISTS.ARTISTID = ALBUMS.ARTISTID     GROUP BY          ARTISTS.ARTISTID, ARTISTS.NAME ), BEST_SELLING_ARTIST AS (     SELECT          ARTIST_ID,          ARTIST_NAME     FROM          ARTIST_SALES     ORDER BY          TOTAL_SALES DESC,         ARTIST_NAME ASC     LIMIT 1 ), LEAST_SELLING_ARTIST AS (     SELECT          ARTIST_ID,          ARTIST_NAME     FROM          ARTIST_SALES     ORDER BY          TOTAL_SALES ASC,         ARTIST_NAME ASC     LIMIT 1 ), CUSTOMER_SPENDING AS (     SELECT         CUSTOMERS.FIRSTNAME,         ARTISTS.NAME,         SUM(INVOICE_ITEMS.UNITPRICE * INVOICE_ITEMS.QUANTITY) AS AMOUNT_SPENT     FROM         INVOICES     JOIN         CUSTOMERS ON CUSTOMERS.CUSTOMERID = INVOICES.CUSTOMERID     JOIN         INVOICE_ITEMS ON INVOICE_ITEMS.INVOICEID = INVOICES.INVOICEID     JOIN         TRACKS ON TRACKS.TRACKID = INVOICE_ITEMS.TRACKID     JOIN         ALBUMS ON ALBUMS.ALBUMID = TRACKS.ALBUMID     JOIN         ARTISTS ON ARTISTS.ARTISTID = ALBUMS.ARTISTID     GROUP BY         CUSTOMERS.FIRSTNAME, ARTISTS.NAME ), AVERAGE_SPENDING AS (     SELECT          NAME,         AVG(AMOUNT_SPENT) AS AVERAGE_SPENT     FROM          CUSTOMER_SPENDING     WHERE          NAME IN (SELECT ARTIST_NAME FROM BEST_SELLING_ARTIST UNION SELECT ARTIST_NAME FROM LEAST_SELLING_ARTIST)     GROUP BY          NAME ) SELECT      ABS(         (SELECT AVERAGE_SPENT FROM AVERAGE_SPENDING WHERE NAME = (SELECT ARTIST_NAME FROM BEST_SELLING_ARTIST))         -         (SELECT AVERAGE_SPENT FROM AVERAGE_SPENDING WHERE NAME = (SELECT ARTIST_NAME FROM LEAST_SELLING_ARTIST))     ) AS DIFFERENCE;",
        "schema": {
            "public": {
                "INVOICE_ITEMS": [
                    "UNITPRICE",
                    "QUANTITY",
                    "TRACKID",
                    "INVOICEID"
                ],
                "TRACKS": [
                    "TRACKID",
                    "ALBUMID"
                ],
                "ALBUMS": [
                    "ALBUMID",
                    "ARTISTID"
                ],
                "ARTISTS": [
                    "ARTISTID",
                    "NAME"
                ],
                "INVOICES": [
                    "CUSTOMERID",
                    "INVOICEID"
                ],
                "CUSTOMERS": [
                    "CUSTOMERID",
                    "FIRSTNAME"
                ],
                "ARTIST_SALES": [
                    "ARTIST_ID",
                    "ARTIST_NAME",
                    "TOTAL_SALES"
                ],
                "BEST_SELLING_ARTIST": [
                    "ARTIST_ID",
                    "ARTIST_NAME"
                ],
                "LEAST_SELLING_ARTIST": [
                    "ARTIST_ID",
                    "ARTIST_NAME"
                ],
                "CUSTOMER_SPENDING": [
                    "FIRSTNAME",
                    "NAME",
                    "AMOUNT_SPENT"
                ],
                "AVERAGE_SPENDING": [
                    "NAME",
                    "AVERAGE_SPENT"
                ]
            }
        }
    },
    "local059": {
        "query": "WITH RankedProducts AS (     SELECT         dp.division,         fsm.product_code,         dp.product,         SUM(fsm.sold_quantity) AS total_sold_quantity,         ROW_NUMBER() OVER(PARTITION BY dp.division ORDER BY SUM(fsm.sold_quantity) DESC) AS rank_order     FROM         fact_sales_monthly fsm     JOIN         dim_product dp ON fsm.product_code = dp.product_code     WHERE         strftime('%Y', fsm.date) = '2021'     GROUP BY         dp.division, fsm.product_code, dp.product ), Top3Products AS (     SELECT         division,         product_code,         product,         total_sold_quantity,         rank_order     FROM         RankedProducts     WHERE         rank_order <= 3 ) SELECT     division,     AVG(total_sold_quantity) AS avg_sold_quantity FROM     Top3Products GROUP BY     division ORDER BY     avg_sold_quantity DESC;",
        "schema": {
            "public": {
                "fact_sales_monthly": [
                    "date",
                    "product_code",
                    "sold_quantity"
                ],
                "dim_product": [
                    "division",
                    "product_code",
                    "product"
                ],
                "RankedProducts": [
                    "division",
                    "product_code",
                    "product",
                    "total_sold_quantity",
                    "rank_order"
                ],
                "Top3Products": [
                    "division",
                    "product_code",
                    "product",
                    "total_sold_quantity",
                    "rank_order"
                ]
            }
        }
    },
    "local062_2": {
        "query": "-- profit by cust, prod, day, channel, promo WITH cust_prod_mon_profit AS (    SELECT s.cust_id,            s.prod_id,            s.time_id,           s.channel_id,            s.promo_id,           s.quantity_sold * (c.unit_price - c.unit_cost) AS profit,           s.amount_sold AS dol_sold,            c.unit_price AS price,            c.unit_cost AS cost    FROM sales s    JOIN costs c ON s.prod_id = c.prod_id                AND s.time_id = c.time_id                AND s.promo_id = c.promo_id                AND s.channel_id = c.channel_id    WHERE s.cust_id IN (          SELECT cust_id FROM customers          WHERE country_id = 52770    )    AND s.time_id IN (          SELECT time_id FROM times          WHERE calendar_month_desc = '2021-12'    ) ), cust_mon_profit AS (    SELECT cust_id,            SUM(profit) AS cust_profit    FROM cust_prod_mon_profit    GROUP BY cust_id ), -- Calculate min and max profit min_max_p AS (    SELECT MIN(cust_profit) AS min_p,            MAX(cust_profit) AS max_p    FROM cust_mon_profit ), -- Creating a simplified bucket system due to lack of `width_bucket` function cust_bucket AS (    SELECT cust_id, cust_profit,           CASE              WHEN cust_profit <= min_p + (max_p - min_p) / 10 THEN 1              WHEN cust_profit <= min_p + 2 * (max_p - min_p) / 10 THEN 2              WHEN cust_profit <= min_p + 3 * (max_p - min_p) / 10 THEN 3              WHEN cust_profit <= min_p + 4 * (max_p - min_p) / 10 THEN 4              WHEN cust_profit <= min_p + 5 * (max_p - min_p) / 10 THEN 5              WHEN cust_profit <= min_p + 6 * (max_p - min_p) / 10 THEN 6              WHEN cust_profit <= min_p + 7 * (max_p - min_p) / 10 THEN 7              WHEN cust_profit <= min_p + 8 * (max_p - min_p) / 10 THEN 8              WHEN cust_profit <= min_p + 9 * (max_p - min_p) / 10 THEN 9              ELSE 10           END AS bucket    FROM cust_mon_profit, min_max_p ), -- Calculating the minimum profit in each bucket bucket_min_profits AS (    SELECT bucket,            MIN(cust_profit) AS min_profit    FROM cust_bucket    GROUP BY bucket ) -- Main query block to calculate the average of the minimum profits SELECT AVG(min_profit) AS average_min_profit FROM bucket_min_profits;",
        "schema": {
            "public": {
                "sales": [
                    "cust_id",
                    "prod_id",
                    "time_id",
                    "channel_id",
                    "promo_id",
                    "quantity_sold",
                    "amount_sold"
                ],
                "costs": [
                    "prod_id",
                    "time_id",
                    "promo_id",
                    "channel_id",
                    "unit_price",
                    "unit_cost"
                ],
                "customers": [
                    "cust_id",
                    "country_id"
                ],
                "times": [
                    "time_id",
                    "calendar_month_desc"
                ],
                "cust_prod_mon_profit": [
                    "cust_id",
                    "prod_id",
                    "time_id",
                    "channel_id",
                    "promo_id",
                    "profit",
                    "dol_sold",
                    "price",
                    "cost"
                ],
                "cust_mon_profit": [
                    "cust_id",
                    "cust_profit"
                ],
                "min_max_p": [
                    "min_p",
                    "max_p"
                ],
                "cust_bucket": [
                    "cust_id",
                    "cust_profit",
                    "bucket"
                ],
                "bucket_min_profits": [
                    "bucket",
                    "min_profit"
                ]
            }
        }
    },
    "local062_3": {
        "query": "-- profit by cust, prod, day, channel, promo WITH cust_prod_mon_profit AS (    SELECT s.cust_id,            s.prod_id,            s.time_id,           s.channel_id,            s.promo_id,           s.quantity_sold * (c.unit_price - c.unit_cost) AS profit,           s.amount_sold AS dol_sold,            c.unit_price AS price,            c.unit_cost AS cost    FROM sales s    JOIN costs c ON s.prod_id = c.prod_id                AND s.time_id = c.time_id                AND s.promo_id = c.promo_id                AND s.channel_id = c.channel_id    WHERE s.cust_id IN (          SELECT cust_id FROM customers          WHERE country_id = 52770    )    AND s.time_id IN (          SELECT time_id FROM times          WHERE calendar_month_desc = '2021-12'    ) ), cust_mon_profit AS (    SELECT cust_id,            SUM(profit) AS cust_profit    FROM cust_prod_mon_profit    GROUP BY cust_id ), -- Calculate min and max profit min_max_p AS (    SELECT MIN(cust_profit) AS min_p,            MAX(cust_profit) AS max_p    FROM cust_mon_profit ), -- Creating a simplified bucket system due to lack of `width_bucket` function cust_bucket AS (    SELECT cust_id, cust_profit,           CASE              WHEN cust_profit <= min_p + (max_p - min_p) / 10 THEN 1              WHEN cust_profit <= min_p + 2 * (max_p - min_p) / 10 THEN 2              WHEN cust_profit <= min_p + 3 * (max_p - min_p) / 10 THEN 3              WHEN cust_profit <= min_p + 4 * (max_p - min_p) / 10 THEN 4              WHEN cust_profit <= min_p + 5 * (max_p - min_p) / 10 THEN 5              WHEN cust_profit <= min_p + 6 * (max_p - min_p) / 10 THEN 6              WHEN cust_profit <= min_p + 7 * (max_p - min_p) / 10 THEN 7              WHEN cust_profit <= min_p + 8 * (max_p - min_p) / 10 THEN 8              WHEN cust_profit <= min_p + 9 * (max_p - min_p) / 10 THEN 9              ELSE 10           END AS bucket    FROM cust_mon_profit, min_max_p ), -- Calculating the maximum profit in each bucket bucket_max_profits AS (    SELECT bucket,            MAX(cust_profit) AS max_profit    FROM cust_bucket    GROUP BY bucket ) -- Main query block to calculate the average of the maximum profits SELECT AVG(max_profit) AS average_max_profit FROM bucket_max_profits;",
        "schema": {
            "public": {
                "sales": [
                    "cust_id",
                    "prod_id",
                    "time_id",
                    "channel_id",
                    "promo_id",
                    "quantity_sold",
                    "amount_sold"
                ],
                "costs": [
                    "prod_id",
                    "time_id",
                    "promo_id",
                    "channel_id",
                    "unit_price",
                    "unit_cost"
                ],
                "customers": [
                    "cust_id",
                    "country_id"
                ],
                "times": [
                    "time_id",
                    "calendar_month_desc"
                ],
                "cust_prod_mon_profit": [
                    "cust_id",
                    "prod_id",
                    "time_id",
                    "channel_id",
                    "promo_id",
                    "profit",
                    "dol_sold",
                    "price",
                    "cost"
                ],
                "cust_mon_profit": [
                    "cust_id",
                    "cust_profit"
                ],
                "min_max_p": [
                    "min_p",
                    "max_p"
                ],
                "cust_bucket": [
                    "cust_id",
                    "cust_profit",
                    "bucket"
                ],
                "bucket_max_profits": [
                    "bucket",
                    "max_profit"
                ]
            }
        }
    },
    "local062_4": {
        "query": "-- profit by cust, prod, day, channel, promo WITH cust_prod_mon_profit AS (    SELECT s.cust_id,            s.prod_id,            s.time_id,           s.channel_id,            s.promo_id,           s.quantity_sold * (c.unit_price - c.unit_cost) AS profit,           s.amount_sold AS dol_sold,            c.unit_price AS price,            c.unit_cost AS cost    FROM sales s    JOIN costs c ON s.prod_id = c.prod_id                AND s.time_id = c.time_id                AND s.promo_id = c.promo_id                AND s.channel_id = c.channel_id    WHERE s.cust_id IN (          SELECT cust_id FROM customers          WHERE country_id = 52770    )    AND s.time_id IN (          SELECT time_id FROM times          WHERE calendar_month_desc = '2021-12'    ) ), cust_mon_profit AS (    SELECT cust_id,            SUM(profit) AS cust_profit    FROM cust_prod_mon_profit    GROUP BY cust_id ), -- Calculate min and max profit min_max_p AS (    SELECT MIN(cust_profit) AS min_p,            MAX(cust_profit) AS max_p    FROM cust_mon_profit ), -- Creating a simplified bucket system due to lack of `width_bucket` function cust_bucket AS (    SELECT cust_id, cust_profit,           CASE              WHEN cust_profit <= min_p + (max_p - min_p) / 10 THEN 1              WHEN cust_profit <= min_p + 2 * (max_p - min_p) / 10 THEN 2              WHEN cust_profit <= min_p + 3 * (max_p - min_p) / 10 THEN 3              WHEN cust_profit <= min_p + 4 * (max_p - min_p) / 10 THEN 4              WHEN cust_profit <= min_p + 5 * (max_p - min_p) / 10 THEN 5              WHEN cust_profit <= min_p + 6 * (max_p - min_p) / 10 THEN 6              WHEN cust_profit <= min_p + 7 * (max_p - min_p) / 10 THEN 7              WHEN cust_profit <= min_p + 8 * (max_p - min_p) / 10 THEN 8              WHEN cust_profit <= min_p + 9 * (max_p - min_p) / 10 THEN 9              ELSE 10           END AS bucket    FROM cust_mon_profit, min_max_p ), -- Aggregated data needed for each bucket histo_data AS (    SELECT bucket,           COUNT(*) AS histo_count    FROM cust_bucket    GROUP BY bucket ), -- Main query block to calculate the difference between the largest and smallest number of customers min_max_bucket_customers AS (    SELECT MIN(histo_count) AS min_customers,           MAX(histo_count) AS max_customers    FROM histo_data ) SELECT max_customers - min_customers AS difference FROM min_max_bucket_customers;",
        "schema": {
            "public": {
                "sales": [
                    "cust_id",
                    "prod_id",
                    "time_id",
                    "channel_id",
                    "promo_id",
                    "quantity_sold",
                    "amount_sold"
                ],
                "costs": [
                    "prod_id",
                    "time_id",
                    "promo_id",
                    "channel_id",
                    "unit_price",
                    "unit_cost"
                ],
                "customers": [
                    "cust_id",
                    "country_id"
                ],
                "times": [
                    "time_id",
                    "calendar_month_desc"
                ],
                "cust_prod_mon_profit": [
                    "cust_id",
                    "prod_id",
                    "time_id",
                    "channel_id",
                    "promo_id",
                    "profit",
                    "dol_sold",
                    "price",
                    "cost"
                ],
                "cust_mon_profit": [
                    "cust_id",
                    "cust_profit"
                ],
                "min_max_p": [
                    "min_p",
                    "max_p"
                ],
                "cust_bucket": [
                    "cust_id",
                    "cust_profit",
                    "bucket"
                ],
                "histo_data": [
                    "bucket",
                    "histo_count"
                ],
                "min_max_bucket_customers": [
                    "min_customers",
                    "max_customers"
                ]
            }
        }
    },
    "local070_3_3": {
        "query": "WITH get_dates AS (     SELECT         insert_date,         country_code_2     FROM (         SELECT             insert_date,             country_code_2,             ROW_NUMBER() OVER (PARTITION BY insert_date, country_code_2 ORDER BY insert_date) AS row_num         FROM             cities         WHERE             insert_date BETWEEN '2022-06-01' AND '2022-06-30'     )     WHERE row_num = 1 ), get_diff AS (     SELECT         country_code_2,         insert_date,         CAST(strftime('%d', insert_date) AS INTEGER) - ROW_NUMBER() OVER (PARTITION BY country_code_2 ORDER BY insert_date) AS diff     FROM (         SELECT             country_code_2,             insert_date,             ROW_NUMBER() OVER (PARTITION BY country_code_2 ORDER BY insert_date) AS row_num         FROM             get_dates     ) ), get_diff_count AS (     SELECT         country_code_2,         insert_date,         COUNT(*) OVER (PARTITION BY country_code_2, diff) AS diff_count     FROM         get_diff ), get_rank AS (     SELECT         country_code_2,         DENSE_RANK() OVER (PARTITION BY country_code_2 ORDER BY diff_count DESC) AS rnk,         insert_date     FROM         get_diff_count ), count_rank AS( \tSELECT \t\tcountry_code_2, \t\tCOUNT(rnk) AS diff_count \tFROM \t\tget_rank \tGROUP BY  \t\tcountry_code_2, \t\trnk ) SELECT     country_code_2 AS country FROM     count_rank WHERE \tdiff_count = ( \t\tSELECT             MAX(diff_count)         FROM             count_rank \t)",
        "schema": {
            "public": {
                "cities": [
                    "insert_date",
                    "country_code_2"
                ],
                "get_dates": [
                    "insert_date",
                    "country_code_2"
                ],
                "get_diff": [
                    "country_code_2",
                    "insert_date"
                ],
                "get_diff_count": [
                    "country_code_2",
                    "insert_date"
                ],
                "get_rank": [
                    "country_code_2",
                    "insert_date"
                ],
                "count_rank": [
                    "country_code_2",
                    "diff_count"
                ]
            }
        }
    },
    "local070_3_4": {
        "query": "WITH get_dates AS (     SELECT         insert_date,         country_code_2     FROM (         SELECT             insert_date,             country_code_2,             ROW_NUMBER() OVER (PARTITION BY insert_date, country_code_2 ORDER BY insert_date) AS row_num         FROM             cities         WHERE             insert_date BETWEEN '2022-06-01' AND '2022-06-30'     )     WHERE row_num = 1 ), get_diff AS (     SELECT         country_code_2,         insert_date,         CAST(strftime('%d', insert_date) AS INTEGER) - ROW_NUMBER() OVER (PARTITION BY country_code_2 ORDER BY insert_date) AS diff     FROM (         SELECT             country_code_2,             insert_date,             ROW_NUMBER() OVER (PARTITION BY country_code_2 ORDER BY insert_date) AS row_num         FROM             get_dates     ) ), get_diff_count AS (     SELECT         country_code_2,         insert_date,         COUNT(*) OVER (PARTITION BY country_code_2, diff) AS diff_count     FROM         get_diff ), get_rank AS (     SELECT         country_code_2,         DENSE_RANK() OVER (PARTITION BY country_code_2 ORDER BY diff_count DESC) AS rnk,         insert_date     FROM         get_diff_count ), count_rank AS( \tSELECT \t\tcountry_code_2, \t\tCOUNT(rnk) AS diff_count \tFROM \t\tget_rank \tGROUP BY  \t\tcountry_code_2, \t\trnk \tHAVING diff_count > 10 ) SELECT     COUNT(DISTINCT country_code_2) AS num_countries FROM     count_rank;",
        "schema": {
            "public": {
                "cities": [
                    "insert_date",
                    "country_code_2"
                ],
                "get_dates": [
                    "insert_date",
                    "country_code_2"
                ],
                "get_diff": [
                    "country_code_2",
                    "insert_date"
                ],
                "get_diff_count": [
                    "country_code_2",
                    "insert_date"
                ],
                "get_rank": [
                    "country_code_2",
                    "insert_date"
                ],
                "count_rank": [
                    "country_code_2"
                ]
            }
        }
    },
    "local074": {
        "query": "WITH RECURSIVE generate_series AS (     SELECT 0 AS value     UNION ALL     SELECT value + 1     FROM generate_series     WHERE value < 3 ), closing_balance AS (     SELECT         customer_id,         strftime('%Y-%m', DATE(txn_date, 'start of month')) AS txn_month,         SUM(             CASE                 WHEN txn_type = 'deposit' THEN txn_amount                 ELSE -txn_amount             END         ) AS transaction_amount     FROM         customer_transactions     GROUP BY         customer_id,         txn_month     ORDER BY         customer_id ), generate_months_cte AS (     SELECT DISTINCT         customer_id,         strftime('%Y-%m', DATE('2020-01-01', '+' || value || ' month')) AS generated_month     FROM         customer_transactions, generate_series ) SELECT      t1.customer_id,     t1.generated_month,     COALESCE(t2.transaction_amount, 0) AS balance_activity,     SUM(COALESCE(t2.transaction_amount, 0)) OVER (         PARTITION BY t1.customer_id         ORDER BY t1.generated_month     ) AS month_end_balance FROM     generate_months_cte AS t1 LEFT JOIN      closing_balance AS t2 ON     t1.generated_month = t2.txn_month AND     t1.customer_id = t2.customer_id;",
        "schema": {
            "public": {
                "generate_series": [
                    "value"
                ],
                "customer_transactions": [
                    "customer_id",
                    "txn_date",
                    "txn_amount",
                    "txn_type"
                ],
                "closing_balance": [
                    "customer_id",
                    "txn_month",
                    "transaction_amount"
                ],
                "generate_months_cte": [
                    "customer_id",
                    "generated_month"
                ]
            }
        }
    },
    "local074_4": {
        "query": "WITH RECURSIVE generate_series AS (     SELECT 0 AS value     UNION ALL     SELECT value + 1     FROM generate_series     WHERE value < 3 ), generate_months_cte AS (     SELECT DISTINCT         customer_id,         strftime('%Y-%m', DATE('2020-01-01', '+' || value || ' month')) AS generated_month     FROM         customer_transactions, generate_series     WHERE         strftime('%Y', DATE('2020-01-01', '+' || value || ' month')) = '2020' ), closing_balance AS (     SELECT         customer_id,         strftime('%Y-%m', DATE(txn_date, 'start of month')) AS txn_month,         SUM(             CASE                 WHEN txn_type = 'deposit' THEN txn_amount                 ELSE -txn_amount             END         ) AS transaction_amount     FROM         customer_transactions     WHERE         strftime('%Y', txn_date) = '2020'     GROUP BY         customer_id,         txn_month ), final_balance AS (     SELECT          t1.customer_id,         t1.generated_month,         COALESCE(SUM(t2.transaction_amount), 0) AS month_end_balance     FROM         generate_months_cte AS t1     LEFT JOIN          closing_balance AS t2     ON         t1.generated_month = t2.txn_month         AND t1.customer_id = t2.customer_id     GROUP BY         t1.customer_id,         t1.generated_month ), positive_balance_counts AS (     SELECT         generated_month,         COUNT(DISTINCT customer_id) AS positive_balance_count     FROM         final_balance     WHERE         month_end_balance > 0     GROUP BY         generated_month ), most_positive_month AS (     SELECT         generated_month     FROM         positive_balance_counts     ORDER BY         positive_balance_count DESC     LIMIT 1 ), least_positive_month AS (     SELECT         generated_month     FROM         positive_balance_counts     ORDER BY         positive_balance_count ASC     LIMIT 1 ), average_balance AS (     SELECT         'most_positive' AS month_type,         AVG(month_end_balance) AS avg_balance     FROM         final_balance     WHERE         generated_month = (SELECT generated_month FROM most_positive_month)     UNION ALL     SELECT         'least_positive' AS month_type,         AVG(month_end_balance) AS avg_balance     FROM         final_balance     WHERE         generated_month = (SELECT generated_month FROM least_positive_month) ) SELECT     (SELECT avg_balance FROM average_balance WHERE month_type = 'most_positive') -     (SELECT avg_balance FROM average_balance WHERE month_type = 'least_positive') AS balance_diff;",
        "schema": {
            "public": {
                "customer_transactions": [
                    "customer_id",
                    "txn_date",
                    "txn_amount",
                    "txn_type"
                ],
                "generate_series": [
                    "value"
                ],
                "generate_months_cte": [
                    "customer_id",
                    "generated_month"
                ],
                "closing_balance": [
                    "customer_id",
                    "txn_month",
                    "transaction_amount"
                ],
                "final_balance": [
                    "customer_id",
                    "generated_month",
                    "month_end_balance"
                ],
                "positive_balance_counts": [
                    "generated_month",
                    "positive_balance_count"
                ],
                "most_positive_month": [
                    "generated_month"
                ],
                "least_positive_month": [
                    "generated_month"
                ],
                "average_balance": [
                    "month_type",
                    "avg_balance"
                ]
            }
        }
    },
    "local298": {
        "query": "WITH customer_balance AS (     SELECT *,            SUM(txn_amount) OVER (PARTITION BY customer_id ORDER BY month_ ASC) AS balance     FROM (         SELECT customer_id,                 strftime('%Y-%m-01', txn_date) AS month_,                 SUM(txn_group) AS txn_amount          FROM (             SELECT *,                    CASE                       WHEN txn_type = 'deposit' THEN txn_amount                      ELSE -1 * txn_amount                     END AS txn_group             FROM Customer_Transactions             ORDER BY customer_id, txn_date         ) AS update_txn_amount         GROUP BY customer_id, strftime('%Y-%m-01', txn_date)     ) AS monthly_totals ), growth_rates AS (     SELECT customer_id,             month_,             balance,             previous_month_balance,            CASE               WHEN previous_month_balance < 0 THEN 0               ELSE previous_month_balance             END AS data_storage,            ROW_NUMBER() OVER (PARTITION BY customer_id ORDER BY month_) AS rn     FROM (         SELECT *,                 LAG(balance) OVER (PARTITION BY customer_id ORDER BY month_) AS previous_month_balance         FROM customer_balance     ) AS add_previous_month_balance ) SELECT month_,         SUM(data_storage) AS total_data_storage FROM growth_rates WHERE rn > 1 GROUP BY month_ ORDER BY month_;",
        "schema": {
            "public": {
                "Customer_Transactions": [
                    "customer_id",
                    "txn_date",
                    "txn_amount",
                    "txn_type",
                    "txn_group"
                ],
                "customer_balance": [
                    "customer_id",
                    "month_",
                    "txn_amount",
                    "balance"
                ],
                "growth_rates": [
                    "customer_id",
                    "month_",
                    "balance",
                    "previous_month_balance",
                    "data_storage",
                    "rn"
                ]
            }
        }
    },
    "local299": {
        "query": "WITH RECURSIVE customer_date_series AS (     SELECT customer_id, MIN(txn_date) AS date_series, MAX(txn_date) AS last_date     FROM customer_transactions     GROUP BY customer_id     UNION ALL     SELECT customer_id, date(date_series, '+1 day'), last_date     FROM customer_date_series     WHERE date(date_series, '+1 day') <= last_date ), customer_txn AS (     SELECT *,            CASE WHEN txn_type = 'deposit' THEN txn_amount                 ELSE -1 * txn_amount END AS txn_group     FROM customer_transactions ), customer_balance AS (     SELECT s.customer_id, s.date_series, COALESCE(b.txn_group, 0) AS txn_group,            SUM(COALESCE(b.txn_group, 0)) OVER (PARTITION BY s.customer_id ORDER BY s.date_series) AS balance     FROM customer_date_series s     LEFT JOIN customer_txn b ON s.customer_id = b.customer_id AND s.date_series = b.txn_date     ORDER BY s.customer_id, s.date_series ), customer_data AS (     SELECT customer_id, date_series,            CASE WHEN txn_row < 30 THEN NULL                 WHEN avg_last_30 < 0 THEN 0                 ELSE avg_last_30 END AS data_storage     FROM (         SELECT *,                AVG(balance) OVER (PARTITION BY customer_id ORDER BY date_series ROWS BETWEEN 30 PRECEDING AND CURRENT ROW) AS avg_last_30,                ROW_NUMBER() OVER (PARTITION BY customer_id ORDER BY date_series) AS txn_row         FROM customer_balance     ) AS tmp ), monthly_data AS (     SELECT customer_id,            strftime('%Y-%m', date_series) AS month,            MAX(data_storage) AS data_allocation,            ROW_NUMBER() OVER (PARTITION BY customer_id ORDER BY strftime('%Y-%m', date_series)) AS month_row     FROM customer_data     GROUP BY customer_id, month ) SELECT month, ROUND(SUM(data_allocation), 1) AS total_allocation FROM monthly_data WHERE month_row > 1 GROUP BY month ORDER BY month;",
        "schema": {
            "public": {
                "customer_transactions": [
                    "customer_id",
                    "txn_date",
                    "txn_amount",
                    "txn_type",
                    "txn_group"
                ],
                "customer_date_series": [
                    "customer_id",
                    "date_series",
                    "last_date"
                ],
                "customer_txn": [
                    "txn_amount",
                    "txn_type",
                    "txn_group"
                ],
                "customer_balance": [
                    "customer_id",
                    "date_series",
                    "txn_group",
                    "balance"
                ],
                "customer_data": [
                    "customer_id",
                    "date_series",
                    "data_storage"
                ],
                "monthly_data": [
                    "customer_id",
                    "month",
                    "data_allocation",
                    "month_row"
                ]
            }
        }
    },
    "local300": {
        "query": "WITH RECURSIVE customer_date_series AS (     SELECT customer_id, MIN(txn_date) AS date_series, MAX(txn_date) AS last_date     FROM customer_transactions     GROUP BY customer_id     UNION ALL     SELECT customer_id, date(date_series, '+1 day') AS date_series, last_date     FROM customer_date_series     WHERE date(date_series, '+1 day') <= last_date ), customer_txn AS (     SELECT *,            CASE WHEN txn_type = 'deposit' THEN txn_amount                 ELSE -1 * txn_amount END AS txn_group     FROM customer_transactions ), customer_balance AS (     SELECT s.customer_id, s.date_series, COALESCE(b.txn_group, 0) AS txn_group,            SUM(COALESCE(b.txn_group, 0)) OVER (PARTITION BY s.customer_id ORDER BY s.date_series) AS balance     FROM customer_date_series s     LEFT JOIN customer_txn b ON s.customer_id = b.customer_id AND s.date_series = b.txn_date     ORDER BY s.customer_id, s.date_series ), customer_data AS (     SELECT customer_id, date_series,            CASE WHEN balance < 0 THEN 0                 ELSE balance END AS data_storage     FROM customer_balance ) SELECT month, ROUND(SUM(data_allocation), 1) AS total_allocation FROM (     SELECT customer_id,            strftime('%Y-%m', date_series) AS month,            MAX(data_storage) AS data_allocation     FROM customer_data     GROUP BY customer_id, strftime('%Y-%m', date_series) ) AS tmp GROUP BY month ORDER BY month;",
        "schema": {
            "public": {
                "customer_transactions": [
                    "customer_id",
                    "txn_date",
                    "txn_amount",
                    "txn_type"
                ],
                "customer_date_series": [
                    "customer_id",
                    "date_series",
                    "last_date"
                ],
                "customer_txn": [
                    "txn_amount",
                    "txn_type",
                    "txn_group"
                ],
                "customer_balance": [
                    "customer_id",
                    "date_series",
                    "txn_group",
                    "balance"
                ],
                "customer_data": [
                    "customer_id",
                    "date_series",
                    "balance",
                    "data_storage"
                ]
            }
        }
    },
    "local075_2": {
        "query": "WITH product_viewed AS (     SELECT         t1.page_id,         SUM(CASE WHEN event_type = 1 THEN 1 ELSE 0 END) AS n_page_views,         SUM(CASE WHEN event_type = 2 THEN 1 ELSE 0 END) AS n_added_to_cart     FROM         page_hierarchy AS t1     JOIN         events AS t2     ON         t1.page_id = t2.page_id     WHERE         t1.product_id IS NOT NULL     GROUP BY         t1.page_id ), product_purchased AS (     SELECT         t2.page_id,         SUM(CASE WHEN event_type = 2 THEN 1 ELSE 0 END) AS purchased_from_cart     FROM         page_hierarchy AS t1     JOIN         events AS t2     ON         t1.page_id = t2.page_id     WHERE         t1.product_id IS NOT NULL         AND EXISTS (             SELECT                 visit_id             FROM                 events             WHERE                 event_type = 3                 AND t2.visit_id = visit_id         )         AND t1.page_id NOT IN (1, 2, 12, 13)     GROUP BY         t2.page_id ), product_abandoned AS (     SELECT         t2.page_id,         SUM(CASE WHEN event_type = 2 THEN 1 ELSE 0 END) AS abandoned_in_cart     FROM         page_hierarchy AS t1     JOIN         events AS t2     ON         t1.page_id = t2.page_id     WHERE         t1.product_id IS NOT NULL         AND NOT EXISTS (             SELECT                 visit_id             FROM                 events             WHERE                 event_type = 3                 AND t2.visit_id = visit_id         )         AND t1.page_id NOT IN (1, 2, 12, 13)     GROUP BY         t2.page_id ) SELECT     t1.page_id,     t1.page_name,     t2.n_page_views AS 'number of product being viewed',     t2.n_added_to_cart AS 'number added to the cart',     t4.abandoned_in_cart AS 'without being purchased in cart',     t3.purchased_from_cart AS 'count of actual purchases' FROM     page_hierarchy AS t1 JOIN     product_viewed AS t2  ON     t2.page_id = t1.page_id JOIN     product_purchased AS t3  ON      t3.page_id = t1.page_id JOIN     product_abandoned AS t4  ON      t4.page_id = t1.page_id;",
        "schema": {
            "public": {
                "page_hierarchy": [
                    "page_id",
                    "product_id",
                    "page_name"
                ],
                "events": [
                    "page_id",
                    "event_type",
                    "visit_id"
                ],
                "product_viewed": [
                    "page_id",
                    "n_page_views",
                    "n_added_to_cart"
                ],
                "product_purchased": [
                    "page_id",
                    "purchased_from_cart"
                ],
                "product_abandoned": [
                    "page_id",
                    "abandoned_in_cart"
                ]
            }
        }
    },
    "local077": {
        "query": "WITH get_top_avg_composition AS (     SELECT         t1.month_year,         t1.interest_id,         t2.interest_name,         ROUND((t1.composition / t1.index_value), 2) AS avg_composition,         RANK() OVER (             PARTITION BY month_year              ORDER BY ROUND((t1.composition / t1.index_value), 2) DESC         ) AS rnk     FROM         interest_metrics AS t1     JOIN         interest_map AS t2     ON          t2.id = t1.interest_id     ORDER BY         month_year, avg_composition DESC ), get_moving_avg AS (     SELECT         month_year,         interest_name,         avg_composition AS max_index_composition,         ROUND(AVG(avg_composition) OVER (              ORDER BY substr(month_year, 4, 4) || '-' || substr(month_year, 1, 2)             ROWS BETWEEN 2 PRECEDING AND CURRENT ROW         ), 2) AS \"3_month_moving_avg\"     FROM         get_top_avg_composition     WHERE         rnk = 1 ), get_lag_avg AS (     SELECT         *,         LAG(interest_name, 1) OVER (             ORDER BY substr(month_year, 4, 4) || '-' || substr(month_year, 1, 2)         ) AS interest_1_name,         LAG(interest_name, 2) OVER (             ORDER BY substr(month_year, 4, 4) || '-' || substr(month_year, 1, 2)         ) AS interest_2_name,         LAG(max_index_composition, 1) OVER (             ORDER BY substr(month_year, 4, 4) || '-' || substr(month_year, 1, 2)         ) AS interest_1_avg,         LAG(max_index_composition, 2) OVER (             ORDER BY substr(month_year, 4, 4) || '-' || substr(month_year, 1, 2)         ) AS interest_2_avg     FROM          get_moving_avg ) SELECT     month_year,     interest_name,     max_index_composition,     \"3_month_moving_avg\",     interest_1_avg AS \"1_month_ago\",     interest_1_name AS \"1_month_ago_interest_name\",     interest_2_avg AS \"2_month_ago\",     interest_2_name AS \"2_month_ago_interest_name\" FROM      get_lag_avg WHERE     substr(month_year, 4, 4) || '-' || substr(month_year, 1, 2) BETWEEN '2018-09' AND '2019-08';",
        "schema": {
            "public": {
                "interest_metrics": [
                    "month_year",
                    "interest_id",
                    "composition",
                    "index_value"
                ],
                "interest_map": [
                    "id",
                    "interest_name"
                ],
                "get_top_avg_composition": [
                    "month_year",
                    "interest_id",
                    "interest_name",
                    "avg_composition",
                    "rnk"
                ],
                "get_moving_avg": [
                    "month_year",
                    "interest_name",
                    "max_index_composition",
                    "3_month_moving_avg"
                ],
                "get_lag_avg": [
                    "month_year",
                    "interest_name",
                    "max_index_composition",
                    "3_month_moving_avg",
                    "interest_1_name",
                    "interest_2_name",
                    "interest_1_avg",
                    "interest_2_avg"
                ]
            }
        }
    },
    "local077_2": {
        "query": "WITH get_interest_rank AS (     SELECT         t1.month_year,         t2.interest_name,         t1.composition,         RANK() OVER (             PARTITION BY t2.interest_name             ORDER BY t1.composition DESC         ) AS interest_rank     FROM          interest_metrics AS t1     JOIN          interest_map AS t2     ON          t1.interest_id = t2.id     WHERE          t1.month_year IS NOT NULL ), get_top_10 AS (     SELECT         month_year,         interest_name,         composition     FROM          get_interest_rank     WHERE          interest_rank = 1     ORDER BY          composition DESC     LIMIT 10 ), get_bottom_10 AS (     SELECT         month_year,         interest_name,         composition     FROM          get_interest_rank     WHERE          interest_rank = 1     ORDER BY          composition ASC     LIMIT 10 ) SELECT *  FROM      get_top_10 UNION SELECT *  FROM      get_bottom_10 ORDER BY      composition DESC;",
        "schema": {
            "public": {
                "interest_metrics": [
                    "month_year",
                    "interest_id",
                    "composition"
                ],
                "interest_map": [
                    "id",
                    "interest_name"
                ],
                "get_interest_rank": [
                    "month_year",
                    "interest_name",
                    "composition",
                    "interest_rank"
                ],
                "get_top_10": [
                    "month_year",
                    "interest_name",
                    "composition"
                ],
                "get_bottom_10": [
                    "month_year",
                    "interest_name",
                    "composition"
                ]
            }
        }
    },
    "local081": {
        "query": "WITH orders_1998 AS (     SELECT         o.customerid,         COALESCE(SUM(od.unitprice * od.quantity), 0) AS total     FROM         orders o     INNER JOIN         order_details od ON o.orderid = od.orderid     WHERE         CAST(STRFTIME('%Y', o.orderdate) AS INTEGER) = 1998     GROUP BY         o.customerid ), customer_groups AS (     SELECT         cgt.groupname AS `group`     FROM         orders_1998 o     INNER JOIN         customergroupthreshold cgt ON o.total BETWEEN cgt.rangebottom AND cgt.rangetop ), groups_count AS (     SELECT         cg.`group`,         COUNT(cg.`group`) AS group_total     FROM         customer_groups cg     GROUP BY         cg.`group` ) SELECT     gc.`group`,     gc.group_total AS total_customer,     ROUND((100.0 * gc.group_total / (SELECT SUM(group_total) FROM groups_count)), 2) || '%' AS percentage FROM     groups_count gc ORDER BY     gc.group_total DESC;",
        "schema": {
            "public": {
                "orders": [
                    "customerid",
                    "orderid",
                    "orderdate"
                ],
                "order_details": [
                    "orderid",
                    "unitprice",
                    "quantity"
                ],
                "customergroupthreshold": [
                    "groupname",
                    "rangebottom",
                    "rangetop"
                ],
                "orders_1998": [
                    "customerid",
                    "total"
                ],
                "customer_groups": [
                    "group"
                ],
                "groups_count": [
                    "group",
                    "group_total"
                ]
            }
        }
    },
    "local084": {
        "query": "WITH late_orders AS (     SELECT         employeeid,         COUNT(employeeid) AS total     FROM         orders     WHERE         requireddate <= shippeddate --late     GROUP BY         employeeid ),  orders_summary AS (     SELECT         employeeid,         COUNT(employeeid) AS total     FROM         orders     GROUP BY         employeeid ) SELECT     os.employeeid FROM     orders_summary os INNER JOIN     employees e ON os.employeeid = e.employeeid LEFT JOIN     late_orders lo ON os.employeeid = lo.employeeid ORDER BY     COALESCE(CAST(lo.total AS REAL) / os.total, 0) DESC LIMIT 1;",
        "schema": {
            "public": {
                "orders": [
                    "employeeid",
                    "requireddate",
                    "shippeddate"
                ],
                "orders_summary": [
                    "employeeid",
                    "total"
                ],
                "employees": [
                    "employeeid"
                ],
                "late_orders": [
                    "employeeid",
                    "total"
                ]
            }
        }
    },
    "local097": {
        "query": "WITH DISTINCT_YEARS AS ( SELECT     DISTINCT     CAST(SUBSTR(year,-4) AS UNSIGNED) YEAR,     CAST(SUBSTR(year,-4) AS UNSIGNED) START_OF_DECADE,     CAST(SUBSTR(year,-4) AS UNSIGNED)+9 END_OF_DECADE,     SUBSTR(year,-4)   DECADE_OF FROM     Movie ), NUMBER_OF_MOV_BY_YR AS ( SELECT COUNT(DISTINCT MID) NUM_OF_MOV, CAST(SUBSTR(year,-4) AS UNSIGNED) YEAR FROM \tMovie GROUP BY \tCAST(SUBSTR(year,-4) AS UNSIGNED) ), NUM_OF_MOV_IN_DECADE AS  ( SELECT \tSUM(NUM_OF_MOV) TOTAL_MOVIES, \tDY.DECADE_OF FROM \tNUMBER_OF_MOV_BY_YR NM, \tDISTINCT_YEARS DY WHERE \tNM.YEAR BETWEEN DY.START_OF_DECADE AND DY.END_OF_DECADE GROUP BY \tDY.DECADE_OF ) SELECT \tDECADE_OF, \tTOTAL_MOVIES FROM \tNUM_OF_MOV_IN_DECADE WHERE \tTOTAL_MOVIES = ( \t\tSELECT \t\t\tMAX(TOTAL_MOVIES) \t\tFROM \t\t\tNUM_OF_MOV_IN_DECADE \t\t)",
        "schema": {
            "public": {
                "Movie": [
                    "year",
                    "MID"
                ],
                "DISTINCT_YEARS": [
                    "YEAR",
                    "START_OF_DECADE",
                    "END_OF_DECADE",
                    "DECADE_OF"
                ],
                "NUMBER_OF_MOV_BY_YR": [
                    "NUM_OF_MOV",
                    "YEAR"
                ],
                "NUM_OF_MOV_IN_DECADE": [
                    "TOTAL_MOVIES",
                    "DECADE_OF"
                ]
            }
        }
    },
    "local098": {
        "query": "WITH     NUM_OF_MOV_FOR_AN_ACTR_BY_YR AS (         SELECT             TRIM(MC.PID) AS PID,             CAST(SUBSTR(year, -4) AS UNSIGNED) AS YEAR,             COUNT(DISTINCT TRIM(M.MID)) AS NUM_OF_MOV         FROM             M_Cast MC             JOIN Movie M ON TRIM(MC.MID) = TRIM(M.MID)         GROUP BY             TRIM(MC.PID),             CAST(SUBSTR(year, -4) AS UNSIGNED)         ORDER BY             NUM_OF_MOV DESC     ),     ACTRS_FOR_MORE_THAN_ONE_YR AS (         SELECT             PID,             COUNT(YEAR) AS NUM_OF_YEARS,             MIN(YEAR) AS MIN_YEAR,             MAX(YEAR) AS MAX_YEAR         FROM             NUM_OF_MOV_FOR_AN_ACTR_BY_YR         GROUP BY             PID     ),     NUM_OF_FOR_ACTR_W_MRE_THN_1_YR AS (         SELECT             NM.PID,             NM.YEAR,             NM.YEAR + 4 AS YEAR_PLUS_4,             NM.NUM_OF_MOV,             AY.MIN_YEAR,             AY.MAX_YEAR         FROM             NUM_OF_MOV_FOR_AN_ACTR_BY_YR NM             JOIN ACTRS_FOR_MORE_THAN_ONE_YR AY ON NM.PID = AY.PID     ),     NUM_OF_MOV_TILL_DATE_BY_ACTOR AS (         SELECT             NA.PID,             NY.YEAR,             SUM(NA.NUM_OF_MOV) AS NUM_OF_MOV_TILL_THAT_YEAR         FROM             NUM_OF_FOR_ACTR_W_MRE_THN_1_YR NA             JOIN NUM_OF_FOR_ACTR_W_MRE_THN_1_YR NY ON NA.PID = NY.PID         WHERE             NA.YEAR BETWEEN NY.MIN_YEAR AND NY.YEAR         GROUP BY             NA.PID,             NY.YEAR     ),     NUM_OF_MV_BY_ACTR_BY_YR_PLS_4 AS (         SELECT             NA.PID,             NY.YEAR,             SUM(NA.NUM_OF_MOV) AS NUM_OF_MOV_TILL_AS_OF_YR_PLS_4         FROM             NUM_OF_FOR_ACTR_W_MRE_THN_1_YR NA             JOIN NUM_OF_FOR_ACTR_W_MRE_THN_1_YR NY ON NA.PID = NY.PID         WHERE             NA.YEAR BETWEEN NY.MIN_YEAR AND NY.YEAR_PLUS_4             AND NY.YEAR_PLUS_4 <= NY.MAX_YEAR         GROUP BY             NA.PID,             NY.YEAR     ) SELECT     COUNT(DISTINCT TRIM(P.Name)) AS NUM_OF_ACTORS_NEVER_UNEMPLOYED_FOR_MORE_THAN_3_YRS FROM     Person P WHERE     TRIM(P.PID) NOT IN (         SELECT DISTINCT             NMT.PID         FROM             NUM_OF_MOV_TILL_DATE_BY_ACTOR NMT             JOIN NUM_OF_MV_BY_ACTR_BY_YR_PLS_4 NMP ON NMT.PID = NMP.PID AND NMT.YEAR = NMP.YEAR         WHERE             NMT.NUM_OF_MOV_TILL_THAT_YEAR = NMP.NUM_OF_MOV_TILL_AS_OF_YR_PLS_4     );",
        "schema": {
            "public": {
                "M_Cast": [
                    "PID",
                    "MID"
                ],
                "Movie": [
                    "MID",
                    "year"
                ],
                "Person": [
                    "PID",
                    "Name"
                ],
                "NUM_OF_MOV_FOR_AN_ACTR_BY_YR": [
                    "PID",
                    "YEAR",
                    "NUM_OF_MOV"
                ],
                "ACTRS_FOR_MORE_THAN_ONE_YR": [
                    "PID",
                    "NUM_OF_YEARS",
                    "MIN_YEAR",
                    "MAX_YEAR"
                ],
                "NUM_OF_FOR_ACTR_W_MRE_THN_1_YR": [
                    "PID",
                    "YEAR",
                    "YEAR_PLUS_4",
                    "NUM_OF_MOV",
                    "MIN_YEAR",
                    "MAX_YEAR"
                ],
                "NUM_OF_MOV_TILL_DATE_BY_ACTOR": [
                    "PID",
                    "YEAR",
                    "NUM_OF_MOV_TILL_THAT_YEAR"
                ],
                "NUM_OF_MV_BY_ACTR_BY_YR_PLS_4": [
                    "PID",
                    "YEAR",
                    "NUM_OF_MOV_TILL_AS_OF_YR_PLS_4"
                ]
            }
        }
    },
    "local099": {
        "query": "WITH YASH_CHOPRAS_PID AS (     SELECT         TRIM(P.PID) AS PID     FROM         Person P     WHERE         TRIM(P.Name) = 'Yash Chopra' ), NUM_OF_MOV_BY_ACTOR_DIRECTOR AS (     SELECT         TRIM(MC.PID) AS ACTOR_PID,         TRIM(MD.PID) AS DIRECTOR_PID,         COUNT(DISTINCT TRIM(MD.MID)) AS NUM_OF_MOV     FROM         M_Cast MC     JOIN         M_Director MD ON TRIM(MC.MID) = TRIM(MD.MID)     GROUP BY         ACTOR_PID,         DIRECTOR_PID ), NUM_OF_MOVIES_BY_YC AS (     SELECT         NM.ACTOR_PID,         NM.DIRECTOR_PID,         NM.NUM_OF_MOV AS NUM_OF_MOV_BY_YC     FROM         NUM_OF_MOV_BY_ACTOR_DIRECTOR NM     JOIN         YASH_CHOPRAS_PID YCP ON NM.DIRECTOR_PID = YCP.PID ), MAX_MOV_BY_OTHER_DIRECTORS AS (     SELECT         ACTOR_PID,         MAX(NUM_OF_MOV) AS MAX_NUM_OF_MOV     FROM         NUM_OF_MOV_BY_ACTOR_DIRECTOR NM     JOIN         YASH_CHOPRAS_PID YCP ON NM.DIRECTOR_PID <> YCP.PID     GROUP BY         ACTOR_PID ), ACTORS_MOV_COMPARISION AS (     SELECT         NMY.ACTOR_PID,         CASE WHEN NMY.NUM_OF_MOV_BY_YC > IFNULL(NMO.MAX_NUM_OF_MOV, 0) THEN 'Y' ELSE 'N' END AS MORE_MOV_BY_YC     FROM         NUM_OF_MOVIES_BY_YC NMY     LEFT OUTER JOIN         MAX_MOV_BY_OTHER_DIRECTORS NMO ON NMY.ACTOR_PID = NMO.ACTOR_PID ) SELECT     COUNT(DISTINCT TRIM(P.Name)) AS \"Number of actor\" FROM     Person P WHERE     TRIM(P.PID) IN (         SELECT             DISTINCT ACTOR_PID         FROM             ACTORS_MOV_COMPARISION         WHERE             MORE_MOV_BY_YC = 'Y'     );",
        "schema": {
            "public": {
                "Person": [
                    "PID",
                    "Name"
                ],
                "M_Cast": [
                    "PID",
                    "MID"
                ],
                "M_Director": [
                    "PID",
                    "MID"
                ],
                "YASH_CHOPRAS_PID": [
                    "PID"
                ],
                "NUM_OF_MOV_BY_ACTOR_DIRECTOR": [
                    "ACTOR_PID",
                    "DIRECTOR_PID",
                    "NUM_OF_MOV"
                ],
                "NUM_OF_MOVIES_BY_YC": [
                    "ACTOR_PID",
                    "DIRECTOR_PID",
                    "NUM_OF_MOV_BY_YC"
                ],
                "MAX_MOV_BY_OTHER_DIRECTORS": [
                    "ACTOR_PID",
                    "MAX_NUM_OF_MOV"
                ],
                "ACTORS_MOV_COMPARISION": [
                    "ACTOR_PID",
                    "MORE_MOV_BY_YC"
                ]
            }
        }
    },
    "local100": {
        "query": "WITH      SHAHRUKH_0 AS (         SELECT              TRIM(P.PID) AS PID         FROM              Person P         WHERE              TRIM(P.Name) LIKE '%Shahrukh%'     ),     SHAHRUKH_1_MOVIES AS (         SELECT              DISTINCT TRIM(MC.MID) AS MID,              S0.PID         FROM              M_Cast MC         JOIN              SHAHRUKH_0 S0 ON TRIM(MC.PID) = S0.PID     ),     SHAHRUKH_1_ACTORS AS (         SELECT              DISTINCT TRIM(MC.PID) AS PID         FROM              M_Cast MC         JOIN              SHAHRUKH_1_MOVIES S1M ON TRIM(MC.MID) = S1M.MID         WHERE              TRIM(MC.PID) <> S1M.PID     ),     SHAHRUKH_2_MOVIES AS (         SELECT              DISTINCT TRIM(MC.MID) AS MID,              S1A.PID         FROM              M_Cast MC         JOIN              SHAHRUKH_1_ACTORS S1A ON TRIM(MC.PID) = S1A.PID     ) SELECT      COUNT(DISTINCT TRIM(MC.PID)) AS 'Number of actor' FROM      Person P JOIN      M_Cast MC ON TRIM(MC.PID) = TRIM(P.PID) JOIN      SHAHRUKH_2_MOVIES S2M ON TRIM(MC.MID) = S2M.MID WHERE      TRIM(MC.PID) <> S2M.PID;",
        "schema": {
            "public": {
                "Person": [
                    "PID",
                    "Name"
                ],
                "M_Cast": [
                    "MID",
                    "PID"
                ],
                "SHAHRUKH_0": [
                    "PID"
                ],
                "SHAHRUKH_1_MOVIES": [
                    "MID",
                    "PID"
                ],
                "SHAHRUKH_1_ACTORS": [
                    "PID"
                ],
                "SHAHRUKH_2_MOVIES": [
                    "MID",
                    "PID"
                ]
            }
        }
    },
    "local114": {
        "query": "WITH rgn_ttl AS (     SELECT          MAX(total_usd) total_usd,         region     FROM (         SELECT              r.name region,             SUM(o.total_amt_usd) total_usd         FROM              orders o         JOIN              accounts a ON a.id = o.account_id         JOIN              sales_reps s ON a.sales_rep_id = s.id         JOIN              region r ON r.id = s.region_id         GROUP BY              1     ) x     GROUP BY          2     ORDER BY          1 DESC     LIMIT          1 ) SELECT      COUNT(*) AS total_order FROM      orders o JOIN      accounts a ON a.id = o.account_id JOIN      sales_reps s ON a.sales_rep_id = s.id JOIN      region r ON r.id = s.region_id WHERE      r.name = (         SELECT              region         FROM              rgn_ttl     );",
        "schema": {
            "public": {
                "orders": [
                    "total_amt_usd",
                    "account_id"
                ],
                "accounts": [
                    "id",
                    "sales_rep_id"
                ],
                "sales_reps": [
                    "id",
                    "region_id"
                ],
                "region": [
                    "id",
                    "name"
                ],
                "rgn_ttl": [
                    "region",
                    "total_usd"
                ]
            }
        }
    },
    "local115": {
        "query": "WITH ttl_rep_rgn AS (     SELECT          MAX(total_usd) total_usd,         region,         rep     FROM (         SELECT              r.name region,             s.name rep,             SUM(o.total_amt_usd) total_usd         FROM accounts a         JOIN orders o ON a.id = o.account_id         JOIN sales_reps s ON a.sales_rep_id = s.id         JOIN region r ON s.region_id = r.id         GROUP BY r.name, s.name     ) x     GROUP BY region ) SELECT      region,     rep FROM ttl_rep_rgn ORDER BY total_usd DESC;",
        "schema": {
            "public": {
                "accounts": [
                    "id",
                    "sales_rep_id"
                ],
                "orders": [
                    "account_id",
                    "total_amt_usd"
                ],
                "sales_reps": [
                    "id",
                    "name",
                    "region_id"
                ],
                "region": [
                    "id",
                    "name"
                ],
                "ttl_rep_rgn": [
                    "total_usd",
                    "region",
                    "rep"
                ]
            }
        }
    },
    "local128": {
        "query": "WITH QualifiedBowlers AS (     SELECT          BowlerID     FROM          Bowler_Scores bs     JOIN          Tourney_Matches tm ON bs.MatchID = tm.MatchID     JOIN          Tournaments t ON tm.TourneyID = t.TourneyID     WHERE          bs.HandiCapScore <= 190         AND bs.WonGame = 1         AND t.TourneyLocation IN ('Thunderbird Lanes', 'Totem Lanes', 'Bolero Lanes')     GROUP BY          BowlerID     HAVING          COUNT(DISTINCT t.TourneyLocation) = 3 ) SELECT      Bowlers.BowlerID,      Bowlers.BowlerFirstName,      Bowlers.BowlerLastName,      Bowler_Scores.MatchID,     Bowler_Scores.GameNumber,     Bowler_Scores.HandiCapScore,     Tournaments.TourneyDate,     Tournaments.TourneyLocation FROM      Bowlers JOIN      Bowler_Scores ON Bowlers.BowlerID = Bowler_Scores.BowlerID JOIN      Tourney_Matches ON Bowler_Scores.MatchID = Tourney_Matches.MatchID JOIN      Tournaments ON Tournaments.TourneyID = Tourney_Matches.TourneyID JOIN      QualifiedBowlers qb ON Bowlers.BowlerID = qb.BowlerID WHERE      Bowler_Scores.HandiCapScore <= 190     AND Bowler_Scores.WonGame = 1     AND Tournaments.TourneyLocation IN ('Thunderbird Lanes', 'Totem Lanes', 'Bolero Lanes');",
        "schema": {
            "public": {
                "Bowler_Scores": [
                    "BowlerID",
                    "MatchID",
                    "HandiCapScore",
                    "WonGame",
                    "GameNumber"
                ],
                "Tourney_Matches": [
                    "MatchID",
                    "TourneyID"
                ],
                "Tournaments": [
                    "TourneyID",
                    "TourneyLocation",
                    "TourneyDate"
                ],
                "Bowlers": [
                    "BowlerID",
                    "BowlerFirstName",
                    "BowlerLastName"
                ],
                "QualifiedBowlers": [
                    "BowlerID"
                ]
            }
        }
    },
    "local130": {
        "query": "SELECT    S1.StudLastName AS LastName,   (CASE        WHEN RankInCategory <= 0.2 * NumStudents THEN 'First'       WHEN RankInCategory <= 0.4 * NumStudents THEN 'Second'       WHEN RankInCategory <= 0.6 * NumStudents THEN 'Third'       WHEN RankInCategory <= 0.8 * NumStudents THEN 'Fourth'       ELSE 'Fifth'     END) AS Quintile FROM   (SELECT       Students.StudLastName,      (SELECT COUNT(*)       FROM Classes       INNER JOIN Student_Schedules AS SS2 ON Classes.ClassID = SS2.ClassID       INNER JOIN Subjects AS S3 ON S3.SubjectID = Classes.SubjectID       WHERE S3.CategoryID = 'ENG'         AND SS2.Grade >= Student_Schedules.Grade) AS RankInCategory    FROM       Subjects    INNER JOIN Classes ON Subjects.SubjectID = Classes.SubjectID    INNER JOIN Student_Schedules ON Student_Schedules.ClassID = Classes.ClassID    INNER JOIN Students ON Students.StudentID = Student_Schedules.StudentID    WHERE       Student_Schedules.ClassStatus = 2       AND Subjects.CategoryID = 'ENG'   ) AS S1,   (SELECT COUNT(*) AS NumStudents    FROM Classes AS C2    INNER JOIN Student_Schedules AS SS3 ON C2.ClassID = SS3.ClassID    INNER JOIN Subjects AS S2 ON S2.SubjectID = C2.SubjectID    WHERE SS3.ClassStatus = 2       AND S2.CategoryID = 'ENG'   ) AS StudCount ORDER BY    S1.RankInCategory DESC;",
        "schema": {
            "public": {
                "Subjects": [
                    "SubjectID",
                    "CategoryID"
                ],
                "Classes": [
                    "ClassID",
                    "SubjectID"
                ],
                "Student_Schedules": [
                    "ClassID",
                    "StudentID",
                    "Grade",
                    "ClassStatus"
                ],
                "Students": [
                    "StudentID",
                    "StudLastName"
                ]
            }
        }
    },
    "local131": {
        "query": "SELECT    Musical_Styles.StyleName,   COUNT(RankedPreferences.FirstStyle)     AS FirstPreference,   COUNT(RankedPreferences.SecondStyle)     AS SecondPreference,   COUNT(RankedPreferences.ThirdStyle)     AS ThirdPreference FROM Musical_Styles,  (SELECT (CASE WHEN     Musical_Preferences.PreferenceSeq = 1                THEN Musical_Preferences.StyleID                ELSE Null END) As FirstStyle,          (CASE WHEN     Musical_Preferences.PreferenceSeq = 2                THEN Musical_Preferences.StyleID                ELSE Null END) As SecondStyle,          (CASE WHEN     Musical_Preferences.PreferenceSeq = 3                THEN Musical_Preferences.StyleID                ELSE Null END) AS ThirdStyle    FROM Musical_Preferences)  AS RankedPreferences WHERE Musical_Styles.StyleID =          RankedPreferences.FirstStyle   OR Musical_Styles.StyleID =          RankedPreferences.SecondStyle   OR Musical_Styles.StyleID =          RankedPreferences.ThirdStyle GROUP BY StyleID, StyleName HAVING COUNT(FirstStyle) > 0      OR     COUNT(SecondStyle) > 0      OR     COUNT(ThirdStyle) > 0 ORDER BY FirstPreference DESC,         SecondPreference DESC,         ThirdPreference DESC, StyleID;",
        "schema": {
            "public": {
                "Musical_Styles": [
                    "StyleID",
                    "StyleName"
                ],
                "Musical_Preferences": [
                    "PreferenceSeq",
                    "StyleID"
                ],
                "RankedPreferences": [
                    "FirstStyle",
                    "SecondStyle",
                    "ThirdStyle"
                ]
            }
        }
    },
    "local131_3": {
        "query": "WITH ScoreCounts AS (   SELECT      Musical_Styles.StyleName,     (COUNT(RankedPreferences.FirstStyle) * 3 +       COUNT(RankedPreferences.SecondStyle) * 2 +       COUNT(RankedPreferences.ThirdStyle) * 1) AS WeightedScore   FROM      Musical_Styles   LEFT JOIN      (SELECT         (CASE WHEN Musical_Preferences.PreferenceSeq = 1             THEN Musical_Preferences.StyleID END) AS FirstStyle,        (CASE WHEN Musical_Preferences.PreferenceSeq = 2             THEN Musical_Preferences.StyleID END) AS SecondStyle,        (CASE WHEN Musical_Preferences.PreferenceSeq = 3             THEN Musical_Preferences.StyleID END) AS ThirdStyle      FROM         Musical_Preferences) AS RankedPreferences   ON      Musical_Styles.StyleID = RankedPreferences.FirstStyle     OR Musical_Styles.StyleID = RankedPreferences.SecondStyle     OR Musical_Styles.StyleID = RankedPreferences.ThirdStyle   GROUP BY      Musical_Styles.StyleID, Musical_Styles.StyleName   HAVING      COUNT(RankedPreferences.FirstStyle) > 0      OR COUNT(RankedPreferences.SecondStyle) > 0      OR COUNT(RankedPreferences.ThirdStyle) > 0 ), AvgScoreCTE AS (   SELECT      AVG(WeightedScore) AS AvgScoreValue   FROM      ScoreCounts ) SELECT    SC.StyleName FROM    ScoreCounts SC CROSS JOIN    AvgScoreCTE AC ORDER BY    ABS(SC.WeightedScore - AC.AvgScoreValue) ASC,   SC.StyleName ASC LIMIT 1;",
        "schema": {
            "public": {
                "Musical_Styles": [
                    "StyleID",
                    "StyleName"
                ],
                "Musical_Preferences": [
                    "PreferenceSeq",
                    "StyleID"
                ],
                "ScoreCounts": [
                    "StyleName",
                    "WeightedScore"
                ],
                "AvgScoreCTE": [
                    "AvgScoreValue"
                ]
            }
        }
    },
    "local132": {
        "query": "WITH EntertainerStrengths AS (     SELECT e.EntertainerID,            e.EntStageName,            MAX(CASE WHEN es.StyleStrength = 1 THEN es.StyleID END) AS FirstStyle,            MAX(CASE WHEN es.StyleStrength = 2 THEN es.StyleID END) AS SecondStyle,            MAX(CASE WHEN es.StyleStrength = 3 THEN es.StyleID END) AS ThirdStyle     FROM Entertainers e     LEFT JOIN Entertainer_Styles es ON e.EntertainerID = es.EntertainerID     GROUP BY e.EntertainerID, e.EntStageName ), CustomerPreferences AS (     SELECT c.CustomerID,            c.CustLastName,            MAX(CASE WHEN mp.PreferenceSeq = 1 THEN mp.StyleID END) AS FirstStyle,            MAX(CASE WHEN mp.PreferenceSeq = 2 THEN mp.StyleID END) AS SecondStyle,            MAX(CASE WHEN mp.PreferenceSeq = 3 THEN mp.StyleID END) AS ThirdStyle     FROM Customers c     LEFT JOIN Musical_Preferences mp ON c.CustomerID = mp.CustomerID     GROUP BY c.CustomerID, c.CustLastName ) SELECT e.EntStageName AS StageName,        c.CustLastName AS LastName FROM EntertainerStrengths e JOIN CustomerPreferences c ON e.FirstStyle = c.FirstStyle AND e.SecondStyle = c.SecondStyle UNION SELECT e.EntStageName,        c.CustLastName  FROM EntertainerStrengths e JOIN CustomerPreferences c ON e.FirstStyle = c.SecondStyle AND e.SecondStyle = c.FirstStyle ORDER BY e.EntStageName, c.CustLastName;",
        "schema": {
            "public": {
                "Entertainers": [
                    "EntertainerID",
                    "EntStageName"
                ],
                "Entertainer_Styles": [
                    "EntertainerID",
                    "StyleStrength",
                    "StyleID"
                ],
                "Customers": [
                    "CustomerID",
                    "CustLastName"
                ],
                "Musical_Preferences": [
                    "CustomerID",
                    "PreferenceSeq",
                    "StyleID"
                ],
                "EntertainerStrengths": [
                    "EntertainerID",
                    "EntStageName",
                    "FirstStyle",
                    "SecondStyle",
                    "ThirdStyle"
                ],
                "CustomerPreferences": [
                    "CustomerID",
                    "CustLastName",
                    "FirstStyle",
                    "SecondStyle",
                    "ThirdStyle"
                ]
            }
        }
    },
    "local141": {
        "query": "WITH Sales_CTE AS (     SELECT          SalesPersonID,          SUM(TotalDue) AS TotalSales,          strftime('%Y', OrderDate) AS SalesYear     FROM          SalesOrderHeader     WHERE          SalesPersonID <> ''     GROUP BY          SalesPersonID,          strftime('%Y', OrderDate) ), Sales_Quota_CTE AS (     SELECT          BusinessEntityID,          SUM(SalesQuota) AS SalesQuota,          strftime('%Y', QuotaDate) AS SalesQuotaYear     FROM          SalesPersonQuotaHistory     GROUP BY          BusinessEntityID,          strftime('%Y', QuotaDate) ) SELECT      Sales_CTE.SalesPersonID,     Sales_CTE.SalesYear,     CAST(Sales_CTE.TotalSales AS TEXT) AS TotalSales,     Sales_Quota_CTE.SalesQuotaYear,     CAST(Sales_Quota_CTE.SalesQuota AS TEXT) AS SalesQuota,     CAST(Sales_CTE.TotalSales - Sales_Quota_CTE.SalesQuota AS TEXT) AS Amt_Above_or_Below_Quota FROM      Sales_CTE JOIN      Sales_Quota_CTE      ON Sales_Quota_CTE.BusinessEntityID = Sales_CTE.SalesPersonID     AND Sales_CTE.SalesYear = Sales_Quota_CTE.SalesQuotaYear ORDER BY      Sales_CTE.SalesPersonID,      Sales_CTE.SalesYear;",
        "schema": {
            "public": {
                "SalesOrderHeader": [
                    "SalesPersonID",
                    "TotalDue",
                    "OrderDate"
                ],
                "SalesPersonQuotaHistory": [
                    "BusinessEntityID",
                    "SalesQuota",
                    "QuotaDate"
                ],
                "Sales_CTE": [
                    "SalesPersonID",
                    "SalesYear",
                    "TotalSales"
                ],
                "Sales_Quota_CTE": [
                    "BusinessEntityID",
                    "SalesQuotaYear",
                    "SalesQuota"
                ]
            }
        }
    },
    "local230": {
        "query": "WITH top_genre AS (   SELECT      g.genre,      COUNT(g.movie_id) AS movie_count   FROM      genre AS g   INNER JOIN      ratings AS r ON g.movie_id = r.movie_id   WHERE      avg_rating > 8   GROUP BY      genre   ORDER BY      movie_count DESC   LIMIT 3 ), top_director AS (   SELECT      n.name AS director_name,     COUNT(g.movie_id) AS movie_count   FROM      names AS n    INNER JOIN      director_mapping AS dm ON n.id = dm.name_id    INNER JOIN      genre AS g ON dm.movie_id = g.movie_id    INNER JOIN      ratings AS r ON r.movie_id = g.movie_id,     top_genre   WHERE      g.genre IN (top_genre.genre)      AND avg_rating > 8   GROUP BY      director_name   ORDER BY      movie_count DESC ) SELECT    * FROM    top_director LIMIT    3;",
        "schema": {
            "public": {
                "genre": [
                    "genre",
                    "movie_id"
                ],
                "ratings": [
                    "movie_id",
                    "avg_rating"
                ],
                "names": [
                    "id",
                    "name"
                ],
                "director_mapping": [
                    "name_id",
                    "movie_id"
                ],
                "top_genre": [
                    "genre",
                    "movie_count"
                ]
            }
        }
    },
    "local156": {
        "query": "WITH cte_dollar_cost_average AS (   SELECT     strftime('%Y', substr(transactions.txn_date, 7, 4) || '-' || substr(transactions.txn_date, 4, 2) || '-' || substr(transactions.txn_date, 1, 2)) AS year_start,     members.region,     SUM(transactions.quantity * prices.price) / SUM(transactions.quantity) AS btc_dca   FROM transactions   INNER JOIN prices     ON transactions.ticker = prices.ticker     AND transactions.txn_date = prices.market_date   INNER JOIN members     ON transactions.member_id = members.member_id   WHERE transactions.ticker = 'BTC'     AND transactions.txn_type = 'BUY'   GROUP BY year_start, members.region ),  cte_window_functions AS (   SELECT     year_start,     region,     btc_dca,     (SELECT COUNT(*)       FROM cte_dollar_cost_average AS sub      WHERE sub.year_start = cte_dollar_cost_average.year_start         AND sub.btc_dca <= cte_dollar_cost_average.btc_dca) AS dca_ranking,     (SELECT btc_dca       FROM cte_dollar_cost_average AS sub      WHERE sub.region = cte_dollar_cost_average.region         AND sub.year_start < cte_dollar_cost_average.year_start      ORDER BY sub.year_start DESC      LIMIT 1) AS previous_btc_dca,      ROW_NUMBER() OVER (PARTITION BY region ORDER BY year_start) AS rn   FROM cte_dollar_cost_average )  SELECT   year_start,   region,   ROUND(btc_dca, 2) AS btc_dca,   dca_ranking,   ROUND(     100.0 * (btc_dca - previous_btc_dca) / previous_btc_dca,     2   ) AS dca_percentage_change FROM cte_window_functions WHERE rn > 1 ORDER BY region, year_start;",
        "schema": {
            "public": {
                "transactions": [
                    "txn_date",
                    "quantity",
                    "ticker",
                    "txn_type",
                    "member_id"
                ],
                "prices": [
                    "ticker",
                    "market_date",
                    "price"
                ],
                "members": [
                    "member_id",
                    "region"
                ],
                "cte_dollar_cost_average": [
                    "year_start",
                    "region",
                    "btc_dca"
                ],
                "cte_window_functions": [
                    "year_start",
                    "region",
                    "btc_dca",
                    "dca_ranking",
                    "previous_btc_dca",
                    "rn"
                ]
            }
        }
    },
    "local162": {
        "query": "WITH AllISCourses AS (     SELECT DISTINCT CourseNo     FROM Offering     WHERE CourseNo LIKE 'IS%'      AND SUBSTR(CourseNo, 3, 1) BETWEEN '0' AND '9' ), TotalISCourseCount AS (     SELECT COUNT(*) AS TotalCourses     FROM AllISCourses ), QualifiedStudents AS (     SELECT Enrollment.StdNo     FROM Enrollment     JOIN Offering      ON Enrollment.OfferNo = Offering.OfferNo     WHERE Offering.CourseNo IN (SELECT CourseNo FROM AllISCourses)     AND Enrollment.EnrGrade >= 3.0     GROUP BY Enrollment.StdNo     HAVING COUNT(DISTINCT Offering.CourseNo) = (SELECT TotalCourses FROM TotalISCourseCount) ) SELECT COUNT(*) AS 'Num of student' FROM QualifiedStudents;",
        "schema": {
            "public": {
                "Offering": [
                    "CourseNo",
                    "OfferNo"
                ],
                "Enrollment": [
                    "StdNo",
                    "OfferNo",
                    "EnrGrade"
                ],
                "AllISCourses": [
                    "CourseNo"
                ],
                "TotalISCourseCount": [
                    "TotalCourses"
                ],
                "QualifiedStudents": [
                    "StdNo"
                ]
            }
        }
    },
    "local162_2": {
        "query": "WITH AvgSalaries AS (     SELECT          facrank AS FacRank,         AVG(facsalary) AS AvSalary     FROM          faculty     GROUP BY          facrank ), SalaryDifferences AS (     SELECT          faculty.facrank AS FacRank,          faculty.facfirstname AS FacFirstName,          faculty.faclastname AS FacLastName,          faculty.facsalary AS Salary,          ABS(faculty.facsalary - AvgSalaries.AvSalary) AS Diff     FROM          faculty     JOIN          AvgSalaries ON faculty.facrank = AvgSalaries.FacRank ), MinDifferences AS (     SELECT          FacRank,          MIN(Diff) AS MinDiff     FROM          SalaryDifferences     GROUP BY          FacRank ) SELECT      s.FacRank,      s.FacFirstName,      s.FacLastName,      s.Salary FROM      SalaryDifferences s JOIN      MinDifferences m ON s.FacRank = m.FacRank AND s.Diff = m.MinDiff;",
        "schema": {
            "public": {
                "faculty": [
                    "facrank",
                    "facsalary",
                    "facfirstname",
                    "faclastname"
                ],
                "AvgSalaries": [
                    "FacRank",
                    "AvSalary"
                ],
                "SalaryDifferences": [
                    "FacRank",
                    "FacFirstName",
                    "FacLastName",
                    "Salary",
                    "Diff"
                ],
                "MinDifferences": [
                    "FacRank",
                    "MinDiff"
                ]
            }
        }
    },
    "local168": {
        "query": "WITH skills_demand AS (     SELECT         skills_dim.skill_id,         COUNT(skills_job_dim.job_id) AS demand_count     FROM job_postings_fact     INNER JOIN skills_job_dim ON job_postings_fact.job_id = skills_job_dim.job_id     INNER JOIN skills_dim ON skills_job_dim.skill_id = skills_dim.skill_id     WHERE         job_title_short = 'Data Analyst'          AND salary_year_avg IS NOT NULL         AND job_work_from_home = True      GROUP BY         skills_dim.skill_id     ORDER BY demand_count DESC     LIMIT 3 ), average_salary AS (     SELECT          skills_job_dim.skill_id,         AVG(job_postings_fact.salary_year_avg) AS avg_salary     FROM job_postings_fact     INNER JOIN skills_job_dim ON job_postings_fact.job_id = skills_job_dim.job_id     INNER JOIN skills_dim ON skills_job_dim.skill_id = skills_dim.skill_id     WHERE         job_title_short = 'Data Analyst'         AND salary_year_avg IS NOT NULL         AND job_work_from_home = True      GROUP BY         skills_job_dim.skill_id ), top_skills_with_salary AS (     SELECT         average_salary.avg_salary     FROM         skills_demand     INNER JOIN average_salary ON skills_demand.skill_id = average_salary.skill_id ) SELECT     AVG(avg_salary) AS avg_salary FROM     top_skills_with_salary;",
        "schema": {
            "public": {
                "job_postings_fact": [
                    "job_id",
                    "job_title_short",
                    "salary_year_avg",
                    "job_work_from_home"
                ],
                "skills_job_dim": [
                    "job_id",
                    "skill_id"
                ],
                "skills_dim": [
                    "skill_id"
                ],
                "skills_demand": [
                    "skill_id",
                    "demand_count"
                ],
                "average_salary": [
                    "skill_id",
                    "avg_salary"
                ],
                "top_skills_with_salary": [
                    "avg_salary"
                ]
            }
        }
    },
    "local209": {
        "query": "WITH store_order_counts AS (     SELECT         s.store_name,         COUNT(o.order_id) AS total_orders     FROM         orders o      LEFT JOIN         stores s ON o.store_id = s.store_id      GROUP BY          s.store_name     ORDER BY          total_orders DESC     LIMIT 1   ), deliveries_completed AS (     SELECT         s.store_name,         COUNT(o.order_id) AS deliveries_completed     FROM         orders o      LEFT JOIN         stores s ON o.store_id = s.store_id      INNER JOIN (             SELECT                  DISTINCT delivery_order_id             FROM deliveries             WHERE delivery_status = 'DELIVERED'         ) AS ud ON o.delivery_order_id = ud.delivery_order_id     GROUP BY          s.store_name ) SELECT     CAST(dc.deliveries_completed AS REAL) / NULLIF(CAST(soc.total_orders AS REAL), 0) AS completion_ratio FROM     store_order_counts soc LEFT JOIN     deliveries_completed dc ON soc.store_name = dc.store_name;",
        "schema": {
            "public": {
                "orders": [
                    "order_id",
                    "store_id",
                    "delivery_order_id"
                ],
                "stores": [
                    "store_id",
                    "store_name"
                ],
                "deliveries": [
                    "delivery_order_id",
                    "delivery_status"
                ],
                "store_order_counts": [
                    "store_name",
                    "total_orders"
                ],
                "deliveries_completed": [
                    "store_name",
                    "deliveries_completed"
                ]
            }
        }
    },
    "local210": {
        "query": "WITH february_orders AS (     SELECT         h.hub_name AS hub_name,         COUNT(*) AS orders_february     FROM          orders o      LEFT JOIN         stores s ON o.store_id = s.store_id      LEFT JOIN          hubs h ON s.hub_id = h.hub_id      WHERE o.order_created_month = 2 AND o.order_status = 'FINISHED'     GROUP BY         h.hub_name ), march_orders AS (     SELECT         h.hub_name AS hub_name,         COUNT(*) AS orders_march     FROM          orders o      LEFT JOIN         stores s ON o.store_id = s.store_id      LEFT JOIN          hubs h ON s.hub_id = h.hub_id      WHERE o.order_created_month = 3 AND o.order_status = 'FINISHED'     GROUP BY         h.hub_name ) SELECT     fo.hub_name FROM     february_orders fo LEFT JOIN      march_orders mo ON fo.hub_name = mo.hub_name WHERE      fo.orders_february > 0 AND      mo.orders_march > 0 AND     (CAST((mo.orders_march - fo.orders_february) AS REAL) / CAST(fo.orders_february AS REAL)) > 0.2  -- Filter for hubs with more than a 20% increase",
        "schema": {
            "public": {
                "orders": [
                    "store_id",
                    "order_created_month",
                    "order_status"
                ],
                "stores": [
                    "store_id",
                    "hub_id"
                ],
                "hubs": [
                    "hub_id",
                    "hub_name"
                ],
                "february_orders": [
                    "hub_name",
                    "orders_february"
                ],
                "march_orders": [
                    "hub_name",
                    "orders_march"
                ]
            }
        }
    },
    "local211_2": {
        "query": "WITH media_entregador AS ( \tSELECT  \t\tentregador, \t\tCAST(strftime('%m', data) AS INTEGER) AS mes, \t\tROUND(AVG(entregas_por_dia), 2) AS media_entregas_por_dia, \t\tRANK() OVER(PARTITION BY CAST(strftime('%m', data) AS INTEGER) ORDER BY AVG(entregas_por_dia) DESC) AS rank_entregador \tFROM ( \t\tSELECT \t\t\tud.driver_id AS entregador, \t\t\tDATE(o.order_moment_created) AS data, \t\t\tCOUNT(o.order_id) AS entregas_por_dia \t\tFROM  \t\t\torders o  \t\tINNER JOIN ( \t\t\tSELECT  \t\t\t\tDISTINCT delivery_order_id,  \t\t\t\tdriver_id,  \t\t\t\tdelivery_status \t\t\tFROM  \t\t\t\tdeliveries    \t \t\t) AS ud \t\tON o.delivery_order_id = ud.delivery_order_id \t\tLEFT JOIN  \t\t\tdrivers dr ON ud.driver_id = dr.driver_id\t \t\tWHERE  \t\t\to.order_status = 'FINISHED' AND  \t\t\tud.driver_id IS NOT NULL AND   \t\t\tud.delivery_status = 'DELIVERED' \t\tGROUP BY  \t\t\tud.driver_id,  \t\t\tCAST(strftime('%Y-%m-%d', o.order_moment_created) AS DATE) \t) AS subquery \tGROUP BY \t\tentregador, \t\tCAST(strftime('%m', data) AS INTEGER) ) SELECT \tentregador AS driver_id FROM \tmedia_entregador WHERE \trank_entregador <= 5 ORDER BY  \tmes, \trank_entregador;",
        "schema": {
            "public": {
                "orders": [
                    "delivery_order_id",
                    "order_moment_created",
                    "order_id",
                    "order_status"
                ],
                "deliveries": [
                    "delivery_order_id",
                    "driver_id",
                    "delivery_status"
                ],
                "drivers": [
                    "driver_id"
                ],
                "media_entregador": [
                    "driver_id"
                ]
            }
        }
    },
    "local220": {
        "query": "WITH match_view AS (     SELECT M.id,            L.name AS league,            M.season,            M.match_api_id,            T.team_long_name AS home_team,            TM.team_long_name AS away_team,            M.home_team_goal,            M.away_team_goal,            P1.player_name AS home_gk,            P2.player_name AS home_center_back_1,            P3.player_name AS home_center_back_2,            P4.player_name AS home_right_back,            P5.player_name AS home_left_back,            P6.player_name AS home_midfield_1,            P7.player_name AS home_midfield_2,            P8.player_name AS home_midfield_3,            P9.player_name AS home_midfield_4,            P10.player_name AS home_second_forward,            P11.player_name AS home_center_forward,            P12.player_name AS away_gk,            P13.player_name AS away_center_back_1,            P14.player_name AS away_center_back_2,            P15.player_name AS away_right_back,            P16.player_name AS away_left_back,            P17.player_name AS away_midfield_1,            P18.player_name AS away_midfield_2,            P19.player_name AS away_midfield_3,            P20.player_name AS away_midfield_4,            P21.player_name AS away_second_forward,            P22.player_name AS away_center_forward,            M.goal,            M.card       FROM match M            LEFT JOIN            league L ON M.league_id = L.id            LEFT JOIN            team T ON M.home_team_api_id = T.team_api_id            LEFT JOIN            team TM ON M.away_team_api_id = TM.team_api_id            LEFT JOIN            player P1 ON M.home_player_1 = P1.player_api_id            LEFT JOIN            player P2 ON M.home_player_2 = P2.player_api_id            LEFT JOIN            player P3 ON M.home_player_3 = P3.player_api_id            LEFT JOIN            player P4 ON M.home_player_4 = P4.player_api_id            LEFT JOIN            player P5 ON M.home_player_5 = P5.player_api_id            LEFT JOIN            player P6 ON M.home_player_6 = P6.player_api_id            LEFT JOIN            player P7 ON M.home_player_7 = P7.player_api_id            LEFT JOIN            player P8 ON M.home_player_8 = P8.player_api_id            LEFT JOIN            player P9 ON M.home_player_9 = P9.player_api_id            LEFT JOIN            player P10 ON M.home_player_10 = P10.player_api_id            LEFT JOIN            player P11 ON M.home_player_11 = P11.player_api_id            LEFT JOIN            player P12 ON M.away_player_1 = P12.player_api_id            LEFT JOIN            player P13 ON M.away_player_2 = P13.player_api_id            LEFT JOIN            player P14 ON M.away_player_3 = P14.player_api_id            LEFT JOIN            player P15 ON M.away_player_4 = P15.player_api_id            LEFT JOIN            player P16 ON M.away_player_5 = P16.player_api_id            LEFT JOIN            player P17 ON M.away_player_6 = P17.player_api_id            LEFT JOIN            player P18 ON M.away_player_7 = P18.player_api_id            LEFT JOIN            player P19 ON M.away_player_8 = P19.player_api_id            LEFT JOIN            player P20 ON M.away_player_9 = P20.player_api_id            LEFT JOIN            player P21 ON M.away_player_10 = P21.player_api_id            LEFT JOIN            player P22 ON M.away_player_11 = P22.player_api_id ), players AS (     SELECT home_gk AS player      FROM match_view      WHERE home_team_goal > away_team_goal          UNION ALL          SELECT home_center_back_1 AS player      FROM match_view      WHERE home_team_goal > away_team_goal          UNION ALL          SELECT home_center_back_2 AS player      FROM match_view      WHERE home_team_goal > away_team_goal          UNION ALL          SELECT home_right_back AS player      FROM match_view      WHERE home_team_goal > away_team_goal          UNION ALL          SELECT home_left_back AS player      FROM match_view      WHERE home_team_goal > away_team_goal          UNION ALL          SELECT home_midfield_1 AS player      FROM match_view      WHERE home_team_goal > away_team_goal          UNION ALL          SELECT home_midfield_2 AS player      FROM match_view      WHERE home_team_goal > away_team_goal          UNION ALL          SELECT home_midfield_3 AS player      FROM match_view      WHERE home_team_goal > away_team_goal          UNION ALL          SELECT home_midfield_4 AS player      FROM match_view      WHERE home_team_goal > away_team_goal          UNION ALL          SELECT home_second_forward AS player      FROM match_view      WHERE home_team_goal > away_team_goal          UNION ALL          SELECT home_center_forward AS player      FROM match_view      WHERE home_team_goal > away_team_goal          UNION ALL          SELECT away_gk AS player      FROM match_view      WHERE away_team_goal > home_team_goal          UNION ALL          SELECT away_center_back_1 AS player      FROM match_view      WHERE away_team_goal > home_team_goal          UNION ALL          SELECT away_center_back_2 AS player      FROM match_view      WHERE away_team_goal > home_team_goal          UNION ALL          SELECT away_right_back AS player      FROM match_view      WHERE away_team_goal > home_team_goal          UNION ALL          SELECT away_left_back AS player      FROM match_view      WHERE away_team_goal > home_team_goal          UNION ALL          SELECT away_midfield_1 AS player      FROM match_view      WHERE away_team_goal > home_team_goal          UNION ALL          SELECT away_midfield_2 AS player      FROM match_view      WHERE away_team_goal > home_team_goal          UNION ALL          SELECT away_midfield_3 AS player      FROM match_view      WHERE away_team_goal > home_team_goal          UNION ALL          SELECT away_midfield_4 AS player      FROM match_view      WHERE away_team_goal > home_team_goal          UNION ALL          SELECT away_second_forward AS player      FROM match_view      WHERE away_team_goal > home_team_goal          UNION ALL          SELECT away_center_forward AS player      FROM match_view      WHERE away_team_goal > home_team_goal )  -- Now, select from the CTE and create a temporary result SELECT     player FROM     players GROUP BY     player HAVING     player IS NOT NULL ORDER BY     COUNT(*) DESC LIMIT 1;",
        "schema": {
            "public": {
                "match": [
                    "id",
                    "league_id",
                    "season",
                    "match_api_id",
                    "home_team_api_id",
                    "away_team_api_id",
                    "home_team_goal",
                    "away_team_goal",
                    "home_player_1",
                    "home_player_2",
                    "home_player_3",
                    "home_player_4",
                    "home_player_5",
                    "home_player_6",
                    "home_player_7",
                    "home_player_8",
                    "home_player_9",
                    "home_player_10",
                    "home_player_11",
                    "away_player_1",
                    "away_player_2",
                    "away_player_3",
                    "away_player_4",
                    "away_player_5",
                    "away_player_6",
                    "away_player_7",
                    "away_player_8",
                    "away_player_9",
                    "away_player_10",
                    "away_player_11",
                    "goal",
                    "card"
                ],
                "league": [
                    "id",
                    "name"
                ],
                "team": [
                    "team_api_id",
                    "team_long_name"
                ],
                "player": [
                    "player_api_id",
                    "player_name"
                ],
                "match_view": [
                    "home_gk",
                    "home_center_back_1",
                    "home_center_back_2",
                    "home_right_back",
                    "home_left_back",
                    "home_midfield_1",
                    "home_midfield_2",
                    "home_midfield_3",
                    "home_midfield_4",
                    "home_second_forward",
                    "home_center_forward",
                    "away_gk",
                    "away_center_back_1",
                    "away_center_back_2",
                    "away_right_back",
                    "away_left_back",
                    "away_midfield_1",
                    "away_midfield_2",
                    "away_midfield_3",
                    "away_midfield_4",
                    "away_second_forward",
                    "away_center_forward",
                    "home_team_goal",
                    "away_team_goal"
                ],
                "players": [
                    "player"
                ]
            }
        }
    },
    "local220_1": {
        "query": "WITH match_view AS (     SELECT M.id,            L.name AS league,            M.season,            M.match_api_id,            T.team_long_name AS home_team,            TM.team_long_name AS away_team,            M.home_team_goal,            M.away_team_goal,            P1.player_name AS home_gk,            P2.player_name AS home_center_back_1,            P3.player_name AS home_center_back_2,            P4.player_name AS home_right_back,            P5.player_name AS home_left_back,            P6.player_name AS home_midfield_1,            P7.player_name AS home_midfield_2,            P8.player_name AS home_midfield_3,            P9.player_name AS home_midfield_4,            P10.player_name AS home_second_forward,            P11.player_name AS home_center_forward,            P12.player_name AS away_gk,            P13.player_name AS away_center_back_1,            P14.player_name AS away_center_back_2,            P15.player_name AS away_right_back,            P16.player_name AS away_left_back,            P17.player_name AS away_midfield_1,            P18.player_name AS away_midfield_2,            P19.player_name AS away_midfield_3,            P20.player_name AS away_midfield_4,            P21.player_name AS away_second_forward,            P22.player_name AS away_center_forward,            M.goal,            M.card       FROM match M            LEFT JOIN            league L ON M.league_id = L.id            LEFT JOIN            team T ON M.home_team_api_id = T.team_api_id            LEFT JOIN            team TM ON M.away_team_api_id = TM.team_api_id            LEFT JOIN            player P1 ON M.home_player_1 = P1.player_api_id            LEFT JOIN            player P2 ON M.home_player_2 = P2.player_api_id            LEFT JOIN            player P3 ON M.home_player_3 = P3.player_api_id            LEFT JOIN            player P4 ON M.home_player_4 = P4.player_api_id            LEFT JOIN            player P5 ON M.home_player_5 = P5.player_api_id            LEFT JOIN            player P6 ON M.home_player_6 = P6.player_api_id            LEFT JOIN            player P7 ON M.home_player_7 = P7.player_api_id            LEFT JOIN            player P8 ON M.home_player_8 = P8.player_api_id            LEFT JOIN            player P9 ON M.home_player_9 = P9.player_api_id            LEFT JOIN            player P10 ON M.home_player_10 = P10.player_api_id            LEFT JOIN            player P11 ON M.home_player_11 = P11.player_api_id            LEFT JOIN            player P12 ON M.away_player_1 = P12.player_api_id            LEFT JOIN            player P13 ON M.away_player_2 = P13.player_api_id            LEFT JOIN            player P14 ON M.away_player_3 = P14.player_api_id            LEFT JOIN            player P15 ON M.away_player_4 = P15.player_api_id            LEFT JOIN            player P16 ON M.away_player_5 = P16.player_api_id            LEFT JOIN            player P17 ON M.away_player_6 = P17.player_api_id            LEFT JOIN            player P18 ON M.away_player_7 = P18.player_api_id            LEFT JOIN            player P19 ON M.away_player_8 = P19.player_api_id            LEFT JOIN            player P20 ON M.away_player_9 = P20.player_api_id            LEFT JOIN            player P21 ON M.away_player_10 = P21.player_api_id            LEFT JOIN            player P22 ON M.away_player_11 = P22.player_api_id ), players AS (     SELECT home_gk AS player      FROM match_view      WHERE home_team_goal < away_team_goal          UNION ALL          SELECT home_center_back_1 AS player      FROM match_view      WHERE home_team_goal < away_team_goal          UNION ALL          SELECT home_center_back_2 AS player      FROM match_view      WHERE home_team_goal < away_team_goal          UNION ALL          SELECT home_right_back AS player      FROM match_view      WHERE home_team_goal < away_team_goal          UNION ALL          SELECT home_left_back AS player      FROM match_view      WHERE home_team_goal < away_team_goal          UNION ALL          SELECT home_midfield_1 AS player      FROM match_view      WHERE home_team_goal < away_team_goal          UNION ALL          SELECT home_midfield_2 AS player      FROM match_view      WHERE home_team_goal < away_team_goal          UNION ALL          SELECT home_midfield_3 AS player      FROM match_view      WHERE home_team_goal < away_team_goal          UNION ALL          SELECT home_midfield_4 AS player      FROM match_view      WHERE home_team_goal < away_team_goal          UNION ALL          SELECT home_second_forward AS player      FROM match_view      WHERE home_team_goal < away_team_goal          UNION ALL          SELECT home_center_forward AS player      FROM match_view      WHERE home_team_goal < away_team_goal          UNION ALL          SELECT away_gk AS player      FROM match_view      WHERE away_team_goal < home_team_goal          UNION ALL          SELECT away_center_back_1 AS player      FROM match_view      WHERE away_team_goal < home_team_goal          UNION ALL          SELECT away_center_back_2 AS player      FROM match_view      WHERE away_team_goal < home_team_goal          UNION ALL          SELECT away_right_back AS player      FROM match_view      WHERE away_team_goal < home_team_goal          UNION ALL          SELECT away_left_back AS player      FROM match_view      WHERE away_team_goal < home_team_goal          UNION ALL          SELECT away_midfield_1 AS player      FROM match_view      WHERE away_team_goal < home_team_goal          UNION ALL          SELECT away_midfield_2 AS player      FROM match_view      WHERE away_team_goal < home_team_goal          UNION ALL          SELECT away_midfield_3 AS player      FROM match_view      WHERE away_team_goal < home_team_goal          UNION ALL          SELECT away_midfield_4 AS player      FROM match_view      WHERE away_team_goal < home_team_goal          UNION ALL          SELECT away_second_forward AS player      FROM match_view      WHERE away_team_goal < home_team_goal          UNION ALL          SELECT away_center_forward AS player      FROM match_view      WHERE away_team_goal < home_team_goal )  SELECT     player FROM     players GROUP BY     player HAVING     player IS NOT NULL ORDER BY     COUNT(*) DESC LIMIT 1;",
        "schema": {
            "public": {
                "match": [
                    "id",
                    "league_id",
                    "season",
                    "match_api_id",
                    "home_team_api_id",
                    "away_team_api_id",
                    "home_team_goal",
                    "away_team_goal",
                    "home_player_1",
                    "home_player_2",
                    "home_player_3",
                    "home_player_4",
                    "home_player_5",
                    "home_player_6",
                    "home_player_7",
                    "home_player_8",
                    "home_player_9",
                    "home_player_10",
                    "home_player_11",
                    "away_player_1",
                    "away_player_2",
                    "away_player_3",
                    "away_player_4",
                    "away_player_5",
                    "away_player_6",
                    "away_player_7",
                    "away_player_8",
                    "away_player_9",
                    "away_player_10",
                    "away_player_11",
                    "goal",
                    "card"
                ],
                "league": [
                    "id",
                    "name"
                ],
                "team": [
                    "team_api_id",
                    "team_long_name"
                ],
                "player": [
                    "player_api_id",
                    "player_name"
                ],
                "match_view": [
                    "home_gk",
                    "home_center_back_1",
                    "home_center_back_2",
                    "home_right_back",
                    "home_left_back",
                    "home_midfield_1",
                    "home_midfield_2",
                    "home_midfield_3",
                    "home_midfield_4",
                    "home_second_forward",
                    "home_center_forward",
                    "away_gk",
                    "away_center_back_1",
                    "away_center_back_2",
                    "away_right_back",
                    "away_left_back",
                    "away_midfield_1",
                    "away_midfield_2",
                    "away_midfield_3",
                    "away_midfield_4",
                    "away_second_forward",
                    "away_center_forward",
                    "home_team_goal",
                    "away_team_goal"
                ],
                "players": [
                    "player"
                ]
            }
        }
    },
    "local228": {
        "query": "WITH season_bat AS (     SELECT          m.season_id AS season_year,          p.player_id,          SUM(bs.runs_scored) AS runs,          ROW_NUMBER() OVER (PARTITION BY m.season_id ORDER BY SUM(bs.runs_scored) DESC, p.player_id ASC) AS runs_row     FROM          match m     JOIN          ball_by_ball b ON m.match_id = b.match_id     JOIN          batsman_scored bs ON b.match_id = bs.match_id          AND b.over_id = bs.over_id          AND b.ball_id = bs.ball_id          AND b.innings_no = bs.innings_no     JOIN          player p ON p.player_id = b.striker     GROUP BY          m.season_id, p.player_id ), season_bowl AS (     SELECT          m.season_id AS season_year,          p.player_id,          COUNT(wt.player_out) AS wickets,         ROW_NUMBER() OVER (PARTITION BY m.season_id ORDER BY COUNT(wt.player_out) DESC, p.player_id ASC) AS wickets_row     FROM          match m     JOIN          ball_by_ball b ON m.match_id = b.match_id     JOIN          wicket_taken wt ON b.match_id = wt.match_id          AND b.over_id = wt.over_id          AND b.ball_id = wt.ball_id          AND b.innings_no = wt.innings_no     JOIN          player p ON p.player_id = b.bowler     WHERE          wt.kind_out NOT IN ('run out', 'hit wicket', 'retired hurt')     GROUP BY          m.season_id, p.player_id ) SELECT      sbat.season_year AS 'season id',      sbat.player_id AS batsman,      sbat.runs,      sbowl.player_id AS bowler,      sbowl.wickets FROM      season_bat sbat JOIN      season_bowl sbowl ON sbat.season_year = sbowl.season_year AND sbat.runs_row = sbowl.wickets_row WHERE      sbat.runs_row <= 3 AND sbowl.wickets_row <= 3 ORDER BY      sbat.season_year, sbat.runs_row;",
        "schema": {
            "public": {
                "match": [
                    "match_id",
                    "season_id"
                ],
                "ball_by_ball": [
                    "match_id",
                    "over_id",
                    "ball_id",
                    "innings_no",
                    "striker",
                    "bowler"
                ],
                "batsman_scored": [
                    "match_id",
                    "over_id",
                    "ball_id",
                    "innings_no",
                    "runs_scored"
                ],
                "player": [
                    "player_id"
                ],
                "wicket_taken": [
                    "match_id",
                    "over_id",
                    "ball_id",
                    "innings_no",
                    "player_out",
                    "kind_out"
                ],
                "season_bat": [
                    "season_year",
                    "player_id",
                    "runs",
                    "runs_row"
                ],
                "season_bowl": [
                    "season_year",
                    "player_id",
                    "wickets",
                    "wickets_row"
                ]
            }
        }
    },
    "local229": {
        "query": "WITH ball_extend AS (     SELECT          b.*,         CASE              WHEN b.striker < b.non_striker THEN b.striker              ELSE b.non_striker          END AS u1,         CASE              WHEN b.striker > b.non_striker THEN b.striker              ELSE b.non_striker          END AS u2     FROM          ball_by_ball b ), match_part AS (     SELECT          be.match_id,          be.u1,          be.u2,          SUM(bs.runs_scored) AS runs,         RANK() OVER(PARTITION BY be.match_id ORDER BY SUM(bs.runs_scored) DESC) AS prank     FROM          ball_extend be     JOIN          batsman_scored bs ON be.match_id = bs.match_id          AND be.over_id = bs.over_id          AND be.ball_id = bs.ball_id          AND be.innings_no = bs.innings_no     GROUP BY          be.match_id, be.u1, be.u2     ORDER BY          be.match_id, SUM(bs.runs_scored) DESC ), match_part2 AS (     SELECT          b.match_id,          mp.u1,          mp.u2,          mp.runs,          mp.prank,         SUM(bs.runs_scored) AS u1_runs,         (mp.runs - SUM(bs.runs_scored)) AS u2_runs     FROM          match_part mp     JOIN          ball_by_ball b ON mp.match_id = b.match_id      JOIN          batsman_scored bs ON b.match_id = bs.match_id          AND b.over_id = bs.over_id          AND b.ball_id = bs.ball_id          AND b.innings_no = bs.innings_no     WHERE          mp.u1 = b.striker          AND mp.u2 = b.non_striker     GROUP BY          b.match_id, mp.u1, mp.u2, mp.runs, mp.prank ), match_part3 AS (     SELECT          match_id,         CASE              WHEN u1_runs > u2_runs THEN u1              WHEN u1_runs = u2_runs THEN (CASE WHEN u1 > u2 THEN u1 ELSE u2 END)             ELSE u2          END AS player1_id,         CASE              WHEN u1_runs < u2_runs THEN u1              WHEN u1_runs = u2_runs THEN (CASE WHEN u1 > u2 THEN u2 ELSE u1 END)             ELSE u2          END AS player2_id,         CASE              WHEN u1_runs >= u2_runs THEN u1_runs              ELSE u2_runs          END AS runs1,         CASE              WHEN u1_runs <= u2_runs THEN u1_runs              ELSE u2_runs          END AS runs2,         runs, prank     FROM          match_part2 ) SELECT      match_id,      player1_id,      player2_id,      runs1,      runs2,      runs AS pship_runs  FROM      match_part3 WHERE      prank <= 1 ORDER BY      pship_runs DESC, match_id ASC;",
        "schema": {
            "public": {
                "ball_by_ball": [
                    "striker",
                    "non_striker",
                    "match_id",
                    "over_id",
                    "ball_id",
                    "innings_no"
                ],
                "batsman_scored": [
                    "match_id",
                    "over_id",
                    "ball_id",
                    "innings_no",
                    "runs_scored"
                ]
            }
        }
    },
    "local253": {
        "query": "WITH salary_cleaned AS (     SELECT          *,         REPLACE(REPLACE(REPLACE(Salary, '/yr', ''), '\u20b9', ''), ',', '') AS salary_clean     FROM SalaryDataset ), state_avg_salary AS (     SELECT          location,         companyname,         AVG(CAST(salary_clean AS REAL)) AS avg_sal_state     FROM salary_cleaned     WHERE location IN ('Mumbai', 'Pune', 'New Delhi', 'Hyderabad')     GROUP BY location, companyname ), state_ranked AS (     SELECT          location,         companyname,         avg_sal_state,         ROW_NUMBER() OVER (PARTITION BY location ORDER BY avg_sal_state DESC) AS row_number     FROM state_avg_salary ), state_top5 AS (     SELECT          location,         companyname,         avg_sal_state     FROM state_ranked     WHERE row_number <= 5 ), country_avg_salary AS (     SELECT          companyname,         ROUND(AVG(CAST(salary_clean AS REAL)), 2) AS avg_salary_final     FROM salary_cleaned     GROUP BY companyname ) SELECT      state_top5.location,     state_top5.companyname,     state_top5.avg_sal_state,     country_avg_salary.avg_salary_final AS avg_salary_country FROM state_top5 JOIN country_avg_salary ON state_top5.companyname = country_avg_salary.companyname",
        "schema": {
            "public": {
                "SalaryDataset": [
                    "Salary",
                    "location",
                    "companyname",
                    "salary_clean"
                ],
                "salary_cleaned": [
                    "*",
                    "salary_clean"
                ],
                "state_avg_salary": [
                    "location",
                    "companyname",
                    "avg_sal_state"
                ],
                "state_ranked": [
                    "location",
                    "companyname",
                    "avg_sal_state",
                    "row_number"
                ],
                "state_top5": [
                    "location",
                    "companyname",
                    "avg_sal_state"
                ],
                "country_avg_salary": [
                    "companyname",
                    "avg_salary_final"
                ]
            }
        }
    },
    "local262": {
        "query": "WITH total AS (     SELECT          name, COUNT(*) AS count     FROM         solution     GROUP BY name ), step_counts AS (     SELECT          A.name,         SUM(CASE WHEN A.step = 1 AND A.max_test_score < B.stack_score THEN 1 ELSE 0 END) AS count_step_1,         SUM(CASE WHEN A.step = 2 AND A.max_test_score < B.stack_score THEN 1 ELSE 0 END) AS count_step_2,         SUM(CASE WHEN A.step = 3 AND A.max_test_score < B.stack_score THEN 1 ELSE 0 END) AS count_step_3     FROM (         SELECT              name, version, step, MAX(test_score) AS max_test_score         FROM             model_score         WHERE             model NOT IN ('Stack')         GROUP BY name, version, step     ) AS A     INNER JOIN (         SELECT              name, version, step, test_score AS stack_score         FROM             model_score         WHERE             model = 'Stack'     ) AS B ON A.name = B.name AND A.version = B.version AND A.step = B.step     GROUP BY A.name ) SELECT      total.name AS problem FROM      total INNER JOIN      step_counts ON total.name = step_counts.name WHERE      (count_step_1 + count_step_2 + count_step_3) > total.count;",
        "schema": {
            "public": {
                "solution": [
                    "name"
                ],
                "model_score": [
                    "name",
                    "version",
                    "step",
                    "test_score",
                    "model"
                ],
                "total": [
                    "name",
                    "count"
                ],
                "step_counts": [
                    "name",
                    "count_step_1",
                    "count_step_2",
                    "count_step_3"
                ]
            }
        }
    },
    "local269": {
        "query": "WITH RECURSIVE recursive_pr (root_id, packaging_id, contains_id, qty, lvl) AS (     SELECT         pr.packaging_id AS root_id,         pr.packaging_id,         pr.contains_id,         pr.qty,         1 AS lvl     FROM packaging_relations pr     WHERE pr.packaging_id NOT IN (         SELECT c.contains_id FROM packaging_relations c     )     UNION ALL     SELECT         rpr.root_id,         pr.packaging_id,         pr.contains_id,         rpr.qty * pr.qty AS qty,         rpr.lvl + 1 AS lvl     FROM recursive_pr rpr     JOIN packaging_relations pr ON pr.packaging_id = rpr.contains_id ), ranked_recursive_pr AS (     SELECT         rpr.*,         ROW_NUMBER() OVER (PARTITION BY rpr.root_id ORDER BY rpr.lvl) AS rpr_order     FROM recursive_pr rpr ), leaf AS (     SELECT         rrp.*,         CASE             WHEN COALESCE(                 (SELECT MIN(lvl) FROM ranked_recursive_pr WHERE root_id = rrp.root_id AND lvl > rrp.lvl),                 0             ) > rrp.lvl THEN 0             ELSE 1         END AS is_leaf     FROM ranked_recursive_pr rrp ), packaging_combination_quantities AS (     SELECT         p.id AS packaging_id,         c.id AS contained_item_id,         SUM(leaf.qty) AS total_qty     FROM leaf     JOIN packaging p ON p.id = leaf.root_id     JOIN packaging c ON c.id = leaf.contains_id     WHERE leaf.is_leaf = 1     GROUP BY p.id, c.id ) SELECT     ROUND(AVG(total_qty), 2) AS avg_qty FROM packaging_combination_quantities;",
        "schema": {
            "public": {
                "packaging_relations": [
                    "packaging_id",
                    "contains_id",
                    "qty"
                ],
                "recursive_pr": [
                    "root_id",
                    "packaging_id",
                    "contains_id",
                    "qty",
                    "lvl"
                ],
                "ranked_recursive_pr": [
                    "root_id",
                    "packaging_id",
                    "contains_id",
                    "qty",
                    "lvl",
                    "rpr_order"
                ],
                "leaf": [
                    "root_id",
                    "packaging_id",
                    "contains_id",
                    "qty",
                    "lvl",
                    "rpr_order",
                    "is_leaf"
                ],
                "packaging": [
                    "id"
                ],
                "packaging_combination_quantities": [
                    "packaging_id",
                    "contained_item_id",
                    "total_qty"
                ]
            }
        }
    },
    "local270": {
        "query": "WITH RECURSIVE recursive_pr AS (    SELECT       pr.packaging_id AS root_id,       pr.packaging_id,       pr.contains_id,       pr.qty,       1 AS lvl    FROM packaging_relations pr    WHERE pr.packaging_id NOT IN (       SELECT contains_id FROM packaging_relations    )    UNION ALL    SELECT       rpr.root_id,       pr.packaging_id,       pr.contains_id,       rpr.qty * pr.qty AS qty,       rpr.lvl + 1 AS lvl    FROM recursive_pr rpr    JOIN packaging_relations pr ON pr.packaging_id = rpr.contains_id ), leaf AS (    SELECT       root_id,       contains_id,       SUM(qty) AS qty    FROM (       SELECT          rpr.*,          CASE             WHEN COALESCE(LEAD(rpr.lvl) OVER (ORDER BY rpr.contains_id), 0) > rpr.lvl             THEN 0             ELSE 1          END AS is_leaf       FROM recursive_pr rpr    )    WHERE is_leaf = 1    GROUP BY root_id, contains_id ) SELECT    p.name AS p_name,    c.name AS c_name FROM leaf JOIN packaging p ON p.id = leaf.root_id JOIN packaging c ON c.id = leaf.contains_id WHERE leaf.qty > 500 ORDER BY p.id, c.id;",
        "schema": {
            "public": {
                "packaging_relations": [
                    "packaging_id",
                    "contains_id",
                    "qty"
                ],
                "recursive_pr": [
                    "root_id",
                    "packaging_id",
                    "contains_id",
                    "qty",
                    "lvl"
                ],
                "packaging": [
                    "id",
                    "name"
                ],
                "leaf": [
                    "root_id",
                    "contains_id",
                    "qty"
                ]
            }
        }
    },
    "local272": {
        "query": "with orderlines_cte as (     select         ol.order_id,         ol.product_id,         ol.qty,         ifnull(             sum(ol.qty) over (                 partition by ol.product_id                 order by ol.order_id                 rows between unbounded preceding and 1 preceding             ), 0         ) + 1 as from_q,         ifnull(             sum(ol.qty) over (                 partition by ol.product_id                 order by ol.order_id                 rows between unbounded preceding and 1 preceding             ), 0         ) + ol.qty as to_q     from orderlines ol     where ol.order_id = 423 ), inventory_cte as (     select         i.product_id,         i.qty,         ifnull(             sum(i.qty) over (                 partition by i.product_id                 order by i.purchased, i.qty                 rows between unbounded preceding and 1 preceding             ), 0         ) as acc_prv_q,         i.purchased,         i.warehouse,         i.aisle,         i.position     from inventory_with_dims i ) select     i.product_id as product_id,     i.aisle as aisle,     i.position as position,     case         when i.qty < ob.qty - i.acc_prv_q then i.qty         else ob.qty - i.acc_prv_q     end as quantity_to_be_picked from orderlines_cte ol join (     select         product_id,         sum(qty) as qty     from orderlines_cte     group by product_id ) ob on ol.product_id = ob.product_id join inventory_cte i on i.product_id = ob.product_id where i.acc_prv_q < ob.qty   and ol.to_q >= i.acc_prv_q + 1   and ol.from_q <= case         when i.acc_prv_q + i.qty < ob.qty then i.acc_prv_q + i.qty         else ob.qty     end   and i.warehouse = 1 order by quantity_to_be_picked desc;",
        "schema": {
            "public": {
                "orderlines": [
                    "order_id",
                    "product_id",
                    "qty"
                ],
                "inventory_with_dims": [
                    "product_id",
                    "qty",
                    "purchased",
                    "warehouse",
                    "aisle",
                    "position"
                ]
            }
        }
    },
    "local273": {
        "query": "WITH olines AS (     SELECT         ol.order_id AS o_id,         ol.product_id AS p_id,         ol.qty,         COALESCE(SUM(ol.qty) OVER (             PARTITION BY ol.product_id             ORDER BY ol.order_id             ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING         ), 0) + 1 AS from_q,         COALESCE(SUM(ol.qty) OVER (             PARTITION BY ol.product_id             ORDER BY ol.order_id             ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING         ), 0) + ol.qty AS to_q     FROM orderlines ol ), orderbatch AS (     SELECT         ol.p_id,         SUM(ol.qty) AS qty     FROM olines ol     GROUP BY ol.p_id ), fifo AS (     SELECT         wh, ai, pos, p_id, loc_q,         MIN(loc_q, ord_q - acc_prv_q) AS pick_q,         acc_prv_q + 1 AS from_q,         MIN(acc_prv_q + loc_q, ord_q) AS to_q     FROM (         SELECT             i.product_id AS p_id,             ob.qty AS ord_q,             i.qty AS loc_q,             COALESCE(SUM(i.qty) OVER (                 PARTITION BY i.product_id                 ORDER BY i.purchased, i.qty                 ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING             ), 0) AS acc_prv_q,             i.purchased,             i.warehouse AS wh,             i.aisle AS ai,             i.position AS pos         FROM orderbatch ob         JOIN inventory_with_dims i ON i.product_id = ob.p_id     )     WHERE acc_prv_q < ord_q ), picked_data AS (     SELECT         f.wh, f.ai, f.pos, f.p_id,         f.pick_q, o.o_id,         MIN(             f.loc_q,             MIN(o.to_q, f.to_q) - MAX(o.from_q, f.from_q) + 1         ) AS q_f_o,         -- Calculate percentage of quantity picked         ROUND(             (MIN(                 f.loc_q,                 MIN(o.to_q, f.to_q) - MAX(o.from_q, f.from_q) + 1             ) * 100.0 / f.pick_q), 2         ) AS pick_percentage     FROM fifo f     JOIN olines o         ON o.p_id = f.p_id         AND o.to_q >= f.from_q         AND o.from_q <= f.to_q ) SELECT     p.name AS product_name,     AVG(pd.pick_percentage) AS avg_pick_percentage FROM picked_data pd JOIN products p ON p.id = pd.p_id GROUP BY p.name ORDER BY p.name;",
        "schema": {
            "public": {
                "orderlines": [
                    "order_id",
                    "product_id",
                    "qty"
                ],
                "inventory_with_dims": [
                    "product_id",
                    "qty",
                    "purchased",
                    "warehouse",
                    "aisle",
                    "position"
                ],
                "products": [
                    "id",
                    "name"
                ],
                "olines": [
                    "o_id",
                    "p_id",
                    "qty",
                    "from_q",
                    "to_q"
                ],
                "orderbatch": [
                    "p_id",
                    "qty"
                ],
                "fifo": [
                    "wh",
                    "ai",
                    "pos",
                    "p_id",
                    "loc_q",
                    "pick_q",
                    "from_q",
                    "to_q"
                ],
                "picked_data": [
                    "wh",
                    "ai",
                    "pos",
                    "p_id",
                    "pick_q",
                    "o_id",
                    "q_f_o",
                    "pick_percentage"
                ]
            }
        }
    },
    "local274": {
        "query": "WITH olines AS (     SELECT         ol.order_id AS o_id,         ol.product_id AS p_id,         ol.qty,         IFNULL((             SELECT SUM(ol2.qty)             FROM orderlines ol2             WHERE ol2.product_id = ol.product_id               AND ol2.order_id < ol.order_id         ), 0) + 1 AS from_q,         IFNULL((             SELECT SUM(ol2.qty)             FROM orderlines ol2             WHERE ol2.product_id = ol.product_id               AND ol2.order_id < ol.order_id         ), 0) + ol.qty AS to_q     FROM orderlines ol     WHERE ol.order_id = 421 ), orderbatch AS (     SELECT         ol.p_id,         SUM(ol.qty) AS qty     FROM olines ol     GROUP BY ol.p_id ), fifo AS (     SELECT         wh, ai, pos, p_id, loc_q,         MIN(loc_q, ord_q - acc_prv_q) AS pick_q,         acc_prv_q + 1 AS from_q,         MIN(acc_prv_q + loc_q, ord_q) AS to_q     FROM (         SELECT             i.product_id AS p_id,             ob.qty AS ord_q,             i.qty AS loc_q,             IFNULL((                 SELECT SUM(i2.qty)                 FROM inventory_with_dims i2                 WHERE i2.product_id = i.product_id                   AND (i2.purchased < i.purchased OR (i2.purchased = i.purchased AND i2.qty < i.qty))             ), 0) AS acc_prv_q,             i.purchased,             i.warehouse AS wh,             i.aisle AS ai,             i.position AS pos         FROM orderbatch ob         JOIN inventory_with_dims i           ON i.product_id = ob.p_id     ) sub     WHERE acc_prv_q < ord_q ), pick AS (     SELECT         f.wh, f.ai,         DENSE_RANK() OVER (             ORDER BY wh, ai         ) AS ai_rank,         f.pos, f.p_id,         f.pick_q, o.o_id,         MIN(             f.loc_q,             MIN(o.to_q, f.to_q) - MAX(o.from_q, f.from_q) + 1         ) AS q_f_o     FROM fifo f     JOIN olines o       ON o.p_id = f.p_id      AND o.to_q >= f.from_q      AND o.from_q <= f.to_q ) SELECT     pr.name AS product_name,     AVG(p.pick_q) AS avg_units_picked FROM pick p JOIN products pr ON pr.id = p.p_id GROUP BY p.p_id, pr.name ORDER BY p.p_id;",
        "schema": {
            "public": {
                "orderlines": [
                    "order_id",
                    "product_id",
                    "qty"
                ],
                "inventory_with_dims": [
                    "product_id",
                    "qty",
                    "purchased",
                    "warehouse",
                    "aisle",
                    "position"
                ],
                "products": [
                    "id",
                    "name"
                ]
            }
        }
    },
    "local275": {
        "query": "WITH RECURSIVE date_series AS (     SELECT date('2016-01-01') AS mth, 1 AS ts     UNION ALL     SELECT date(mth, '+1 month'), ts + 1     FROM date_series     WHERE ts < 48 ), s1 AS (     SELECT         ms.product_id,         mths.mth,         mths.ts,         strftime('%Y', mths.mth) AS yr,         strftime('%m', mths.mth) AS mthno,         ms.qty     FROM date_series mths     LEFT JOIN (         SELECT product_id, mth, qty         FROM monthly_sales     ) ms     ON ms.mth = mths.mth ), s2 AS (     SELECT         product_id,         mth,         ts,         yr,         mthno,         qty,         CASE             WHEN ts BETWEEN 7 AND 30 THEN                 (ifnull(AVG(qty) OVER (                     PARTITION BY product_id                     ORDER BY ts                     ROWS BETWEEN 5 PRECEDING AND 6 FOLLOWING                 ), 0) + ifnull(AVG(qty) OVER (                     PARTITION BY product_id                     ORDER BY ts                     ROWS BETWEEN 6 PRECEDING AND 5 FOLLOWING                 ), 0)) / 2             ELSE                 NULL         END AS cma     FROM s1 ), s3 AS (     SELECT         s2.product_id,         s2.mth,         s2.ts,         s2.yr,         s2.mthno,         s2.qty,         s2.cma,         ifnull(AVG(             CASE WHEN s2.qty = 0 THEN 0.0001 ELSE s2.qty END / NULLIF(s2.cma, 0)         ) OVER (             PARTITION BY s2.product_id, s2.mthno         ), 0) AS s     FROM s2 ) SELECT DISTINCT     p.name AS product_name FROM s3 JOIN products p ON p.id = s3.product_id WHERE s3.s > 2     AND strftime('%Y', s3.mth) = '2017' ORDER BY p.name, s3.mth;",
        "schema": {
            "public": {
                "date_series": [
                    "mth",
                    "ts"
                ],
                "monthly_sales": [
                    "product_id",
                    "mth",
                    "qty"
                ],
                "s1": [
                    "product_id",
                    "mth",
                    "ts",
                    "yr",
                    "mthno",
                    "qty"
                ],
                "s2": [
                    "product_id",
                    "mth",
                    "ts",
                    "yr",
                    "mthno",
                    "qty",
                    "cma"
                ],
                "s3": [
                    "product_id",
                    "mth",
                    "ts",
                    "yr",
                    "mthno",
                    "qty",
                    "cma",
                    "s"
                ],
                "products": [
                    "id",
                    "name"
                ]
            }
        }
    },
    "local277": {
        "query": "WITH RECURSIVE mths AS (     SELECT         date('2016-01-01') AS mth,         1 AS ts     UNION ALL     SELECT         date(mth, '+1 month'),         ts + 1     FROM mths     WHERE ts < 48 ), s1 AS (     SELECT         ms.product_id,         mths.mth,         mths.ts,         strftime('%Y', mths.mth) AS yr,         strftime('%m', mths.mth) AS mthno,         COALESCE(ms.qty, 0) AS qty     FROM mths     LEFT JOIN monthly_sales ms ON ms.mth = mths.mth AND ms.product_id IN (4160, 7790) ), s2 AS (     SELECT         product_id,         mth,         ts,         yr,         mthno,         qty,         CASE             WHEN ts BETWEEN 7 AND 30 THEN (                 COALESCE(AVG(qty) OVER (                     PARTITION BY product_id                     ORDER BY ts                     ROWS BETWEEN 5 PRECEDING AND 6 FOLLOWING                 ), 0) + COALESCE(AVG(qty) OVER (                     PARTITION BY product_id                     ORDER BY ts                     ROWS BETWEEN 6 PRECEDING AND 5 FOLLOWING                 ), 0)) / 2             ELSE NULL         END AS cma     FROM s1 ), s3 AS (     SELECT         product_id,         mth,         ts,         yr,         mthno,         qty,         cma,         COALESCE(AVG(CASE             WHEN qty = 0 THEN 0.0001             ELSE qty         END / NULLIF(cma, 0)) OVER (             PARTITION BY product_id, mthno         ), 0) AS s     FROM s2 ), s4 AS (     SELECT         product_id,         mth,         ts,         yr,         mthno,         qty,         cma,         s,         CASE             WHEN ts <= 36 THEN COALESCE(CASE                 WHEN qty = 0 THEN 0.0001                 ELSE qty             END / NULLIF(s, 0), 0)         END AS des     FROM s3 ), s5 AS (     SELECT         product_id,         mth,         ts,         yr,         mthno,         qty,         cma,         s,         des,         (AVG(des * ts) OVER (PARTITION BY product_id) -          AVG(des) OVER (PARTITION BY product_id) * AVG(ts) OVER (PARTITION BY product_id)) /         (AVG(ts * ts) OVER (PARTITION BY product_id) -          AVG(ts) OVER (PARTITION BY product_id) * AVG(ts) OVER (PARTITION BY product_id)) AS slope,         AVG(des) OVER (PARTITION BY product_id) -          (AVG(des * ts) OVER (PARTITION BY product_id) -          AVG(des) OVER (PARTITION BY product_id) * AVG(ts) OVER (PARTITION BY product_id)) /         (AVG(ts * ts) OVER (PARTITION BY product_id) -          AVG(ts) OVER (PARTITION BY product_id) * AVG(ts) OVER (PARTITION BY product_id)) * AVG(ts) OVER (PARTITION BY product_id) AS intercept     FROM s4 ) SELECT     ROUND(AVG((intercept + ts * slope) * s), 2) AS avg_forecasted_annual_sales FROM s5 WHERE yr = '2018';",
        "schema": {
            "public": {
                "monthly_sales": [
                    "product_id",
                    "mth",
                    "qty"
                ]
            }
        }
    },
    "local279": {
        "query": "WITH RECURSIVE mb_recur AS (    -- Initial data selection    SELECT       it.product_id,       date('2018-12-01') AS mth,       0 AS qty,       0 AS inv_begin,       NULL AS date_purch,       0 AS p_qty,       it.qty AS inv_end,       pm.qty_minimum,       pm.qty_purchase    FROM inventory_totals it    JOIN product_minimums pm ON pm.product_id = it.product_id     UNION ALL     -- Recursive step    SELECT       mb.product_id,       date(mb.mth, '+1 month') AS mth,       CASE          WHEN mbr.inv_end - COALESCE(mb.qty, 0) > 0 THEN mbr.inv_end - COALESCE(mb.qty, 0)          ELSE 0       END AS qty,       mbr.inv_end AS inv_begin,       CASE          WHEN mbr.inv_end - COALESCE(mb.qty, 0) < mbr.qty_minimum THEN             date(mbr.mth, '+' || CAST(((strftime('%s', date(mb.mth, '+1 month')) - strftime('%s', mbr.mth)) * (mbr.inv_end - mbr.qty_minimum)) / mb.qty AS INTEGER) || ' month')       END AS date_purch,       CASE          WHEN mbr.inv_end - COALESCE(mb.qty, 0) < mbr.qty_minimum THEN mbr.qty_purchase       END AS p_qty,       mbr.inv_end - COALESCE(mb.qty, 0) + CASE          WHEN mbr.inv_end - COALESCE(mb.qty, 0) < mbr.qty_minimum THEN mbr.qty_purchase          ELSE 0       END AS inv_end,       mbr.qty_minimum,       mbr.qty_purchase    FROM mb_recur mbr    JOIN monthly_budget mb ON mb.product_id = mbr.product_id AND mb.mth = date(mbr.mth, '+1 month')    LEFT JOIN monthly_orders mo ON mo.product_id = mb.product_id AND mo.mth = mb.mth ), inventory_diff AS (    SELECT       m.product_id,       m.mth,       ABS(m.inv_end - m.qty_minimum) AS diff    FROM mb_recur m    WHERE m.mth >= date('2019-01-01')      AND m.mth < date('2020-01-01') ), min_diff AS (    SELECT       product_id,       MIN(diff) AS min_diff    FROM inventory_diff    GROUP BY product_id ) SELECT    d.product_id,    d.mth AS date,    d.diff FROM inventory_diff d JOIN min_diff md ON d.product_id = md.product_id AND d.diff = md.min_diff ORDER BY d.product_id, d.mth;",
        "schema": {
            "public": {
                "inventory_totals": [
                    "product_id",
                    "qty"
                ],
                "product_minimums": [
                    "product_id",
                    "qty_minimum",
                    "qty_purchase"
                ],
                "monthly_budget": [
                    "product_id",
                    "mth",
                    "qty"
                ],
                "monthly_orders": [
                    "product_id",
                    "mth"
                ],
                "mb_recur": [
                    "product_id",
                    "mth",
                    "qty",
                    "inv_begin",
                    "date_purch",
                    "p_qty",
                    "inv_end",
                    "qty_minimum",
                    "qty_purchase"
                ],
                "inventory_diff": [
                    "product_id",
                    "mth",
                    "diff"
                ],
                "min_diff": [
                    "product_id",
                    "min_diff"
                ]
            }
        }
    },
    "local283": {
        "query": "WITH TABLE_1 AS (     SELECT          Match.id,         Country.name AS country_name,          League.name AS league_name,          season,          stage,          date,         HT.team_long_name AS home_team,         AT.team_long_name AS away_team,         home_team_goal,          away_team_goal,         CASE             WHEN home_team_goal > away_team_goal THEN \"Win\"             WHEN home_team_goal < away_team_goal THEN \"Loss\"             ELSE \"Tie\"         END AS home_team_result,          CASE             WHEN away_team_goal > home_team_goal THEN \"Win\"             WHEN away_team_goal < home_team_goal THEN \"Loss\"             ELSE \"Tie\"         END AS away_team_result     FROM Match     JOIN Country ON Country.id = Match.country_id     JOIN League ON League.id = Match.league_id     LEFT JOIN Team AS HT ON HT.team_api_id = Match.home_team_api_id     LEFT JOIN Team AS AT ON AT.team_api_id = Match.away_team_api_id ), HOME_TEAM AS (     SELECT          id,         country_name,          league_name,          season,          stage,          date,         home_team AS team,          'Home' AS team_type,         home_team_goal AS goals,         home_team_result AS result     FROM TABLE_1 ), AWAY_TEAM AS (     SELECT          id,         country_name,          league_name,          season,          stage,          date,         away_team AS team,          'Away' AS team_type,         away_team_goal AS goals,         away_team_result AS result     FROM TABLE_1 ),  TABLE_2 AS (     SELECT *      FROM HOME_TEAM     UNION ALL     SELECT *      FROM AWAY_TEAM ), TABLE_3 AS (     SELECT *,          CASE              WHEN result = 'Win' THEN 3             WHEN result = 'Tie' THEN 1             ELSE 0         END AS points     FROM TABLE_2 ),  TABLE_4 AS (     SELECT         season,         team,         league_name,         country_name,         SUM(points) AS total_points,         RANK() OVER(PARTITION BY season ORDER BY SUM(points) DESC) AS season_rank     FROM TABLE_3     GROUP BY          season,          team,         league_name,         country_name     ORDER BY total_points DESC ) SELECT *  FROM TABLE_4  WHERE season_rank = 1 ORDER BY total_points DESC;",
        "schema": {
            "public": {
                "Match": [
                    "id",
                    "country_id",
                    "league_id",
                    "season",
                    "stage",
                    "date",
                    "home_team_api_id",
                    "away_team_api_id",
                    "home_team_goal",
                    "away_team_goal"
                ],
                "Country": [
                    "id",
                    "name"
                ],
                "League": [
                    "id",
                    "name"
                ],
                "Team": [
                    "team_api_id",
                    "team_long_name"
                ],
                "TABLE_1": [
                    "id",
                    "country_name",
                    "league_name",
                    "season",
                    "stage",
                    "date",
                    "home_team",
                    "away_team",
                    "home_team_goal",
                    "away_team_goal",
                    "home_team_result",
                    "away_team_result"
                ],
                "HOME_TEAM": [
                    "id",
                    "country_name",
                    "league_name",
                    "season",
                    "stage",
                    "date",
                    "team",
                    "team_type",
                    "goals",
                    "result"
                ],
                "AWAY_TEAM": [
                    "id",
                    "country_name",
                    "league_name",
                    "season",
                    "stage",
                    "date",
                    "team",
                    "team_type",
                    "goals",
                    "result"
                ],
                "TABLE_2": [
                    "id",
                    "country_name",
                    "league_name",
                    "season",
                    "stage",
                    "date",
                    "team",
                    "team_type",
                    "goals",
                    "result"
                ],
                "TABLE_3": [
                    "id",
                    "country_name",
                    "league_name",
                    "season",
                    "stage",
                    "date",
                    "team",
                    "team_type",
                    "goals",
                    "result",
                    "points"
                ],
                "TABLE_4": [
                    "season",
                    "team",
                    "league_name",
                    "country_name",
                    "total_points",
                    "season_rank"
                ]
            }
        }
    },
    "local284": {
        "query": "WITH avg_loss_tb AS (     SELECT          AVG([Loss_Rate_%]) AS avg_loss_rate,         COUNT([index]) AS total_num      FROM          loss_rate_df     WHERE          [loss_rate_%] <> '' ),  std AS (     SELECT          ROUND(SQRT(SUM(POWER(([Loss_Rate_%] - (SELECT avg_loss_rate FROM avg_loss_tb)), 2)) / alt.total_num), 2) AS std     FROM          loss_rate_df lrd, avg_loss_tb alt ) SELECT     AVG([Loss_Rate_%]) AS 'avg_loss_rate_%',     SUM(         CASE             WHEN [Loss_Rate_%] BETWEEN (SELECT avg_loss_rate FROM avg_loss_tb) - (SELECT std FROM std) AND (SELECT avg_loss_rate FROM avg_loss_tb) + (SELECT std FROM std) THEN 1             ELSE 0         END     ) AS items_within_stdev,     SUM(         CASE             WHEN [Loss_Rate_%] > ((SELECT avg_loss_rate FROM avg_loss_tb) + (SELECT std FROM std)) THEN 1             ELSE 0         END     ) AS above_stdev,     SUM(         CASE             WHEN [Loss_Rate_%] < ((SELECT avg_loss_rate FROM avg_loss_tb) - (SELECT std FROM std)) THEN 1             ELSE 0         END     ) AS items_below_stdev FROM      loss_rate_df;",
        "schema": {
            "public": {
                "loss_rate_df": [
                    "Loss_Rate_%",
                    "index"
                ],
                "avg_loss_tb": [
                    "avg_loss_rate",
                    "total_num"
                ],
                "std": [
                    "std"
                ]
            }
        }
    },
    "local285": {
        "query": "WITH item_2020 AS (     SELECT         strftime('%Y', v.[txn_date]) AS 'yr',         c.category_code,         c.category_name,         ROUND(AVG(`whsle_px_rmb-kg`), 2) AS avg_whole_sale,         ROUND(MAX(`whsle_px_rmb-kg`), 2) AS max_whole_sale,         ROUND(MIN(`whsle_px_rmb-kg`), 2) AS min_whole_sale,         ROUND(ROUND(MAX(`whsle_px_rmb-kg`), 2) - ROUND(MIN(`whsle_px_rmb-kg`), 2), 2) AS whole_sale_diff,         ROUND(SUM((v.`qty_sold(kg)`) * (w.`whsle_px_rmb-kg`)), 2) AS whole_sale_price,         ROUND(SUM((v.`unit_selling_px_rmb/kg`) * (v.`qty_sold(kg)`)), 2) AS selling_price,         ROUND(AVG(alr.`loss_rate_%`), 2) AS 'avg_loss_rate_%'     FROM veg_txn_df v     LEFT JOIN veg_whsle_df w ON v.txn_date = w.whsle_date AND v.item_code = w.item_code     LEFT JOIN veg_cat c ON v.item_code = c.item_code     LEFT JOIN loss_rate_df alr ON alr.item_code = v.item_code     WHERE v.`qty_sold(kg)` > 0 AND yr = '2020'     GROUP BY strftime('%Y', v.[txn_date]), c.category_code, c.category_name ), item_2021 AS (     SELECT         strftime('%Y', v.[txn_date]) AS 'yr',         c.category_code,         c.category_name,         ROUND(AVG(`whsle_px_rmb-kg`), 2) AS avg_whole_sale,         ROUND(MAX(`whsle_px_rmb-kg`), 2) AS max_whole_sale,         ROUND(MIN(`whsle_px_rmb-kg`), 2) AS min_whole_sale,         ROUND(ROUND(MAX(`whsle_px_rmb-kg`), 2) - ROUND(MIN(`whsle_px_rmb-kg`), 2), 2) AS whole_sale_diff,         ROUND(SUM((v.`qty_sold(kg)`) * (w.`whsle_px_rmb-kg`)), 2) AS whole_sale_price,         ROUND(SUM((v.`unit_selling_px_rmb/kg`) * (v.`qty_sold(kg)`)), 2) AS selling_price,         ROUND(AVG(alr.`loss_rate_%`), 2) AS 'avg_loss_rate_%'     FROM veg_txn_df v     LEFT JOIN veg_whsle_df w ON v.txn_date = w.whsle_date AND v.item_code = w.item_code     LEFT JOIN veg_cat c ON v.item_code = c.item_code     LEFT JOIN loss_rate_df alr ON alr.item_code = v.item_code     WHERE v.`qty_sold(kg)` > 0 AND yr = '2021'     GROUP BY strftime('%Y', v.[txn_date]), c.category_code, c.category_name ), item_2022 AS (     SELECT         strftime('%Y', v.[txn_date]) AS 'yr',         c.category_code,         c.category_name,         ROUND(AVG(`whsle_px_rmb-kg`), 2) AS avg_whole_sale,         ROUND(MAX(`whsle_px_rmb-kg`), 2) AS max_whole_sale,         ROUND(MIN(`whsle_px_rmb-kg`), 2) AS min_whole_sale,         ROUND(ROUND(MAX(`whsle_px_rmb-kg`), 2) - ROUND(MIN(`whsle_px_rmb-kg`), 2), 2) AS whole_sale_diff,         ROUND(SUM((v.`qty_sold(kg)`) * (w.`whsle_px_rmb-kg`)), 2) AS whole_sale_price,         ROUND(SUM((v.`unit_selling_px_rmb/kg`) * (v.`qty_sold(kg)`)), 2) AS selling_price,         ROUND(AVG(alr.`loss_rate_%`), 2) AS 'avg_loss_rate_%'     FROM veg_txn_df v     LEFT JOIN veg_whsle_df w ON v.txn_date = w.whsle_date AND v.item_code = w.item_code     LEFT JOIN veg_cat c ON v.item_code = c.item_code     LEFT JOIN loss_rate_df alr ON alr.item_code = v.item_code     WHERE v.`qty_sold(kg)` > 0 AND yr = '2022'     GROUP BY strftime('%Y', v.[txn_date]), c.category_code, c.category_name ), item_2023 AS (     SELECT         strftime('%Y', v.[txn_date]) AS 'yr',         c.category_code,         c.category_name,         ROUND(AVG(`whsle_px_rmb-kg`), 2) AS avg_whole_sale,         ROUND(MAX(`whsle_px_rmb-kg`), 2) AS max_whole_sale,         ROUND(MIN(`whsle_px_rmb-kg`), 2) AS min_whole_sale,         ROUND(MAX(`whsle_px_rmb-kg`), 2) - ROUND(MIN(`whsle_px_rmb-kg`), 2) AS whole_sale_diff,         ROUND(SUM((v.`qty_sold(kg)`) * (w.`whsle_px_rmb-kg`)), 2) AS whole_sale_price,         ROUND(SUM((v.`unit_selling_px_rmb/kg`) * (v.`qty_sold(kg)`)), 2) AS selling_price,         ROUND(AVG(alr.`loss_rate_%`), 2) AS 'avg_loss_rate_%'     FROM veg_txn_df v     LEFT JOIN veg_whsle_df w ON v.txn_date = w.whsle_date AND v.item_code = w.item_code     LEFT JOIN veg_cat c ON v.item_code = c.item_code     LEFT JOIN loss_rate_df alr ON alr.item_code = v.item_code     WHERE v.`qty_sold(kg)` > 0 AND yr = '2023'     GROUP BY strftime('%Y', v.[txn_date]), c.category_code, c.category_name ), final_item AS (     SELECT * FROM item_2020     UNION     SELECT * FROM item_2021     UNION     SELECT * FROM item_2022     UNION     SELECT * FROM item_2023 )  SELECT *,     ROUND(((`avg_loss_rate_%` * whole_sale_price) / 100.00), 2) AS total_loss,     ROUND(((selling_price - whole_sale_price) - (`avg_loss_rate_%` * whole_sale_price) / 100.00), 2) AS profit FROM final_item;",
        "schema": {
            "public": {
                "veg_txn_df": [
                    "txn_date",
                    "item_code",
                    "qty_sold(kg)",
                    "unit_selling_px_rmb/kg"
                ],
                "veg_whsle_df": [
                    "whsle_date",
                    "item_code",
                    "whsle_px_rmb-kg"
                ],
                "veg_cat": [
                    "item_code",
                    "category_code",
                    "category_name"
                ],
                "loss_rate_df": [
                    "item_code",
                    "loss_rate_%"
                ],
                "item_2020": [
                    "yr",
                    "category_code",
                    "category_name",
                    "avg_whole_sale",
                    "max_whole_sale",
                    "min_whole_sale",
                    "whole_sale_diff",
                    "whole_sale_price",
                    "selling_price",
                    "avg_loss_rate_%"
                ],
                "item_2021": [
                    "yr",
                    "category_code",
                    "category_name",
                    "avg_whole_sale",
                    "max_whole_sale",
                    "min_whole_sale",
                    "whole_sale_diff",
                    "whole_sale_price",
                    "selling_price",
                    "avg_loss_rate_%"
                ],
                "item_2022": [
                    "yr",
                    "category_code",
                    "category_name",
                    "avg_whole_sale",
                    "max_whole_sale",
                    "min_whole_sale",
                    "whole_sale_diff",
                    "whole_sale_price",
                    "selling_price",
                    "avg_loss_rate_%"
                ],
                "item_2023": [
                    "yr",
                    "category_code",
                    "category_name",
                    "avg_whole_sale",
                    "max_whole_sale",
                    "min_whole_sale",
                    "whole_sale_diff",
                    "whole_sale_price",
                    "selling_price",
                    "avg_loss_rate_%"
                ],
                "final_item": [
                    "yr",
                    "category_code",
                    "category_name",
                    "avg_whole_sale",
                    "max_whole_sale",
                    "min_whole_sale",
                    "whole_sale_diff",
                    "whole_sale_price",
                    "selling_price",
                    "avg_loss_rate_%"
                ]
            }
        }
    },
    "local286": {
        "query": "WITH products2 AS (     SELECT          product_id,          cn.product_category_name_english AS product_name     FROM          products AS pd     LEFT JOIN          product_category_name_translation AS cn     ON          pd.product_category_name = cn.product_category_name ), product_frequency AS (     SELECT          oi.seller_id,          pd2.product_name,          COUNT(*) AS product_count     FROM          order_items AS oi     JOIN          products2 AS pd2      ON          oi.product_id = pd2.product_id     GROUP BY          oi.seller_id, pd2.product_name ), max_product_frequency AS (     SELECT          seller_id,          product_name AS highlight_product,         product_count     FROM          product_frequency     WHERE          (seller_id, product_count) IN (             SELECT                  seller_id,                  MAX(product_count)             FROM                  product_frequency             GROUP BY                  seller_id         ) ), seller2 AS (     SELECT          oi.seller_id,          SUM(oi.price) AS total_sales,         AVG(oi.price) AS avg_price,         AVG(r.review_score) AS avg_review_score,         AVG(julianday(o.order_delivered_carrier_date) - julianday(o.order_purchase_timestamp)) AS avg_packing_time,         COUNT(*) AS product_cnt,         mpf.highlight_product     FROM          order_items AS oi     LEFT JOIN          orders AS o      ON          o.order_id = oi.order_id     LEFT JOIN          order_reviews AS r      ON          o.order_id = r.order_id     LEFT JOIN          max_product_frequency AS mpf      ON          oi.seller_id = mpf.seller_id     GROUP BY          oi.seller_id     ORDER BY          product_cnt DESC ) SELECT      seller_id,      product_cnt,      avg_price,      total_sales,      avg_packing_time,      avg_review_score,      highlight_product FROM      seller2 WHERE      product_cnt > 100;",
        "schema": {
            "public": {
                "products": [
                    "product_id",
                    "product_category_name"
                ],
                "product_category_name_translation": [
                    "product_category_name",
                    "product_category_name_english"
                ],
                "order_items": [
                    "seller_id",
                    "product_id",
                    "price",
                    "order_id"
                ],
                "orders": [
                    "order_id",
                    "order_delivered_carrier_date",
                    "order_purchase_timestamp"
                ],
                "order_reviews": [
                    "order_id",
                    "review_score"
                ],
                "products2": [
                    "product_id",
                    "product_name"
                ],
                "product_frequency": [
                    "seller_id",
                    "product_name",
                    "product_count"
                ],
                "max_product_frequency": [
                    "seller_id",
                    "highlight_product",
                    "product_count"
                ],
                "seller2": [
                    "seller_id",
                    "total_sales",
                    "avg_price",
                    "avg_review_score",
                    "avg_packing_time",
                    "product_cnt",
                    "highlight_product"
                ]
            }
        }
    },
    "local301": {
        "query": "SELECT      before_effect,     after_effect,     after_effect - before_effect AS change_amount,     ROUND(((after_effect * 1.0 / before_effect) - 1) * 100, 2) AS percent_change,     '2018' AS year FROM (     SELECT          SUM(CASE WHEN delta_weeks BETWEEN 1 AND 4 THEN sales END) AS after_effect,         SUM(CASE WHEN delta_weeks BETWEEN -3 AND 0 THEN sales END) AS before_effect     FROM (         SELECT              week_date,             ROUND((JULIANDAY(week_date) - JULIANDAY('2018-06-15')) / 7.0) + 1 AS delta_weeks,             sales          FROM cleaned_weekly_sales     ) add_delta_weeks ) AS add_before_after UNION ALL SELECT      before_effect,     after_effect,     after_effect - before_effect AS change_amount,     ROUND(((after_effect * 1.0 / before_effect) - 1) * 100, 2) AS percent_change,     '2019' AS year FROM (     SELECT          SUM(CASE WHEN delta_weeks BETWEEN 1 AND 4 THEN sales END) AS after_effect,         SUM(CASE WHEN delta_weeks BETWEEN -3 AND 0 THEN sales END) AS before_effect     FROM (         SELECT              week_date,             ROUND((JULIANDAY(week_date) - JULIANDAY('2019-06-15')) / 7.0) + 1 AS delta_weeks,             sales          FROM cleaned_weekly_sales     ) add_delta_weeks ) AS add_before_after UNION ALL SELECT      before_effect,     after_effect,     after_effect - before_effect AS change_amount,     ROUND(((after_effect * 1.0 / before_effect) - 1) * 100, 2) AS percent_change,     '2020' AS year FROM (     SELECT          SUM(CASE WHEN delta_weeks BETWEEN 1 AND 4 THEN sales END) AS after_effect,         SUM(CASE WHEN delta_weeks BETWEEN -3 AND 0 THEN sales END) AS before_effect     FROM (         SELECT              week_date,             ROUND((JULIANDAY(week_date) - JULIANDAY('2020-06-15')) / 7.0) + 1 AS delta_weeks,             sales          FROM cleaned_weekly_sales     ) add_delta_weeks ) AS add_before_after ORDER BY year;",
        "schema": {
            "public": {
                "cleaned_weekly_sales": [
                    "week_date",
                    "sales"
                ],
                "add_delta_weeks": [
                    "delta_weeks",
                    "sales"
                ],
                "add_before_after": [
                    "after_effect",
                    "before_effect"
                ]
            }
        }
    },
    "local302": {
        "query": "SELECT metric, ROUND(AVG(percent_change), 2) AS avg_percent_change FROM (     SELECT 'region' AS metric,            LOWER(region) AS value,            before_effect,            after_effect,            after_effect - before_effect AS change,            ROUND(((after_effect * 1.0 / before_effect) - 1) * 100, 2) AS percent_change     FROM (         SELECT region,                SUM(CASE WHEN delta_weeks BETWEEN 1 AND 12 THEN sales END) AS after_effect,                SUM(CASE WHEN delta_weeks BETWEEN -11 AND 0 THEN sales END) AS before_effect         FROM (             SELECT region,                    week_date,                    ROUND((JULIANDAY(week_date) - JULIANDAY('2020-06-15')) / 7.0) + 1 AS delta_weeks,                    sales              FROM cleaned_weekly_sales         ) add_delta_weeks         GROUP BY region     ) AS add_before_after      UNION ALL       SELECT 'platform' AS metric,            LOWER(platform) AS value,            before_effect,            after_effect,            after_effect - before_effect AS change,            ROUND(((after_effect * 1.0 / before_effect) - 1) * 100, 2) AS percent_change     FROM (         SELECT platform,                SUM(CASE WHEN delta_weeks BETWEEN 1 AND 12 THEN sales END) AS after_effect,                SUM(CASE WHEN delta_weeks BETWEEN -11 AND 0 THEN sales END) AS before_effect         FROM (             SELECT platform,                    week_date,                    ROUND((JULIANDAY(week_date) - JULIANDAY('2020-06-15')) / 7.0) + 1 AS delta_weeks,                    sales              FROM cleaned_weekly_sales         ) add_delta_weeks         GROUP BY platform     ) AS add_before_after      UNION ALL       SELECT 'age_band' AS metric,            LOWER(age_band) AS value,            before_effect,            after_effect,            after_effect - before_effect AS change,            ROUND(((after_effect * 1.0 / before_effect) - 1) * 100, 2) AS percent_change     FROM (         SELECT age_band,                SUM(CASE WHEN delta_weeks BETWEEN 1 AND 12 THEN sales END) AS after_effect,                SUM(CASE WHEN delta_weeks BETWEEN -11 AND 0 THEN sales END) AS before_effect         FROM (             SELECT age_band,                    week_date,                    ROUND((JULIANDAY(week_date) - JULIANDAY('2020-06-15')) / 7.0) + 1 AS delta_weeks,                    sales              FROM cleaned_weekly_sales         ) add_delta_weeks         GROUP BY age_band     ) AS add_before_after      UNION ALL       SELECT 'demographic' AS metric,            LOWER(demographic) AS value,            before_effect,            after_effect,            after_effect - before_effect AS change,            ROUND(((after_effect * 1.0 / before_effect) - 1) * 100, 2) AS percent_change     FROM (         SELECT demographic,                SUM(CASE WHEN delta_weeks BETWEEN 1 AND 12 THEN sales END) AS after_effect,                SUM(CASE WHEN delta_weeks BETWEEN -11 AND 0 THEN sales END) AS before_effect         FROM (             SELECT demographic,                    week_date,                    ROUND((JULIANDAY(week_date) - JULIANDAY('2020-06-15')) / 7.0) + 1 AS delta_weeks,                    sales              FROM cleaned_weekly_sales         ) add_delta_weeks         GROUP BY demographic     ) AS add_before_after      UNION ALL       SELECT 'customer_type' AS metric,            LOWER(customer_type) AS value,            before_effect,            after_effect,            after_effect - before_effect AS change,            ROUND(((after_effect * 1.0 / before_effect) - 1) * 100, 2) AS percent_change     FROM (         SELECT customer_type,                SUM(CASE WHEN delta_weeks BETWEEN 1 AND 12 THEN sales END) AS after_effect,                SUM(CASE WHEN delta_weeks BETWEEN -11 AND 0 THEN sales END) AS before_effect         FROM (             SELECT customer_type,                    week_date,                    ROUND((JULIANDAY(week_date) - JULIANDAY('2020-06-15')) / 7.0) + 1 AS delta_weeks,                    sales              FROM cleaned_weekly_sales         ) add_delta_weeks         GROUP BY customer_type     ) AS add_before_after ) AS tmp GROUP BY metric ORDER BY avg_percent_change LIMIT 1;",
        "schema": {
            "public": {
                "cleaned_weekly_sales": [
                    "region",
                    "platform",
                    "age_band",
                    "demographic",
                    "customer_type",
                    "week_date",
                    "sales"
                ]
            }
        }
    },
    "local329": {
        "query": "WITH mst_fallout_step AS (   -- Define the stages and paths   SELECT        1 AS step, '/regist/input' AS path   UNION ALL   SELECT        2 AS step, '/regist/confirm' AS path ), form_log_with_fallout_step AS (   SELECT       l.session,       m.step,       m.path,       MAX(l.stamp) AS max_stamp,       MIN(l.stamp) AS min_stamp   FROM       mst_fallout_step AS m       JOIN form_log AS l       ON m.path = l.path   WHERE        status = ''   GROUP BY        l.session, m.step, m.path ), form_log_with_mod_fallout_step AS (   SELECT       session,       step,       path,       max_stamp,       (SELECT MIN(min_stamp)   FROM        form_log_with_fallout_step AS prev   WHERE        prev.session = curr.session AND prev.step = curr.step - 1       ) AS lag_min_stamp,       (SELECT            MIN(step)         FROM            form_log_with_fallout_step AS min_step        WHERE            min_step.session = curr.session       ) AS min_step,       (SELECT            COUNT(*)        FROM             form_log_with_fallout_step AS count_step        WHERE             count_step.session = curr.session AND count_step.step <= curr.step        ) AS cum_count   FROM form_log_with_fallout_step AS curr ), fallout_log AS (   SELECT     session,     step,     path,     max_stamp   FROM      form_log_with_mod_fallout_step   WHERE      min_step = 1     AND step = cum_count     AND (lag_min_stamp IS NULL OR max_stamp >= lag_min_stamp) ), input_to_confirm_counts AS (   SELECT     COUNT(DISTINCT input.session) AS count   FROM      fallout_log AS input   JOIN      fallout_log AS confirm   ON      input.session = confirm.session   WHERE      input.path = '/regist/input'     AND confirm.path = '/regist/confirm'     AND input.max_stamp < confirm.max_stamp ) SELECT   count FROM    input_to_confirm_counts;",
        "schema": {
            "public": {
                "mst_fallout_step": [
                    "step",
                    "path"
                ],
                "form_log": [
                    "session",
                    "path",
                    "status",
                    "stamp"
                ],
                "form_log_with_fallout_step": [
                    "session",
                    "step",
                    "path",
                    "max_stamp",
                    "min_stamp"
                ],
                "form_log_with_mod_fallout_step": [
                    "session",
                    "step",
                    "path",
                    "max_stamp",
                    "lag_min_stamp",
                    "min_step",
                    "cum_count"
                ],
                "fallout_log": [
                    "session",
                    "step",
                    "path",
                    "max_stamp"
                ],
                "input_to_confirm_counts": [
                    "count"
                ]
            }
        }
    },
    "local329_2": {
        "query": "WITH activity_log_with_landing_exit AS (   SELECT     session,     path,     stamp,     FIRST_VALUE(path) OVER (       PARTITION BY session       ORDER BY stamp ASC       ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING     ) AS landing,     LAST_VALUE(path) OVER (       PARTITION BY session       ORDER BY stamp ASC       ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING     ) AS exit   FROM activity_log ), landing_count AS (   SELECT     landing AS path,     COUNT(DISTINCT session) AS count   FROM     activity_log_with_landing_exit   GROUP BY landing ), exit_count AS (   SELECT     exit AS path,     COUNT(DISTINCT session) AS count   FROM     activity_log_with_landing_exit   GROUP BY exit ), combined_counts AS (   SELECT path, SUM(count) AS total_count   FROM (     SELECT path, count FROM landing_count     UNION ALL     SELECT path, count FROM exit_count   ) AS combined   GROUP BY path ) SELECT path FROM combined_counts ORDER BY total_count DESC LIMIT 1;",
        "schema": {
            "public": {
                "activity_log": [
                    "session",
                    "path",
                    "stamp"
                ],
                "activity_log_with_landing_exit": [
                    "session",
                    "path",
                    "stamp",
                    "landing",
                    "exit"
                ],
                "landing_count": [
                    "path",
                    "count"
                ],
                "exit_count": [
                    "path",
                    "count"
                ],
                "combined_counts": [
                    "path",
                    "total_count"
                ]
            }
        }
    },
    "local330": {
        "query": "WITH activity_log_with_lead_path AS (   SELECT     session,     stamp,     path AS path0,     LEAD(path, 1) OVER(PARTITION BY session ORDER BY stamp ASC) AS path1,     LEAD(path, 2) OVER(PARTITION BY session ORDER BY stamp ASC) AS path2   FROM     activity_log ), raw_user_flow AS (   SELECT     path0,     SUM(COUNT(1)) OVER() AS count0,     COALESCE(path1, 'NULL') AS path1,     SUM(COUNT(1)) OVER(PARTITION BY path0, path1) AS count1,     COALESCE(path2, 'NULL') AS path2,     COUNT(1) AS count2   FROM     activity_log_with_lead_path   WHERE     path0 = '/detail'   GROUP BY     path0, path1, path2 ), ranked_user_flow AS (   SELECT     path0,     count0,     path1,     count1,     path2,     count2,     LAG(path0) OVER(ORDER BY count1 DESC, count2 DESC) AS prev_path0,     LAG(path0 || path1) OVER(ORDER BY count1 DESC, count2 DESC) AS prev_path0_path1,     LAG(path0 || path1 || path2) OVER(ORDER BY count1 DESC, count2 DESC) AS prev_path0_path1_path2   FROM     raw_user_flow ) SELECT   path2 FROM   ranked_user_flow WHERE   path0 = '/detail' AND path1 = '/detail' ORDER BY   count2 DESC LIMIT 1;",
        "schema": {
            "public": {
                "activity_log": [
                    "session",
                    "stamp",
                    "path"
                ],
                "activity_log_with_lead_path": [
                    "session",
                    "stamp",
                    "path0",
                    "path1",
                    "path2"
                ],
                "raw_user_flow": [
                    "path0",
                    "path1",
                    "path2"
                ],
                "ranked_user_flow": [
                    "path0",
                    "count0",
                    "path1",
                    "count1",
                    "path2",
                    "count2",
                    "prev_path0",
                    "prev_path0_path1",
                    "prev_path0_path1_path2"
                ]
            }
        }
    },
    "local344": {
        "query": "SELECT   overtake_type,   COUNT(*) AS overtake_count FROM (   SELECT DISTINCT     lap_positions.race_id,     lap_positions.driver_id AS overtaking_driver_id,     lap_positions.lap,     lap_positions.position AS current_position,     previous_lap.position AS previous_position,     cars_behind_this_lap.driver_id AS overtaken_driver_id,     CASE       WHEN retirements.driver_id IS NOT NULL THEN 'R'       WHEN pit_stops.lap = lap_positions.lap THEN 'P'       WHEN pit_stops.milliseconds > overtaking_lap_times.running_milliseconds - overtaken_lap_times.running_milliseconds THEN 'P'       WHEN lap_positions.lap = 1 AND (previous_lap.position - cars_behind_this_lap_results.grid) <= 2 THEN 'S'       ELSE 'T'     END AS overtake_type,     CASE       WHEN retirements.driver_id IS NOT NULL THEN retirements.retirement_type       WHEN pit_stops.lap = lap_positions.lap THEN 'Pit Stop (Pit Entry)'       WHEN pit_stops.milliseconds > overtaking_lap_times.running_milliseconds - overtaken_lap_times.running_milliseconds THEN 'Pit Stop (Pit Exit)'       WHEN lap_positions.lap = 1 AND (previous_lap.position - cars_behind_this_lap_results.grid) <= 2 THEN 'Start'       ELSE 'Track'     END AS overtake_desc   FROM lap_positions     INNER JOIN races_ext AS races       ON races.race_id = lap_positions.race_id       AND races.is_pit_data_available = 1     INNER JOIN lap_positions AS previous_lap       ON previous_lap.race_id = lap_positions.race_id       AND previous_lap.driver_id = lap_positions.driver_id       AND previous_lap.lap = lap_positions.lap - 1     INNER JOIN lap_positions AS cars_behind_this_lap /*Join to ALL cars behind on this lap*/       ON cars_behind_this_lap.race_id = lap_positions.race_id       AND cars_behind_this_lap.lap = lap_positions.lap       AND cars_behind_this_lap.position > lap_positions.position     LEFT JOIN results AS cars_behind_this_lap_results       ON cars_behind_this_lap_results.race_id = lap_positions.race_id       AND cars_behind_this_lap_results.driver_id = cars_behind_this_lap.driver_id     LEFT JOIN lap_positions AS cars_behind_last_lap       ON cars_behind_last_lap.race_id = lap_positions.race_id       AND cars_behind_last_lap.lap = lap_positions.lap - 1       AND cars_behind_last_lap.driver_id = cars_behind_this_lap.driver_id /*NOT lap_positions.driver_id!!!!!!*/       AND cars_behind_last_lap.position > previous_lap.position     LEFT JOIN retirements       ON retirements.race_id = lap_positions.race_id       AND retirements.lap = lap_positions.lap       AND retirements.driver_id = cars_behind_this_lap.driver_id     LEFT JOIN pit_stops AS pit_stops       ON pit_stops.race_id = lap_positions.race_id       AND pit_stops.lap BETWEEN lap_positions.lap - 1 AND lap_positions.lap /*This lets us bring in pit stops from the \"previous\" lap*/       AND pit_stops.driver_id = cars_behind_this_lap.driver_id     LEFT JOIN lap_times_ext AS overtaking_lap_times       ON overtaking_lap_times.race_id = lap_positions.race_id       AND overtaking_lap_times.driver_id = lap_positions.driver_id       AND overtaking_lap_times.lap = pit_stops.lap - 1     LEFT JOIN lap_times_ext AS overtaken_lap_times       ON overtaken_lap_times.race_id = lap_positions.race_id       AND overtaken_lap_times.driver_id = pit_stops.driver_id       AND overtaken_lap_times.lap = pit_stops.lap - 1   WHERE     cars_behind_last_lap.driver_id IS NULL /*The car was NOT behind last lap (but is behind this lap due to the INNER JOIN)*/ ) AS overtakes GROUP BY overtake_type;",
        "schema": {
            "public": {
                "lap_positions": [
                    "race_id",
                    "driver_id",
                    "lap",
                    "position"
                ],
                "races_ext": [
                    "race_id",
                    "is_pit_data_available"
                ],
                "results": [
                    "race_id",
                    "driver_id",
                    "grid"
                ],
                "retirements": [
                    "race_id",
                    "lap",
                    "driver_id",
                    "retirement_type"
                ],
                "pit_stops": [
                    "race_id",
                    "lap",
                    "driver_id",
                    "milliseconds"
                ],
                "lap_times_ext": [
                    "race_id",
                    "driver_id",
                    "lap",
                    "running_milliseconds"
                ]
            }
        }
    },
    "local344_1": {
        "query": "SELECT   overtake_type,   COUNT(*) AS overtake_count FROM (   SELECT DISTINCT     lap_positions.race_id,     lap_positions.driver_id AS overtaking_driver_id,     lap_positions.lap,     cars_behind_this_lap.driver_id AS overtaken_driver_id,     CASE       WHEN retirements.driver_id IS NOT NULL THEN 'R'       WHEN pit_stops.lap = lap_positions.lap THEN 'P'       WHEN pit_stops.milliseconds > overtaking_lap_times.running_milliseconds - overtaken_lap_times.running_milliseconds THEN 'P'       WHEN lap_positions.lap = 1 AND (previous_lap.position - cars_behind_this_lap_results.grid) <= 2 THEN 'S'       ELSE 'T'     END AS overtake_type   FROM lap_positions     INNER JOIN races_ext AS races       ON races.race_id = lap_positions.race_id       AND races.is_pit_data_available = 1     INNER JOIN lap_positions AS previous_lap       ON previous_lap.race_id = lap_positions.race_id       AND previous_lap.driver_id = lap_positions.driver_id       AND previous_lap.lap = lap_positions.lap - 1     INNER JOIN lap_positions AS cars_behind_this_lap       ON cars_behind_this_lap.race_id = lap_positions.race_id       AND cars_behind_this_lap.lap = lap_positions.lap       AND cars_behind_this_lap.position > lap_positions.position     LEFT JOIN results AS cars_behind_this_lap_results       ON cars_behind_this_lap_results.race_id = lap_positions.race_id       AND cars_behind_this_lap_results.driver_id = cars_behind_this_lap.driver_id     LEFT JOIN lap_positions AS cars_behind_last_lap       ON cars_behind_last_lap.race_id = lap_positions.race_id       AND cars_behind_last_lap.lap = lap_positions.lap - 1       AND cars_behind_last_lap.driver_id = cars_behind_this_lap.driver_id       AND cars_behind_last_lap.position > previous_lap.position     LEFT JOIN retirements       ON retirements.race_id = lap_positions.race_id       AND retirements.lap = lap_positions.lap       AND retirements.driver_id = cars_behind_this_lap.driver_id     LEFT JOIN pit_stops AS pit_stops       ON pit_stops.race_id = lap_positions.race_id       AND pit_stops.lap BETWEEN lap_positions.lap - 1 AND lap_positions.lap       AND pit_stops.driver_id = cars_behind_this_lap.driver_id     LEFT JOIN lap_times_ext AS overtaking_lap_times       ON overtaking_lap_times.race_id = lap_positions.race_id       AND overtaking_lap_times.driver_id = lap_positions.driver_id       AND overtaking_lap_times.lap = pit_stops.lap - 1     LEFT JOIN lap_times_ext AS overtaken_lap_times       ON overtaken_lap_times.race_id = lap_positions.race_id       AND overtaken_lap_times.driver_id = pit_stops.driver_id       AND overtaken_lap_times.lap = pit_stops.lap - 1   WHERE     cars_behind_last_lap.driver_id IS NULL     AND lap_positions.lap <= 5 /* Filter for the first five laps */ ) AS overtakes GROUP BY overtake_type;",
        "schema": {
            "public": {
                "lap_positions": [
                    "race_id",
                    "driver_id",
                    "lap",
                    "position"
                ],
                "races_ext": [
                    "race_id",
                    "is_pit_data_available"
                ],
                "results": [
                    "race_id",
                    "driver_id",
                    "grid"
                ],
                "retirements": [
                    "race_id",
                    "lap",
                    "driver_id"
                ],
                "pit_stops": [
                    "race_id",
                    "lap",
                    "driver_id",
                    "milliseconds"
                ],
                "lap_times_ext": [
                    "race_id",
                    "driver_id",
                    "lap",
                    "running_milliseconds"
                ]
            }
        }
    },
    "local335": {
        "query": "WITH points AS (     SELECT          year AS season,         driver_id,         constructor_id,         SUM(points) AS points       FROM          results JOIN races ON results.race_id = races.race_id      GROUP BY           year,          driver_id,          constructor_id     HAVING           SUM(points) > 0 ), tops AS (     SELECT           season,          MIN(points) FILTER (WHERE driver_id IS NOT NULL) AS min_driver_points,          MIN(points) FILTER (WHERE constructor_id IS NOT NULL) AS min_constructor_points       FROM           points      GROUP BY           season ), losers AS (     SELECT           tops.season,          lose_driver.driver_id,          lose_driver.points AS driver_points,          lose_constructor.constructor_id,          lose_constructor.points AS constructor_points       FROM           tops JOIN points AS lose_driver ON lose_driver.season = tops.season AND                                      lose_driver.constructor_id IS NOT NULL AND                                      lose_driver.points = tops.min_constructor_points               JOIN points AS lose_constructor ON lose_constructor.season = tops.season AND                                           lose_constructor.driver_id IS NOT NULL AND                                           lose_constructor.points = tops.min_driver_points ) SELECT       constructors.name AS Constructor   FROM       losers JOIN constructors ON losers.constructor_id = constructors.constructor_id  WHERE       losers.season >= 2001  GROUP BY       losers.constructor_id,      constructors.name  ORDER BY       COUNT( * ) DESC  LIMIT 5;",
        "schema": {
            "public": {
                "results": [
                    "race_id",
                    "driver_id",
                    "constructor_id",
                    "points"
                ],
                "races": [
                    "race_id",
                    "year"
                ],
                "points": [
                    "season",
                    "driver_id",
                    "constructor_id",
                    "points"
                ],
                "tops": [
                    "season",
                    "min_driver_points",
                    "min_constructor_points"
                ],
                "losers": [
                    "season",
                    "driver_id",
                    "driver_points",
                    "constructor_id",
                    "constructor_points"
                ],
                "constructors": [
                    "constructor_id",
                    "name"
                ]
            }
        }
    },
    "local309": {
        "query": "with year_points as (     select races.year,            drivers.forename || ' ' || drivers.surname as driver,            constructors.name as constructor,            sum(results.points) as points     from results     left join races on results.race_id = races.race_id  -- Ensure these columns exist in your schema     left join drivers on results.driver_id = drivers.driver_id  -- Ensure these columns exist in your schema     left join constructors on results.constructor_id = constructors.constructor_id  -- Ensure these columns exist in your schema     group by races.year, driver     union     select races.year,            null as driver,            constructors.name as constructor,            sum(results.points) as points     from results     left join races on results.race_id = races.race_id  -- Ensure these columns exist in your schema     left join drivers on results.driver_id = drivers.driver_id  -- Ensure these columns exist in your schema     left join constructors on results.constructor_id = constructors.constructor_id  -- Ensure these columns exist in your schema     group by races.year, constructor ), max_points as (     select year,            max(case when driver is not null then points else null end) as max_driver_points,            max(case when constructor is not null then points else null end) as max_constructor_points     from year_points     group by year ) select max_points.year,        drivers_year_points.driver,        constructors_year_points.constructor from max_points left join year_points as drivers_year_points on     max_points.year = drivers_year_points.year and     max_points.max_driver_points = drivers_year_points.points and     drivers_year_points.driver is not null left join year_points as constructors_year_points on     max_points.year = constructors_year_points.year and     max_points.max_constructor_points = constructors_year_points.points and     constructors_year_points.constructor is not null order by max_points.year;",
        "schema": {
            "public": {
                "results": [
                    "race_id",
                    "driver_id",
                    "constructor_id",
                    "points"
                ],
                "races": [
                    "race_id",
                    "year"
                ],
                "drivers": [
                    "driver_id",
                    "forename",
                    "surname"
                ],
                "constructors": [
                    "constructor_id",
                    "name"
                ],
                "year_points": [
                    "year",
                    "driver",
                    "constructor",
                    "points"
                ],
                "max_points": [
                    "year",
                    "max_driver_points",
                    "max_constructor_points"
                ]
            }
        }
    },
    "local309_2": {
        "query": "with year_points as (     select          races.year,         drivers.forename || ' ' || drivers.surname as driver,         constructors.name as constructor,         sum(results.points) as points     from          results     left join races on results.race_id = races.race_id  -- Ensure these columns exist in your schema     left join drivers on results.driver_id = drivers.driver_id  -- Ensure these columns exist in your schema     left join constructors on results.constructor_id = constructors.constructor_id  -- Ensure these columns exist in your schema     group by          races.year,          driver     union     select          races.year,         null as driver,         constructors.name as constructor,         sum(results.points) as points     from          results     left join races on results.race_id = races.race_id  -- Ensure these columns exist in your schema     left join drivers on results.driver_id = drivers.driver_id  -- Ensure these columns exist in your schema     left join constructors on results.constructor_id = constructors.constructor_id  -- Ensure these columns exist in your schema     group by          races.year,          constructor ), max_points as (     select          year,         max(case when driver is not null then points else null end) as max_driver_points,         max(case when constructor is not null then points else null end) as max_constructor_points     from          year_points     group by          year ) select      max_points.year from      max_points left join year_points as drivers_year_points on     max_points.year = drivers_year_points.year and     max_points.max_driver_points = drivers_year_points.points and     drivers_year_points.driver is not null left join year_points as constructors_year_points on     max_points.year = constructors_year_points.year and     max_points.max_constructor_points = constructors_year_points.points and     constructors_year_points.constructor is not null order by      max_points.max_driver_points + max_points.max_constructor_points ASC LIMIT 3;",
        "schema": {
            "public": {
                "results": [
                    "race_id",
                    "driver_id",
                    "constructor_id",
                    "points"
                ],
                "races": [
                    "race_id",
                    "year"
                ],
                "drivers": [
                    "driver_id",
                    "forename",
                    "surname"
                ],
                "constructors": [
                    "constructor_id",
                    "name"
                ],
                "year_points": [
                    "year",
                    "driver",
                    "constructor",
                    "points"
                ],
                "max_points": [
                    "year",
                    "max_driver_points",
                    "max_constructor_points"
                ]
            }
        }
    },
    "local309_3": {
        "query": "with year_points as (     select          races.year,         drivers.forename || ' ' || drivers.surname as driver,         constructors.name as constructor,         sum(results.points) as points     from          results     left join races on results.race_id = races.race_id  -- Ensure these columns exist in your schema     left join drivers on results.driver_id = drivers.driver_id  -- Ensure these columns exist in your schema     left join constructors on results.constructor_id = constructors.constructor_id  -- Ensure these columns exist in your schema     group by          races.year,          driver     union     select          races.year,         null as driver,         constructors.name as constructor,         sum(results.points) as points     from          results     left join races on results.race_id = races.race_id  -- Ensure these columns exist in your schema     left join drivers on results.driver_id = drivers.driver_id  -- Ensure these columns exist in your schema     left join constructors on results.constructor_id = constructors.constructor_id  -- Ensure these columns exist in your schema     group by          races.year,          constructor ), max_points as (     select          year,         constructor,         max(case when driver is not null then points else null end) as max_driver_points,         max(case when constructor is not null then points else null end) as max_constructor_points     from          year_points     group by          year ) select      constructors_year_points.year,     max_points.constructor,     max_points.max_driver_points + max_points.max_constructor_points AS combined_points from      max_points left join year_points as drivers_year_points on     max_points.year = drivers_year_points.year and     max_points.max_driver_points = drivers_year_points.points and     drivers_year_points.driver is not null left join year_points as constructors_year_points on     max_points.year = constructors_year_points.year and     max_points.max_constructor_points = constructors_year_points.points and     constructors_year_points.constructor is not null order by      combined_points DESC LIMIT 3;",
        "schema": {
            "public": {
                "results": [
                    "race_id",
                    "driver_id",
                    "constructor_id",
                    "points"
                ],
                "races": [
                    "race_id",
                    "year"
                ],
                "drivers": [
                    "driver_id",
                    "forename",
                    "surname"
                ],
                "constructors": [
                    "constructor_id",
                    "name"
                ],
                "year_points": [
                    "year",
                    "driver",
                    "constructor",
                    "points"
                ],
                "max_points": [
                    "year",
                    "constructor",
                    "max_driver_points",
                    "max_constructor_points"
                ]
            }
        }
    },
    "local353": {
        "query": "SELECT      lap_type,      COUNT(*) AS frequency FROM (   SELECT        'Race' AS lap_type   FROM        lap_times   WHERE        race_id = 1      UNION ALL      SELECT CASE     WHEN qualifying.race_id IS NULL THEN 'Starting Position - No Qualification'     WHEN results.grid = 0 THEN 'Starting Position - Pit Lane Start'     WHEN qualifying.position < results.grid THEN 'Starting Position - Grid Drop'     WHEN qualifying.position > results.grid THEN 'Starting Position - Grid Increase'     ELSE 'Starting Position - Qualifying'   END AS lap_type   FROM        results   LEFT JOIN qualifying     ON qualifying.race_id = results.race_id     AND qualifying.driver_id = results.driver_id   WHERE        results.race_id = 1      UNION ALL      SELECT        retirement_type AS lap_type   FROM        retirements   WHERE        race_id = 1 ) AS combined_laps GROUP BY      lap_type ORDER BY      frequency DESC LIMIT 5;",
        "schema": {
            "public": {
                "lap_times": [
                    "race_id"
                ],
                "results": [
                    "race_id",
                    "grid",
                    "driver_id"
                ],
                "qualifying": [
                    "race_id",
                    "driver_id",
                    "position"
                ],
                "retirements": [
                    "retirement_type",
                    "race_id"
                ]
            }
        }
    },
    "local354": {
        "query": "WITH drives_prelim AS (   SELECT DISTINCT     races.year,     results.driver_id,     races.round,     results.constructor_id,     COALESCE(       CASE          WHEN results.constructor_id = LAG(results.constructor_id) OVER (           PARTITION BY races.year, results.driver_id           ORDER BY races.round ASC         ) THEN 0          ELSE 1        END, 1     ) AS is_first_race,     COALESCE(       CASE          WHEN results.constructor_id = LEAD(results.constructor_id) OVER (           PARTITION BY races.year, results.driver_id           ORDER BY races.round ASC         ) THEN 0          ELSE 1        END, 1     ) AS is_last_race   FROM        results   INNER JOIN races ON races.race_id = results.race_id ), first_last_races AS (   SELECT     year,     driver_id,     MIN(round) AS first_round,     MAX(round) AS last_round   FROM        drives_prelim   GROUP BY        year,        driver_id ) SELECT DISTINCT   dp.driver_id FROM      drives_prelim dp INNER JOIN first_last_races flr   ON dp.year = flr.year   AND dp.driver_id = flr.driver_id   AND (dp.round = flr.first_round OR dp.round = flr.last_round) WHERE      dp.is_first_race = 0   AND dp.is_last_race = 0   AND dp.year BETWEEN 1950 AND 1959 GROUP BY      dp.driver_id HAVING      COUNT(DISTINCT dp.round) > 1;",
        "schema": {
            "public": {
                "races": [
                    "year",
                    "round",
                    "race_id"
                ],
                "results": [
                    "driver_id",
                    "race_id",
                    "constructor_id"
                ],
                "drives_prelim": [
                    "year",
                    "driver_id",
                    "round",
                    "constructor_id",
                    "is_first_race",
                    "is_last_race"
                ],
                "first_last_races": [
                    "year",
                    "driver_id",
                    "first_round",
                    "last_round"
                ]
            }
        }
    },
    "local355": {
        "query": "WITH hiatus_prelim AS (   SELECT DISTINCT     races.year,     driver_standings.driver_id,     races.round,     previous_results.constructor_id AS previous_constructor_id,     next_results.constructor_id AS next_constructor_id,     CASE       WHEN previous_results.constructor_id IS NOT NULL THEN 1       ELSE 0     END AS is_first_race,     CASE       WHEN next_results.constructor_id IS NOT NULL THEN 1       ELSE 0     END AS is_last_race   FROM driver_standings_ext AS driver_standings   INNER JOIN races_ext AS races ON races.race_id = driver_standings.race_id   LEFT JOIN results     ON results.race_id = driver_standings.race_id     AND results.driver_id = driver_standings.driver_id   LEFT JOIN races_ext AS previous_race     ON previous_race.year = races.year     AND previous_race.round = races.round - 1   LEFT JOIN results AS previous_results     ON previous_results.race_id = previous_race.race_id     AND previous_results.driver_id = driver_standings.driver_id   LEFT JOIN races_ext AS next_race     ON next_race.year = races.year     AND next_race.round = races.round + 1   LEFT JOIN results AS next_results     ON next_results.race_id = next_race.race_id     AND next_results.driver_id = driver_standings.driver_id   WHERE results.driver_id IS NULL ), first_race AS (   SELECT     year,     driver_id,     round AS first_round,     ROW_NUMBER() OVER (PARTITION BY year, driver_id ORDER BY round ASC) AS drive_id,     previous_constructor_id   FROM hiatus_prelim   WHERE is_first_race = 1 ), last_race AS (   SELECT     year,     driver_id,     round AS last_round,     ROW_NUMBER() OVER (PARTITION BY year, driver_id ORDER BY round ASC) AS drive_id,     next_constructor_id   FROM hiatus_prelim   WHERE is_last_race = 1 ), missed_races AS (   SELECT     driver_id,     year,     COUNT(*) AS missed_count  -- Count all missed rounds   FROM hiatus_prelim   GROUP BY driver_id, year   HAVING COUNT(*) < 3  -- Less than 3 missed rounds ) SELECT   AVG(first_race.first_round) AS avg_first_round,   AVG(last_race.last_round) AS avg_last_round FROM driver_standings_ext AS driver_standings INNER JOIN races_ext AS races ON races.race_id = driver_standings.race_id LEFT JOIN results   ON results.race_id = driver_standings.race_id   AND results.driver_id = driver_standings.driver_id INNER JOIN first_race   ON first_race.year = races.year   AND first_race.driver_id = driver_standings.driver_id INNER JOIN last_race   ON last_race.year = races.year   AND last_race.driver_id = driver_standings.driver_id   AND last_race.drive_id = first_race.drive_id INNER JOIN missed_races   ON missed_races.year = races.year   AND missed_races.driver_id = driver_standings.driver_id WHERE results.driver_id IS NULL   AND first_race.previous_constructor_id != last_race.next_constructor_id;",
        "schema": {
            "public": {
                "driver_standings_ext": [
                    "driver_id",
                    "race_id"
                ],
                "races_ext": [
                    "race_id",
                    "year",
                    "round"
                ],
                "results": [
                    "race_id",
                    "driver_id",
                    "constructor_id"
                ],
                "hiatus_prelim": [
                    "year",
                    "driver_id",
                    "round",
                    "previous_constructor_id",
                    "next_constructor_id",
                    "is_first_race",
                    "is_last_race"
                ],
                "first_race": [
                    "year",
                    "driver_id",
                    "first_round",
                    "drive_id",
                    "previous_constructor_id"
                ],
                "last_race": [
                    "year",
                    "driver_id",
                    "last_round",
                    "drive_id",
                    "next_constructor_id"
                ],
                "missed_races": [
                    "driver_id",
                    "year",
                    "missed_count"
                ]
            }
        }
    },
    "local356": {
        "query": "WITH overtakes_summary AS (   SELECT     overtaking_driver_id AS driver_id,     COUNT(*) AS overtakes_count   FROM        overtakes   GROUP BY        overtaking_driver_id ), overtaken_summary AS (   SELECT     overtaken_driver_id AS driver_id,     COUNT(*) AS overtaken_count   FROM        overtakes   GROUP BY        overtaken_driver_id ), driver_totals AS (   SELECT         COALESCE(overtakes_summary.driver_id, overtaken_summary.driver_id) AS driver_id,         COALESCE(overtakes_summary.overtakes_count, 0) AS overtakes_count,         COALESCE(overtaken_summary.overtaken_count, 0) AS overtaken_count   FROM        overtakes_summary   FULL OUTER JOIN overtaken_summary     ON overtakes_summary.driver_id = overtaken_summary.driver_id ) SELECT     drivers.full_name FROM      driver_totals INNER JOIN drivers   ON drivers.driver_id = driver_totals.driver_id WHERE      driver_totals.overtaken_count > driver_totals.overtakes_count;",
        "schema": {
            "public": {
                "overtakes": [
                    "overtaking_driver_id",
                    "overtaken_driver_id"
                ],
                "overtakes_summary": [
                    "driver_id",
                    "overtakes_count"
                ],
                "overtaken_summary": [
                    "driver_id",
                    "overtaken_count"
                ],
                "driver_totals": [
                    "driver_id",
                    "overtakes_count",
                    "overtaken_count"
                ],
                "drivers": [
                    "full_name",
                    "driver_id"
                ]
            }
        }
    }
}