[
    {
        "instance_id": "bq187",
        "score": 1,
        "pred_sql": "WITH tokenInfo AS (\n    SELECT address\n    FROM `bigquery-public-data.ethereum_blockchain.tokens`\n    WHERE name = 'BNB'\n),\n\nreceivedTx AS (\n    SELECT tx.to_address as addr, \n           tokens.name as name, \n           SUM(CAST(tx.value AS float64) / POWER(10, 18)) as amount_received\n    FROM `bigquery-public-data.ethereum_blockchain.token_transfers` as tx\n    JOIN tokenInfo ON tx.token_address = tokenInfo.address,\n         `bigquery-public-data.ethereum_blockchain.tokens` as tokens\n    WHERE tx.token_address = tokens.address \n        AND tx.to_address <> '0x0000000000000000000000000000000000000000'\n    GROUP BY 1, 2\n),\n\nsentTx AS (\n    SELECT tx.from_address as addr, \n           tokens.name as name, \n           SUM(CAST(tx.value AS float64) / POWER(10, 18)) as amount_sent\n    FROM `bigquery-public-data.ethereum_blockchain.token_transfers` as tx\n    JOIN tokenInfo ON tx.token_address = tokenInfo.address,\n         `bigquery-public-data.ethereum_blockchain.tokens` as tokens\n    WHERE tx.token_address = tokens.address \n        AND tx.from_address <> '0x0000000000000000000000000000000000000000'\n    GROUP BY 1, 2\n),\n\nwalletBalances AS (\n    SELECT r.addr,\n           COALESCE(SUM(r.amount_received), 0) - COALESCE(SUM(s.amount_sent), 0) as balance\n    FROM \n        receivedTx as r\n    LEFT JOIN \n        sentTx as s\n    ON \n        r.addr = s.addr\n    GROUP BY \n        r.addr\n)\n\nSELECT \n    SUM(balance) as circulating_supply\nFROM \n    walletBalances;",
        "error_info": null
    },
    {
        "instance_id": "bq256",
        "score": 1,
        "pred_sql": "WITH value_table AS (\n    SELECT to_address AS address, value AS value\n    FROM `spider2-public-data.crypto_ethereum.traces`\n    WHERE to_address IS NOT null\n    AND block_timestamp < '2021-09-01 00:00:00' \n    AND status=1\n    AND (call_type NOT IN ('delegatecall', 'callcode', 'staticcall') OR call_type IS null)\n    \n    UNION ALL\n    \n    SELECT from_address AS address, -value AS value\n    FROM `spider2-public-data.crypto_ethereum.traces`\n    WHERE from_address IS NOT null\n    AND block_timestamp < '2021-09-01 00:00:00'\n    AND status=1\n    AND (call_type NOT IN ('delegatecall', 'callcode', 'staticcall') OR call_type IS null)\n    \n    UNION ALL\n    \n    SELECT miner as address, SUM(CAST(receipt_gas_used AS NUMERIC) * CAST(gas_price AS NUMERIC)) AS value\n    FROM `spider2-public-data.crypto_ethereum.transactions` AS transactions\n    JOIN `spider2-public-data.crypto_ethereum.blocks` AS blocks\n    ON blocks.number = transactions.block_number\n    WHERE block_timestamp < '2021-09-01 00:00:00'\n    GROUP BY blocks.miner\n    \n    UNION ALL\n    \n    SELECT from_address as address, -(CAST(receipt_gas_used AS NUMERIC) * CAST(gas_price AS NUMERIC)) AS value\n    FROM  `spider2-public-data.crypto_ethereum.transactions`\n    WHERE block_timestamp < '2021-09-01 00:00:00'\n),\na AS (\n    SELECT SUM(value)/POWER(10,18) AS balance, address\n    FROM value_table\n    GROUP BY address\n    ORDER BY balance DESC\n),\nb AS (\n    SELECT to_address, COUNT(transactions.hash) AS tx_recipient\n    FROM  `spider2-public-data.crypto_ethereum.transactions` AS transactions\n    WHERE block_timestamp < '2021-09-01 00:00:00'\n    GROUP BY to_address\n), \nc AS (\n    SELECT from_address, COUNT(transactions.hash) AS tx_sender\n    FROM  `spider2-public-data.crypto_ethereum.transactions` AS transactions\n    WHERE block_timestamp < '2021-09-01 00:00:00'\n    GROUP BY from_address\n)\nSELECT balance\nFROM c LEFT JOIN a ON (a.address = c.from_address)\nORDER BY tx_sender DESC\nLIMIT 1",
        "error_info": null
    },
    {
        "instance_id": "bq059",
        "score": 1,
        "pred_sql": "WITH stations AS (\n  SELECT station_id\n  FROM\n    `bigquery-public-data.san_francisco_bikeshare.bikeshare_station_info` AS stainfo\n  WHERE stainfo.region_id = (\n    SELECT region.region_id\n    FROM `bigquery-public-data.san_francisco_bikeshare.bikeshare_regions` AS region\n    WHERE region.name = \"Berkeley\"\n  )\n),\nmeta_data AS (\n    SELECT\n        round(st_distance(start_station_geom, end_station_geom), 1) as distancia_metros,\n        round(st_distance(start_station_geom, end_station_geom) / duration_sec, 1) as velocidade_media\n    FROM\n        `bigquery-public-data.san_francisco_bikeshare.bikeshare_trips` AS trips\n    WHERE\n        cast(trips.start_station_id as string) IN (SELECT station_id FROM stations)\n        AND cast(trips.end_station_id as string) IN (SELECT station_id FROM stations)\n        AND start_station_latitude IS NOT NULL\n        AND start_station_longitude IS NOT NULL\n        AND end_station_latitude IS NOT NULL\n        AND end_station_longitude IS NOT NULL\n        AND st_distance(start_station_geom, end_station_geom) > 1000\n    ORDER BY\n        velocidade_media DESC\n    LIMIT 1\n)\n\nSELECT velocidade_media as max_velocity\nFROM meta_data;",
        "error_info": null
    },
    {
        "instance_id": "bq249",
        "score": 1,
        "pred_sql": "WITH\n  lines AS (\n  SELECT\n    SPLIT(content, '\\\\n') AS line,\n    id\n  FROM\n    `bigquery-public-data.github_repos.sample_contents`\n  WHERE\n    sample_path LIKE \"%.sql\" )\nSELECT\n  Indentation,\n  COUNT(Indentation) AS number_of_occurence\nFROM (\n  SELECT\n    CASE\n        WHEN MIN(CHAR_LENGTH(REGEXP_EXTRACT(flatten_line, r\"\\s+$\")))>=1 THEN 'trailing'\n        WHEN MIN(CHAR_LENGTH(REGEXP_EXTRACT(flatten_line, r\"^ +\")))>=1 THEN 'Space'\n        ELSE 'Other'\n    END AS Indentation\n  FROM\n    lines\n  CROSS JOIN\n    UNNEST(lines.line) AS flatten_line\n  GROUP BY\n    id)\nGROUP BY\n  Indentation\nORDER BY\n  number_of_occurence DESC",
        "error_info": null
    },
    {
        "instance_id": "ga020",
        "score": 1,
        "pred_sql": "-- Define the date range and calculate the minimum date for filtering results\nWITH dates AS (\n    SELECT \n        DATE('2018-08-01') AS start_date,\n        DATE('2018-08-15') AS end_date\n),\n-- Create a table of active dates for each user within the specified date range\ndates_active_table AS (\n    SELECT\n        user_pseudo_id,\n        PARSE_DATE('%Y%m%d', `event_date`) AS user_active_date\n    FROM \n        `firebase-public-project.analytics_153293282.events_*` \n    WHERE \n        event_name = 'session_start'\n        AND PARSE_DATE('%Y%m%d', `event_date`) BETWEEN (SELECT start_date FROM dates) AND (SELECT end_date FROM dates)\n    GROUP BY \n        user_pseudo_id, user_active_date\n),\n-- Create a table of the earliest quickplay event date for each user within the specified date range\nevent_table AS (\n    SELECT \n        user_pseudo_id,\n        event_name,\n        MIN(PARSE_DATE('%Y%m%d', `event_date`)) AS event_cohort_date\n    FROM \n        `firebase-public-project.analytics_153293282.events_*` \n    WHERE \n        event_name IN ('level_start_quickplay', 'level_end_quickplay', 'level_complete_quickplay', \n                       'level_fail_quickplay', 'level_reset_quickplay', 'level_retry_quickplay')\n        AND PARSE_DATE('%Y%m%d', `event_date`) BETWEEN (SELECT start_date FROM dates) AND (SELECT end_date FROM dates)\n    GROUP BY \n        user_pseudo_id, event_name\n),\n-- Calculate the number of days since each user's initial quickplay event\ndays_since_event_table AS (\n    SELECT\n        events.user_pseudo_id,\n        events.event_name AS event_cohort,\n        events.event_cohort_date,\n        days.user_active_date,\n        DATE_DIFF(days.user_active_date, events.event_cohort_date, DAY) AS days_since_event\n    FROM \n        event_table events\n    LEFT JOIN \n        dates_active_table days ON events.user_pseudo_id = days.user_pseudo_id\n    WHERE \n        events.event_cohort_date <= days.user_active_date\n),\n-- Calculate the weeks since each user's initial quickplay event and count the active days in each week\nweeks_retention AS (\n    SELECT\n        event_cohort,\n        user_pseudo_id,\n        CAST(CASE WHEN days_since_event = 0 THEN 0 ELSE CEIL(days_since_event / 7) END AS INTEGER) AS weeks_since_event,\n        COUNT(DISTINCT days_since_event) AS days_active_since_event -- Count Days Active in Week\n    FROM \n        days_since_event_table\n    GROUP BY \n        event_cohort, user_pseudo_id, weeks_since_event\n),\n-- Aggregate the weekly retention data\naggregated_weekly_retention_table AS (\n    SELECT\n        event_cohort,\n        weeks_since_event,\n        SUM(days_active_since_event) AS weekly_days_active,\n        COUNT(DISTINCT user_pseudo_id) AS retained_users\n    FROM \n        weeks_retention\n    GROUP BY \n        event_cohort, weeks_since_event\n),\nRETENTION_INFO AS (\n-- Select and calculate the weekly retention rate for each event cohort\nSELECT\n    event_cohort,\n    weeks_since_event,\n    weekly_days_active,\n    retained_users,\n    (retained_users / MAX(retained_users) OVER (PARTITION BY event_cohort)) AS retention_rate\nFROM \n    aggregated_weekly_retention_table\nORDER BY \n    event_cohort, weeks_since_event\n)\n\nSELECT event_cohort\nFROM\nRETENTION_INFO\nWHERE weeks_since_event = 2\nORDER BY retention_rate\nLIMIT 1",
        "error_info": null
    },
    {
        "instance_id": "bq339",
        "score": 1,
        "pred_sql": "WITH monthly_totals AS (\n  SELECT\n    SUM(CASE WHEN subscriber_type = 'Customer' THEN duration_sec / 60 ELSE NULL END) AS customer_minutes_sum,\n    SUM(CASE WHEN subscriber_type = 'Subscriber' THEN duration_sec / 60 ELSE NULL END) AS subscriber_minutes_sum,\n    EXTRACT(MONTH FROM end_date) AS end_month\n  FROM\n    `bigquery-public-data.san_francisco_bikeshare.bikeshare_trips`\n  WHERE\n    EXTRACT(YEAR FROM end_date) = 2017\n  GROUP BY\n    end_month\n),\n\ncumulative_totals AS (\n  SELECT\n    end_month,\n    SUM(customer_minutes_sum) OVER (ORDER BY end_month ROWS UNBOUNDED PRECEDING) / 1000 AS cumulative_minutes_cust,\n    SUM(subscriber_minutes_sum) OVER (ORDER BY end_month ROWS UNBOUNDED PRECEDING) / 1000 AS cumulative_minutes_sub\n  FROM\n    monthly_totals\n),\n\ndifferences AS (\n  SELECT\n    end_month,\n    ABS(cumulative_minutes_cust - cumulative_minutes_sub) AS abs_diff\n  FROM\n    cumulative_totals\n)\n\nSELECT\n  end_month\nFROM\n  differences\nORDER BY\n  abs_diff DESC\nLIMIT 1;",
        "error_info": null
    },
    {
        "instance_id": "bq008",
        "score": 1,
        "pred_sql": "with page_visit_sequence AS (\n    SELECT\n        fullVisitorID,\n        visitID,\n        pagePath,\n        LEAD(timestamp, 1) OVER (PARTITION BY fullVisitorId, visitID order by timestamp) - timestamp AS page_duration,\n        LEAD(pagePath, 1) OVER (PARTITION BY fullVisitorId, visitID order by timestamp) AS next_page,\n        RANK() OVER (PARTITION BY fullVisitorId, visitID order by timestamp) AS step_number\n    FROM (\n        SELECT\n            pages.fullVisitorID,\n            pages.visitID,\n            pages.pagePath,\n            visitors.campaign,\n            MIN(pages.timestamp) timestamp\n        FROM (\n            SELECT\n                fullVisitorId,\n                visitId,\n                trafficSource.campaign campaign\n            FROM\n                `bigquery-public-data.google_analytics_sample.ga_sessions_*`,\n                UNNEST(hits) as hits\n            WHERE\n                _TABLE_SUFFIX BETWEEN '20170101' AND '20170131'\n                AND hits.type='PAGE'\n                AND REGEXP_CONTAINS(hits.page.pagePath, r'^/home')\n                AND REGEXP_CONTAINS(trafficSource.campaign, r'Data Share')\n        ) AS visitors\n        JOIN(\n            SELECT\n                fullVisitorId,\n                visitId,\n                visitStartTime + hits.time / 1000 AS timestamp,\n                hits.page.pagePath AS pagePath\n            FROM\n                `bigquery-public-data.google_analytics_sample.ga_sessions_*`,\n                UNNEST(hits) as hits\n            WHERE\n                _TABLE_SUFFIX BETWEEN '20170101' AND '20170131'\n        ) as pages\n        ON\n            visitors.fullVisitorID = pages.fullVisitorID\n            AND visitors.visitID = pages.visitID\n        GROUP BY \n            pages.fullVisitorID, visitors.campaign, pages.visitID, pages.pagePath\n        ORDER BY \n            pages.fullVisitorID, pages.visitID, timestamp\n    )\n    ORDER BY fullVisitorId, visitID, step_number\n),\nmost_common_next_page AS (\n    SELECT\n        next_page,\n        COUNT(next_page) as page_count\n    FROM page_visit_sequence\n    WHERE\n        next_page IS NOT NULL\n        AND REGEXP_CONTAINS(pagePath, r'^/home')\n    GROUP BY next_page\n    ORDER BY page_count DESC\n    LIMIT 1\n),\nmax_page_duration AS (\n    SELECT MAX(page_duration) as max_duration\n    FROM page_visit_sequence\n    WHERE\n        page_duration IS NOT NULL\n        AND REGEXP_CONTAINS(pagePath, r'^/home')\n)\nSELECT\n    next_page,\n    max_duration\nFROM\n    most_common_next_page,\n    max_page_duration;\n",
        "error_info": null
    },
    {
        "instance_id": "bq031",
        "score": 1,
        "pred_sql": "WITH transrate AS (\n    SELECT\n        DATE(CAST(year AS INT64), CAST(mo AS INT64), CAST(da AS INT64)) AS observation_date\n        , ROUND((temp - 32.0) / 1.8, 1) AS temp_mean_c -- using Celsius instead of Fahrenheit\n        , ROUND(prcp * 2.54, 1) AS prcp_cm -- from inches to centimeters\n        , ROUND(CAST(wdsp AS FLOAT64) * 1.852 / 3.6, 1) AS wdsp_ms -- from knots to meters per second\n    FROM `bigquery-public-data.noaa_gsod.gsod*`\n    WHERE _TABLE_SUFFIX = \"2019\"\n        AND CAST(mo AS INT64) <= 3\n        AND stn in (SELECT usaf FROM `bigquery-public-data.noaa_gsod.stations` WHERE name = \"ROCHESTER\")\n),\n\nmoving_avg AS (\n    SELECT\n        observation_date\n        , temp_mean_c\n        , prcp_cm\n        , wdsp_ms\n        , AVG(temp_mean_c) OVER (ORDER BY observation_date ROWS 7 PRECEDING) AS temp_moving_avg\n        , AVG(prcp_cm) OVER (ORDER BY observation_date ROWS 7 PRECEDING) AS prcp_moving_avg\n        , AVG(wdsp_ms) OVER (ORDER BY observation_date ROWS 7 PRECEDING) AS wdsp_moving_avg\n    FROM transrate\n),\n\nlag_moving_avg AS (\n    SELECT\n        observation_date\n        , temp_mean_c\n        , prcp_cm\n        , wdsp_ms\n        , LAG(temp_moving_avg, 1) OVER (ORDER BY observation_date) AS lag1_temp_moving_avg\n        , LAG(prcp_moving_avg, 1) OVER (ORDER BY observation_date) AS lag1_prcp_moving_avg\n        , LAG(wdsp_moving_avg, 1) OVER (ORDER BY observation_date) AS lag1_wdsp_moving_avg\n\n        , LAG(temp_moving_avg, 2) OVER (ORDER BY observation_date) AS lag2_temp_moving_avg\n        , LAG(prcp_moving_avg, 2) OVER (ORDER BY observation_date) AS lag2_prcp_moving_avg\n        , LAG(wdsp_moving_avg, 2) OVER (ORDER BY observation_date) AS lag2_wdsp_moving_avg\n\n        , LAG(temp_moving_avg, 3) OVER (ORDER BY observation_date) AS lag3_temp_moving_avg\n        , LAG(prcp_moving_avg, 3) OVER (ORDER BY observation_date) AS lag3_prcp_moving_avg\n        , LAG(wdsp_moving_avg, 3) OVER (ORDER BY observation_date) AS lag3_wdsp_moving_avg\n\n        , LAG(temp_moving_avg, 4) OVER (ORDER BY observation_date) AS lag4_temp_moving_avg\n        , LAG(prcp_moving_avg, 4) OVER (ORDER BY observation_date) AS lag4_prcp_moving_avg\n        , LAG(wdsp_moving_avg, 4) OVER (ORDER BY observation_date) AS lag4_wdsp_moving_avg\n\n        , LAG(temp_moving_avg, 5) OVER (ORDER BY observation_date) AS lag5_temp_moving_avg\n        , LAG(prcp_moving_avg, 5) OVER (ORDER BY observation_date) AS lag5_prcp_moving_avg\n        , LAG(wdsp_moving_avg, 5) OVER (ORDER BY observation_date) AS lag5_wdsp_moving_avg\n\n        , LAG(temp_moving_avg, 6) OVER (ORDER BY observation_date) AS lag6_temp_moving_avg\n        , LAG(prcp_moving_avg, 6) OVER (ORDER BY observation_date) AS lag6_prcp_moving_avg\n        , LAG(wdsp_moving_avg, 6) OVER (ORDER BY observation_date) AS lag6_wdsp_moving_avg\n\n        , LAG(temp_moving_avg, 7) OVER (ORDER BY observation_date) AS lag7_temp_moving_avg\n        , LAG(prcp_moving_avg, 7) OVER (ORDER BY observation_date) AS lag7_prcp_moving_avg\n        , LAG(wdsp_moving_avg, 7) OVER (ORDER BY observation_date) AS lag7_wdsp_moving_avg\n\n        , LAG(temp_moving_avg, 8) OVER (ORDER BY observation_date) AS lag8_temp_moving_avg\n        , LAG(prcp_moving_avg, 8) OVER (ORDER BY observation_date) AS lag8_prcp_moving_avg\n        , LAG(wdsp_moving_avg, 8) OVER (ORDER BY observation_date) AS lag8_wdsp_moving_avg\n    FROM moving_avg\n)\n\nSELECT\n    observation_date\n    , temp_mean_c\n    , prcp_cm\n    , wdsp_ms\n\n    , ROUND(lag1_temp_moving_avg, 1) AS lag1_temp_moving_avg\n    , ROUND(lag1_prcp_moving_avg, 1) AS lag1_prcp_moving_avg\n    , ROUND(lag1_wdsp_moving_avg, 1) AS lag1_wdsp_moving_avg\n    \n    , ROUND(lag1_temp_moving_avg - lag2_temp_moving_avg, 1) AS diff2_temp_moving_avg\n    , ROUND(lag1_prcp_moving_avg - lag2_prcp_moving_avg, 1) AS diff2_prcp_moving_avg\n    , ROUND(lag1_wdsp_moving_avg - lag2_wdsp_moving_avg, 1) AS diff2_wdsp_moving_avg\n    , ROUND(lag2_temp_moving_avg, 1) AS lag2_temp_moving_avg\n    , ROUND(lag2_prcp_moving_avg, 1) AS lag2_prcp_moving_avg\n    , ROUND(lag2_wdsp_moving_avg, 1) AS lag2_wdsp_moving_avg\n    \n    , ROUND(lag2_temp_moving_avg - lag3_temp_moving_avg, 1) AS diff3_temp_moving_avg\n    , ROUND(lag2_prcp_moving_avg - lag3_prcp_moving_avg, 1) AS diff3_prcp_moving_avg\n    , ROUND(lag2_wdsp_moving_avg - lag3_wdsp_moving_avg, 1) AS diff3_wdsp_moving_avg\n    , ROUND(lag3_temp_moving_avg, 1) AS lag3_temp_moving_avg\n    , ROUND(lag3_prcp_moving_avg, 1) AS lag3_prcp_moving_avg\n    , ROUND(lag3_wdsp_moving_avg, 1) AS lag3_wdsp_moving_avg\n    \n    , ROUND(lag3_temp_moving_avg - lag4_temp_moving_avg, 1) AS diff4_temp_moving_avg\n    , ROUND(lag3_prcp_moving_avg - lag4_prcp_moving_avg, 1) AS diff4_prcp_moving_avg\n    , ROUND(lag3_wdsp_moving_avg - lag4_wdsp_moving_avg, 1) AS diff4_wdsp_moving_avg\n    , ROUND(lag4_temp_moving_avg, 1) AS lag4_temp_moving_avg\n    , ROUND(lag4_prcp_moving_avg, 1) AS lag4_prcp_moving_avg\n    , ROUND(lag4_wdsp_moving_avg, 1) AS lag4_wdsp_moving_avg\n    \n    , ROUND(lag4_temp_moving_avg - lag5_temp_moving_avg, 1) AS diff5_temp_moving_avg\n    , ROUND(lag4_prcp_moving_avg - lag5_prcp_moving_avg, 1) AS diff5_prcp_moving_avg\n    , ROUND(lag4_wdsp_moving_avg - lag5_wdsp_moving_avg, 1) AS diff5_wdsp_moving_avg\n    , ROUND(lag5_temp_moving_avg, 1) AS lag5_temp_moving_avg\n    , ROUND(lag5_prcp_moving_avg, 1) AS lag5_prcp_moving_avg\n    , ROUND(lag5_wdsp_moving_avg, 1) AS lag5_wdsp_moving_avg\n    \n    , ROUND(lag5_temp_moving_avg - lag6_temp_moving_avg, 1) AS diff6_temp_moving_avg\n    , ROUND(lag5_prcp_moving_avg - lag6_prcp_moving_avg, 1) AS diff6_prcp_moving_avg\n    , ROUND(lag5_wdsp_moving_avg - lag6_wdsp_moving_avg, 1) AS diff6_wdsp_moving_avg\n    , ROUND(lag6_temp_moving_avg, 1) AS lag6_temp_moving_avg\n    , ROUND(lag6_prcp_moving_avg, 1) AS lag6_prcp_moving_avg\n    , ROUND(lag6_wdsp_moving_avg, 1) AS lag6_wdsp_moving_avg\n    \n    , ROUND(lag6_temp_moving_avg - lag7_temp_moving_avg, 1) AS diff7_temp_moving_avg\n    , ROUND(lag6_prcp_moving_avg - lag7_prcp_moving_avg, 1) AS diff7_prcp_moving_avg\n    , ROUND(lag6_wdsp_moving_avg - lag7_wdsp_moving_avg, 1) AS diff7_wdsp_moving_avg\n    , ROUND(lag7_temp_moving_avg, 1) AS lag7_temp_moving_avg\n    , ROUND(lag7_prcp_moving_avg, 1) AS lag7_prcp_moving_avg\n    , ROUND(lag7_wdsp_moving_avg, 1) AS lag7_wdsp_moving_avg\n    \n    , ROUND(lag7_temp_moving_avg - lag8_temp_moving_avg, 1) AS diff8_temp_moving_avg\n    , ROUND(lag7_prcp_moving_avg - lag8_prcp_moving_avg, 1) AS diff8_prcp_moving_avg\n    , ROUND(lag7_wdsp_moving_avg - lag8_wdsp_moving_avg, 1) AS diff8_wdsp_moving_avg\n    , ROUND(lag8_temp_moving_avg, 1) AS lag8_temp_moving_avg\n    , ROUND(lag8_prcp_moving_avg, 1) AS lag8_prcp_moving_avg\n    , ROUND(lag8_wdsp_moving_avg, 1) AS lag8_wdsp_moving_avg\nFROM lag_moving_avg\nWHERE\n  lag8_temp_moving_avg IS NOT NULL\nORDER BY observation_date;\n-- all result rounded to 1 decimal place",
        "error_info": null
    },
    {
        "instance_id": "bq076",
        "score": 1,
        "pred_sql": "\nSELECT\n  incidents AS highest_monthly_thefts\nFROM (\n  SELECT\n    year,\n    EXTRACT(MONTH FROM date) AS month,\n    COUNT(1) AS incidents,\n    RANK() OVER (PARTITION BY year ORDER BY COUNT(1) DESC) AS ranking\n  FROM\n    `bigquery-public-data.chicago_crime.crime`\n  WHERE\n    primary_type = 'MOTOR VEHICLE THEFT'\n    AND year = 2016\n  GROUP BY\n    year,\n    month\n)\nWHERE\n  ranking = 1\nORDER BY\n  year DESC\nLIMIT 1;",
        "error_info": null
    },
    {
        "instance_id": "bq290",
        "score": 1,
        "pred_sql": "with \n\nstations_selected as (\n  select\n    usaf,\n    wban,\n    country,\n    name\n  from\n    `bigquery-public-data.noaa_gsod.stations`\n  where\n    country in ('US', 'UK')\n),\n\ndata_filtered as (\n  select\n    gsod.*,\n    stations.country\n  from\n    `bigquery-public-data.noaa_gsod.gsod2023` gsod\n  join\n    stations_selected stations\n  on\n    gsod.stn = stations.usaf\n    and gsod.wban = stations.wban\n  where\n    date(gsod.date) between '2023-10-01' and '2023-10-31'\n    and gsod.temp != 9999.9\n),\n\n-- US Metrics\nus_metrics as (\n  select\n    date(date) as metric_date,\n    avg(temp) as avg_temp_us,\n    min(temp) as min_temp_us,\n    max(temp) as max_temp_us\n  from\n    data_filtered\n  where\n    country = 'US'\n  group by\n    metric_date\n),\n\n-- UK Metrics\nuk_metrics as (\n  select\n    date(date) as metric_date,\n    avg(temp) as avg_temp_uk,\n    min(temp) as min_temp_uk,\n    max(temp) as max_temp_uk\n  from\n    data_filtered\n  where\n    country = 'UK'\n  group by\n    metric_date\n),\n\n-- Temperature Differences\ntemp_differences as (\n  select\n    us.metric_date,\n    us.max_temp_us - uk.max_temp_uk as max_temp_diff,\n    us.min_temp_us - uk.min_temp_uk as min_temp_diff,\n    us.avg_temp_us - uk.avg_temp_uk as avg_temp_diff\n  from\n    us_metrics us\n  join\n    uk_metrics uk\n  on\n    us.metric_date = uk.metric_date\n)\n\nselect \n  metric_date, \n  max_temp_diff, \n  min_temp_diff, \n  avg_temp_diff\nfrom \n  temp_differences\norder by\n  metric_date;",
        "error_info": null
    },
    {
        "instance_id": "ga001_1",
        "score": 1,
        "pred_sql": "WITH\nParams AS (\n  SELECT 'Google Red Speckled Tee' AS selected_product\n),\nDateRanges AS (\n  SELECT '20201101' AS start_date, '20201130' AS end_date, '202011' AS period UNION ALL\n  SELECT '20201201', '20201231', '202012' UNION ALL\n  SELECT '20210101', '20210131', '202101'\n),\nPurchaseEvents AS (\n  SELECT\n    period,\n    user_pseudo_id,\n    items\n  FROM\n    DateRanges\n  JOIN\n    `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*`\n    ON _TABLE_SUFFIX BETWEEN start_date AND end_date\n  WHERE\n    event_name = 'purchase'\n),\nProductABuyers AS (\n  SELECT DISTINCT\n    period,\n    user_pseudo_id\n  FROM\n    Params,\n    PurchaseEvents,\n    UNNEST(items) AS items\n  WHERE\n    items.item_name = selected_product\n),\nTopProducts AS (\n  SELECT\n    pe.period,\n    items.item_name AS item_name,\n    SUM(items.quantity) AS item_quantity\n  FROM\n    Params,\n    PurchaseEvents pe,\n    UNNEST(items) AS items\n  WHERE\n    user_pseudo_id IN (SELECT user_pseudo_id FROM ProductABuyers pb WHERE pb.period = pe.period)\n    AND items.item_name != selected_product\n  GROUP BY\n    pe.period, items.item_name\n),\nTopProductPerPeriod AS (\n  SELECT\n    period,\n    item_name,\n    item_quantity\n  FROM (\n    SELECT\n      period,\n      item_name,\n      item_quantity,\n      RANK() OVER (PARTITION BY period ORDER BY item_quantity DESC) AS rank\n    FROM\n      TopProducts\n  )\n  WHERE\n    rank = 1\n)\nSELECT\n  period,\n  item_name,\n  item_quantity\nFROM\n  TopProductPerPeriod\nORDER BY\n  period;\n",
        "error_info": null
    },
    {
        "instance_id": "bq270",
        "score": 1,
        "pred_sql": "WITH\n  cte1 AS\n    (SELECT\n      CONCAT(EXTRACT(YEAR FROM (PARSE_DATE('%Y%m%d', date))),'0',\n                EXTRACT(MONTH FROM (PARSE_DATE('%Y%m%d', date)))) AS month,\n      COUNT(hits.eCommerceAction.action_type) AS num_product_view\n    FROM `bigquery-public-data.google_analytics_sample.ga_sessions_2017*`,\n      UNNEST(hits) AS hits\n    WHERE _table_suffix BETWEEN '0101' AND '0331'\n      AND hits.eCommerceAction.action_type = '2'\n    GROUP BY month),\n  cte2 AS\n    (SELECT\n      CONCAT(EXTRACT(YEAR FROM (PARSE_DATE('%Y%m%d', date))),'0',\n                EXTRACT(MONTH FROM (PARSE_DATE('%Y%m%d', date)))) AS month,\n      COUNT(hits.eCommerceAction.action_type) AS num_addtocart\n    FROM `bigquery-public-data.google_analytics_sample.ga_sessions_2017*`,\n      UNNEST(hits) AS hits\n    WHERE _table_suffix BETWEEN '0101' AND '0331'\n      AND hits.eCommerceAction.action_type = '3'\n    GROUP BY month),\n  cte3 AS\n    (SELECT\n      CONCAT(EXTRACT(YEAR FROM (PARSE_DATE('%Y%m%d', date))),'0',\n                EXTRACT(MONTH FROM (PARSE_DATE('%Y%m%d', date)))) AS month,\n      COUNT(hits.eCommerceAction.action_type) AS num_purchase\n    FROM `bigquery-public-data.google_analytics_sample.ga_sessions_2017*`,\n      UNNEST(hits) AS hits,\n      UNNEST(hits.product) AS product\n    WHERE _table_suffix BETWEEN '0101' AND '0331'\n      AND hits.eCommerceAction.action_type = '6'\n      AND product.productRevenue IS NOT NULL\n    GROUP BY month)\nSELECT \n  ROUND((num_addtocart/num_product_view * 100),2) AS add_to_cart_rate,\n  ROUND((num_purchase/num_product_view * 100),2) AS purchase_rate\nFROM cte1\n  LEFT JOIN cte2\n  USING(month) \n  LEFT JOIN cte3\n  USING(month)\nORDER BY month;",
        "error_info": null
    },
    {
        "instance_id": "ga004",
        "score": 1,
        "pred_sql": "WITH\n  UserInfo AS (\n    SELECT\n      user_pseudo_id,\n      COUNTIF(event_name = 'page_view') AS page_view_count,\n      COUNTIF(event_name IN ('in_app_purchase', 'purchase')) AS purchase_event_count\n    FROM `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*`\n    WHERE _TABLE_SUFFIX BETWEEN '20201201' AND '20201231'\n    GROUP BY 1\n  ),\n  Averages AS (\n    SELECT\n      (purchase_event_count > 0) AS purchaser,\n      COUNT(*) AS user_count,\n      SUM(page_view_count) AS total_page_views,\n      SUM(page_view_count) / COUNT(*) AS avg_page_views\n    FROM UserInfo\n    GROUP BY 1\n  )\n\nSELECT\n  MAX(CASE WHEN purchaser THEN avg_page_views ELSE 0 END) -\n  MAX(CASE WHEN NOT purchaser THEN avg_page_views ELSE 0 END) AS avg_page_views_difference\nFROM Averages;",
        "error_info": null
    },
    {
        "instance_id": "bq032_1",
        "score": 1,
        "pred_sql": "WITH hurricane_geometry AS (\n  SELECT\n    * EXCEPT (longitude, latitude),\n    ST_GEOGPOINT(longitude, latitude) AS geom,\n  FROM\n    `bigquery-public-data.noaa_hurricanes.hurricanes`\n  WHERE\n    season = '2020'\n    AND basin = 'NA'\n    AND name != 'NOT NAMED'\n),\ndist_between_points AS (\n  SELECT\n    sid,\n    name,\n    season,\n    iso_time,\n    usa_wind,\n    geom,\n    ST_DISTANCE(geom, LAG(geom, 1) OVER (PARTITION BY sid ORDER BY iso_time ASC)) / 1000 AS dist\n  FROM\n    hurricane_geometry\n),\ntotal_distances AS (\n  SELECT\n    sid,\n    name,\n    season,\n    iso_time,\n    usa_wind,\n    geom,\n    SUM(dist) OVER (PARTITION BY sid ORDER BY iso_time ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_distance,\n    SUM(dist) OVER (PARTITION BY sid) AS total_dist\n  FROM\n    dist_between_points\n),\nranked_hurricanes AS (\n  SELECT\n    *,\n    DENSE_RANK() OVER (ORDER BY total_dist DESC) AS dense_rank\n  FROM\n    total_distances\n)\n\nSELECT\n  geom,cumulative_distance,usa_wind\nFROM\n  ranked_hurricanes\nWHERE\n  dense_rank = 3\nORDER BY\ncumulative_distance;",
        "error_info": null
    },
    {
        "instance_id": "bq181",
        "score": 1,
        "pred_sql": "WITH \nNum2022TempDatesByStation AS (\n  SELECT\n    daily_weather.stn,\n    COUNT(DISTINCT DATE(\n      CAST(daily_weather.year AS INT64),\n      CAST(daily_weather.mo AS INT64),\n      CAST(daily_weather.da AS INT64)\n    )) AS num_2022_temp_dates\n  FROM\n    `bigquery-public-data.noaa_gsod.gsod2022` daily_weather\n  WHERE\n    daily_weather.temp IS NOT NULL\n    AND daily_weather.max IS NOT NULL\n    AND daily_weather.min IS NOT NULL\n    AND daily_weather.temp != 9999.9\n    AND daily_weather.max != 9999.9\n    AND daily_weather.min != 9999.9\n  GROUP BY\n    daily_weather.stn\n),\n\nTotalStations AS (\n  SELECT\n    COUNT(*) AS total_stations\n  FROM\n    `bigquery-public-data.noaa_gsod.stations` Stations\n  WHERE\n    Stations.usaf != '999999'\n),\n\nStationsWith90PercentCoverage AS (\n  SELECT\n    COUNT(*) AS stations_with_90_percent_coverage\n  FROM\n    Num2022TempDatesByStation\n  WHERE\n    num_2022_temp_dates >= 0.90 * 365\n)\n\nSELECT\n  (stations_with_90_percent_coverage / total_stations) * 100 AS percentage_of_stations_with_90_percent_coverage\nFROM\n  TotalStations,\n  StationsWith90PercentCoverage",
        "error_info": null
    },
    {
        "instance_id": "bq016",
        "score": 1,
        "pred_sql": "DECLARE\n    Sys STRING DEFAULT 'PYPI';\n\nWITH HighestReleases AS (\n    SELECT\n        Name,\n        Version,\n    FROM (\n        SELECT\n            Name,\n            Version,\n            ROW_NUMBER() OVER (\n                PARTITION BY Name\n                ORDER BY VersionInfo.Ordinal DESC\n            ) AS RowNumber\n        FROM\n            `spider2-public-data.deps_dev_v1.PackageVersions`\n        WHERE\n            System = Sys\n            AND VersionInfo.IsRelease\n    )\n    WHERE RowNumber = 1\n)\n\nSELECT\n    D.Dependency.Name,\n    D.Dependency.Version\nFROM\n    `spider2-public-data.deps_dev_v1.Dependencies` AS D\nJOIN\n    HighestReleases AS H\nUSING\n    (Name, Version)\nWHERE\n    D.System = Sys\nGROUP BY\n    D.Dependency.Name,\n    D.Dependency.Version\nORDER BY\n    COUNT(*) DESC\nLIMIT 1;",
        "error_info": null
    },
    {
        "instance_id": "bq320",
        "score": 1,
        "pred_sql": "SELECT\n  COUNT(*) AS total_count\nFROM\n  `bigquery-public-data.idc_v11.dicom_pivot_v11` dicom_pivot_v11\nWHERE\n  StudyInstanceUID IN (\n    SELECT\n      StudyInstanceUID\n    FROM\n      `bigquery-public-data.idc_v11.dicom_pivot_v11` dicom_pivot_v11\n    WHERE\n      StudyInstanceUID IN (\n        SELECT\n          StudyInstanceUID\n        FROM\n          `bigquery-public-data.idc_v11.dicom_pivot_v11` dicom_pivot_v11\n        WHERE\n          (\n            LOWER(\n              dicom_pivot_v11.SegmentedPropertyTypeCodeSequence\n            ) LIKE LOWER('80891009:SCT')\n          )\n        GROUP BY\n          StudyInstanceUID\n        INTERSECT DISTINCT\n        SELECT\n          StudyInstanceUID\n        FROM\n          `bigquery-public-data.idc_v11.dicom_pivot_v11` dicom_pivot_v11\n        WHERE\n          (\n            dicom_pivot_v11.collection_id IN ('Community', 'nsclc_radiomics')\n          )\n        GROUP BY\n          StudyInstanceUID\n      )\n    GROUP BY\n      StudyInstanceUID\n  );",
        "error_info": null
    },
    {
        "instance_id": "bq230",
        "score": 1,
        "pred_sql": "WITH \n  temp_table AS\n  (SELECT\n    state_name,\n    commodity_desc,\n    SUM(value) AS total_produce,\n    TIMESTAMP_TRUNC(load_time, YEAR) AS year_load,\n  FROM \n    `bigquery-public-data.usda_nass_agriculture.crops`\n  WHERE\n    group_desc='FIELD CROPS' AND\n    statisticcat_desc='PRODUCTION' AND\n    agg_level_desc='STATE' AND\n    value IS NOT NULL AND\n    unit_desc='BU'\n  GROUP BY\n    commodity_desc,\n    year_load,\n    state_name\n  ORDER BY\n    state_name,\n    commodity_desc,\n    total_produce DESC)\nSELECT\n  state_name,\n  MAX(total_produce) AS total_prod\nFROM\n  temp_table\nWHERE\n  year_load='2018-01-01 00:00:00 UTC' AND\n  commodity_desc='CORN'\nGROUP BY\n  state_name,\n  commodity_desc\nORDER BY\n  state_name",
        "error_info": null
    },
    {
        "instance_id": "bq048",
        "score": 1,
        "pred_sql": "WITH nyc_weather AS (\n    SELECT\n    -- Create a timestamp from the date components.\n    timestamp(concat(year, \"-\", mo, \"-\", da)) as timestamp,\n    -- Replace numerical null values with actual nulls\n    AVG(IF (wdsp=\"999.9\", null, CAST(wdsp AS Float64))) AS wind_speed\n    FROM\n        `bigquery-public-data.noaa_gsod.gsod20*`\n    WHERE\n        CAST(YEAR AS INT64) BETWEEN 2011 AND 2020\n    AND stn = \"744860\" -- JFK Airport\n    GROUP BY timestamp\n),\ncomplaint_correlations AS (\n    SELECT\n        complaint_type,\n        sum(complaint_count) as total_complaint_count,\n        count(wind_speed) as data_count,\n        ROUND(corr(wind_speed, avg_count), 4) AS corr_count,\n        ROUND(corr(wind_speed, avg_pct_count), 4) AS corr_pct\n    From (\n        SELECT\n            avg(pct_count) as avg_pct_count,\n            avg(day_count) as avg_count,\n            sum(day_count) as complaint_count,\n            complaint_type,\n            wind_speed\n        FROM (\n            SELECT\n                DATE(timestamp) AS date,\n                wind_speed\n            FROM\n                nyc_weather) a\n        JOIN (\n            SELECT x.date, complaint_type, day_count, day_count / all_calls_count as pct_count\n            FROM (\n                SELECT\n                        DATE(created_date) AS date,\n                        complaint_type,\n                        COUNT(*) AS day_count\n                FROM\n                    `bigquery-public-data.new_york.311_service_requests`\n                GROUP BY\n                    date,\n                    complaint_type) x\n            JOIN (\n                SELECT\n                    DATE(timestamp) AS date,\n                    COUNT(*) AS all_calls_count\n                FROM nyc_weather\n                GROUP BY date\n            ) y\n            ON x.date=y.date\n        ) b\n        ON\n            a.date = b.date\n        GROUP BY\n            complaint_type,\n            wind_speed\n    )\n    GROUP BY complaint_type\n    HAVING\n        total_complaint_count > 3000\n    ORDER BY\n    corr_pct DESC\n)\nSELECT\n    'Positive' AS correlation_type,\n    complaint_type,\n    corr_pct AS correlation\nFROM\n    complaint_correlations\nWHERE\n    corr_pct = (SELECT MAX(corr_pct) FROM complaint_correlations)\nUNION ALL\nSELECT\n    'Negative' AS correlation_type,\n    complaint_type,\n    corr_pct AS correlation\nFROM\n    complaint_correlations\nWHERE\n    corr_pct = (SELECT MIN(corr_pct) FROM complaint_correlations);",
        "error_info": null
    },
    {
        "instance_id": "bq329",
        "score": 1,
        "pred_sql": "WITH bikeshare_stations AS (\n  SELECT *\n  FROM \n    `bigquery-public-data.austin_bikeshare.bikeshare_stations`\n), \nbikeshare_trips AS (\n  SELECT \n    start_station_id,\n    SAFE_CAST(end_station_id AS INT64) AS end_station_id,\n    duration_minutes\n  FROM \n    `bigquery-public-data.austin_bikeshare.bikeshare_trips`\n),\naverage_duration AS (\n  SELECT \n    start_station_id,\n    AVG(duration_minutes) AS avg_duration_minutes\n  FROM \n    bikeshare_trips\n  GROUP BY \n    start_station_id\n)\nSELECT \n  ad.start_station_id\nFROM \n  average_duration ad\nJOIN bikeshare_stations st ON ad.start_station_id = st.station_id\nORDER BY \n  ad.avg_duration_minutes ASC\nLIMIT 1; ",
        "error_info": null
    },
    {
        "instance_id": "ga010_1",
        "score": 1,
        "pred_sql": "WITH prep AS (\n  SELECT\n    user_pseudo_id,\n    (SELECT value.int_value FROM UNNEST(event_params) WHERE key = 'ga_session_id') AS session_id,\n    ARRAY_AGG((SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'source') IGNORE NULLS \n              ORDER BY event_timestamp)[SAFE_OFFSET(0)] AS source,\n    ARRAY_AGG((SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'medium') IGNORE NULLS \n              ORDER BY event_timestamp)[SAFE_OFFSET(0)] AS medium,\n    ARRAY_AGG((SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'campaign') IGNORE NULLS \n              ORDER BY event_timestamp)[SAFE_OFFSET(0)] AS campaign\n  FROM\n    `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*`\n  WHERE\n    _TABLE_SUFFIX BETWEEN '20201201' AND '20201231'\n  GROUP BY\n    user_pseudo_id,\n    session_id\n)\nSELECT\n  -- session default channel grouping (dimension | the channel group associated with a session) \n  CASE \n    WHEN source = '(direct)' AND (medium IN ('(not set)','(none)')) THEN 'Direct'\n    WHEN REGEXP_CONTAINS(campaign, 'cross-network') THEN 'Cross-network'\n    WHEN (REGEXP_CONTAINS(source,'alibaba|amazon|google shopping|shopify|etsy|ebay|stripe|walmart')\n        OR REGEXP_CONTAINS(campaign, '^(.*(([^a-df-z]|^)shop|shopping).*)$'))\n        AND REGEXP_CONTAINS(medium, '^(.*cp.*|ppc|paid.*)$') THEN 'Paid Shopping'\n    WHEN REGEXP_CONTAINS(source,'baidu|bing|duckduckgo|ecosia|google|yahoo|yandex')\n        AND REGEXP_CONTAINS(medium,'^(.*cp.*|ppc|paid.*)$') THEN 'Paid Search'\n    WHEN REGEXP_CONTAINS(source,'badoo|facebook|fb|instagram|linkedin|pinterest|tiktok|twitter|whatsapp')\n        AND REGEXP_CONTAINS(medium,'^(.*cp.*|ppc|paid.*)$') THEN 'Paid Social'\n    WHEN REGEXP_CONTAINS(source,'dailymotion|disneyplus|netflix|youtube|vimeo|twitch|vimeo|youtube')\n        AND REGEXP_CONTAINS(medium,'^(.*cp.*|ppc|paid.*)$') THEN 'Paid Video'\n    WHEN medium IN ('display', 'banner', 'expandable', 'interstitial', 'cpm') THEN 'Display'\n    WHEN REGEXP_CONTAINS(source,'alibaba|amazon|google shopping|shopify|etsy|ebay|stripe|walmart')\n        OR REGEXP_CONTAINS(campaign, '^(.*(([^a-df-z]|^)shop|shopping).*)$') THEN 'Organic Shopping'\n    WHEN REGEXP_CONTAINS(source,'badoo|facebook|fb|instagram|linkedin|pinterest|tiktok|twitter|whatsapp')\n        OR medium IN ('social','social-network','social-media','sm','social network','social media') THEN 'Organic Social'\n    WHEN REGEXP_CONTAINS(source,'dailymotion|disneyplus|netflix|youtube|vimeo|twitch|vimeo|youtube')\n        OR REGEXP_CONTAINS(medium,'^(.*video.*)$') THEN 'Organic Video'\n    WHEN REGEXP_CONTAINS(source,'baidu|bing|duckduckgo|ecosia|google|yahoo|yandex')\n        OR medium = 'organic' THEN 'Organic Search'\n    WHEN REGEXP_CONTAINS(source,'email|e-mail|e_mail|e mail')\n        OR REGEXP_CONTAINS(medium,'email|e-mail|e_mail|e mail') THEN 'Email'\n    WHEN medium = 'affiliate' THEN 'Affiliates'\n    WHEN medium = 'referral' THEN 'Referral'\n    WHEN medium = 'audio' THEN 'Audio'\n    WHEN medium = 'sms' THEN 'SMS'\n    WHEN medium LIKE '%push'\n        OR REGEXP_CONTAINS(medium,'mobile|notification') THEN 'Mobile Push Notifications'\n    ELSE 'Unassigned' \n  END AS channel_grouping_session,\n  COUNT(DISTINCT CONCAT(user_pseudo_id, session_id)) AS sessions\nFROM\n  prep\nGROUP BY\n  channel_grouping_session",
        "error_info": null
    },
    {
        "instance_id": "bq279",
        "score": 1,
        "pred_sql": "SELECT\n    t.year,\n    CASE \n        WHEN t.year = 2013 THEN (\n                                  SELECT \n                                    COUNT(DISTINCT station_id)\n                                  FROM \n                                    `bigquery-public-data.austin_bikeshare.bikeshare_trips` t\n                                  INNER JOIN \n                                    `bigquery-public-data.austin_bikeshare.bikeshare_stations` s\n                                  ON \n                                    t.start_station_id = s.station_id\n                                  WHERE \n                                    s.status = 'active' AND EXTRACT(YEAR FROM start_time) = 2013\n                                 ) \n        WHEN t.year = 2014 THEN (\n                                  SELECT \n                                    COUNT(DISTINCT station_id)\n                                  FROM \n                                    `bigquery-public-data.austin_bikeshare.bikeshare_trips` t\n                                  INNER JOIN \n                                    `bigquery-public-data.austin_bikeshare.bikeshare_stations` s\n                                  ON \n                                    t.start_station_id = s.station_id\n                                  WHERE \n                                    s.status = 'active' AND EXTRACT(YEAR FROM start_time) = 2014\n                                 )\n    END\n    AS number_status_active,\n    CASE \n        WHEN t.year = 2013 THEN (\n                                  SELECT \n                                   COUNT(DISTINCT station_id)\n                                  FROM \n                                  `bigquery-public-data.austin_bikeshare.bikeshare_trips` t\n                                  INNER JOIN \n                                  `bigquery-public-data.austin_bikeshare.bikeshare_stations` s\n                                  ON \n                                   t.start_station_id = s.station_id\n                                  WHERE \n                                   s.status = 'closed' AND EXTRACT(YEAR FROM start_time) = 2013\n                                 ) \n        WHEN t.year = 2014 THEN (\n                                  SELECT \n                                  COUNT(DISTINCT station_id)\n                                  FROM \n                                    `bigquery-public-data.austin_bikeshare.bikeshare_trips` t\n                                  INNER JOIN \n                                    `bigquery-public-data.austin_bikeshare.bikeshare_stations` s\n                                  ON \n                                    t.start_station_id = s.station_id\n                                  WHERE \n                                    s.status = 'closed' AND EXTRACT(YEAR FROM start_time) = 2014\n                                 )\n    END\n    AS number_status_closed\nFROM\n    (\n      SELECT \n         EXTRACT(YEAR FROM start_time) AS year,\n         start_station_id\n      FROM\n         `bigquery-public-data.austin_bikeshare.bikeshare_trips`\n    ) \n    AS t\nINNER JOIN\n    `bigquery-public-data.austin_bikeshare.bikeshare_stations` s\nON\n    t.start_station_id = s.station_id\nWHERE\n    t.year BETWEEN 2013 AND 2014\nGROUP BY\n    t.year\nORDER BY\n    t.year;",
        "error_info": null
    },
    {
        "instance_id": "bq014",
        "score": 1,
        "pred_sql": "\nWITH first_orders AS (\n  SELECT\n    o.order_id,\n    o.user_id,\n    ROW_NUMBER() OVER (PARTITION BY o.user_id ORDER BY o.created_at ASC) order_sequence\n  FROM\n    `bigquery-public-data.thelook_ecommerce.orders` o\n  WHERE\n    o.status NOT IN ('Cancelled', 'Returned')\n  QUALIFY order_sequence = 1\n), \ncategory_stats AS (\n  SELECT\n    p.category,\n    SUM(oi.sale_price) AS revenue,\n    COUNT(DISTINCT fo.user_id) AS user_count\n  FROM\n    first_orders fo\n  LEFT JOIN\n    `bigquery-public-data.thelook_ecommerce.order_items` oi ON oi.order_id = fo.order_id\n  LEFT JOIN\n    `bigquery-public-data.thelook_ecommerce.products` p ON p.id = oi.product_id\n  GROUP BY\n    p.category\n),\n\ntop_category AS (\n  SELECT\n    category\n  FROM\n    category_stats\n  ORDER BY\n    user_count DESC\n  LIMIT 1\n)\n\nSELECT\n  c.revenue\nFROM\n  category_stats c\nJOIN\n  top_category t ON c.category = t.category;",
        "error_info": null
    },
    {
        "instance_id": "bq214",
        "score": 1,
        "pred_sql": "WITH patents_sample AS (\n    SELECT \n        t1.publication_number, \n        t1.application_number \n    FROM \n        `patents-public-data.patents.publications` t1 \n    WHERE \n        country_code = 'US' AND\n        grant_date BETWEEN 20170101 AND 20170131 AND\n        publication_number LIKE '%B2%'\n),\n\nForward_citation AS (\n    SELECT\n        DISTINCT patents_sample.publication_number,\n        COUNT(DISTINCT t3.citing_application_number) AS forward_citations\n    FROM\n        patents_sample\n    LEFT JOIN (\n        SELECT\n            x2.publication_number,\n            PARSE_DATE('%Y%m%d', CAST(x2.filing_date AS STRING)) AS filing_date\n        FROM\n            `patents-public-data.patents.publications` x2\n        WHERE\n            x2.filing_date != 0\n    ) t2 ON t2.publication_number = patents_sample.publication_number\n    LEFT JOIN (\n        SELECT\n            x3.publication_number AS citing_publication_number,\n            x3.application_number AS citing_application_number,\n            PARSE_DATE('%Y%m%d', CAST(x3.filing_date AS STRING)) AS joined_filing_date,\n            citation_u.publication_number AS cited_publication_number\n        FROM\n            `patents-public-data.patents.publications` x3,\n            UNNEST(citation) AS citation_u\n        WHERE\n            x3.filing_date != 0\n    ) t3 ON patents_sample.publication_number = t3.cited_publication_number AND\n             t3.joined_filing_date BETWEEN t2.filing_date AND DATE_ADD(t2.filing_date, INTERVAL 1 MONTH)\n    GROUP BY\n        patents_sample.publication_number\n),\n\nselect_sample AS (\n    SELECT \n        publication_number\n    FROM\n        Forward_citation\n    ORDER BY\n        forward_citations DESC\n    LIMIT 1\n),\n\nt AS (\n    SELECT\n        t1.publication_number,\n        t4.publication_number AS similar_publication_number,\n        (SELECT SUM(element1 * element2)\n         FROM t5.embedding_v1 element1 WITH OFFSET pos\n         JOIN t6.embedding_v1 element2 WITH OFFSET pos USING (pos)) AS similarity\n    FROM \n        (SELECT * FROM select_sample LIMIT 1) t1\n    LEFT JOIN (\n        SELECT \n            x3.publication_number,\n            EXTRACT(YEAR FROM PARSE_DATE('%Y%m%d', CAST(x3.filing_date AS STRING))) AS focal_filing_year\n        FROM \n            `patents-public-data.patents.publications` x3\n        WHERE \n            x3.filing_date != 0\n    ) t3 ON t3.publication_number = t1.publication_number\n    LEFT JOIN (\n        SELECT \n            x4.publication_number,\n            EXTRACT(YEAR FROM PARSE_DATE('%Y%m%d', CAST(x4.filing_date AS STRING))) AS filing_year\n        FROM \n            `patents-public-data.patents.publications` x4\n        WHERE \n            x4.filing_date != 0\n    ) t4 ON  t4.publication_number != t1.publication_number AND\n             t3.focal_filing_year = t4.filing_year\n    LEFT JOIN `patents-public-data.google_patents_research.publications` t5 ON t5.publication_number = t1.publication_number\n    LEFT JOIN `patents-public-data.google_patents_research.publications` t6 ON t6.publication_number = t4.publication_number\n    ORDER BY \n        t1.publication_number, similarity DESC\n)\n\nSELECT\n    t.similar_publication_number\nFROM (\n    SELECT\n        t.*,\n        ROW_NUMBER() OVER (PARTITION BY publication_number ORDER BY similarity DESC) AS seqnum\n    FROM\n        t\n) t\nWHERE\n    seqnum <= 1;\n\n\n\n",
        "error_info": null
    },
    {
        "instance_id": "bq289",
        "score": 1,
        "pred_sql": "WITH philadelphia AS (\n    SELECT \n        * \n    FROM \n        `bigquery-public-data.geo_us_census_places.places_pennsylvania` \n    WHERE \n        place_name = 'Philadelphia'\n),\namenities AS (\n    SELECT *, \n           (\n                SELECT \n                    tags.value \n                FROM \n                    UNNEST(all_tags) AS tags \n                WHERE \n                    tags.key = 'amenity'\n           ) AS amenity\n    FROM \n        `bigquery-public-data.geo_openstreetmap.planet_features_points` AS features\n    CROSS JOIN philadelphia\n    WHERE ST_CONTAINS(philadelphia.place_geom, features.geometry)\n    AND \n    (\n        EXISTS (\n            SELECT 1 \n            FROM UNNEST(all_tags) AS tags \n            WHERE tags.key = 'amenity' \n            AND tags.value IN ('library', 'place_of_worship', 'community_centre')\n        )\n    )\n),\njoiin AS (\n    SELECT \n        a1.*, \n        a2.osm_id AS nearest_osm_id, \n        ST_DISTANCE(a1.geometry, a2.geometry) AS distance, \n        ROW_NUMBER() OVER (PARTITION BY a1.osm_id ORDER BY ST_Distance(a1.geometry, a2.geometry)) AS row_num\n    FROM amenities a1\n    CROSS JOIN amenities a2\n    WHERE a1.osm_id < a2.osm_id\n    ORDER BY a1.osm_id, distance\n) \nSELECT distance\nFROM joiin  \nWHERE row_num = 1\nORDER BY distance ASC\nLIMIT 1;\n",
        "error_info": null
    },
    {
        "instance_id": "bq227_2",
        "score": 1,
        "pred_sql": "WITH borough_data AS (\n    SELECT \n        year, \n        month, \n        borough, \n        major_category, \n        minor_category, \n        SUM(value) AS total,\n    CASE \n        WHEN \n            major_category = 'Theft and Handling' \n        THEN \n            'Theft and Handling'\n        ELSE \n            'Other' \n    END AS major_division,\n    CASE \n        WHEN \n            minor_category = 'Other Theft' THEN minor_category\n        ELSE \n            'Other'\n    END AS minor_division,\n    FROM \n        bigquery-public-data.london_crime.crime_by_lsoa\n    GROUP BY 1,2,3,4,5\n    ORDER BY 1,2\n)\n\nSELECT year, SUM(total) AS year_total\nFROM borough_data\nWHERE \n    borough = 'Westminster'\nAND\n    major_division != 'Other'\nAND \n    minor_division != 'Other'\nGROUP BY year, major_division, minor_division\nORDER BY year;",
        "error_info": null
    },
    {
        "instance_id": "bq195",
        "score": 1,
        "pred_sql": "WITH value_table AS (\n    SELECT to_address AS address, value AS value\n    FROM `spider2-public-data.crypto_ethereum.traces`\n    WHERE to_address IS NOT null\n    AND block_timestamp < '2021-09-01 00:00:00'\n    AND status=1\n    AND (call_type NOT IN ('delegatecall', 'callcode', 'staticcall') OR call_type IS null)\n    \n    UNION ALL\n    \n    SELECT from_address AS address, -value AS value\n    FROM `spider2-public-data.crypto_ethereum.traces`\n    WHERE from_address IS NOT null\n    AND block_timestamp < '2021-09-01 00:00:00'\n    AND status=1\n    AND (call_type NOT IN ('delegatecall', 'callcode', 'staticcall') OR call_type IS null)\n    \n    UNION ALL\n    \n    SELECT miner as address, SUM(CAST(receipt_gas_used AS NUMERIC) * CAST(gas_price AS NUMERIC)) AS value\n    FROM `spider2-public-data.crypto_ethereum.transactions` AS transactions\n    JOIN `spider2-public-data.crypto_ethereum.blocks` AS blocks\n    ON blocks.number = transactions.block_number\n    WHERE block_timestamp < '2021-09-01 00:00:00'\n    GROUP BY blocks.miner\n    \n    UNION ALL\n    \n    SELECT from_address as address, -(CAST(receipt_gas_used AS NUMERIC) * CAST(gas_price AS NUMERIC)) AS value\n    FROM  `spider2-public-data.crypto_ethereum.transactions`\n    WHERE block_timestamp < '2021-09-01 00:00:00'\n)\nSELECT address, FLOOR(SUM(value) / power(10,18)) AS balance\nFROM value_table\nGROUP BY address\nORDER BY balance DESC\nLIMIT 10",
        "error_info": null
    },
    {
        "instance_id": "bq060",
        "score": 1,
        "pred_sql": "WITH results AS (\n    SELECT\n        growth.country_name,\n        growth.net_migration,\n        CAST(area.country_area as INT64) as country_area\n    FROM (\n        SELECT\n            country_name,\n            net_migration,\n            country_code\n        FROM\n            `bigquery-public-data.census_bureau_international.birth_death_growth_rates`\n        WHERE\n            year = 2017\n    ) growth\n    INNER JOIN (\n        SELECT\n            country_area,\n            country_code\n        FROM\n            `bigquery-public-data.census_bureau_international.country_names_area`\n        WHERE\n            country_area > 500\n    ) area\n    ON\n        growth.country_code = area.country_code\n    ORDER BY\n        net_migration DESC\n    LIMIT 3\n)\nSELECT country_name, net_migration\nFROM results;",
        "error_info": null
    },
    {
        "instance_id": "bq269",
        "score": 1,
        "pred_sql": "WITH \n  cte1 AS\n    (SELECT\n      CONCAT(EXTRACT(YEAR FROM (PARSE_DATE('%Y%m%d', date))),'0',\n            EXTRACT(MONTH FROM (PARSE_DATE('%Y%m%d', date)))) AS month,\n      SUM(totals.pageviews)/COUNT(DISTINCT fullVisitorId) AS avg_pageviews_non_purchase\n    FROM `bigquery-public-data.google_analytics_sample.ga_sessions_2017*`,\n      UNNEST (hits) AS hits,\n      UNNEST (hits.product) AS product\n    WHERE _table_suffix BETWEEN '0601' AND '0731'\n      AND totals.transactions IS NULL\n      AND product.productRevenue IS NULL\n    GROUP BY month),\n  cte2 AS\n    (SELECT\n      CONCAT(EXTRACT(YEAR FROM (PARSE_DATE('%Y%m%d', date))),'0',\n            EXTRACT(MONTH FROM (PARSE_DATE('%Y%m%d', date)))) AS month,\n      SUM(totals.pageviews)/COUNT(DISTINCT fullVisitorId) AS avg_pageviews_purchase\n    FROM `bigquery-public-data.google_analytics_sample.ga_sessions_2017*`,\n      UNNEST (hits) AS hits,\n      UNNEST (hits.product) AS product\n    WHERE _table_suffix BETWEEN '0601' AND '0731'\n      AND totals.transactions >= 1\n      AND product.productRevenue IS NOT NULL\n    GROUP BY month)\nSELECT month, avg_pageviews_purchase, avg_pageviews_non_purchase\nFROM cte1 INNER JOIN cte2\nUSING(month)\nORDER BY month;\n",
        "error_info": null
    },
    {
        "instance_id": "bq004",
        "score": 1,
        "pred_sql": "with product_and_quatity AS (\n    SELECT \n        DISTINCT v2ProductName AS other_purchased_products,\n        SUM(productQuantity) AS quatity\n    FROM\n        `bigquery-public-data.google_analytics_sample.ga_sessions_2017*`,\n        UNNEST(hits) AS hits,\n        UNNEST(hits.product) AS product\n    WHERE\n        _table_suffix BETWEEN '0701' AND '0731'\n        AND product.productRevenue IS NOT NULL\n        AND v2ProductName NOT LIKE '%YouTube%'\n        AND fullVisitorID IN (\n            SELECT \n            DISTINCT fullVisitorId\n            FROM\n                `bigquery-public-data.google_analytics_sample.ga_sessions_2017*`,\n                UNNEST(hits) AS hits,\n                UNNEST(hits.product) AS product\n            WHERE\n                _table_suffix BETWEEN '0701' AND '0731'\n                AND product.productRevenue IS NOT NULL\n                AND v2ProductName LIKE '%YouTube%'\n        )\n    GROUP BY v2ProductName\n)\nSELECT other_purchased_products\nFROM product_and_quatity\nORDER BY quatity DESC\nLIMIT 1;",
        "error_info": null
    },
    {
        "instance_id": "bq017",
        "score": 1,
        "pred_sql": "WITH bounding_area AS (\n  SELECT geometry \n  FROM `bigquery-public-data.geo_openstreetmap.planet_features`\n  WHERE feature_type = \"multipolygons\"\n    AND ('wikidata', 'Q17') IN (\n      SELECT (key, value) \n      FROM unnest(all_tags)\n    )\n),\n\nhighway_info AS (\n  SELECT \n    SUM(ST_LENGTH(planet_features.geometry)) AS highway_length,\n    format(\"%'d\", CAST(SUM(ST_LENGTH(planet_features.geometry)) AS INT64)) AS highway_length_formatted,\n    count(*) AS highway_count,\n    (\n      SELECT value \n      FROM unnest(all_tags) \n      WHERE key = 'highway'\n    ) AS highway_type  -- Extract value of \"highway\" tag\n  FROM \n    `bigquery-public-data.geo_openstreetmap.planet_features` planet_features, \n    bounding_area\n  WHERE \n    feature_type = 'lines'\n    AND 'highway' IN (\n      SELECT key \n      FROM UNNEST(all_tags)\n    ) -- Select highways\n    AND ST_DWithin(bounding_area.geometry, planet_features.geometry, 0)  -- Filter only features within bounding_area\n  GROUP BY \n    highway_type\n)\n\nSELECT \n  highway_type\nFROM\n  highway_info\nORDER BY \n  highway_length DESC\nLIMIT 5\n",
        "error_info": null
    },
    {
        "instance_id": "bq010",
        "score": 1,
        "pred_sql": "WITH GET_CUS_ID AS (\n    SELECT \n        DISTINCT fullVisitorId as Henley_CUSTOMER_ID\n    FROM \n        `bigquery-public-data.google_analytics_sample.ga_sessions_201707*`,\n        UNNEST(hits) AS hits,\n        UNNEST(hits.product) as product\n    WHERE\n        product.v2ProductName = \"YouTube Men's Vintage Henley\"\n        AND product.productRevenue IS NOT NULL\n    )\n\nSELECT\n    product.v2ProductName AS other_purchased_products\nFROM\n    `bigquery-public-data.google_analytics_sample.ga_sessions_201707*` TAB_A \n    RIGHT JOIN GET_CUS_ID\n    ON GET_CUS_ID.Henley_CUSTOMER_ID=TAB_A.fullVisitorId,\n    UNNEST(hits) AS hits,\n    UNNEST(hits.product) as product\nWHERE\n    TAB_A.fullVisitorId IN (\n        SELECT * FROM GET_CUS_ID\n    )\n    AND product.v2ProductName <> \"YouTube Men's Vintage Henley\"\n    AND product.productRevenue IS NOT NULL\nGROUP BY\n    product.v2ProductName\nORDER BY\n    SUM(product.productQuantity) DESC\nLIMIT 1;",
        "error_info": null
    },
    {
        "instance_id": "bq275",
        "score": 1,
        "pred_sql": "WITH \n  visit AS (\n    SELECT fullvisitorid, MIN(date) AS date_first_visit\n    FROM `bigquery-public-data.google_analytics_sample.ga_sessions_*` \n    GROUP BY fullvisitorid\n  ),\n  \n  transactions AS (\n    SELECT fullvisitorid, MIN(date) AS date_transactions, 1 AS transaction\n    FROM `bigquery-public-data.google_analytics_sample.ga_sessions_*` AS ga, \n    UNNEST(ga.hits) AS hits \n    WHERE hits.transaction.transactionId IS NOT NULL \n    GROUP BY fullvisitorid\n  ),\n\n  device_transactions AS (\n    SELECT DISTINCT fullvisitorid, date, device.deviceCategory AS device_transaction\n    FROM `bigquery-public-data.google_analytics_sample.ga_sessions_*` AS ga, \n    UNNEST(ga.hits) AS hits \n    WHERE hits.transaction.transactionId IS NOT NULL\n  ),\n\n  visits_transactions AS (\n    SELECT visit.fullvisitorid, date_first_visit, date_transactions, device_transaction\n    FROM visit \n    LEFT JOIN transactions ON visit.fullvisitorid = transactions.fullvisitorid\n    LEFT JOIN device_transactions ON visit.fullvisitorid = device_transactions.fullvisitorid \n    AND transactions.date_transactions = device_transactions.date\n  )\n\nSELECT fullvisitorid \nFROM visits_transactions\nWHERE DATE_DIFF(PARSE_DATE('%Y%m%d', date_transactions), PARSE_DATE('%Y%m%d', date_first_visit), DAY) > 0\nAND device_transaction = \"mobile\";",
        "error_info": null
    },
    {
        "instance_id": "bq026_2",
        "score": 1,
        "pred_sql": "WITH PatentApplications AS (\n    SELECT \n        ANY_VALUE(assignee_harmonized) AS assignee_harmonized,  -- Collects any sample of harmonized assignee data.\n        ANY_VALUE(filing_date) AS filing_date,  -- Collects any sample of filing date.\n        ANY_VALUE(country_code) AS country_code,  -- Collects any sample of country code.\n        application_number  -- The unique identifier for each patent application.\n    FROM \n        `patents-public-data.patents.publications` AS pubs  -- Using the patents publications dataset.\n    WHERE EXISTS (\n        SELECT 1 FROM UNNEST(pubs.cpc) AS c WHERE REGEXP_CONTAINS(c.code, \"A01B3\")\n    )\n    GROUP BY \n        application_number  -- Group by application number to ensure distinct entries.\n)\n\n,AssigneeApplications AS (\n    SELECT \n        COUNT(*) AS year_country_cnt,  -- Count of applications per assignee, year, and country.\n        a.name AS assignee_name,  -- Name of the assignee.\n        CAST(FLOOR(filing_date / 10000) AS INT64) AS filing_year,  -- Extracts the year from the filing date.\n        apps.country_code  -- Country code of the application.\n    FROM \n        PatentApplications AS apps  -- Using the previously defined CTE.\n    CROSS JOIN\n    UNNEST(assignee_harmonized) AS a  -- Expanding the assignee_harmonized array.\n    GROUP BY \n        a.name, filing_year, country_code  -- Grouping by assignee, year, and country.\n)\n\n-- CTE to aggregate data by assignee and year and to collect top 5 countries by application count.\n,AggregatedData AS (\n    SELECT \n        SUM(year_country_cnt) AS year_cnt,  -- Sum of all applications per assignee per year.\n        assignee_name, \n        filing_year, \n        -- Aggregates the top 5 countries by their application counts in descending order.\n        STRING_AGG(country_code ORDER BY year_country_cnt DESC LIMIT 1) AS countries\n    FROM \n        AssigneeApplications  -- Using the AssigneeApplications CTE.\n    GROUP BY \n        assignee_name, filing_year  -- Grouping results by assignee and year.\n)\n\n-- Final aggregation to find the year with the highest application count for each assignee.\n,FinalAggregation AS (\n    SELECT \n        SUM(year_cnt) AS total_count,  -- Total count of applications for each assignee.\n        assignee_name,\n        -- Aggregates into a structure the year and countries data with the highest application count.\n        ARRAY_AGG(\n            STRUCT<cnt INT64, filing_year INT64, countries STRING>\n            (year_cnt, filing_year, countries) \n            ORDER BY year_cnt DESC LIMIT 1\n        )[SAFE_ORDINAL(1)] AS largest_year  -- Selects the year with the highest application count.\n    FROM \n        AggregatedData  -- Using the AggregatedData CTE.\n    GROUP BY \n        assignee_name  -- Grouping by assignee.\n)\n\n-- Selecting final results including total application count, assignee name, and details of their largest year.\nSELECT \n    total_count,\n    assignee_name,\n    largest_year.cnt,\n    largest_year.filing_year,\n    largest_year.countries\nFROM \n    FinalAggregation  -- Using the FinalAggregation CTE.\nORDER BY \n    total_count DESC  -- Ordering by total application count in descending order.\nLIMIT 20;  -- Limits the results to the top 20 assignees.",
        "error_info": null
    },
    {
        "instance_id": "bq207",
        "score": 1,
        "pred_sql": "WITH table_a AS(\n    SELECT \n        pat_no, claim_no, word_ct\n    FROM `patents-public-data.uspto_oce_claims.patent_claims_stats` \n    WHERE ind_flg='1'\n), matched_publn AS(\n    SELECT\n        publication_number,\n        claim_no,\n        CAST(word_ct AS INT64) AS word_ct  -- Cast word_ct to INT64 if it's stored as a string\n    FROM table_a\n    INNER JOIN `patents-public-data.uspto_oce_claims.match` USING(pat_no)\n), matched_appln AS(\n    SELECT\n        application_number appln_nr,\n        publication_number publn_nr,\n        claim_no,\n        word_ct\n    FROM matched_publn\n    INNER JOIN(\n        SELECT \n            publication_number, application_number, country_code,\n            ROW_NUMBER() OVER(PARTITION BY application_number ORDER BY publication_date ASC) row_num,\n            kind_code, publication_date\n        FROM `patents-public-data.patents.publications`\n    ) USING(publication_number)\n    WHERE row_num=1\n)\n\nSELECT *\nFROM matched_appln\nORDER BY word_ct DESC\nLIMIT 100\n",
        "error_info": null
    },
    {
        "instance_id": "bq041",
        "score": 1,
        "pred_sql": "DECLARE yr, conversion_window INT64;\nSET (yr, conversion_window) = (2021, 30);\n\nWITH users AS (\n  SELECT *\n  FROM `bigquery-public-data.stackoverflow.users`\n  WHERE EXTRACT(YEAR FROM creation_date) = yr\n),\n\nusers_questions AS (\n  SELECT \n    u.display_name, \n    u.id AS user_id, \n    u.creation_date AS signup, \n    COUNT(q.id) AS questions, \n    MIN(q.creation_date) AS first_question\n  FROM users u\n  LEFT JOIN `bigquery-public-data.stackoverflow.posts_questions` q \n    ON q.owner_user_id = u.id \n    AND DATE_DIFF(q.creation_date, u.creation_date, DAY) <= conversion_window\n  GROUP BY \n    u.display_name, \n    u.id, \n    u.creation_date\n),\n\nusers_questions_answers AS (\n  SELECT \n    display_name, \n    user_id, \n    signup, \n    questions, \n    first_question, \n    COUNT(a.id) AS answers_after_question\n  FROM users_questions uq\n  LEFT JOIN `bigquery-public-data.stackoverflow.posts_answers` a \n    ON a.owner_user_id = uq.user_id \n    AND a.creation_date > uq.first_question\n    AND DATE_DIFF(a.creation_date, uq.first_question, DAY) <= conversion_window\n  GROUP BY \n    display_name, \n    user_id, \n    signup, \n    questions, \n    first_question\n)\n\nSELECT \n  EXTRACT(MONTH FROM signup) AS month,\n  COUNT(user_id) AS new_users,\n  COUNT(DISTINCT CASE WHEN questions > 0 THEN user_id ELSE NULL END) AS asked,\n  ROUND(COUNT(DISTINCT CASE WHEN questions > 0 THEN user_id ELSE NULL END) / COUNT(user_id) * 100, 2) AS pct_asked,\n  COUNT(DISTINCT CASE WHEN answers_after_question > 0 THEN user_id ELSE NULL END) AS then_answered,\n  ROUND(COUNT(DISTINCT CASE WHEN answers_after_question > 0 THEN user_id ELSE NULL END) / COUNT(user_id) * 100, 2) AS pct_then_answered\nFROM users_questions_answers\nGROUP BY \n  EXTRACT(MONTH FROM signup)\nORDER BY \n  month ASC;",
        "error_info": null
    },
    {
        "instance_id": "ga028",
        "score": 1,
        "pred_sql": "WITH dates AS (\n    SELECT \n        DATE('2018-07-02') AS start_date,\n        DATE('2018-10-02') AS end_date,\n        DATE_ADD(DATE_TRUNC(DATE('2018-10-02'), WEEK(TUESDAY)), INTERVAL -4 WEEK) AS min_date\n),\n\ndate_table AS (\n    SELECT DISTINCT \n        PARSE_DATE('%Y%m%d', `event_date`) AS event_date,\n        user_pseudo_id,\n        CASE \n            WHEN DATE_DIFF(PARSE_DATE('%Y%m%d', `event_date`), DATE(TIMESTAMP_MICROS(user_first_touch_timestamp)), DAY) = 0 \n            THEN 1 \n            ELSE 0 \n        END AS is_new_user\n    FROM \n        `firebase-public-project.analytics_153293282.events_*` \n    WHERE \n        event_name = 'session_start'\n),\n\nnew_user_list AS (\n    SELECT DISTINCT \n        user_pseudo_id,\n        event_date\n    FROM \n        date_table\n    WHERE \n        is_new_user = 1\n),\n\ndays_since_start_table AS (\n    SELECT DISTINCT \n        is_new_user,\n        nu.event_date AS date_cohort,\n        dt.user_pseudo_id,\n        dt.event_date,\n        DATE_DIFF(dt.event_date, nu.event_date, DAY) AS days_since_start\n    FROM \n        date_table dt\n    JOIN \n        new_user_list nu ON dt.user_pseudo_id = nu.user_pseudo_id\n),\n\nweeks_retention AS (\n    SELECT \n        date_cohort,\n        DATE_TRUNC(date_cohort, WEEK(MONDAY)) AS week_cohort,\n        user_pseudo_id,\n        days_since_start,\n        CASE \n            WHEN days_since_start = 0 \n            THEN 0 \n            ELSE CEIL(days_since_start / 7) \n        END AS weeks_since_start\n    FROM \n        days_since_start_table\n),\nRETENTION_INFO AS (\n  SELECT \n      week_cohort,\n      weeks_since_start,\n      COUNT(DISTINCT user_pseudo_id) AS retained_users\n  FROM \n      weeks_retention\n  WHERE \n      week_cohort <= (SELECT min_date FROM dates)\n  GROUP BY \n      week_cohort,\n      weeks_since_start\n  HAVING \n      weeks_since_start <= 4\n  ORDER BY \n      week_cohort,\n      weeks_since_start\n)\n\nSELECT weeks_since_start, retained_users\nFROM RETENTION_INFO\nWHERE week_cohort = DATE('2018-07-02')\n\n",
        "error_info": null
    },
    {
        "instance_id": "ga020_1",
        "score": 1,
        "pred_sql": "-- Define the date range and calculate the minimum date for filtering results\nWITH dates AS (\n    SELECT \n        DATE('2018-07-02') AS start_date,\n        DATE('2018-07-16') AS end_date\n),\n-- Create a table of active dates for each user within the specified date range\ndates_active_table AS (\n    SELECT\n        user_pseudo_id,\n        PARSE_DATE('%Y%m%d', `event_date`) AS user_active_date\n    FROM \n        `firebase-public-project.analytics_153293282.events_*` \n    WHERE \n        event_name = 'session_start'\n        AND PARSE_DATE('%Y%m%d', `event_date`) BETWEEN (SELECT start_date FROM dates) AND (SELECT end_date FROM dates)\n    GROUP BY \n        user_pseudo_id, user_active_date\n),\n-- Create a table of the earliest quickplay event date for each user within the specified date range\nevent_table AS (\n    SELECT \n        user_pseudo_id,\n        event_name,\n        MIN(PARSE_DATE('%Y%m%d', `event_date`)) AS event_cohort_date\n    FROM \n        `firebase-public-project.analytics_153293282.events_*` \n    WHERE \n        event_name IN ('level_start_quickplay', 'level_end_quickplay', 'level_complete_quickplay', \n                       'level_fail_quickplay', 'level_reset_quickplay', 'level_retry_quickplay')\n        AND PARSE_DATE('%Y%m%d', `event_date`) BETWEEN (SELECT start_date FROM dates) AND (SELECT end_date FROM dates)\n    GROUP BY \n        user_pseudo_id, event_name\n),\n-- Calculate the number of days since each user's initial quickplay event\ndays_since_event_table AS (\n    SELECT\n        events.user_pseudo_id,\n        events.event_name AS event_cohort,\n        events.event_cohort_date,\n        days.user_active_date,\n        DATE_DIFF(days.user_active_date, events.event_cohort_date, DAY) AS days_since_event\n    FROM \n        event_table events\n    LEFT JOIN \n        dates_active_table days ON events.user_pseudo_id = days.user_pseudo_id\n    WHERE \n        events.event_cohort_date <= days.user_active_date\n),\n-- Calculate the weeks since each user's initial quickplay event and count the active days in each week\nweeks_retention AS (\n    SELECT\n        event_cohort,\n        user_pseudo_id,\n        CAST(CASE WHEN days_since_event = 0 THEN 0 ELSE CEIL(days_since_event / 7) END AS INTEGER) AS weeks_since_event,\n        COUNT(DISTINCT days_since_event) AS days_active_since_event -- Count Days Active in Week\n    FROM \n        days_since_event_table\n    GROUP BY \n        event_cohort, user_pseudo_id, weeks_since_event\n),\n-- Aggregate the weekly retention data\naggregated_weekly_retention_table AS (\n    SELECT\n        event_cohort,\n        weeks_since_event,\n        SUM(days_active_since_event) AS weekly_days_active,\n        COUNT(DISTINCT user_pseudo_id) AS retained_users\n    FROM \n        weeks_retention\n    GROUP BY \n        event_cohort, weeks_since_event\n),\nRETENTION_INFO AS (\nSELECT\n    event_cohort,\n    weeks_since_event,\n    weekly_days_active,\n    retained_users,\n    (retained_users / MAX(retained_users) OVER (PARTITION BY event_cohort)) AS retention_rate\nFROM \n    aggregated_weekly_retention_table\nORDER BY \n    event_cohort, weeks_since_event\n)\n\nSELECT event_cohort, retention_rate\nFROM\nRETENTION_INFO\nWHERE weeks_since_event = 2",
        "error_info": null
    },
    {
        "instance_id": "bq221",
        "score": 1,
        "pred_sql": "CREATE TEMPORARY FUNCTION highest_moving_avg(yearcnt ARRAY<STRUCT<filing_year INT64, cnt INT64>>)\nRETURNS STRUCT<filing_year INT64, avg INT64>\nLANGUAGE js AS \"\"\"\n    let a = 0.2;\n    let avg = yearcnt.length > 0 ? yearcnt[0].cnt : 0;\n    let highest = {filing_year: -1, avg: -1};\n    for (let x of yearcnt) {\n        avg = a * x.cnt + (1 - a) * avg;\n        if (avg > highest.avg) {\n                highest = {filing_year: x.filing_year, avg: avg};\n        }\n    }\n    return highest;\n\"\"\";\n    \nWITH patent_cpcs AS (\n    SELECT\n        cd.parents,\n        CAST(FLOOR(filing_date/10000) AS INT64) AS filing_year\n    FROM (\n        SELECT\n            ANY_VALUE(cpc) AS cpc,\n            ANY_VALUE(filing_date) AS filing_date\n        FROM\n            `patents-public-data.patents.publications`\n        WHERE \n            application_number != \"\"\n        GROUP BY\n            application_number\n        ), UNNEST(cpc) AS cpcs\n    JOIN\n        `patents-public-data.cpc.definition` cd\n    ON cd.symbol = cpcs.code\n    WHERE\n        cpcs.first = TRUE\n        AND filing_date > 0\n)\n\nSELECT c.titleFull, cpc_group, best_year.filing_year\nFROM (\n    SELECT\n        cpc_group,\n        highest_moving_avg(ARRAY_AGG(STRUCT<filing_year INT64, cnt INT64>(filing_year, cnt) ORDER BY filing_year ASC)) AS best_year\n    FROM (\n        SELECT\n            cpc_group,\n            filing_year,\n            COUNT(*) AS cnt\n        FROM (\n            SELECT\n                cpc_parent AS cpc_group,\n                filing_year\n            FROM\n                patent_cpcs,\n                UNNEST(parents) AS cpc_parent\n        )\n        GROUP BY cpc_group, filing_year\n        ORDER BY filing_year DESC, cnt DESC\n    )\n    GROUP BY cpc_group\n)\nJOIN `patents-public-data.cpc.definition` c\nON cpc_group = c.symbol\nWHERE c.level = 5\nORDER BY c.titleFull, cpc_group ASC;",
        "error_info": null
    },
    {
        "instance_id": "bq077",
        "score": 1,
        "pred_sql": "SELECT\n  year,\n  incidents\nFROM (\n  SELECT\n    year,\n    EXTRACT(MONTH\n    FROM\n      date) AS month,\n    COUNT(1) AS incidents,\n    RANK() OVER (PARTITION BY year ORDER BY COUNT(1) DESC) AS ranking\n  FROM\n    `bigquery-public-data.chicago_crime.crime`\n  WHERE\n    primary_type = 'MOTOR VEHICLE THEFT'\n    AND year BETWEEN 2010 AND 2016\n  GROUP BY\n    year,\n    month )\nWHERE\n  ranking = 1\nORDER BY\n  year ASC",
        "error_info": null
    },
    {
        "instance_id": "bq260",
        "score": 1,
        "pred_sql": "WITH filtered_users AS (\n    SELECT \n        first_name, \n        last_name, \n        gender, \n        age,\n        created_at\n    FROM \n        bigquery-public-data.thelook_ecommerce.users\n    WHERE \n        created_at BETWEEN '2019-01-01' AND '2022-04-30'\n),\nyoungest_ages AS (\n    SELECT \n        gender, \n        MIN(age) AS age\n    FROM \n        filtered_users\n    GROUP BY \n        gender\n),\noldest_ages AS (\n    SELECT \n        gender, \n        MAX(age) AS age\n    FROM \n        filtered_users\n    GROUP BY \n        gender\n),\nyoungest_oldest AS (\n    SELECT \n        u.first_name, \n        u.last_name, \n        u.gender, \n        u.age, \n        'youngest' AS tag\n    FROM \n        filtered_users u\n    JOIN \n        youngest_ages y\n    ON \n        u.gender = y.gender AND u.age = y.age\n    UNION ALL\n    SELECT \n        u.first_name, \n        u.last_name, \n        u.gender, \n        u.age, \n        'oldest' AS tag\n    FROM \n        filtered_users u\n    JOIN \n        oldest_ages o\n    ON \n        u.gender = o.gender AND u.age = o.age\n)\nSELECT COUNT(*) AS num \nFROM youngest_oldest\nGROUP BY tag, gender\n",
        "error_info": null
    },
    {
        "instance_id": "bq281",
        "score": 1,
        "pred_sql": "SELECT\n  COUNT(1) AS num_rides\nFROM\n  `bigquery-public-data.austin_bikeshare.bikeshare_trips` \nWHERE \nstart_station_name \n    NOT IN ('Mobile Station', 'Repair Shop')\nAND\nend_station_name \n    NOT IN ('Mobile Station', 'Repair Shop')\nAND \nsubscriber_type = 'Student Membership'\nAND\nbike_type = 'electric'\nAND\nduration_minutes > 10\nGROUP BY \n    EXTRACT(YEAR from start_time), \n    EXTRACT(MONTH from start_time), \n    EXTRACT(DAY from start_time)\nORDER BY num_rides DESC\nLIMIT 1",
        "error_info": null
    },
    {
        "instance_id": "bq265",
        "score": 1,
        "pred_sql": "WITH\n  main AS (\n  SELECT\n    id AS user_id,\n    email,\n    gender,\n    country,\n    traffic_source\n  FROM\n    `bigquery-public-data.thelook_ecommerce.users` \n  WHERE\n    created_at BETWEEN '2019-01-01' AND '2019-12-31'),\n\n  daate AS (\n  SELECT\n    user_id,\n    order_id,\n    EXTRACT (date\n    FROM\n      created_at) AS order_date,\n    num_of_item\n  FROM\n    `bigquery-public-data.thelook_ecommerce.orders` \n  WHERE\n    created_at BETWEEN '2019-01-01' AND '2019-12-31' ),\n\n  orders AS (\n  SELECT\n    user_id,\n    order_id,\n    product_id,\n    sale_price,\n    status\n  FROM\n    `bigquery-public-data.thelook_ecommerce.order_items` \n  WHERE \n    created_at BETWEEN '2019-01-01' AND '2019-12-31' ),\n\n  nest AS (\n  SELECT\n    o.user_id,\n    o.order_id,\n    o.product_id,\n    d.order_date,\n    d.num_of_item,\n    ROUND(o.sale_price,2)AS sale_price,\n    ROUND(d.num_of_item*o.sale_price,2) AS total_sale,\n  FROM\n    orders o\n  INNER JOIN\n    daate d\n  ON\n    o.order_id = d.order_id\n  ORDER BY\n    o.user_id ),\n\n  type AS (\n  SELECT\n    user_id,\n    MIN(nest.order_date) AS cohort_date,\n    MAX(nest.order_date) AS latest_shopping_date,\n    DATE_DIFF(MAX(nest.order_date),MIN(nest.order_date),month) AS lifespan_months,\n    ROUND(SUM(total_sale),2) AS ltv,\n    COUNT(order_id) AS no_of_order\n  FROM\n    nest\n  GROUP BY\n    user_id ),\n\n  kite AS (\n  SELECT\n    m.user_id,\n    m.email,\n    m.gender,\n    m.country,\n    m.traffic_source,\n    extract(year from n.cohort_date) as cohort_year,\n    n.latest_shopping_date,\n    n.lifespan_months,\n    n.ltv,\n    n.no_of_order,\n    ROUND(n.ltv/n.no_of_order, 2) as avg_order_value\n  FROM\n    main m\n  INNER JOIN\n    type n\n  ON\n    m.user_id = n.user_id )\n\nSELECT\n  email\nFROM\n  kite\nORDER BY avg_order_value DESC\nLIMIT 10",
        "error_info": null
    },
    {
        "instance_id": "bq197",
        "score": 1,
        "pred_sql": "WITH \nreport_monthly_orders_product_agg AS\n(\nSELECT \n    p.name AS product_name,\n    p.brand,\n    p.category,\n    FORMAT_TIMESTAMP('%Y-%m', o.created_at) AS month,\n    o.status,\n    COUNT(o.product_id) AS total_sales,\n    SUM(o.sale_price) AS total_revenue \nFROM \n    `bigquery-public-data.thelook_ecommerce.products` p\nLEFT JOIN \n    `bigquery-public-data.thelook_ecommerce.order_items` o\nON \n    p.id = o.product_id\nWHERE\n    o.status = 'Complete'\n    AND o.created_at < TIMESTAMP('2024-07-01') \nGROUP BY \n    product_name, \n    month,\n    o.status,\n    p.brand,\n    p.category        \nHAVING\n    month IS NOT NULL AND total_revenue IS NOT NULL AND p.brand IS NOT NULL\n)\n\nSELECT \n    month, \n    product_name, \n    brand,\n    category,\n    total_sales,\n    ROUND(total_revenue, 2) AS total_revenue,\n    status    \nFROM \n    (\n        SELECT \n            month, \n            product_name,\n            brand,\n            category, \n            total_sales,\n            total_revenue,\n            status,\n            ROW_NUMBER() OVER (PARTITION BY month ORDER BY total_sales DESC, total_revenue DESC) as row_num\n        FROM \n           report_monthly_orders_product_agg\n    ) \nWHERE \n    row_num = 1\nORDER BY month ASC;",
        "error_info": null
    },
    {
        "instance_id": "bq283",
        "score": 1,
        "pred_sql": "WITH StationStats AS (\n  SELECT\n    BT.start_station_id,\n    COUNT(BT.trip_id) AS total_trips,\n    RANK() OVER (ORDER BY COUNT(BT.trip_id) DESC) AS station_rank,\n    ROUND((COUNT(BT.trip_id) / SUM(COUNT(BT.trip_id)) OVER ()) * 100, 2) AS percentage_of_total_trips\n  FROM `bigquery-public-data.austin_bikeshare.bikeshare_trips` BT\n  JOIN `bigquery-public-data.austin_bikeshare.bikeshare_stations` BS\n  ON BT.start_station_id = BS.station_id \n  WHERE BS.status = 'active'\n  GROUP BY BT.start_station_id\n)\n, Top15 as(\n  SELECT\n    start_station_id,\n    total_trips,\n    station_rank,\n    percentage_of_total_trips\n  FROM StationStats\n  WHERE station_rank <= 15 \n  ORDER BY station_rank ASC\n)\n\nSELECT SUM(T.percentage_of_total_trips)\nFROM Top15 T;\n",
        "error_info": null
    },
    {
        "instance_id": "ga009",
        "score": 1,
        "pred_sql": "SELECT\n  engaged_sessions_number / user_number AS engaged_sessions_per_user\nFROM (\n  SELECT\n    COUNT(\n      DISTINCT CASE\n        WHEN (SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'session_engaged') = '1' THEN\n          CONCAT(\n            user_pseudo_id, \n            CAST(\n              (SELECT value.int_value FROM UNNEST(event_params) WHERE key = 'ga_session_id') AS STRING\n            )\n          )\n      END\n    ) AS engaged_sessions_number,\n    COUNT(DISTINCT user_pseudo_id) AS user_number\n  FROM\n    `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*`\n  WHERE\n    _TABLE_SUFFIX BETWEEN '20201201' and '20201231'\n) AS summary\n",
        "error_info": null
    },
    {
        "instance_id": "bq356",
        "score": 1,
        "pred_sql": "# Subquery to count # of dates w/ valid temperature data by station\nWITH\nNum2019TempDatesByStation AS\n(\n    SELECT\n    daily_weather.stn,\n\n    # Count # of distinct dates w/ temperature data for each station\n    COUNT(DISTINCT\n        # Convert year/month/day info into date\n        DATE(\n        CAST(daily_weather.year AS INT64),\n        CAST(daily_weather.mo AS INT64),\n        CAST(daily_weather.da AS INT64)\n        )) AS num_2019_temp_dates\n\n    FROM\n    bigquery-public-data.noaa_gsod.gsod2019 daily_weather\n\n    WHERE\n    daily_weather.temp IS NOT NULL AND\n    daily_weather.max IS NOT NULL AND\n    daily_weather.min IS NOT NULL AND\n    # Remove days w/ missing temps coded as 9999.9\n    daily_weather.temp != 9999.9 AND\n    daily_weather.max != 9999.9 AND\n    daily_weather.min != 9999.9\n\n    GROUP BY\n    daily_weather.stn\n),\n\n# Calculate max number of 2019 temperature dates across all stations\nMaxNum2019TempDates AS\n(\n    SELECT\n    MAX(num_2019_temp_dates) AS max_num_2019_temp_dates\n\n    FROM\n    Num2019TempDatesByStation\n)\n\nSELECT\n    COUNT(*)\nFROM\n    bigquery-public-data.noaa_gsod.stations Stations\n\n# Inner join to filter to only stations present in 2019 data\nINNER JOIN\n    Num2019TempDatesByStation ON (\n    stations.usaf = Num2019TempDatesByStation.stn\n    )\n\n# Cross join to get max number on each row, to use in filtering below\nCROSS JOIN\n    MaxNum2019TempDates\n\nWHERE\n    # Filter to stations that have had tracking since at least 1/1/2000\n    Stations.begin <= '20000101' AND\n    # Filter to stations that have had tracking through at least 6/30/2019\n    Stations.end >= '20190630' AND\n    # Filter to stations w/ >= 90% of the max number of dates for 2019\n    Num2019TempDatesByStation.num_2019_temp_dates >=\n    (0.90 * MaxNum2019TempDates.max_num_2019_temp_dates)",
        "error_info": null
    },
    {
        "instance_id": "bq352",
        "score": 1,
        "pred_sql": "WITH natality_2018 AS (\n  SELECT County_of_Residence_FIPS AS FIPS, Ave_Number_of_Prenatal_Wks AS Vist_Ave, County_of_Residence\n  FROM `bigquery-public-data.sdoh_cdc_wonder_natality.county_natality` \n  WHERE SUBSTR(County_of_Residence_FIPS, 0, 2) = \"55\" AND Year = '2018-01-01'\n),\n\nacs_2017 AS (\n  SELECT geo_id, commute_45_59_mins, employed_pop\n  FROM `bigquery-public-data.census_bureau_acs.county_2017_5yr`\n),\n\ncorr_tbl AS (\n  SELECT\n    n.County_of_Residence,\n    ROUND((a.commute_45_59_mins / a.employed_pop) * 100, 2) AS percent_high_travel,\n    n.Vist_Ave\n  FROM acs_2017 a\n  JOIN natality_2018 n\n  ON a.geo_id = n.FIPS\n)\n\nSELECT County_of_Residence, Vist_Ave\nFROM corr_tbl\nWHERE percent_high_travel > 5\n",
        "error_info": null
    },
    {
        "instance_id": "bq286",
        "score": 1,
        "pred_sql": "SELECT\n  a.name AS name\nFROM\n  `bigquery-public-data.usa_names.usa_1910_current` a\nJOIN (\n  SELECT\n    name,\n    gender,\n    year,\n    SUM(number) AS total_number\n  FROM\n    `bigquery-public-data.usa_names.usa_1910_current`\n  GROUP BY\n    name,\n    gender,\n    year) b\nON\n  a.name = b.name\n  AND a.gender = b.gender\n  AND a.year = b.year\nWHERE \n    a.gender = 'F' AND\n    a.state = 'WY' AND\n    a.year = 2021\nORDER BY (a.number / b.total_number) DESC\nLIMIT 1\n",
        "error_info": null
    },
    {
        "instance_id": "bq003",
        "score": 1,
        "pred_sql": "WITH cte1 AS (\n    SELECT\n        CONCAT(EXTRACT(YEAR FROM (PARSE_DATE('%Y%m%d', date))), '0',\n            EXTRACT(MONTH FROM (PARSE_DATE('%Y%m%d', date)))) AS month,\n        SUM(totals.pageviews) / COUNT(DISTINCT fullVisitorId) AS avg_pageviews_non_purchase\n    FROM\n        `bigquery-public-data.google_analytics_sample.ga_sessions_2017*`,\n        UNNEST (hits) AS hits,\n        UNNEST (hits.product) AS product\n    WHERE\n        _table_suffix BETWEEN '0401' AND '0731'\n        AND totals.transactions IS NULL\n        AND product.productRevenue IS NULL\n    GROUP BY month\n),\ncte2 AS (\n    SELECT\n        CONCAT(EXTRACT(YEAR FROM (PARSE_DATE('%Y%m%d', date))), '0',\n            EXTRACT(MONTH FROM (PARSE_DATE('%Y%m%d', date)))) AS month,\n        SUM(totals.pageviews) / COUNT(DISTINCT fullVisitorId) AS avg_pageviews_purchase\n    FROM\n        `bigquery-public-data.google_analytics_sample.ga_sessions_2017*`,\n        UNNEST (hits) AS hits,\n        UNNEST (hits.product) AS product\n    WHERE\n        _table_suffix BETWEEN '0401' AND '0731'\n        AND totals.transactions >= 1\n        AND product.productRevenue IS NOT NULL\n    GROUP BY month\n)\nSELECT\n    month, avg_pageviews_purchase, avg_pageviews_non_purchase\nFROM cte1 INNER JOIN cte2\nUSING(month)\nORDER BY month;",
        "error_info": null
    },
    {
        "instance_id": "bq213",
        "score": 1,
        "pred_sql": "WITH interim_table as(\nSELECT \n    t1.publication_number, \n    SUBSTR(ipc_u.code, 0, 4) as ipc4\nFROM \n    `patents-public-data.patents.publications` t1, \n    UNNEST(ipc) AS ipc_u \nWHERE\ncountry_code = 'US'  \nAND grant_date between 20180601 AND 20180607\n  AND grant_date != 0\n  AND publication_number LIKE '%B2%'  \nGROUP BY \n    t1.publication_number, \n    ipc4\n) \nSELECT \nipc4\nFROM \ninterim_table \nGROUP BY ipc4\nORDER BY COUNT(publication_number) DESC\nLIMIT 1",
        "error_info": null
    },
    {
        "instance_id": "bq271",
        "score": 1,
        "pred_sql": "WITH\norders_x_order_items AS (\n  SELECT orders.*,\n         order_items.inventory_item_id,\n         order_items.sale_price\n  FROM `bigquery-public-data.thelook_ecommerce.orders` AS orders\n  LEFT JOIN `bigquery-public-data.thelook_ecommerce.order_items` AS order_items\n  ON orders.order_id = order_items.order_id\n  WHERE orders.created_at BETWEEN '2021-01-01' AND '2021-12-31'\n),\n\norders_x_inventory AS (\n  SELECT orders_x_order_items.*,\n         inventory_items.product_category,\n         inventory_items.product_department,\n         inventory_items.product_retail_price,\n         inventory_items.product_distribution_center_id,\n         inventory_items.cost,\n         distribution_centers.name\n  FROM orders_x_order_items\n  LEFT JOIN `bigquery-public-data.thelook_ecommerce.inventory_items` AS inventory_items\n  ON orders_x_order_items.inventory_item_id = inventory_items.id\n  LEFT JOIN `bigquery-public-data.thelook_ecommerce.distribution_centers` AS distribution_centers\n  ON inventory_items.product_distribution_center_id = distribution_centers.id\n  WHERE inventory_items.created_at BETWEEN '2021-01-01' AND '2021-12-31'\n),\n\norders_x_users AS (\n  SELECT orders_x_inventory.*,\n         users.country AS users_country,\n  FROM orders_x_inventory \n  LEFT JOIN `bigquery-public-data.thelook_ecommerce.users` AS users\n  ON orders_x_inventory.user_id = users.id\n  WHERE users.created_at BETWEEN '2021-01-01' AND '2021-12-31'\n),\n\nmonthly_order_product_category AS (\n  SELECT DATE_TRUNC(DATE(created_at),MONTH) AS reporting_month,\n         users_country,\n         product_department,\n         product_category,\n         COUNT(DISTINCT order_id) AS n_order,\n         COUNT(DISTINCT user_id) AS n_purchasers,\n         SUM(product_retail_price) AS total_product_retail_price,\n         SUM(cost) AS total_cost\n  FROM orders_x_users\n  GROUP BY 1,2,3,4\n  ORDER BY 1,2,3,4\n)\n\nSELECT users_country, total_product_retail_price - total_cost AS profit\nFROM monthly_order_product_category\nORDER BY profit DESC\nLIMIT 1;",
        "error_info": null
    },
    {
        "instance_id": "bq033",
        "score": 1,
        "pred_sql": "WITH\n  Patent_Matches AS (\n    SELECT\n      PARSE_DATE('%Y%m%d', SAFE_CAST(ANY_VALUE(patentsdb.filing_date) AS STRING)) AS Patent_Filing_Date,\n      patentsdb.application_number AS Patent_Application_Number,\n      ANY_VALUE(abstract_info.text) AS Patent_Title,\n      ANY_VALUE(abstract_info.language) AS Patent_Title_Language\n    FROM\n      `patents-public-data.patents.publications` AS patentsdb,\n      UNNEST(abstract_localized) AS abstract_info\n    WHERE\n      LOWER(abstract_info.text) LIKE '%internet of things%'\n      AND patentsdb.country_code = 'US'\n    GROUP BY\n      Patent_Application_Number\n  ),\n\n  Date_Series_Table AS (\n    SELECT\n      day,\n      0 AS Number_of_Patents\n    FROM\n      UNNEST(GENERATE_DATE_ARRAY(\n        DATE '2008-01-01', \n        DATE '2022-12-31'\n      )) AS day\n  )\n\nSELECT\n  SAFE_CAST(FORMAT_DATE('%Y-%m', Date_Series_Table.day) AS STRING) AS Patent_Date_YearMonth,\n  COUNT(Patent_Matches.Patent_Application_Number) AS Number_of_Patent_Applications\nFROM\n  Date_Series_Table\n  LEFT JOIN Patent_Matches\n    ON Date_Series_Table.day = Patent_Matches.Patent_Filing_Date\nGROUP BY\n  Patent_Date_YearMonth\nORDER BY\n  Patent_Date_YearMonth;",
        "error_info": null
    },
    {
        "instance_id": "bq025_1",
        "score": 1,
        "pred_sql": "SELECT\ncountry_name\nFROM\n(SELECT\n  age.country_name,\n  SUM(age.population) AS under_25,\n  pop.midyear_population AS total,\n  ROUND((SUM(age.population) / pop.midyear_population) * 100,2) AS pct_under_25\nFROM (\n  SELECT\n    country_name,\n    population,\n    country_code\n  FROM\n    `bigquery-public-data.census_bureau_international.midyear_population_agespecific`\n  WHERE\n    year =2017\n    AND age < 25) age\nINNER JOIN (\n  SELECT\n    midyear_population,\n    country_code\n  FROM\n    `bigquery-public-data.census_bureau_international.midyear_population`\n  WHERE\n    year = 2017) pop\nON\n  age.country_code = pop.country_code\nGROUP BY\n  1,\n  3\nORDER BY\n  4 DESC\n)\nLIMIT\n1",
        "error_info": null
    },
    {
        "instance_id": "bq262",
        "score": 1,
        "pred_sql": "WITH orders_data AS (\n    SELECT\n        FORMAT_TIMESTAMP('%Y-%m', o.created_at) AS month,\n        i.product_id,\n        COUNT(o.order_id) AS order_count,\n        SUM(i.sale_price) AS total_sales\n    FROM \n        bigquery-public-data.thelook_ecommerce.orders AS o\n    JOIN \n        bigquery-public-data.thelook_ecommerce.order_items AS i \n    ON\n        o.order_id = i.order_id\n    WHERE\n        o.created_at BETWEEN TIMESTAMP('2019-06-01') AND TIMESTAMP('2019-12-31')\n    GROUP BY \n        month, i.product_id\n),\nproduct_data AS (\n    SELECT \n        p.id AS product_id,\n        p.category AS product_category,\n        p.cost\n    FROM \n        bigquery-public-data.thelook_ecommerce.products AS p\n),\nmonthly_metrics AS (\n    SELECT \n        o.month,\n        p.product_category,\n        SUM(o.order_count) AS total_order,\n        SUM(o.total_sales) AS total_revenue, \n        SUM(o.total_sales - (p.cost * o.order_count)) AS total_profit \n    FROM \n        orders_data AS o\n    JOIN \n        product_data AS p\n    ON \n        o.product_id = p.product_id\n    GROUP BY \n        o.month, p.product_category\n),\ngrowth_metrics AS (\n    SELECT \n        month,\n        product_category,\n        total_order,\n        (total_order - LAG(total_order) OVER (PARTITION BY product_category ORDER BY month)) / LAG(total_order) OVER (PARTITION BY product_category ORDER BY month) * 100 AS order_growth,\n        total_revenue,\n        (total_revenue - LAG(total_revenue) OVER (PARTITION BY product_category ORDER BY month)) / LAG(total_revenue) OVER (PARTITION BY product_category ORDER BY month) * 100 AS revenue_growth,\n        total_profit,\n        (total_profit - LAG(total_profit) OVER (PARTITION BY product_category ORDER BY month)) / LAG(total_profit) OVER (PARTITION BY product_category ORDER BY month) * 100 AS profit_growth\n    FROM \n        monthly_metrics\n)\n\nSELECT\n    *\nFROM \n    growth_metrics\nWHERE\n    month <> '2019-06'\nORDER BY\n    month, product_category ASC;",
        "error_info": null
    },
    {
        "instance_id": "bq062",
        "score": 1,
        "pred_sql": "WITH Counts AS (\n    SELECT\n        System,\n        License,\n        COUNT(DISTINCT Name) AS NPackages\n    FROM\n        `spider2-public-data.deps_dev_v1.PackageVersions`\n    CROSS JOIN\n        UNNEST(Licenses) AS License\n    GROUP BY\n        System,\n        License\n),\nRanked AS (\n    SELECT\n        System,\n        License,\n        NPackages,\n        ROW_NUMBER() OVER (PARTITION BY System ORDER BY NPackages DESC) AS LicenseRank\n    FROM Counts\n)\nSELECT\n    System,\n    License\nFROM\n    Ranked\nWHERE\n    LicenseRank <= 1\nORDER BY\n    System,\n    LicenseRank;",
        "error_info": null
    },
    {
        "instance_id": "bq284",
        "score": 1,
        "pred_sql": "SELECT \n  category,\n  COUNT(*) AS number_total_by_category,  \n  CASE \n    WHEN category = 'tech' THEN \n          (SELECT count(*)\n                FROM `bigquery-public-data.bbc_news.fulltext`\n                WHERE (body LIKE '%Education%') AND category = 'tech') * 100 /\n                (SELECT count(*)\n                FROM `bigquery-public-data.bbc_news.fulltext`\n                WHERE category = 'tech')\n    WHEN category = 'sport' THEN \n          (SELECT count(*)\n                FROM `bigquery-public-data.bbc_news.fulltext`\n                WHERE (body LIKE '%Education%') AND category = 'sport') * 100 /\n                (SELECT count(*)\n                FROM `bigquery-public-data.bbc_news.fulltext`\n                WHERE category = 'sport')\n    WHEN category = 'business' THEN \n          (SELECT count(*)\n                FROM `bigquery-public-data.bbc_news.fulltext`\n                WHERE (body LIKE '%Education%') AND category = 'business') * 100 /\n                (SELECT count(*)\n                FROM `bigquery-public-data.bbc_news.fulltext`\n                WHERE category = 'business')\n    WHEN category = 'politics' THEN \n          (SELECT count(*)\n                FROM `bigquery-public-data.bbc_news.fulltext`\n                WHERE (body LIKE '%Education%') AND category = 'politics') * 100 /\n                (SELECT count(*)\n                FROM `bigquery-public-data.bbc_news.fulltext`\n                WHERE category = 'politics')\n    WHEN category = 'entertainment' THEN \n          (SELECT count(*)\n                FROM `bigquery-public-data.bbc_news.fulltext`\n                WHERE (body LIKE '%Education%') AND category = 'entertainment') * 100 /\n                (SELECT count(*)\n                FROM `bigquery-public-data.bbc_news.fulltext`\n                WHERE category = 'entertainment')\n  END AS percent_education\nFROM `bigquery-public-data.bbc_news.fulltext`\nGROUP BY\n  category;",
        "error_info": null
    },
    {
        "instance_id": "bq182_1",
        "score": 1,
        "pred_sql": "SELECT COUNT(*) AS total_pull_requests\nFROM (\n  SELECT\n    a.type AS type,\n    b.language AS lang,\n    a.y AS y,\n    a.q AS q\n  FROM (\n    SELECT\n      type,\n      EXTRACT(YEAR FROM created_at) AS y,\n      EXTRACT(QUARTER FROM created_at) AS q,\n      REGEXP_REPLACE(\n        repo.url,\n        r'https:\\/\\/github\\.com\\/|https:\\/\\/api\\.github\\.com\\/repos\\/',\n        ''\n      ) AS name\n    FROM `githubarchive.day.20230118`\n    -- If needed, you can uncomment and add more tables\n    -- , `githubarchive.day.20140118`\n  ) a\n  JOIN (\n    SELECT\n      repo_name AS name,\n      language\n    FROM (\n      SELECT\n        repo_name,\n        language\n      FROM (\n        SELECT repo_name, language.name AS language, language.bytes\n        FROM `bigquery-public-data.github_repos.languages`,\n        UNNEST(language) AS language\n      )\n    )\n    WHERE language = 'JavaScript'\n    GROUP BY repo_name, language\n  ) b\n  ON a.name = b.name\n)\nWHERE type = 'PullRequestEvent';",
        "error_info": null
    },
    {
        "instance_id": "bq137",
        "score": 1,
        "pred_sql": "with zip_pop AS (\n  SELECT\n    zip_census.zipcode AS zipcode,\n    population\n  FROM\n    `bigquery-public-data.census_bureau_usa.population_by_zip_2010` AS zip_census\n  WHERE\n    (gender LIKE 'male'\n      OR gender LIKE 'female')\n    AND minimum_age IS NULL\n    AND maximum_age IS NULL )\nSELECT\n  zip_area.zipcode_geom AS zipcode_polygon,\n  zip_area.zipcode AS zipcode,\n  area_land_meters,\n  area_water_meters,\n  ST_GeogPoint(longitude,\n    latitude) AS lat_lon,\n  state_code,\n  state_name,\n  city,\n  county,\n  population\nFROM\n  `bigquery-public-data.utility_us.zipcode_area` AS zip_area\nJOIN\n  zip_pop\nON\n  zip_area.zipcode = zip_pop.zipcode\nWHERE\n  ST_DWITHIN(ST_GeogPoint(longitude,latitude),\n  ST_GeogPoint(-122.3321,47.6062),10000)",
        "error_info": null
    },
    {
        "instance_id": "bq126",
        "score": 1,
        "pred_sql": "SELECT\n  o.artist_display_name,\n  o.title,\n  o.object_end_date,\n  o.medium,\n  i.original_image_url\nFROM (\n  SELECT\n    object_id,\n    title,\n    artist_display_name,\n    object_end_date,\n    medium\n  FROM\n    `bigquery-public-data.the_met.objects`\n  WHERE\n    department = \"Photographs\"\n    AND object_name LIKE \"%Photograph%\"\n    AND artist_display_name != \"Unknown\"\n    AND object_end_date <= 1839\n) o\nINNER JOIN (\n  SELECT\n    original_image_url,\n    object_id\n  FROM\n    `bigquery-public-data.the_met.images`\n) i\nON\n  o.object_id = i.object_id\nORDER BY\n  o.object_end_date\n;",
        "error_info": null
    },
    {
        "instance_id": "ga003",
        "score": 1,
        "pred_sql": "WITH EventData AS (\n    SELECT \n        user_pseudo_id, \n        event_timestamp, \n        param\n    FROM \n        `firebase-public-project.analytics_153293282.events_20180915`,\n        UNNEST(event_params) AS param\n    WHERE \n        event_name = \"level_complete_quickplay\"\n        AND (param.key = \"value\" OR param.key = \"board\")\n),\nProcessedData AS (\n    SELECT \n        user_pseudo_id, \n        event_timestamp, \n        MAX(IF(param.key = \"value\", param.value.int_value, NULL)) AS score,\n        MAX(IF(param.key = \"board\", param.value.string_value, NULL)) AS board_type\n    FROM \n        EventData\n    GROUP BY \n        user_pseudo_id, \n        event_timestamp\n)\nSELECT \n    ANY_VALUE(board_type) AS board, \n    AVG(score) AS average_score\nFROM \n    ProcessedData\nGROUP BY \n    board_type\n",
        "error_info": null
    },
    {
        "instance_id": "bq322",
        "score": 1,
        "pred_sql": "WITH modality_counts AS (\n  SELECT\n    Modality,\n    COUNT(*) AS frequency\n  FROM\n    `bigquery-public-data.idc_v15.dicom_pivot` dicom_pivot\n  WHERE\n    StudyInstanceUID IN (\n      SELECT\n        StudyInstanceUID\n      FROM\n        `bigquery-public-data.idc_v15.dicom_pivot` dicom_pivot\n      WHERE\n        collection_id IN ('Community', 'nsclc_radiomics')\n      GROUP BY\n        StudyInstanceUID\n    )\n  GROUP BY\n    Modality\n)\n\nSELECT\n  Modality\nFROM\n  modality_counts\nORDER BY\n  frequency DESC\nLIMIT 1;",
        "error_info": null
    },
    {
        "instance_id": "bq293",
        "score": 1,
        "pred_sql": "\nWITH base_data AS (\n    SELECT \n        nyc_taxi.*, \n        gis.* EXCEPT (zip_code_geom)\n    FROM (\n        SELECT * \n        FROM `bigquery-public-data.new_york.tlc_yellow_trips_2015`\n        WHERE DATE(pickup_datetime) = '2015-01-01'\n            AND pickup_latitude <= 90 \n            AND pickup_latitude >= -90\n    ) AS nyc_taxi\n    JOIN (\n        SELECT \n            zip_code, \n            state_code, \n            state_name, \n            city, \n            county, \n            zip_code_geom \n        FROM `bigquery-public-data.geo_us_boundaries.zip_codes`\n        WHERE state_code = 'NY'\n    ) AS gis \n    ON ST_CONTAINS(zip_code_geom, ST_GEOGPOINT(pickup_longitude, pickup_latitude))\n),\ndistinct_datetime AS (\n    SELECT DISTINCT \n        DATETIME_TRUNC(pickup_datetime, hour) AS pickup_hour\n    FROM base_data\n),\ndistinct_zip_code AS (\n    SELECT DISTINCT zip_code \n    FROM base_data\n),\nzip_code_datetime_join AS (\n    SELECT \n        *,\n        EXTRACT(MONTH FROM pickup_hour) AS month,\n        EXTRACT(DAY FROM pickup_hour) AS day,\n        CAST(FORMAT_DATETIME('%u', pickup_hour) AS INT64) - 1 AS weekday,\n        EXTRACT(HOUR FROM pickup_hour) AS hour,\n        CASE \n            WHEN CAST(FORMAT_DATETIME('%u', pickup_hour) AS INT64) IN (6, 7) THEN 1 \n            ELSE 0 \n        END AS is_weekend\n    FROM distinct_zip_code\n    CROSS JOIN distinct_datetime\n),\nagg_data AS (\n    SELECT \n        zip_code,\n        DATETIME_TRUNC(pickup_datetime, hour) AS pickup_hour,\n        COUNT(*) AS cnt\n    FROM base_data\n    GROUP BY zip_code, pickup_hour\n),\njoin_output AS (\n    SELECT \n        zip_code_datetime.*, \n        IFNULL(agg_data.cnt, 0) AS cnt\n    FROM zip_code_datetime_join AS zip_code_datetime\n    LEFT JOIN agg_data \n    ON zip_code_datetime.zip_code = agg_data.zip_code \n        AND zip_code_datetime.pickup_hour = agg_data.pickup_hour\n),\nfinal_output AS (\n    SELECT \n        *,\n        LAG(cnt, 1) OVER (PARTITION BY zip_code ORDER BY pickup_hour) AS lag_1h_cnt,\n        LAG(cnt, 24) OVER (PARTITION BY zip_code ORDER BY pickup_hour) AS lag_1d_cnt,\n        LAG(cnt, 168) OVER (PARTITION BY zip_code ORDER BY pickup_hour) AS lag_7d_cnt,\n        LAG(cnt, 336) OVER (PARTITION BY zip_code ORDER BY pickup_hour) AS lag_14d_cnt,\n        ROUND(AVG(cnt) OVER (PARTITION BY zip_code ORDER BY pickup_hour ROWS BETWEEN 168 PRECEDING AND 1 PRECEDING), 2) AS avg_14d_cnt,\n        ROUND(AVG(cnt) OVER (PARTITION BY zip_code ORDER BY pickup_hour ROWS BETWEEN 336 PRECEDING AND 1 PRECEDING), 2) AS avg_21d_cnt,\n        CAST(STDDEV(cnt) OVER (PARTITION BY zip_code ORDER BY pickup_hour ROWS BETWEEN 168 PRECEDING AND 1 PRECEDING) AS INT64) AS std_14d_cnt,\n        CAST(STDDEV(cnt) OVER (PARTITION BY zip_code ORDER BY pickup_hour ROWS BETWEEN 336 PRECEDING AND 1 PRECEDING) AS INT64) AS std_21d_cnt\n    FROM join_output\n)\nSELECT *\nFROM final_output\nORDER BY cnt DESC\nLIMIT 5;",
        "error_info": null
    },
    {
        "instance_id": "bq045",
        "score": 1,
        "pred_sql": "WITH WashingtonStations2023 AS \n    (\n        SELECT \n            weather.stn AS station_id,\n            ANY_VALUE(station.name) AS name\n        FROM\n            `bigquery-public-data.noaa_gsod.stations` AS station\n        INNER JOIN\n            `bigquery-public-data.noaa_gsod.gsod2023` AS weather\n        ON\n            station.usaf = weather.stn\n        WHERE\n            station.state = 'WA' \n            AND \n            station.usaf != '999999'\n        GROUP BY\n            station_id\n    ),\nprcp2023 AS (\nSELECT\n    washington_stations.name,\n    (\n        SELECT \n            COUNT(*)\n        FROM\n            `bigquery-public-data.noaa_gsod.gsod2023` AS weather\n        WHERE\n            washington_stations.station_id = weather.stn\n            AND\n            prcp > 0\n            AND\n            prcp !=99.99\n    )\n    AS rainy_days\nFROM \n    WashingtonStations2023 AS washington_stations\nORDER BY\n    rainy_days DESC\n),\nWashingtonStations2022 AS \n    (\n        SELECT \n            weather.stn AS station_id,\n            ANY_VALUE(station.name) AS name\n        FROM\n            `bigquery-public-data.noaa_gsod.stations` AS station\n        INNER JOIN\n            `bigquery-public-data.noaa_gsod.gsod2022` AS weather\n        ON\n            station.usaf = weather.stn\n        WHERE\n            station.state = 'WA' \n            AND \n            station.usaf != '999999'\n        GROUP BY\n            station_id\n    ),\nprcp2022 AS (\nSELECT\n    washington_stations.name,\n    (\n        SELECT \n            COUNT(*)\n        FROM\n            `bigquery-public-data.noaa_gsod.gsod2022` AS weather\n        WHERE\n            washington_stations.station_id = weather.stn\n            AND\n            prcp > 0\n            AND\n            prcp != 99.99\n    )\n    AS rainy_days\nFROM \n    WashingtonStations2022 AS washington_stations\nORDER BY\n    rainy_days DESC\n)\n\nSELECT prcp2023.name\nFROM prcp2023\nJOIN prcp2022\non prcp2023.name = prcp2022.name\nWHERE prcp2023.rainy_days > 150\nAND prcp2023.rainy_days < prcp2022.rainy_days",
        "error_info": null
    },
    {
        "instance_id": "ga019",
        "score": 1,
        "pred_sql": "WITH\n--List of users who installed\nsept_cohort AS (\n  SELECT DISTINCT user_pseudo_id,\n  FORMAT_DATE('%Y-%m-%d', PARSE_DATE('%Y%m%d', event_date)) AS date_first_open,\n  FROM `firebase-public-project.analytics_153293282.events_*`\n  WHERE event_name = 'first_open'\n  AND _TABLE_SUFFIX BETWEEN '20180801' and '20180930'\n),\n--Get the list of users who uninstalled\nuninstallers AS (\n  SELECT DISTINCT user_pseudo_id,\n  FORMAT_DATE('%Y-%m-%d', PARSE_DATE('%Y%m%d', event_date)) AS date_app_remove,\n  FROM `firebase-public-project.analytics_153293282.events_*`\n  WHERE event_name = 'app_remove'\n  AND _TABLE_SUFFIX BETWEEN '20180801' and '20180930'\n),\n--Join the 2 tables and compute for # of days to uninstall\njoined AS (\n  SELECT a.*,\n  b.date_app_remove,\n  DATE_DIFF(DATE(b.date_app_remove), DATE(a.date_first_open), DAY) AS days_to_uninstall\n  FROM sept_cohort a\n  LEFT JOIN uninstallers b\n  ON a.user_pseudo_id = b.user_pseudo_id\n)\n--Compute for the percentage\nSELECT\nCOUNT(DISTINCT\nCASE WHEN days_to_uninstall > 7 OR days_to_uninstall IS NULL THEN user_pseudo_id END) /\nCOUNT(DISTINCT user_pseudo_id)\nAS percent_users_7_days\nFROM joined\n",
        "error_info": null
    },
    {
        "instance_id": "ga031",
        "score": 1,
        "pred_sql": "WITH base_table AS (\n  SELECT\n    event_name,\n    event_date,\n    event_timestamp,\n    user_pseudo_id,\n    user_id,\n    device,\n    geo,\n    traffic_source,\n    event_params,\n    user_properties\n  FROM\n    `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*`\n  WHERE\n    _table_suffix = '20210102'\n    AND event_name IN ('page_view')\n),\nunnested_events AS (\n  SELECT\n    event_date AS date,\n    event_timestamp AS event_timestamp_microseconds,\n    user_pseudo_id,\n    MAX(CASE WHEN c.key = 'ga_session_id' THEN c.value.int_value END) AS visitID,\n    MAX(CASE WHEN c.key = 'ga_session_number' THEN c.value.int_value END) AS visitNumber,\n    MAX(CASE WHEN c.key = 'page_title' THEN c.value.string_value END) AS page_title,\n    MAX(CASE WHEN c.key = 'page_location' THEN c.value.string_value END) AS page_location\n  FROM \n    base_table,\n    UNNEST (event_params) c\n  GROUP BY 1,2,3\n),\nhome_visits AS (\n  SELECT\n    user_pseudo_id,\n    visitID\n  FROM\n    unnested_events\n  WHERE\n    page_title = 'Home'\n),\ncheckout_visits AS (\n  SELECT\n    user_pseudo_id,\n    visitID\n  FROM\n    unnested_events\n  WHERE\n    page_title = 'Checkout Confirmation'\n),\nhome_to_checkout AS (\n  SELECT\n    h.user_pseudo_id,\n    h.visitID\n  FROM\n    home_visits h\n  JOIN\n    checkout_visits c ON h.user_pseudo_id = c.user_pseudo_id AND h.visitID = c.visitID\n),\ntotal_home_visits AS (\n  SELECT\n    COUNT(*) AS total_home\n  FROM\n    home_visits\n),\ntotal_checkout_visits AS (\n  SELECT\n    COUNT(*) AS total_checkout\n  FROM\n    home_to_checkout\n)\n\nSELECT\n  (total_checkout * 100.0) / total_home AS conversion_rate\nFROM\n  total_home_visits,\n  total_checkout_visits;",
        "error_info": null
    },
    {
        "instance_id": "bq182",
        "score": 1,
        "pred_sql": "-- Some reformatting and such of GitHub queries.\n\nSELECT language AS name, count\nFROM (\n  SELECT *\n  FROM (\n    SELECT\n      lang AS language,\n      y AS year,\n      q AS quarter,\n      type,\n      COUNT(*) AS count\n    FROM (\n      SELECT\n        a.type AS type,\n        b.lang AS lang,\n        a.y AS y,\n        a.q AS q\n      FROM (\n        SELECT\n          type,\n          EXTRACT(YEAR FROM created_at) AS y,\n          EXTRACT(QUARTER FROM created_at) AS q,\n          REGEXP_REPLACE(\n            repo.url,\n            r'https:\\/\\/github\\.com\\/|https:\\/\\/api\\.github\\.com\\/repos\\/',\n            ''\n          ) AS name\n        FROM `githubarchive.day.20230118`\n        -- If needed, you can uncomment and add more tables\n        -- , `githubarchive.day.20140118`\n      ) a\n      JOIN (\n        SELECT\n          repo_name AS name,\n          lang\n        FROM (\n          SELECT\n            repo_name,\n            FIRST_VALUE(language) OVER (\n              PARTITION BY repo_name ORDER BY bytes DESC\n            ) AS lang\n          FROM (\n            SELECT repo_name, language.name AS language, language.bytes\n            FROM `bigquery-public-data.github_repos.languages`,\n            UNNEST(language) AS language\n          )\n        )\n        WHERE lang IS NOT NULL\n        GROUP BY repo_name, lang\n      ) b\n      ON a.name = b.name\n    )\n    GROUP BY type, language, year, quarter\n    ORDER BY year, quarter, count DESC\n  )\n  WHERE count >= 100\n)\nWHERE type = 'PullRequestEvent';",
        "error_info": null
    },
    {
        "instance_id": "bq287",
        "score": 0,
        "pred_sql": "with utah_fips AS\n   (\n        SELECT\n            state_fips_code\n        FROM\n            `bigquery-public-data.census_utility.fips_codes_states`\n        WHERE\n            state_name = \"Utah\"\n    ),\n\nutah_zip AS\n    (\n        SELECT\n            z.zip_code\n        FROM\n            `bigquery-public-data.geo_us_boundaries.zip_codes` z, utah_fips u\n        WHERE\n            z.state_fips_code = u.state_fips_code\n    ),\n\nlocations AS\n    (\n        SELECT\n            COUNT(i.institution_name) AS count_locations,\n            l.zip_code\n        FROM\n            utah_zip z\n        JOIN\n            `bigquery-public-data.fdic_banks.locations` l USING (zip_code)\n        JOIN\n            `bigquery-public-data.fdic_banks.institutions` i USING (fdic_certificate_number)\n        WHERE\n            l.state IS NOT NULL\n            AND l.state_name IS NOT NULL\n            AND l.zip_code = z.zip_code\n        GROUP BY 2\n    ),\n\n    acs_2017 AS \n        (\n            SELECT\n                CAST(geo_id as STRING) AS zip_code,\n                ROUND(SAFE_DIVIDE(employed_pop, pop_16_over), 4) AS rate_employment,\n            FROM\n                `bigquery-public-data.census_bureau_acs.zip_codes_2017_5yr`\n            JOIN\n                utah_zip \n            ON \n                geo_id = zip_code\n        )\n\nSELECT\n    rate_employment\nFROM\n  utah_zip z\nJOIN\n  locations l USING (zip_code)\nJOIN\n  acs_2017 acs USING (zip_code)\nORDER BY\n  l.count_locations ASC\nLIMIT 1;\n",
        "error_info": "Result Error"
    },
    {
        "instance_id": "bq268",
        "score": 1,
        "pred_sql": "WITH \n\nvisit AS (\nSELECT fullvisitorid, MIN(date) AS date_first_visit, MAX(date) AS date_last_visit \nFROM `bigquery-public-data.google_analytics_sample.ga_sessions_*` GROUP BY fullvisitorid),\n\ndevice_visit AS (\nSELECT DISTINCT fullvisitorid, date, device.deviceCategory\nFROM `bigquery-public-data.google_analytics_sample.ga_sessions_*`),\n\ntransactions AS (\nSELECT fullvisitorid, MIN(date) AS date_transactions, 1 AS transaction\nFROM `bigquery-public-data.google_analytics_sample.ga_sessions_*` AS ga, UNNEST(ga.hits) AS hits\nWHERE  hits.transaction.transactionId IS NOT NULL GROUP BY fullvisitorid),\n\ndevice_transactions AS (\nSELECT DISTINCT fullvisitorid, date, device.deviceCategory\nFROM `bigquery-public-data.google_analytics_sample.ga_sessions_*` AS ga, UNNEST(ga.hits) AS hits\nWHERE hits.transaction.transactionId IS NOT NULL),\n\nvisits_transactions AS (\nSELECT visit.fullvisitorid, date_first_visit, date_transactions, date_last_visit , \n       device_visit.deviceCategory AS device_last_visit, device_transactions.deviceCategory AS device_transaction, \n       IFNULL(transactions.transaction,0) AS transaction\nFROM visit LEFT JOIN transactions ON visit.fullvisitorid = transactions.fullvisitorid\nLEFT JOIN device_visit ON visit.fullvisitorid = device_visit.fullvisitorid \nAND visit.date_last_visit = device_visit.date\n\nLEFT JOIN device_transactions ON visit.fullvisitorid = device_transactions.fullvisitorid \nAND transactions.date_transactions = device_transactions.date ),\n\nmortality_table AS (\nSELECT fullvisitorid, date_first_visit, \n       CASE WHEN date_transactions IS NULL THEN date_last_visit ELSE date_transactions  END AS date_event, \n       CASE WHEN device_transaction IS NULL THEN device_last_visit ELSE device_transaction END AS device, transaction\nFROM visits_transactions )\n\nSELECT DATE_DIFF(PARSE_DATE('%Y%m%d',date_event), PARSE_DATE('%Y%m%d', date_first_visit),DAY) AS time \nFROM mortality_table\nWHERE device = 'mobile'\nORDER BY DATE_DIFF(PARSE_DATE('%Y%m%d',date_event), PARSE_DATE('%Y%m%d', date_first_visit),DAY) DESC\nLIMIT 1",
        "error_info": null
    },
    {
        "instance_id": "bq264",
        "score": 0,
        "pred_sql": "with youngest as (SELECT\n        gender, id,\n        first_name,\n        last_name,\n        age,\n        'youngest' AS tag,\n  FROM `bigquery-public-data.thelook_ecommerce.users`\n  WHERE age = (SELECT MIN(age) FROM `bigquery-public-data.thelook_ecommerce.users`)\n        AND (created_at BETWEEN '2019-01-01' AND '2022-04-30')\n  GROUP BY gender, id, first_name, last_name, age\n  order by gender),\n\n  oldest as (SELECT\n        gender, id,\n        first_name,\n        last_name,\n        age,\n        'oldest' AS tag\n  FROM `bigquery-public-data.thelook_ecommerce.users`\n  WHERE age = (SELECT MAX(age) FROM `bigquery-public-data.thelook_ecommerce.users`)\n        AND (created_at BETWEEN '2019-01-01' AND '2022-04-30')\n  GROUP BY gender, id, first_name, last_name, age\n  order by gender),\n\n  TEMP_record as (\n  select *\n  from youngest \n  union all \n  select *\n  from oldest)\n \nselect \n      sum( CASE\n        WHEN age = (SELECT MAX(age) FROM `bigquery-public-data.thelook_ecommerce.users`) THEN 1\n      END)- sum( CASE\n        WHEN age = (SELECT MIN(age) FROM `bigquery-public-data.thelook_ecommerce.users`) THEN 1\n      END) as diff\n from TEMP_record",
        "error_info": "Result Error"
    },
    {
        "instance_id": "bq261",
        "score": 1,
        "pred_sql": "WITH product_sales AS (\n    SELECT \n        FORMAT_TIMESTAMP('%Y-%m', i.created_at) AS month_year,\n        p.id AS product_id,\n        p.name AS product_name,\n        SUM(i.sale_price) AS sales,\n        SUM(p.cost) AS cost,\n        SUM(i.sale_price - p.cost) AS profit\n    FROM \n        bigquery-public-data.thelook_ecommerce.order_items AS i\n    JOIN \n        bigquery-public-data.thelook_ecommerce.products AS p \n    ON \n        i.product_id = p.id\n    WHERE created_at < TIMESTAMP \"2024-01-01 00:00:00 UTC\"\n    GROUP BY \n        month_year, product_id, product_name\n),\n\nranked_products AS (\n    SELECT \n        month_year,\n        product_id,\n        product_name,\n        sales,\n        cost,\n        profit,\n        RANK() OVER (PARTITION BY month_year ORDER BY profit DESC) AS rank_per_month\n    FROM \n        product_sales\n)\n\nSELECT \n    month_year,\n    product_id,\n    product_name,\n    sales,\n    cost,\n    profit\nFROM \n    ranked_products\nWHERE \n    rank_per_month = 1\nORDER BY \n    month_year;",
        "error_info": null
    },
    {
        "instance_id": "bq252",
        "score": 1,
        "pred_sql": "WITH selected_repos as (\n  SELECT\n    f.id,\n    f.repo_name as repo_name,\n    f.path as path,\n  FROM\n    `bigquery-public-data.github_repos.sample_files` as f\n),\n\ndeduped_files as (\n  SELECT\n    f.id,\n    MIN(f.repo_name) as repo_name,\n    MIN(f.path) as path,\n  FROM\n    selected_repos as f\n  GROUP BY\n    f.id\n)\n\nSELECT\n  f.repo_name,\nFROM\n  deduped_files as f\n  JOIN `bigquery-public-data.github_repos.sample_contents` as c on f.id = c.id\nWHERE\n  NOT c.binary\n  AND f.path like '%.swift'\nORDER BY c.copies DESC\nLIMIT 1;",
        "error_info": null
    },
    {
        "instance_id": "bq210",
        "score": 1,
        "pred_sql": "WITH patents_sample AS (\n  SELECT \n    t1.publication_number,\n    claim.text AS claims_text\n  FROM \n    patents-public-data.patents.publications t1,\n    UNNEST(t1.claims_localized) AS claim\n  WHERE \n    t1.country_code = 'US'\n    AND t1.grant_date BETWEEN 20150101 AND 20181231\n    AND t1.grant_date != 0\n    AND t1.publication_number LIKE '%B2%'\n),\nPublication_data AS (\n  SELECT\n    publication_number,\n    COUNTIF(claims_text NOT LIKE '%claim%') AS nb_indep_claims\n  FROM\n    patents_sample\n  GROUP BY\n    publication_number\n)\n\nSELECT COUNT(nb_indep_claims)\nFROM Publication_data\nWHERE nb_indep_claims != 0",
        "error_info": null
    },
    {
        "instance_id": "bq194",
        "score": 1,
        "pred_sql": "WITH extracted_modules AS (\n  SELECT\n    file_id, repo_name, path, line,\n    IF(\n      ENDS_WITH(path, '.py'),\n      'Python',\n      IF(\n        (\n          ENDS_WITH(path, '.r') OR\n          ENDS_WITH(path, '.R') OR\n          ENDS_WITH(path, '.Rmd') OR\n          ENDS_WITH(path, '.rmd')\n        ),\n        'R',\n        IF(\n          ENDS_WITH(path, '.ipynb'),\n          'IPython',\n          'Others'\n        )\n      )\n    ) AS script_type,\n    IF(\n      ENDS_WITH(path, '.py'),\n      IF(\n        REGEXP_CONTAINS(line, r'^\\s*import\\s+'),\n        REGEXP_EXTRACT_ALL(line, r'(?:^\\s*import\\s|,)\\s*([a-zA-Z0-9\\_\\.]+)'),\n        REGEXP_EXTRACT_ALL(line, r'^\\s*from\\s+([a-zA-Z0-9\\_\\.]+)')\n      ),\n      IF(\n        (\n          ENDS_WITH(path, '.r') OR\n          ENDS_WITH(path, '.R') OR\n          ENDS_WITH(path, '.Rmd') OR\n          ENDS_WITH(path, '.rmd')\n        ),\n        REGEXP_EXTRACT_ALL(line, r'library\\s*\\((?:package=|)[\\\"\\']*([a-zA-Z0-9\\_\\.]+)[\\\"\\']*.*?\\)'), -- we're still ignoring commented out imports\n        IF(\n          ENDS_WITH(path, '.ipynb'),\n          IF(\n            REGEXP_CONTAINS(line, r'\"\\s*import\\s+'),\n            REGEXP_EXTRACT_ALL(line, r'(?:\"\\s*import\\s|,)\\s*([a-zA-Z0-9\\_\\.]+)'),\n            REGEXP_EXTRACT_ALL(line, r'\"\\s*from\\s+([a-zA-Z0-9\\_\\.]+)')\n          ),\n          ['']\n        )\n      )\n    ) AS modules\n  FROM (\n    SELECT\n      ct.id AS file_id, repo_name, path,\n      # Add a space after each line.\n      # It is required to ensure correct line numbering.\n      SPLIT(REPLACE(content, \"\\n\", \" \\n\"), \"\\n\") AS lines\n    FROM `bigquery-public-data.github_repos.sample_files` AS fl\n    JOIN `bigquery-public-data.github_repos.sample_contents` AS ct ON fl.id = ct.id\n    WHERE\n      ENDS_WITH(path, '.py') OR\n      (\n        ENDS_WITH(path, '.r') OR\n        ENDS_WITH(path, '.R') OR\n        ENDS_WITH(path, '.Rmd') OR\n        ENDS_WITH(path, '.rmd')\n      ) OR\n      ENDS_WITH(path, '.ipynb')\n  ), UNNEST(lines) AS line\n  WHERE\n    (ENDS_WITH(path, '.py') AND (REGEXP_CONTAINS(line, r'^\\s*import\\s+') OR REGEXP_CONTAINS(line, r'^\\s*from .* import '))) OR\n    (\n      (\n        ENDS_WITH(path, '.r') OR\n        ENDS_WITH(path, '.R') OR\n        ENDS_WITH(path, '.Rmd') OR\n        ENDS_WITH(path, '.rmd')\n      ) AND REGEXP_CONTAINS(line, r'library\\s*\\(')\n    ) OR\n    (\n      ENDS_WITH(path, '.ipynb') AND\n      (\n        REGEXP_CONTAINS(line, r'\"\\s*import\\s+') OR\n        REGEXP_CONTAINS(line, r'\"\\s*from .* import ')\n      )\n    )\n), unnested_modules AS (\n  SELECT\n    file_id, repo_name, path, script_type, module\n  FROM extracted_modules,\n  UNNEST(modules) AS module\n), module_frequencies AS (\n  SELECT\n    module,\n    script_type,\n    COUNT(*) AS frequency\n  FROM unnested_modules\n  GROUP BY module, script_type\n  ORDER BY frequency DESC\n)\n\nSELECT\n  module\nFROM module_frequencies\nORDER BY frequency DESC\nLIMIT 1\nOFFSET 1;",
        "error_info": null
    },
    {
        "instance_id": "bq258",
        "score": 1,
        "pred_sql": "  WITH monthly_summary AS (\n  SELECT \n    FORMAT_DATE('%m', oi.delivered_at) AS Month,\n    FORMAT_DATE('%Y', oi.delivered_at) AS Year,\n    p.category AS Product_category,\n    SUM(oi.sale_price) AS TPV,\n    COUNT(DISTINCT oi.order_id) AS TPO\n  FROM \n    bigquery-public-data.thelook_ecommerce.order_items oi\n  JOIN \n    bigquery-public-data.thelook_ecommerce.products p ON oi.product_id = p.id\n  JOIN \n    bigquery-public-data.thelook_ecommerce.orders o ON oi.order_id = o.order_id\n  WHERE \n    oi.status ='Complete'\n  AND\n    FORMAT_DATE('%Y', oi.delivered_at) < '2023'\n  GROUP BY\n    Month, Year, Product_category\n  ORDER BY \n    Year, Month\n),\n\nlagged_summary AS (\n  SELECT \n    month,\n    year,\n    Product_category,\n    TPV,\n    TPO,\n    LAG(TPV) OVER(PARTITION BY Product_category ORDER BY year, month) AS Lagged_TPV,\n    LAG(TPO) OVER(PARTITION BY Product_category ORDER BY year, month) AS Lagged_TPO\n  FROM \n    monthly_summary\n)\n\nSELECT \n  month,\n  year,\n  Product_category,\n  TPV,\n  TPO,\n  Lagged_TPV,\n  Lagged_TPO,\n  ROUND((TPV - Lagged_TPV) / NULLIF(Lagged_TPV, 0) * 100, 2) AS Revenue_growth,\n  ROUND((TPO - Lagged_TPO) / NULLIF(Lagged_TPO, 0) * 100, 2) AS Order_growth,\n  ROUND(SUM(p.cost), 2) AS Total_cost,\n  ROUND(TPV - SUM(p.cost), 2) AS Total_profit,\n  ROUND(TPV / NULLIF(SUM(p.cost), 0) * 100, 2) AS Profit_to_cost_ratio\nFROM \n  lagged_summary ls\nJOIN \n  bigquery-public-data.thelook_ecommerce.products p ON ls.Product_category = p.category \nGROUP BY \n  month, year, Product_category, TPV, TPO, Lagged_TPV, Lagged_TPO;",
        "error_info": null
    },
    {
        "instance_id": "bq321",
        "score": 1,
        "pred_sql": "WITH relevant_series AS (\n  SELECT \n    DISTINCT StudyInstanceUID\n  FROM \n    `bigquery-public-data.idc_v14.dicom_all`\n  WHERE \n    collection_id = 'qin_prostate_repeatability'\n    AND \n         SeriesDescription IN (\n            'DWI',\n            'T2 Weighted Axial',\n            'Apparent Diffusion Coefficient',\n            'T2 Weighted Axial Segmentations',\n            'Apparent Diffusion Coefficient Segmentations'\n    )    \n),\nt2_seg_lesion_series AS (\n  SELECT \n    DISTINCT StudyInstanceUID\n  FROM \n    `bigquery-public-data.idc_v14.dicom_all`\n  CROSS JOIN UNNEST(SegmentSequence) AS segSeq\n  WHERE \n    collection_id = 'qin_prostate_repeatability'\n    AND SeriesDescription = 'T2 Weighted Axial Segmentations'\n)\n\nSELECT \n    COUNT(DISTINCT StudyInstanceUID) AS total_count\nFROM (\n  SELECT \n    StudyInstanceUID \n  FROM relevant_series\n  UNION ALL\n  SELECT \n    StudyInstanceUID\n  FROM t2_seg_lesion_series\n);",
        "error_info": null
    },
    {
        "instance_id": "bq023",
        "score": 1,
        "pred_sql": "with median_income_by_geo as (\n    select\n        geo_id\n        , median_income \n    from `bigquery-public-data.census_bureau_acs.censustract_2018_5yr`\n)\n\n, donations_by_zip as (\n    select\n        zip_code\n        , transaction_amt\n    from `bigquery-public-data.fec.indiv20` \n    where state = 'NY'\n)\n\n, zip_to_geo as (\n    select\n        zip_code\n        , census_tract_geoid \n    from `bigquery-public-data.hud_zipcode_crosswalk.zipcode_to_census_tracts`\n)\n\n, avg_donations_by_geo_id as (\n    select\n        zip_to_geo.census_tract_geoid as geo_id\n        , sum(donations_by_zip.transaction_amt) as average_donation\n    from donations_by_zip\n    join zip_to_geo\n    on zip_to_geo.zip_code = donations_by_zip.zip_code\n    group by 1\n)\n\n, census_tracts_kings as (\n    select \n        geo_id\n        , tract_ce\n        , tract_geom\n    from `bigquery-public-data.geo_census_tracts.census_tracts_new_york`\n    where county_fips_code = '047'\n    and state_fips_code = '36'\n)\n\nselect \n    census_tracts_kings.tract_ce as census_tract\n    , avg_donations_by_geo_id.average_donation\n    , median_income_by_geo.median_income\nfrom \n    census_tracts_kings\n    LEFT JOIN avg_donations_by_geo_id  \n    ON census_tracts_kings.geo_id = avg_donations_by_geo_id.geo_id\n    LEFT join median_income_by_geo\n    on census_tracts_kings.geo_id = median_income_by_geo.geo_id\norder by census_tract;",
        "error_info": null
    },
    {
        "instance_id": "bq019",
        "score": 1,
        "pred_sql": "WITH most_common_drg AS (\n  SELECT\n    drg_definition,\n    SUM(total_discharges) AS national_num_cases\n  FROM\n    `bigquery-public-data.cms_medicare.inpatient_charges_2014`\n  GROUP BY\n    drg_definition\n  ORDER BY\n    national_num_cases DESC\n  LIMIT\n    1\n),\ncity_data AS (\n  SELECT\n    drg_definition,\n    provider_city,\n    provider_state,\n    SUM(total_discharges) AS citywise_num_cases,\n    SUM(average_total_payments * total_discharges) / SUM(total_discharges) AS citywise_avg_total_payments,\n    SUM(average_total_payments * total_discharges) AS citywise_sum_total_payments\n  FROM\n    `bigquery-public-data.cms_medicare.inpatient_charges_2014`\n  GROUP BY\n    drg_definition,\n    provider_city,\n    provider_state\n),\nranked_city_data AS (\n  SELECT\n    cd.drg_definition,\n    cd.provider_city,\n    cd.provider_state,\n    cd.citywise_avg_total_payments,\n    RANK() OVER (PARTITION BY cd.drg_definition ORDER BY cd.citywise_num_cases DESC) AS cityrank\n  FROM\n    city_data cd\n  WHERE\n    cd.drg_definition = (SELECT drg_definition FROM most_common_drg)\n)\nSELECT\n  drg_definition AS Diagnosis,\n  provider_city AS City,\n  provider_state AS State,\n  cityrank AS City_Rank,\n  CAST(ROUND(citywise_avg_total_payments) AS INT64) AS Citywise_Avg_Payments,\nFROM\n  (SELECT\n    drg_definition,\n    provider_city,\n    provider_state,\n    cityrank,\n    citywise_avg_total_payments\n  FROM\n    ranked_city_data\n  WHERE\n    cityrank <= 3)  # Limit to top 3 cities for the most common diagnosis\nORDER BY\n  cityrank;",
        "error_info": null
    },
    {
        "instance_id": "bq259",
        "score": 0,
        "pred_sql": "with a as(\n  select\n    user_id,\n    format_date('%Y-%m',first_purchase_date) as cohort_date,\n    created_at,\n    (extract(year from created_at) - extract(year from first_purchase_date))*12\n    + (extract(month from created_at) - extract(month from first_purchase_date)) + 1 as index\n  from (\n  select\n    user_id,\n    min(created_at) over(partition by user_id) as first_purchase_date,\n    created_at,\n    from bigquery-public-data.thelook_ecommerce.order_items\n    where created_at < TIMESTAMP \"2024-01-01 00:00:00 UTC\"\n  ) b\n),\n\nxxx as (\n  select \n        cohort_date,\n        index,\n        count(distinct user_id) as total_user,\n  from a \n  group by cohort_date, index\n), \n\nuser_cohort as(\nselect\n  cohort_date,\n  sum(case when index=1 then total_user else 0 end) as index_0,\n  sum(case when index=2 then total_user else 0 end) as index_1,\n  sum(case when index=3 then total_user else 0 end) as index_2,\n  sum(case when index=4 then total_user else 0 end) as index_3,\nfrom xxx\ngroup by cohort_date\norder by cohort_date)\n\nselect cohort_date,\n100.00 * index_1 / index_0 as First,\n100.00 * index_2 / index_0 as Second,\n100.00 * index_3 / index_0 as Third,\nfrom user_cohort",
        "error_info": "Result Error"
    },
    {
        "instance_id": "bq209",
        "score": 1,
        "pred_sql": "WITH patents_sample AS (               -- name of our table\nSELECT \n  t1.publication_number, \n  t1.application_number \nFROM \n  `patents-public-data.patents.publications` t1 \nWHERE \n  country_code = 'US'                                                        -- only consider US patents\n  AND grant_date between 20100101 AND 20100131                               -- grant dates between 2002 and 2006\n  AND grant_date != 0                                                        -- only consider granted patents\n  AND publication_number LIKE '%B2%'                                         -- only consider patents with kind code B2\n),\nForward_citation AS (\n     SELECT\n     DISTINCT patents_sample.publication_number,\n     COUNT(DISTINCT t3.citing_application_number) AS forward_citations\n     FROM\n     patents_sample\n     LEFT JOIN (\n     SELECT\n     x2.publication_number,\n     PARSE_DATE('%Y%m%d', CAST(x2.filing_date AS STRING)) AS filing_date\n     FROM\n     `patents-public-data.patents.publications` x2\n     WHERE\n     x2.filing_date != 0) t2\n     ON\n     t2.publication_number = patents_sample.publication_number\n     LEFT JOIN (\n     SELECT\n     x3.publication_number AS citing_publication_number,\n     x3.application_number AS citing_application_number,\n     PARSE_DATE('%Y%m%d', CAST(x3.filing_date AS STRING)) AS joined_filing_date,\n     citation_u.publication_number AS cited_publication_number\n     FROM\n     `patents-public-data.patents.publications` x3,\n     UNNEST(citation) AS citation_u\n     WHERE\n     x3.filing_date!=0) t3\n     ON\n     patents_sample.publication_number = t3.cited_publication_number\n     AND t3.joined_filing_date BETWEEN t2.filing_date\n     AND DATE_ADD(t2.filing_date, INTERVAL 10 YEAR)\n     GROUP BY\n     patents_sample.publication_number\n)\n\nSELECT \n     publication_number\nFROM\n     Forward_citation\nORDER BY\n  forward_citations\nDESC\nLIMIT 1",
        "error_info": null
    },
    {
        "instance_id": "bq285",
        "score": 1,
        "pred_sql": "with _fips AS\n    (\n        SELECT\n            state_fips_code\n        FROM\n            `bigquery-public-data.census_utility.fips_codes_states`\n        WHERE\n            state_name = \"Florida\"\n    )\n\n    ,_zip AS\n    (\n        SELECT\n            z.zip_code,\n            z.zip_code_geom,\n        FROM\n            `bigquery-public-data.geo_us_boundaries.zip_codes` z, _fips u\n        WHERE\n            z.state_fips_code = u.state_fips_code\n    )\n\n    ,locations AS\n    (\n        SELECT\n            COUNT(i.institution_name) AS count_locations,\n            l.zip_code\n        FROM\n            `bigquery-public-data.fdic_banks.institutions` i\n        JOIN\n            `bigquery-public-data.fdic_banks.locations` l \n        USING (fdic_certificate_number)\n        WHERE\n            l.state IS NOT NULL\n        AND \n            l.state_name IS NOT NULL\n        GROUP BY 2\n    )\n\n    SELECT\n        z.zip_code\n    FROM\n        _zip z\n    JOIN\n        locations l \n    USING (zip_code)\n    GROUP BY\n        z.zip_code\n    ORDER BY\n        SUM(l.count_locations) DESC\n    LIMIT 1;",
        "error_info": null
    },
    {
        "instance_id": "bq247",
        "score": 0,
        "pred_sql": "WITH\n  family_list AS (\n    SELECT\n      family_id,\n      COUNT(publication_number) AS publication_number_count\n    FROM\n      `patents-public-data.patents.publications`\n    GROUP BY\n      family_id\n  ),\n  most_published_family AS (\n    SELECT\n      family_id\n    FROM\n      family_list\n    WHERE family_id != '-1'\n    ORDER BY\n      publication_number_count DESC\n    LIMIT 1\n  ),\n  publications_with_abstracts AS (\n    SELECT\n      p.family_id,\n      gpr.abstract\n    FROM\n      `patents-public-data.google_patents_research.publications` gpr\n    JOIN\n      `patents-public-data.patents.publications` p\n    ON\n      p.publication_number = gpr.publication_number\n    WHERE\n      gpr.abstract IS NOT NULL AND gpr.abstract != ''\n  ),\n  abstracts_from_top_family AS (\n    SELECT\n      fwa.abstract\n    FROM\n      publications_with_abstracts fwa\n    JOIN\n      most_published_family mpf\n    ON\n      fwa.family_id = mpf.family_id\n  )\nSELECT\n  abstract\nFROM\n  abstracts_from_top_family;\n",
        "error_info": "Result Error"
    },
    {
        "instance_id": "bq273",
        "score": 1,
        "pred_sql": "with \norders as (\n  select\n    order_id, \n    user_id, \n    created_at,\n    date_trunc(delivered_at, MONTH) as delivery_month,\n    status \n  from bigquery-public-data.thelook_ecommerce.orders \n),\n\norder_items as (\n  select \n    order_id, \n    product_id, \n    sale_price \n  from bigquery-public-data.thelook_ecommerce.order_items \n),\n\nproducts as (\n  select \n    id, \n    cost\n  from bigquery-public-data.thelook_ecommerce.products\n),\n\nusers as (\n  select\n    id, \n    traffic_source \n  from bigquery-public-data.thelook_ecommerce.users \n),\n\nfilter_join as (\n  select \n    orders.order_id,\n    orders.user_id,\n    order_items.product_id,\n    orders.delivery_month,\n    orders.status,\n    order_items.sale_price,\n    products.cost,\n    users.traffic_source\n  from orders\n  join order_items on orders.order_id = order_items.order_id\n  join products on order_items.product_id = products.id\n  join users on orders.user_id = users.id\n  where orders.status = 'Complete' \n      and users.traffic_source = 'Facebook'\n      and orders.created_at between '2022-01-01' and '2023-06-30'\n),\n\nmonthly_sales as (\n select \n    delivery_month,\n    traffic_source,\n    sum(sale_price) as total_revenue,\n    sum(sale_price) - sum(cost) as total_profit,\n    count(distinct product_id) as product_quantity,\n    count(distinct order_id) as orders_quantity,\n    count(distinct user_id) as users_quantity\n  from filter_join\n  group by delivery_month, traffic_source\n)\nselect \n  monthly_sales.delivery_month,\n  monthly_sales.total_profit - lag(monthly_sales.total_profit, 1) over(partition by monthly_sales.traffic_source order by monthly_sales.delivery_month) \n    as profit_vs_prior_month\nfrom monthly_sales\norder by profit_vs_prior_month DESC\nlimit 5;\n",
        "error_info": null
    },
    {
        "instance_id": "bq227_1",
        "score": 1,
        "pred_sql": "WITH top5_vs_other_minor_cat AS (\n  SELECT year, month, minor_category,\n       CASE \n        WHEN minor_category IN (SELECT minor_category\n                                  FROM (SELECT minor_category, SUM(value) AS total\n                                    FROM bigquery-public-data.london_crime.crime_by_lsoa\n                                    GROUP BY 1\n                                    ORDER BY 2 DESC\n                                    LIMIT 5))\n                            THEN 'Top 5' \n        ELSE 'Other Minor Categories'-- Dividing the data into 'Top 5' and 'Other Minor Categories'\n       END AS division,\n       SUM(value) AS total\n  FROM bigquery-public-data.london_crime.crime_by_lsoa\n    GROUP BY 1,2,3\n    ORDER BY 3 DESC\n),\ntop5_percentage AS (\n  SELECT \n    year, \n    division, \n    year_total / SUM(year_total) OVER (PARTITION BY year) * 100 AS percentage \n  FROM \n    (\n      SELECT \n        year, division, SUM(total) AS year_total\n      FROM \n        top5_vs_other_minor_cat\n      GROUP BY 1,2\n      ORDER BY 1\n    )\n)\nSELECT\n  year,\n  percentage\nFROM \n  top5_percentage\nWHERE division = 'Top 5'\nORDER BY year;",
        "error_info": null
    },
    {
        "instance_id": "bq006",
        "score": 1,
        "pred_sql": "WITH incident_stats AS (\n  SELECT \n    COUNT(descript) AS total_pub_intox\n  FROM \n    `bigquery-public-data.austin_incidents.incidents_2016` \n  WHERE \n    descript = 'PUBLIC INTOXICATION' \n  GROUP BY \n    date\n),\naverage_and_stddev AS (\n  SELECT \n    AVG(total_pub_intox) AS avg, \n    STDDEV(total_pub_intox) AS stddev \n  FROM \n    incident_stats\n),\ndaily_z_scores AS (\n  SELECT \n    date, \n    COUNT(descript) AS total_pub_intox, \n    ROUND((COUNT(descript) - a.avg) / a.stddev, 2) AS z_score\n  FROM \n    `bigquery-public-data.austin_incidents.incidents_2016`,\n    (SELECT avg, stddev FROM average_and_stddev) AS a\n  WHERE \n    descript = 'PUBLIC INTOXICATION'\n  GROUP BY \n    date, avg, stddev\n)\n\nSELECT \n  date\nFROM \n  daily_z_scores\nORDER BY \n  z_score DESC\nLIMIT 1\nOFFSET 1",
        "error_info": null
    },
    {
        "instance_id": "bq071",
        "score": 0,
        "pred_sql": "SELECT\n  z.city as city\n  ,z.zip_code as zip_code\n  ,z.state_name as state\n  ,COUNT(DISTINCT(h.name)) as count_hurricanes\n  ,STRING_AGG(DISTINCT(h.name)) as hurricanes\n--  ,CONCAT(CAST(latitude as STRING), \",\" , CAST(longitude as STRING)) as position\nFROM \n  `bigquery-public-data.geo_us_boundaries.zip_codes` as z\n  ,`bigquery-public-data.noaa_hurricanes.hurricanes` as h\nWHERE\n  ST_WITHIN(ST_GeogPoint(h.longitude,h.latitude), z.zip_code_geom)\n  AND h.name != \"NOT_NAMED\"\nGROUP BY \n  zip_code\n  ,city\n  ,state  \n--  ,position\nORDER BY\n  count_hurricanes desc\nLIMIT 10",
        "error_info": "Result Error"
    },
    {
        "instance_id": "ga011",
        "score": 1,
        "pred_sql": "SELECT \npage_views\nFROM\n(\nSELECT\n    CASE \n        WHEN SPLIT(SPLIT((SELECT value.string_value \n                          FROM UNNEST(event_params) \n                          WHERE event_name = 'page_view' AND key = 'page_location'),'/')[SAFE_ORDINAL(4)],'?')[SAFE_ORDINAL(1)] = '' \n        THEN NULL \n        ELSE CONCAT('/', SPLIT(SPLIT((SELECT value.string_value \n                                      FROM UNNEST(event_params) \n                                      WHERE event_name = 'page_view' AND key = 'page_location'),'/')[SAFE_ORDINAL(4)],'?')[SAFE_ORDINAL(1)]) \n    END AS pagepath_level_1,\n    CASE \n        WHEN SPLIT(SPLIT((SELECT value.string_value \n                          FROM UNNEST(event_params) \n                          WHERE event_name = 'page_view' AND key = 'page_location'),'/')[SAFE_ORDINAL(5)],'?')[SAFE_ORDINAL(1)] = '' \n        THEN NULL \n        ELSE CONCAT('/', SPLIT(SPLIT((SELECT value.string_value \n                                      FROM UNNEST(event_params) \n                                      WHERE event_name = 'page_view' AND key = 'page_location'),'/')[SAFE_ORDINAL(5)],'?')[SAFE_ORDINAL(1)]) \n    END AS pagepath_level_2,\n    CASE \n        WHEN SPLIT(SPLIT((SELECT value.string_value \n                          FROM UNNEST(event_params) \n                          WHERE event_name = 'page_view' AND key = 'page_location'),'/')[SAFE_ORDINAL(6)],'?')[SAFE_ORDINAL(1)] = '' \n        THEN NULL \n        ELSE CONCAT('/', SPLIT(SPLIT((SELECT value.string_value \n                                      FROM UNNEST(event_params) \n                                      WHERE event_name = 'page_view' AND key = 'page_location'),'/')[SAFE_ORDINAL(6)],'?')[SAFE_ORDINAL(1)]) \n    END AS pagepath_level_3,\n    COUNTIF(event_name = 'page_view') AS page_views\nFROM\n    `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*`\nWHERE\n    _table_suffix BETWEEN '20201201' and '20201231'\nGROUP BY\n    pagepath_level_1,\n    pagepath_level_2,\n    pagepath_level_3\n)\nORDER BY\n    page_views DESC\nLIMIT 1\n",
        "error_info": null
    },
    {
        "instance_id": "bq228",
        "score": 1,
        "pred_sql": "WITH ranked_crimes AS (\n    SELECT\n        borough,\n        major_category,\n        RANK() OVER(PARTITION BY borough ORDER BY SUM(value) DESC) AS rank_per_borough,\n        SUM(value) AS no_of_incidents\n    FROM\n        `bigquery-public-data.london_crime.crime_by_lsoa`\n    GROUP BY\n        borough,\n        major_category\n)\n\nSELECT\n    borough,\n    major_category,\n    rank_per_borough,\n    no_of_incidents\nFROM\n    ranked_crimes\nWHERE\n    rank_per_borough <= 3\nAND \n    borough = 'Barking and Dagenham'\nORDER BY\n    borough,\n    rank_per_borough;",
        "error_info": null
    },
    {
        "instance_id": "ga001",
        "score": 1,
        "pred_sql": "WITH\n  Params AS (\n    SELECT 'Google Navy Speckled Tee' AS selected_product\n  ),\n  PurchaseEvents AS (\n    SELECT\n      user_pseudo_id,\n      items\n    FROM\n      `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*`\n    WHERE\n      _TABLE_SUFFIX BETWEEN '20201201' AND '20201231'\n      AND event_name = 'purchase'\n  ),\n  ProductABuyers AS (\n    SELECT DISTINCT\n      user_pseudo_id\n    FROM\n      Params,\n      PurchaseEvents,\n      UNNEST(items) AS items\n    WHERE\n      items.item_name = selected_product\n  )\nSELECT\n  items.item_name AS item_name,\n  SUM(items.quantity) AS item_quantity\nFROM\n  Params,\n  PurchaseEvents,\n  UNNEST(items) AS items\nWHERE\n  user_pseudo_id IN (SELECT user_pseudo_id FROM ProductABuyers)\n  AND items.item_name != selected_product\nGROUP BY 1\nORDER BY item_quantity DESC\nLIMIT 1;",
        "error_info": null
    },
    {
        "instance_id": "bq222",
        "score": 1,
        "pred_sql": "CREATE TEMPORARY FUNCTION highest_moving_avg(yearcnt ARRAY<STRUCT<filing_year INT64, cnt INT64>>)\nRETURNS STRUCT<filing_year INT64, avg INT64>\nLANGUAGE js AS \"\"\"\nlet a = 0.1;\nlet avg = yearcnt.length > 0 ? yearcnt[0].cnt : 0;\nlet highest = {filing_year: -1, avg: -1};\nfor (let x of yearcnt) {\n    avg = a * x.cnt + (1 - a) * avg;\n    if (avg > highest.avg) {\n        highest = {filing_year: x.filing_year, avg: avg};\n    }\n}\nreturn highest;\n\"\"\";\n    \nWITH patent_cpcs AS (\n    SELECT cd.parents,\n    CAST(FLOOR(filing_date/10000) AS INT64) AS filing_year\n    FROM (\n        SELECT ANY_VALUE(cpc) AS cpc, ANY_VALUE(filing_date) AS filing_date\n        FROM `patents-public-data.patents.publications`\n        WHERE application_number != \"\"\n        AND country_code = 'DE'\n        AND grant_date >= 20161201\n        AND grant_date <= 20161231\n        GROUP BY application_number), UNNEST(cpc) AS cpcs\n    JOIN `patents-public-data.cpc.definition` cd ON cd.symbol = cpcs.code\n    WHERE cpcs.first = TRUE AND filing_date > 0)\n\nSELECT c.titleFull, cpc_group, best_year.filing_year\nFROM (\n    SELECT cpc_group, highest_moving_avg(ARRAY_AGG(STRUCT<filing_year INT64, cnt INT64>(filing_year, cnt) ORDER BY filing_year ASC)) AS best_year\n    FROM (\n        SELECT cpc_group, filing_year, COUNT(*) AS cnt\n        FROM (\n            SELECT cpc_parent AS cpc_group, filing_year\n            FROM patent_cpcs, UNNEST(parents) AS cpc_parent)\n        GROUP BY cpc_group, filing_year\n        ORDER BY filing_year DESC, cnt DESC)\n    GROUP BY cpc_group)\nJOIN `patents-public-data.cpc.definition` c ON cpc_group = c.symbol\nWHERE c.level = 4\nORDER BY titleFull, cpc_group ASC;",
        "error_info": null
    },
    {
        "instance_id": "bq020_2",
        "score": 1,
        "pred_sql": "WITH density_data AS (\n  SELECT \n    reference_name, \n    COUNT(reference_name) / r.length AS variant_density, \n    COUNT(reference_name) AS variant_count, \n    r.length AS reference_length \n  FROM \n    `bigquery-public-data.genomics_cannabis.MNPR01_201703` v, \n    `bigquery-public-data.genomics_cannabis.MNPR01_reference_201703` r \n  WHERE \n    v.reference_name= r.name \n    AND EXISTS ( \n      SELECT \n        1 \n      FROM \n        UNNEST(v.call) AS call \n      WHERE \n        EXISTS ( \n          SELECT \n            1 \n          FROM \n            UNNEST(call.genotype) AS gt \n          WHERE \n            gt > 0)) \n  GROUP BY \n    reference_name, \n    r.length\n) \nSELECT \n  *\nFROM\n  density_data\nORDER BY \n  reference_length DESC, \n  reference_name\nLIMIT 1;",
        "error_info": null
    },
    {
        "instance_id": "bq231",
        "score": 1,
        "pred_sql": "WITH\n  temp_table AS\n  (SELECT\n    state_name,\n    commodity_desc,\n    SUM(value) as total_produce,\n    TIMESTAMP_TRUNC(load_time, YEAR) AS year_load,\n  FROM \n    `bigquery-public-data.usda_nass_agriculture.crops`\n  WHERE\n    group_desc='HORTICULTURE' AND\n    statisticcat_desc='PRODUCTION' AND\n    agg_level_desc='STATE' AND\n    commodity_desc='MUSHROOMS' AND\n    value IS NOT NULL\n  GROUP BY\n    state_name,\n    commodity_desc,\n    year_load),\nstate_with_prod AS (\nSELECT\n  state_name,\n  MAX(total_produce) AS total_prod\nFROM\n  temp_table\nWHERE\n  year_load='2022-01-01 00:00:00 UTC'\nGROUP BY\n  state_name,\n  commodity_desc\n)\n\nSELECT state_name\nFROM state_with_prod\nORDER BY total_prod DESC\nLIMIT 1\n",
        "error_info": null
    },
    {
        "instance_id": "bq250",
        "score": 1,
        "pred_sql": "WITH country_name AS (\n  SELECT 'Singapore' AS value\n),\n\nlast_updated AS (\n  SELECT\n    MAX(last_updated) AS value\n  FROM `bigquery-public-data.worldpop.population_grid_1km` AS pop\n    INNER JOIN country_name ON (pop.country_name = country_name.value)\n  WHERE last_updated < '2023-01-01'\n),\n\npopulation AS (\n  SELECT\n    SUM(sum_population) AS sum_population,\n    ST_CONVEXHULL(st_union_agg(centr)) AS boundingbox\n  FROM (\n    SELECT\n      SUM(population) AS sum_population,\n      ST_CENTROID_AGG(ST_GEOGPOINT(longitude_centroid, latitude_centroid)) AS centr\n    FROM\n      `bigquery-public-data.worldpop.population_grid_1km` AS pop\n      INNER JOIN country_name ON (pop.country_name = country_name.value)\n      INNER JOIN last_updated ON (pop.last_updated = last_updated.value)\n    GROUP BY geo_id\n  )\n),\n\nhospitals AS (\n  SELECT\n    layer.geometry\n  FROM\n    `bigquery-public-data.geo_openstreetmap.planet_layers` AS layer\n    INNER JOIN population ON ST_INTERSECTS(population.boundingbox, layer.geometry)\n  WHERE\n    layer.layer_code in (2110, 2120)\n),\n\ndistances AS (\n  SELECT\n    pop.geo_id,\n    pop.population,\n    MIN(ST_DISTANCE(pop.geog, hospitals.geometry)) AS distance\n  FROM\n    `bigquery-public-data.worldpop.population_grid_1km` AS pop\n      INNER JOIN country_name ON pop.country_name = country_name.value\n      INNER JOIN last_updated ON pop.last_updated = last_updated.value  \n      CROSS JOIN hospitals\n  WHERE pop.population > 0\n  GROUP BY geo_id, population\n)\n\nSELECT\n  SUM(pd.population) AS population\nFROM\n  distances pd\nCROSS JOIN population p\nGROUP BY distance\nORDER BY distance DESC\nLIMIT 1",
        "error_info": null
    },
    {
        "instance_id": "bq109",
        "score": 1,
        "pred_sql": "WITH coloc_stats AS (\n  SELECT\n    coloc.coloc_log2_h4_h3,\n    coloc.right_study AS qtl_source\n  FROM\n    `open-targets-genetics.genetics.variant_disease_coloc` AS coloc\n  JOIN\n    `open-targets-genetics.genetics.studies` AS studies\n  ON\n    coloc.left_study = studies.study_id\n  WHERE\n    coloc.right_gene_id = \"ENSG00000169174\"\n    AND coloc.coloc_h4 > 0.8\n    AND coloc.coloc_h3 < 0.02\n    AND studies.trait_reported LIKE \"%lesterol levels%\"\n    AND coloc.right_bio_feature = 'IPSC'\n    AND CONCAT(coloc.left_chrom, '_', coloc.left_pos, '_', coloc.left_ref, '_', coloc.left_alt) = '1_55029009_C_T'\n),\nmax_value AS (\n  SELECT\n    MAX(coloc_log2_h4_h3) AS max_log2_h4_h3\n  FROM\n    coloc_stats\n)\n\nSELECT\n  AVG(coloc_log2_h4_h3) AS average,\n  VAR_SAMP(coloc_log2_h4_h3) AS variance,\n  MAX(coloc_log2_h4_h3) - MIN(coloc_log2_h4_h3) AS max_min_difference,\n  (SELECT qtl_source FROM coloc_stats WHERE coloc_log2_h4_h3 = (SELECT max_log2_h4_h3 FROM max_value)) AS qtl_source_of_max\nFROM\n  coloc_stats;",
        "error_info": null
    },
    {
        "instance_id": "bq291",
        "score": 1,
        "pred_sql": "WITH daily_forecasts AS (\n  SELECT\n    creation_time,\n    DATE(DATETIME_ADD(forecast.time, INTERVAL 1 HOUR)) AS local_forecast_date,\n    MAX(IF(forecast.temperature_2m_above_ground IS NOT NULL, forecast.temperature_2m_above_ground, NULL)) AS max_temp,\n    MIN(IF(forecast.temperature_2m_above_ground IS NOT NULL, forecast.temperature_2m_above_ground, NULL)) AS min_temp,\n    AVG(IF(forecast.temperature_2m_above_ground IS NOT NULL, forecast.temperature_2m_above_ground, NULL)) AS avg_temp,\n    SUM(IF(forecast.total_precipitation_surface IS NOT NULL, forecast.total_precipitation_surface, 0)) AS total_precipitation,\n    AVG(IF(TIME(DATETIME_ADD(forecast.time, INTERVAL 1 HOUR)) BETWEEN '10:00:00' AND '17:00:00' AND forecast.total_cloud_cover_entire_atmosphere IS NOT NULL, forecast.total_cloud_cover_entire_atmosphere, NULL)) AS avg_cloud_cover,\n    CASE\n      WHEN AVG(forecast.temperature_2m_above_ground) < 32 THEN SUM(IF(forecast.total_precipitation_surface IS NOT NULL, forecast.total_precipitation_surface, 0))\n      ELSE 0\n    END AS total_snow,\n    CASE\n      WHEN AVG(forecast.temperature_2m_above_ground) >= 32 THEN SUM(IF(forecast.total_precipitation_surface IS NOT NULL, forecast.total_precipitation_surface, 0))\n      ELSE 0\n    END AS total_rain\n  FROM\n    `spider2-public-data.noaa_global_forecast_system.NOAA_GFS0P25`,\n    UNNEST(forecast) AS forecast\n  WHERE\n    creation_time BETWEEN '2021-11-28 00:00:00' AND '2021-11-29 00:00:00'\n    AND ST_DWithin(geography, ST_GeogPoint(17.5, 23.25), 5000)\n    AND DATE(forecast.time) = DATE_ADD(DATE(creation_time), INTERVAL 1 DAY)\n  GROUP BY\n    creation_time,\n    local_forecast_date\n)\nSELECT\n  creation_time,\n  local_forecast_date AS forecast_date,\n  max_temp,\n  min_temp,\n  avg_temp,\n  total_precipitation,\n  avg_cloud_cover,\n  total_snow,\n  total_rain\nFROM\n  daily_forecasts\nORDER BY\n  creation_time,\n  local_forecast_date",
        "error_info": null
    },
    {
        "instance_id": "bq295",
        "score": 1,
        "pred_sql": "WITH watched_repos AS (\n    SELECT\n        repo.name AS repo\n    FROM \n        `githubarchive.month.2017*`\n    WHERE\n        type = \"WatchEvent\"\n),\nrepo_watch_counts AS (\n    SELECT\n        repo,\n        COUNT(*) AS watch_count\n    FROM\n        watched_repos\n    GROUP BY\n        repo\n)\n\nSELECT\n    r.repo,\n    r.watch_count\nFROM\n    `bigquery-public-data.github_repos.sample_files` AS f\nJOIN\n    `bigquery-public-data.github_repos.sample_contents` AS c\nON\n    f.id = c.id\nJOIN \n    repo_watch_counts AS r\nON\n    f.repo_name = r.repo\nWHERE\n    f.path LIKE '%.py' \n    AND c.size < 15000 \n    AND REGEXP_CONTAINS(c.content, r'def ')\nGROUP BY\n    r.repo, r.watch_count\nORDER BY\n    r.watch_count DESC\nLIMIT \n    3;",
        "error_info": null
    },
    {
        "instance_id": "bq172_1",
        "score": 1,
        "pred_sql": "WITH total_ip_cost AS (\n  SELECT\n    provider_id,\n    SUM(average_medicare_payments * total_discharges) AS total_ip_cost\n  FROM (\n    SELECT * FROM `bigquery-public-data.cms_medicare.inpatient_charges_2011`\n    UNION ALL\n    SELECT * FROM `bigquery-public-data.cms_medicare.inpatient_charges_2012`\n    UNION ALL\n    SELECT * FROM `bigquery-public-data.cms_medicare.inpatient_charges_2013`\n    UNION ALL\n    SELECT * FROM `bigquery-public-data.cms_medicare.inpatient_charges_2014`\n    UNION ALL\n    SELECT * FROM `bigquery-public-data.cms_medicare.inpatient_charges_2015`\n  )\n  GROUP BY\n    provider_id\n  ORDER BY\n    total_ip_cost DESC\n  LIMIT 1\n),\nprovider_id_with_highest_ip_cost AS (\n  SELECT provider_id FROM total_ip_cost\n)\n\n-- Step 2: Retrieve the annual inpatient and outpatient costs for the identified provider from 2011-2015\nSELECT\n  ip.provider_name AS Provider_Name,\n  IP.year,\n  ROUND(ip.average_ip_cost) AS Average_IP_Cost,\n  ROUND(op.average_op_cost) AS Average_OP_Cost\nFROM (\n  SELECT\n    provider_id,\n    provider_state,\n    provider_city,\n    provider_name,\n    _TABLE_SUFFIX AS year,\n    AVG(average_medicare_payments * total_discharges) AS average_ip_cost\n  FROM\n    `bigquery-public-data.cms_medicare.inpatient_charges_*`\n  WHERE\n    provider_id IN (SELECT provider_id FROM provider_id_with_highest_ip_cost)\n  GROUP BY\n    provider_id,\n    provider_state,\n    provider_city,\n    provider_name,\n    year\n) AS ip\nLEFT JOIN (\n  SELECT\n    provider_id,\n    provider_state,\n    provider_city,\n    provider_name,\n    _TABLE_SUFFIX AS year,\n    AVG(average_total_payments * outpatient_services) AS average_op_cost\n  FROM\n    `bigquery-public-data.cms_medicare.outpatient_charges_*`\n  WHERE \n    provider_id IN (SELECT provider_id FROM provider_id_with_highest_ip_cost)\n  GROUP BY\n    provider_id,\n    provider_state,\n    provider_city,\n    provider_name,\n    year\n) AS op\nON\n  ip.provider_id = op.provider_id\n  AND ip.provider_state = op.provider_state\n  AND ip.provider_city = op.provider_city\n  AND ip.provider_name = op.provider_name\n  AND ip.year = op.year\nORDER BY\n  year;",
        "error_info": null
    },
    {
        "instance_id": "bq186",
        "score": 1,
        "pred_sql": "WITH aaa AS (\n    SELECT *,                 \n        CONCAT(CAST(EXTRACT(YEAR FROM start_date) AS STRING),\n               LPAD(CAST(EXTRACT(MONTH FROM start_date) AS STRING), 2, '0')) AS trip_date\n    FROM `bigquery-public-data.san_francisco.bikeshare_trips` AS bt\n    -- WHERE EXTRACT(YEAR FROM start_date) = 2015\n),\nbbb AS (\n    SELECT \n        trip_date AS date, \n        FIRST_VALUE(duration_sec) OVER (\n            PARTITION BY trip_date\n            ORDER BY trip_date\n        ) / 60.0 AS open,\n        LAST_VALUE(duration_sec) OVER (\n            PARTITION BY trip_date\n            ORDER BY trip_date\n        ) / 60.0 AS close,\n        MAX(duration_sec) OVER (\n            PARTITION BY trip_date\n            ORDER BY trip_date\n        ) / 60.0 AS high,\n        MIN(duration_sec) OVER (\n            PARTITION BY trip_date\n            ORDER BY trip_date\n        ) / 60.0 AS low\n    FROM aaa\n    ORDER BY start_date\n)\nSELECT date, open, high, close, low\nFROM bbb\nGROUP BY date, open, high, close, low\nORDER BY date;",
        "error_info": null
    },
    {
        "instance_id": "bq036",
        "score": 1,
        "pred_sql": "WITH \nCTERepoCommits AS (\n  SELECT\n    RName AS repo_name,\n    committer.date,\n    t1.COMMIT,\n    CONCAT(CAST(EXTRACT(YEAR FROM TIMESTAMP_SECONDS(committer.time_sec)) AS STRING), '-', \n           LPAD(CAST(EXTRACT(MONTH FROM TIMESTAMP_SECONDS(committer.time_sec)) AS STRING), 2, '0')) AS YearMonth\n  FROM `bigquery-public-data.github_repos.commits` t1\n  LEFT JOIN UNNEST(t1.repo_name) RName\n  WHERE EXTRACT(YEAR FROM TIMESTAMP_SECONDS(committer.time_sec)) = 2020\n),\nCTERepoLang AS (\n  SELECT\n    t2.repo_name,\n    l.name AS LangName\n  FROM `bigquery-public-data.github_repos.languages` t2\n  LEFT JOIN UNNEST(t2.LANGUAGE) AS l\n)\n, MonthlyCommits AS (\n  SELECT\n    CTERepoCommits.YearMonth,\n    COUNT(*) AS CommitCnts\n  FROM CTERepoCommits\n  INNER JOIN CTERepoLang ON CTERepoCommits.repo_name = CTERepoLang.repo_name\n  WHERE CTERepoLang.LangName = 'Python'\n  GROUP BY CTERepoCommits.YearMonth\n  ORDER BY CTERepoCommits.YearMonth\n)\nSELECT\n  AVG(CommitCnts) AS AvgMonthlyCommits\nFROM MonthlyCommits;",
        "error_info": null
    },
    {
        "instance_id": "ga032",
        "score": 1,
        "pred_sql": "WITH base_table AS (\n-- pulls relevant columns from relevant dates to decrease the size of data scanned\n  SELECT\n    event_name,\n    event_date,\n    event_timestamp,\n    user_pseudo_id,\n    user_id,\n    device,\n    geo,\n    traffic_source,\n    event_params,\n    user_properties\n  FROM\n    `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*`\n  WHERE\n    _table_suffix = '20210128' \n  AND event_name IN ('page_view')\n)\n, unnested_events AS (\n-- unnests event parameters to get to relevant keys and values\n  SELECT\n    event_date AS date,\n    event_timestamp AS event_timestamp_microseconds,\n    user_pseudo_id,\n    MAX(CASE WHEN c.key = 'ga_session_id' THEN c.value.int_value END) AS visitID,\n    MAX(CASE WHEN c.key = 'ga_session_number' THEN c.value.int_value END) AS visitNumber,\n    MAX(CASE WHEN c.key = 'page_title' THEN c.value.string_value END) AS page_title,\n    MAX(CASE WHEN c.key = 'page_location' THEN c.value.string_value END) AS page_location\n  FROM \n    base_table,\n    UNNEST (event_params) c\n  WHERE user_pseudo_id='1362228.4966015575'\n  GROUP BY 1,2,3\n)\n\n, unnested_events_categorised AS (\n-- categorizing Page Titles into PDPs and PLPs\n  SELECT\n  *,\n  CASE WHEN ARRAY_LENGTH(SPLIT(page_location, '/')) >= 5 \n            AND\n            CONTAINS_SUBSTR(ARRAY_REVERSE(SPLIT(page_location, '/'))[SAFE_OFFSET(0)], '+')\n            AND (LOWER(SPLIT(page_location, '/')[SAFE_OFFSET(4)]) IN \n                                        ('accessories','apparel','brands','campus+collection','drinkware',\n                                          'electronics','google+redesign',\n                                          'lifestyle','nest','new+2015+logo','notebooks+journals',\n                                          'office','shop+by+brand','small+goods','stationery','wearables'\n                                          )\n                  OR\n                  LOWER(SPLIT(page_location, '/')[SAFE_OFFSET(3)]) IN \n                                        ('accessories','apparel','brands','campus+collection','drinkware',\n                                          'electronics','google+redesign',\n                                          'lifestyle','nest','new+2015+logo','notebooks+journals',\n                                          'office','shop+by+brand','small+goods','stationery','wearables'\n                                          )\n            )\n            THEN 'PDP'\n            WHEN NOT(CONTAINS_SUBSTR(ARRAY_REVERSE(SPLIT(page_location, '/'))[SAFE_OFFSET(0)], '+'))\n            AND (LOWER(SPLIT(page_location, '/')[SAFE_OFFSET(4)]) IN \n                                        ('accessories','apparel','brands','campus+collection','drinkware',\n                                          'electronics','google+redesign',\n                                          'lifestyle','nest','new+2015+logo','notebooks+journals',\n                                          'office','shop+by+brand','small+goods','stationery','wearables'\n                                          )\n                  OR \n                  LOWER(SPLIT(page_location, '/')[SAFE_OFFSET(3)]) IN \n                                          ('accessories','apparel','brands','campus+collection','drinkware',\n                                            'electronics','google+redesign',\n                                            'lifestyle','nest','new+2015+logo','notebooks+journals',\n                                            'office','shop+by+brand','small+goods','stationery','wearables'\n                                            )\n            )\n            THEN 'PLP'\n        ELSE page_title\n        END AS page_title_adjusted \n\n  FROM \n    unnested_events\n)\n\n, ranked_screens AS (\n-- prepares additional data points for analytics to understand transitions between the previous, current and following pages\n  SELECT\n    *,\n    DENSE_RANK() OVER (PARTITION BY  user_pseudo_id, visitID ORDER BY event_timestamp_microseconds ASC) page_rank,\n    LAG(page_title_adjusted,1) OVER (PARTITION BY  user_pseudo_id, visitID ORDER BY event_timestamp_microseconds ASC) previous_page,\n    LEAD(page_title_adjusted,1) OVER (PARTITION BY  user_pseudo_id, visitID ORDER BY event_timestamp_microseconds ASC)  next_page\n  FROM \n    unnested_events_categorised\n\n)\n, screen_summary AS (\n-- another layer of analytics: check the last page number viewed on a session\n-- aggregate all screens per session, which will be helpful in identifying power users\n  SELECT\n    *,\n    MAX(page_rank) OVER (PARTITION BY  user_pseudo_id, visitID) last_page_rank,\n    ARRAY_AGG(page_title_adjusted) OVER (PARTITION BY  user_pseudo_id, visitID) pages_on_a_visit\n  FROM \n    ranked_screens\n)\n\n\nSELECT \n  distinct ARRAY_TO_STRING(ARRAY(SELECT DISTINCT * FROM UNNEST(pages_on_a_visit) ORDER BY 1 ASC), '>>') AS screens_on_a_visit\nFROM \n  screen_summary;",
        "error_info": null
    },
    {
        "instance_id": "ga010",
        "score": 1,
        "pred_sql": "WITH prep AS (\n  SELECT\n    user_pseudo_id,\n    (SELECT value.int_value FROM UNNEST(event_params) WHERE key = 'ga_session_id') AS session_id,\n    ARRAY_AGG((SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'source') IGNORE NULLS \n              ORDER BY event_timestamp)[SAFE_OFFSET(0)] AS source,\n    ARRAY_AGG((SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'medium') IGNORE NULLS \n              ORDER BY event_timestamp)[SAFE_OFFSET(0)] AS medium,\n    ARRAY_AGG((SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'campaign') IGNORE NULLS \n              ORDER BY event_timestamp)[SAFE_OFFSET(0)] AS campaign\n  FROM\n    `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*`\n  WHERE\n    _TABLE_SUFFIX BETWEEN '20201201' AND '20201231'\n  GROUP BY\n    user_pseudo_id,\n    session_id\n)\nSELECT\n  -- session default channel grouping (dimension | the channel group associated with a session) \n  CASE \n    WHEN source = '(direct)' AND (medium IN ('(not set)','(none)')) THEN 'Direct'\n    WHEN REGEXP_CONTAINS(campaign, 'cross-network') THEN 'Cross-network'\n    WHEN (REGEXP_CONTAINS(source,'alibaba|amazon|google shopping|shopify|etsy|ebay|stripe|walmart')\n        OR REGEXP_CONTAINS(campaign, '^(.*(([^a-df-z]|^)shop|shopping).*)$'))\n        AND REGEXP_CONTAINS(medium, '^(.*cp.*|ppc|paid.*)$') THEN 'Paid Shopping'\n    WHEN REGEXP_CONTAINS(source,'baidu|bing|duckduckgo|ecosia|google|yahoo|yandex')\n        AND REGEXP_CONTAINS(medium,'^(.*cp.*|ppc|paid.*)$') THEN 'Paid Search'\n    WHEN REGEXP_CONTAINS(source,'badoo|facebook|fb|instagram|linkedin|pinterest|tiktok|twitter|whatsapp')\n        AND REGEXP_CONTAINS(medium,'^(.*cp.*|ppc|paid.*)$') THEN 'Paid Social'\n    WHEN REGEXP_CONTAINS(source,'dailymotion|disneyplus|netflix|youtube|vimeo|twitch|vimeo|youtube')\n        AND REGEXP_CONTAINS(medium,'^(.*cp.*|ppc|paid.*)$') THEN 'Paid Video'\n    WHEN medium IN ('display', 'banner', 'expandable', 'interstitial', 'cpm') THEN 'Display'\n    WHEN REGEXP_CONTAINS(source,'alibaba|amazon|google shopping|shopify|etsy|ebay|stripe|walmart')\n        OR REGEXP_CONTAINS(campaign, '^(.*(([^a-df-z]|^)shop|shopping).*)$') THEN 'Organic Shopping'\n    WHEN REGEXP_CONTAINS(source,'badoo|facebook|fb|instagram|linkedin|pinterest|tiktok|twitter|whatsapp')\n        OR medium IN ('social','social-network','social-media','sm','social network','social media') THEN 'Organic Social'\n    WHEN REGEXP_CONTAINS(source,'dailymotion|disneyplus|netflix|youtube|vimeo|twitch|vimeo|youtube')\n        OR REGEXP_CONTAINS(medium,'^(.*video.*)$') THEN 'Organic Video'\n    WHEN REGEXP_CONTAINS(source,'baidu|bing|duckduckgo|ecosia|google|yahoo|yandex')\n        OR medium = 'organic' THEN 'Organic Search'\n    WHEN REGEXP_CONTAINS(source,'email|e-mail|e_mail|e mail')\n        OR REGEXP_CONTAINS(medium,'email|e-mail|e_mail|e mail') THEN 'Email'\n    WHEN medium = 'affiliate' THEN 'Affiliates'\n    WHEN medium = 'referral' THEN 'Referral'\n    WHEN medium = 'audio' THEN 'Audio'\n    WHEN medium = 'sms' THEN 'SMS'\n    WHEN medium LIKE '%push'\n        OR REGEXP_CONTAINS(medium,'mobile|notification') THEN 'Mobile Push Notifications'\n    ELSE 'Unassigned' \n  END AS channel_grouping_session\nFROM\n  prep\nGROUP BY\n  channel_grouping_session\nORDER BY\n  COUNT(DISTINCT CONCAT(user_pseudo_id, session_id)) DESC\nLIMIT 1 OFFSET 3",
        "error_info": null
    },
    {
        "instance_id": "bq002",
        "score": 1,
        "pred_sql": "DECLARE start_date STRING DEFAULT '20170101';\nDECLARE end_date STRING DEFAULT '20170630';\n\n-- Step 1: Calculate daily, weekly, and monthly revenues for each traffic source\nWITH daily_revenue AS (\n    SELECT\n        trafficSource.source AS source,\n        date,\n        SUM(productRevenue) / 1000000 AS revenue\n    FROM\n        `bigquery-public-data.google_analytics_sample.ga_sessions_*`,\n        UNNEST (hits) AS hits,\n        UNNEST (hits.product) AS product\n    WHERE\n        _table_suffix BETWEEN start_date AND end_date\n    GROUP BY\n        source, date\n),\nweekly_revenue AS (\n    SELECT\n        source,\n        CONCAT(EXTRACT(YEAR FROM (PARSE_DATE('%Y%m%d', date))), 'W', EXTRACT(WEEK FROM (PARSE_DATE('%Y%m%d', date)))) AS week,\n        SUM(revenue) AS revenue\n    FROM daily_revenue\n    GROUP BY source, week\n),\nmonthly_revenue AS (\n    SELECT\n        source,\n        CONCAT(EXTRACT(YEAR FROM (PARSE_DATE('%Y%m%d', date))),'0', EXTRACT(MONTH FROM (PARSE_DATE('%Y%m%d', date)))) AS month,\n        SUM(revenue) AS revenue\n    FROM daily_revenue\n    GROUP BY source, month\n),\n\n-- Step 2: Determine the top-performing traffic source\ntop_source AS (\n    SELECT source, SUM(revenue) AS total_revenue\n    FROM daily_revenue\n    GROUP BY source\n    ORDER BY total_revenue DESC\n    LIMIT 1\n),\n\n-- Step 3: Calculate maximum revenues for the top-performing traffic source\nmax_revenues AS (\n    (\n      SELECT\n        'Daily' AS time_type,\n        date AS time,\n        source,\n        MAX(revenue) AS max_revenue\n      FROM daily_revenue\n      WHERE source = (SELECT source FROM top_source)\n      GROUP BY source, date\n      ORDER BY max_revenue DESC\n      LIMIT 1\n    )\n\n    UNION ALL\n\n    (\n      SELECT\n        'Weekly' AS time_type,\n        week AS time,\n        source,\n        MAX(revenue) AS max_revenue\n      FROM weekly_revenue\n      WHERE source = (SELECT source FROM top_source)\n      GROUP BY source, week\n      ORDER BY max_revenue DESC\n      LIMIT 1\n    )\n\n    UNION ALL\n\n    (\n      SELECT\n          'Monthly' AS time_type,\n          month AS time,\n          source,\n          MAX(revenue) AS max_revenue\n      FROM monthly_revenue\n      WHERE source = (SELECT source FROM top_source)\n      GROUP BY source, month\n      ORDER BY max_revenue DESC\n      LIMIT 1\n    )\n)\n\n-- Step 4: Select final results\nSELECT\n    time_type,\n    time,\n    source,\n    max_revenue\nFROM max_revenues\nORDER BY time_type, time;\n",
        "error_info": null
    },
    {
        "instance_id": "bq123",
        "score": 1,
        "pred_sql": "WITH question_answer_stats AS (\n  SELECT\n    EXTRACT(DAYOFWEEK FROM q.creation_date) AS question_day,\n    COUNT(DISTINCT a.id) AS count_answers,\n    COUNT(DISTINCT q.id) AS count_questions,\n    ROUND(COUNT(DISTINCT a.id) * 1.0 / COUNT(DISTINCT q.id) * 100, 2) AS percent_questions\n  FROM \n    `bigquery-public-data.stackoverflow.posts_questions` q\n  LEFT JOIN\n    `bigquery-public-data.stackoverflow.posts_answers` a \n  ON \n    q.id = a.parent_id \n    AND a.creation_date < TIMESTAMP_ADD(q.creation_date, INTERVAL 1 HOUR) \n  GROUP BY\n    EXTRACT(DAYOFWEEK FROM q.creation_date)\n  ORDER BY \n    percent_questions DESC\n)\n\nSELECT \n  question_day, \n  percent_questions\nFROM \n  question_answer_stats\nORDER BY \n  percent_questions DESC\nLIMIT 1 OFFSET 2;",
        "error_info": null
    },
    {
        "instance_id": "bq088",
        "score": 1,
        "pred_sql": "SELECT\n  table_2019.avg_symptom_Anxiety_2019,\n  table_2020.avg_symptom_Anxiety_2020,\n  ((table_2020.avg_symptom_Anxiety_2020 - table_2019.avg_symptom_Anxiety_2019)/table_2019.avg_symptom_Anxiety_2019) * 100 AS percent_increase_anxiety,\n  table_2019.avg_symptom_Depression_2019,\n  table_2020.avg_symptom_Depression_2020,\n  ((table_2020.avg_symptom_Depression_2020 - table_2019.avg_symptom_Depression_2019)/table_2019.avg_symptom_Depression_2019) * 100 AS percent_increase_depression\nFROM (\n  SELECT\n    AVG(CAST(symptom_Anxiety AS FLOAT64)) AS avg_symptom_Anxiety_2020,\n    AVG(CAST(symptom_Depression AS FLOAT64)) AS avg_symptom_Depression_2020,\n  FROM\n    `bigquery-public-data.covid19_symptom_search.symptom_search_country_weekly`\n  WHERE\n    country_region_code = \"US\"\n    AND date >= '2020-01-01'\n    AND date <'2021-01-01') AS table_2020,\n  (\n  SELECT\n    AVG(CAST(symptom_Anxiety AS FLOAT64)) AS avg_symptom_Anxiety_2019,\n    AVG(CAST(symptom_Depression AS FLOAT64)) AS avg_symptom_Depression_2019,\n  FROM\n    `bigquery-public-data.covid19_symptom_search.symptom_search_country_weekly`\n  WHERE\n    country_region_code = \"US\"\n    AND date >= '2019-01-01'\n    AND date <'2020-01-01') AS table_2019",
        "error_info": null
    },
    {
        "instance_id": "bq009",
        "score": 1,
        "pred_sql": "WITH MONTHLY_REVENUE AS (\n    SELECT \n        FORMAT_DATE(\"%Y%m\", PARSE_DATE(\"%Y%m%d\", date)) AS month,\n        trafficSource.source AS source,\n        ROUND(SUM(totals.totalTransactionRevenue) / 1000000, 2) AS revenue\n    FROM `bigquery-public-data.google_analytics_sample.ga_sessions_2017*`\n    GROUP BY 1, 2\n),\n\nYEARLY_REVENUE AS (\n    SELECT\n        source,\n        SUM(revenue) AS total_revenue\n    FROM MONTHLY_REVENUE\n    GROUP BY source\n),\n\nTOP_SOURCE AS (\n    SELECT \n        source\n    FROM YEARLY_REVENUE\n    ORDER BY total_revenue DESC\n    LIMIT 1\n),\n\nSOURCE_MONTHLY_REVENUE AS (\n    SELECT\n        month,\n        source,\n        revenue\n    FROM MONTHLY_REVENUE\n    WHERE source IN (SELECT source FROM TOP_SOURCE)\n),\n\nREVENUE_DIFF AS (\n    SELECT \n        source,\n        ROUND(MAX(revenue), 2) AS max_revenue,\n        ROUND(MIN(revenue), 2) AS min_revenue,\n        ROUND(MAX(revenue) - MIN(revenue), 2) AS diff_revenue\n    FROM SOURCE_MONTHLY_REVENUE\n    GROUP BY source\n)\n\nSELECT \n    source,\n    diff_revenue\nFROM REVENUE_DIFF;\n",
        "error_info": null
    },
    {
        "instance_id": "bq052",
        "score": 0,
        "pred_sql": "SELECT\n    app.patent_id as patent_id,\n    patent.title,\n    app.date as application_date,\n    filterData.bkwdCitations_1,\n    filterData.fwrdCitations_1,\n    summary.text as summary_text\nFROM\n    `patents-public-data.patentsview.brf_sum_text` as summary,\n    `patents-public-data.patentsview.patent` as patent,\n    `patents-public-data.patentsview.application` as app,\n    (\n        SELECT DISTINCT\n            cpc.patent_id,\n            IFNULL(citation_1.bkwdCitations_1, 0) as bkwdCitations_1,\n            IFNULL(citation_1.fwrdCitations_1, 0) as fwrdCitations_1\n        FROM\n            `patents-public-data.patentsview.cpc_current` AS cpc\n        JOIN\n        (\n            SELECT  b.patent_id, b.bkwdCitations_1, f.fwrdCitations_1\n            FROM (\n                SELECT \n                    cited.patent_id,\n                    COUNT(*) as fwrdCitations_1\n                FROM \n                    `patents-public-data.patentsview.uspatentcitation` AS cited,\n                    `patents-public-data.patentsview.application` AS apps\n                WHERE\n                    apps.country = 'US'\n                    AND cited.patent_id = apps.patent_id \n                    AND cited.date >= apps.date\n                    AND SAFE_CAST(cited.date AS DATE) <= DATE_ADD(SAFE_CAST(apps.date AS DATE), INTERVAL 1 MONTH)\n                GROUP BY \n                    cited.patent_id\n            ) AS f,\n            (\n                SELECT \n                    cited.patent_id,\n                    COUNT(*) as bkwdCitations_1\n                FROM \n                    `patents-public-data.patentsview.uspatentcitation` AS cited,\n                    `patents-public-data.patentsview.application` AS apps\n                WHERE\n                    apps.country = 'US'\n                    AND cited.patent_id = apps.patent_id \n                    AND cited.date < apps.date AND SAFE_CAST(cited.date AS DATE) >= DATE_SUB(SAFE_CAST(apps.date AS DATE), INTERVAL 1 MONTH) -- get in one year interval \n                GROUP BY \n                    cited.patent_id\n            ) AS b\n            WHERE\n                b.patent_id = f.patent_id\n                AND b.bkwdCitations_1 IS NOT NULL\n                AND f.fwrdCitations_1 IS NOT NULL\n                AND (b.bkwdCitations_1 > 0 OR f.fwrdCitations_1 > 0)\n        ) AS citation_1 \n        ON cpc.patent_id=citation_1.patent_id\n        WHERE (\n            cpc.subsection_id = 'C05'\n            OR cpc.group_id = 'A01G'\n        )\n    ) as filterData\nWHERE\n    app.patent_id = filterData.patent_id\n    AND summary.patent_id = app.patent_id\n    AND app.patent_id = patent.id\nORDER BY application_date;",
        "error_info": "Result Error"
    },
    {
        "instance_id": "bq224",
        "score": 1,
        "pred_sql": "WITH allowed_repos as (\n    select\n        repo_name,\n        license\n    from `bigquery-public-data.github_repos.licenses`\n    where license in unnest(\n      [\"gpl-3.0\", \"artistic-2.0\", \"isc\", \"cc0-1.0\", \"epl-1.0\", \"gpl-2.0\",\n       \"mpl-2.0\", \"lgpl-2.1\", \"bsd-2-clause\", \"apache-2.0\", \"mit\", \"lgpl-3.0\"])\n),\nwatch_counts as (\n    SELECT \n        repo.name as repo,\n        COUNT(DISTINCT actor.login) watches,\n    FROM `githubarchive.month.202204`\n    WHERE type = \"WatchEvent\"\n    GROUP BY repo\n),\nissue_counts as (\n    SELECT \n        repo.name as repo,\n        COUNT(*) issue_events,\n    FROM `githubarchive.month.202204`\n    WHERE type = 'IssuesEvent'\n    GROUP BY repo\n),\nfork_counts as (\n    SELECT \n        repo.name as repo,\n        COUNT(*) forks,\n    FROM `githubarchive.month.202204`\n    WHERE type = 'ForkEvent'\n    GROUP BY repo\n)\nSELECT repo_name\nFROM allowed_repos\nINNER JOIN fork_counts ON repo_name = fork_counts.repo\nINNER JOIN issue_counts on repo_name = issue_counts.repo\nINNER JOIN watch_counts ON repo_name = watch_counts.repo\nORDER BY forks + issue_events + watches DESC\nLIMIT 1;",
        "error_info": null
    },
    {
        "instance_id": "bq263",
        "score": 1,
        "pred_sql": "with d as(\n    select\n        a.order_id, \n        format_date('%Y-%m', a.created_at) as month,\n        format_date('%Y', a.created_at) as year,\n        b.product_id, b.sale_price, c.category, c.cost\n    from bigquery-public-data.thelook_ecommerce.orders as a\n    JOIN\n        bigquery-public-data.thelook_ecommerce.order_items as b\n    on a.order_id = b.order_id\n    JOIN bigquery-public-data.thelook_ecommerce.products as c\n    on b.order_id = c.id\n    where a.status = 'Complete'\n    and a.created_at BETWEEN TIMESTAMP('2023-01-01') AND TIMESTAMP('2023-12-31')\n    and c.category = 'Sleep & Lounge'\n),\n\ne as (\n    select month, year, sale_price, category, cost,\n        sum(sale_price) over(partition by month, category) as TPV,\n        sum(cost) over(partition by month, category) as total_cost,\n        count(distinct order_id) over(partition by month, category) as TPO,\n        sum(sale_price-cost) over(partition by month, category) as total_profit,\n        sum((sale_price-cost)/cost) over(partition by month, category) as Profit_to_cost_ratio\n    from d\n)\n\nselect distinct month, category, TPV, total_cost, TPO, total_profit, Profit_to_cost_ratio\nfrom e\norder by month",
        "error_info": null
    },
    {
        "instance_id": "bq032",
        "score": 1,
        "pred_sql": "WITH hurricane_geometry AS (\n  SELECT\n    * EXCEPT (longitude, latitude),\n    ST_GEOGPOINT(longitude, latitude) AS geom,\n    MAX(usa_wind) OVER (PARTITION BY sid) AS max_wnd_speed\n  FROM\n    `bigquery-public-data.noaa_hurricanes.hurricanes`\n  WHERE\n    season = '2020'\n    AND basin = 'NA'\n    AND name != 'NOT NAMED'\n),\ndist_between_points AS (\n  SELECT\n    sid,\n    name,\n    season,\n    iso_time,\n    max_wnd_speed,\n    geom,\n    ST_DISTANCE(geom, LAG(geom, 1) OVER (PARTITION BY sid ORDER BY iso_time ASC)) / 1000 AS dist\n  FROM\n    hurricane_geometry\n),\ntotal_distances AS (\n  SELECT\n    sid,\n    name,\n    season,\n    iso_time,\n    max_wnd_speed,\n    geom,\n    SUM(dist) OVER (PARTITION BY sid ORDER BY iso_time ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_distance,\n    SUM(dist) OVER (PARTITION BY sid) AS total_dist\n  FROM\n    dist_between_points\n),\nranked_hurricanes AS (\n  SELECT\n    *,\n    DENSE_RANK() OVER (ORDER BY total_dist DESC) AS dense_rank\n  FROM\n    total_distances\n)\n\nSELECT\n  ST_Y(geom)\nFROM\n  ranked_hurricanes\nWHERE\n  dense_rank = 2\nORDER BY\ncumulative_distance\nDESC\nLIMIT 1\n;",
        "error_info": null
    },
    {
        "instance_id": "bq198",
        "score": 1,
        "pred_sql": "SELECT\n  team_name,\n  COUNT(*) AS top_performer_count\nFROM (\n  SELECT\n    DISTINCT c2.season,\n    c2.market AS team_name\n  FROM (\n    SELECT\n      season AS a,\n      MAX(wins) AS win_max\n    FROM\n      `bigquery-public-data.ncaa_basketball.mbb_historical_teams_seasons`\n    WHERE\n      season<=2000\n      AND season >=1900\n    GROUP BY\n      season ),\n    `bigquery-public-data.ncaa_basketball.mbb_historical_teams_seasons` c2\n  WHERE\n    win_max = c2.wins\n    AND a = c2.season\n    AND c2.market IS NOT NULL\n  ORDER BY\n    c2.season)\nGROUP BY\n  team_name\nORDER BY\n  top_performer_count DESC,\n  team_name\nLIMIT\n  5",
        "error_info": null
    },
    {
        "instance_id": "bq180_1",
        "score": 1,
        "pred_sql": "\nWITH extracted_modules AS (\n  SELECT \n    file_id, \n    repo_name, \n    path, \n    line, \n    IF(\n      ENDS_WITH(path, '.py'),\n      'python',\n      IF(ENDS_WITH(path, '.r'), 'r', NULL)\n    ) AS language,\n    IF(\n      ENDS_WITH(path, '.py'),\n      ARRAY_CONCAT(\n        REGEXP_EXTRACT_ALL(line, r'\\bimport\\s+(\\w+)'), \n        REGEXP_EXTRACT_ALL(line, r'\\bfrom\\s+(\\w+)')\n      ),\n      IF(\n        ENDS_WITH(path, '.r'),\n        REGEXP_EXTRACT_ALL(line, r'library\\s*\\(\\s*([^\\s)]+)\\s*\\)'),\n        []\n      )\n    ) AS modules\n  FROM (\n    SELECT\n      ct.id AS file_id, \n      fl.repo_name, \n      path, \n      SPLIT(REPLACE(ct.content, \"\\n\", \" \\n\"), \"\\n\") AS lines\n    FROM `bigquery-public-data.github_repos.sample_files` AS fl\n    JOIN `bigquery-public-data.github_repos.sample_contents` AS ct ON fl.id = ct.id\n  ), UNNEST(lines) as line\n  WHERE\n    (ENDS_WITH(path, '.py') AND (REGEXP_CONTAINS(line, r'^import ') OR REGEXP_CONTAINS(line, r'^from '))) OR \n    (ENDS_WITH(path, '.r') AND REGEXP_CONTAINS(line, r'library\\s*\\('))\n),\nmodule_counts AS (\n  SELECT \n    language,\n    module,\n    COUNT(*) AS occurrence_count\n  FROM (\n    SELECT \n      language,\n      modules\n    FROM extracted_modules\n    WHERE modules IS NOT NULL\n  ),UNNEST(modules) AS module\n  GROUP BY language, module\n),\ntop5_python AS (\n  SELECT \n    'python' AS language,\n    module,\n    occurrence_count\n  FROM module_counts\n  WHERE language = 'python'\n  ORDER BY occurrence_count DESC\n  LIMIT 5\n),\ntop5_r AS (\n  SELECT \n    'r' AS language,\n    module,\n    occurrence_count\n  FROM module_counts\n  WHERE language = 'r'\n  ORDER BY occurrence_count DESC\n  LIMIT 5\n)\nSELECT * FROM top5_python\nUNION ALL\nSELECT * FROM top5_r\nORDER BY language, occurrence_count DESC;",
        "error_info": null
    },
    {
        "instance_id": "bq101",
        "score": 1,
        "pred_sql": "SELECT\n  package,\n  COUNT(*) count\nFROM (\n  SELECT\n    REGEXP_EXTRACT(line, r' ([a-z0-9\\._]*)\\.') AS package,\n    id\n  FROM (\n    SELECT\n      SPLIT(content, '\\n') AS lines,\n      id\n    FROM\n      `bigquery-public-data.github_repos.sample_contents`\n    WHERE\n      REGEXP_CONTAINS(content, r'import')\n      AND sample_path LIKE '%.java'\n  ), UNNEST(lines) AS line\n  WHERE\n    LEFT(line, 6) = 'import'\n  GROUP BY\n    package,\n    id\n)\nGROUP BY\n  package\nORDER BY\n  count DESC\nLIMIT\n  10;\n",
        "error_info": null
    },
    {
        "instance_id": "bq280",
        "score": 1,
        "pred_sql": "WITH UserAnswers AS (\n  SELECT\n    owner_user_id AS answer_owner_id,\n    COUNT(id) AS answer_count\n  FROM bigquery-public-data.stackoverflow.posts_answers\n  WHERE owner_user_id IS NOT NULL\n  GROUP BY owner_user_id\n),\nDetailedUsers AS (\n  SELECT\n    id AS user_id,\n    display_name AS user_display_name,\n    reputation\n  FROM bigquery-public-data.stackoverflow.users\n  WHERE display_name IS NOT NULL AND reputation > 10\n),\nRankedUsers AS (\n  SELECT\n    u.user_display_name,\n    u.reputation,\n    a.answer_count,\n    ROW_NUMBER() OVER (ORDER BY a.answer_count DESC) AS rank\n  FROM DetailedUsers u\n  JOIN UserAnswers a ON u.user_id = a.answer_owner_id\n)\nSELECT\n  user_display_name,\nFROM RankedUsers\nWHERE rank = 1;\n",
        "error_info": null
    },
    {
        "instance_id": "bq106",
        "score": 1,
        "pred_sql": "WITH boundary AS (\n    SELECT\n        layer_class,\n        layer_name,\n        all_tags,\n        geometry\n    FROM\n        `bigquery-public-data.geo_openstreetmap.planet_layers` AS layers\n    WHERE\n        TRUE\n        AND layer_class = 'boundary'\n        AND layer_name = 'national'\n        AND EXISTS (\n            SELECT 1\n            FROM layers.all_tags\n            WHERE\n                key = 'ISO3166-1'\n                AND value IN ('SD')\n                -- for country Sudan\n        )\n),\ncells AS (\n    SELECT\n        gfs.*\n    FROM\n        boundary,\n        `spider2-public-data.noaa_global_forecast_system.NOAA_GFS0P25` AS gfs\n    WHERE\n        creation_time = '2021-11-28T00:00:00'\n        AND ST_WITHIN(gfs.geography,\n            boundary.geometry)\n),\npred1 AS (\n    SELECT\n        creation_time,\n        time,\n        AVG(temperature_2m_above_ground) AS temp\n    FROM\n        cells\n    JOIN\n        UNNEST(forecast) AS forecast\n    WHERE\n        MOD(hours, 24) = 0\n        AND hours / 24 <= 14\n        AND temperature_2m_above_ground IS NOT NULL\n    GROUP BY\n        creation_time,\n        time\n),\nobserved AS (\n    SELECT\n        pred1.creation_time AS prediction_made,\n        pred1.time AS predicted_time,\n        gfs.creation_time AS observed_time,\n        pred1.temp AS predicted_temp,\n        AVG(forecast.temperature_2m_above_ground) AS observed_temp\n    FROM\n        pred1,\n        boundary,\n        `spider2-public-data.noaa_global_forecast_system.NOAA_GFS0P25` AS gfs\n    JOIN\n        UNNEST(forecast) AS forecast\n    WHERE\n        gfs.creation_time = pred1.time\n        AND ST_WITHIN(gfs.geography,\n            boundary.geometry)\n    GROUP BY\n        prediction_made,\n        predicted_time,\n        observed_time,\n        predicted_temp )\nSELECT\n    observed_time,\n    observed_temp - predicted_temp AS prediction_error\nFROM\n    observed\nORDER BY\n    observed_time ASC",
        "error_info": null
    },
    {
        "instance_id": "bq042",
        "score": 1,
        "pred_sql": "SELECT\n  -- Create a timestamp from the date components.\n  TIMESTAMP(CONCAT(year,\"-\",mo,\"-\",da)) AS timestamp,\n  -- Replace numerical null values with actual null\n  AVG(IF (temp=9999.9,\n      null,\n      temp)) AS temperature,\n  AVG(IF (wdsp=\"999.9\",\n      null,\n      CAST(wdsp AS Float64))) AS wind_speed,\n  AVG(IF (prcp=99.99,\n      0,\n      prcp)) AS precipitation\nFROM\n  `bigquery-public-data.noaa_gsod.gsod20*`\nWHERE\n  CAST(YEAR AS INT64) > 2010\n  AND CAST(YEAR AS INT64) < 2021\n  AND CAST(MO AS INT64) = 6\n  AND CAST(DA AS INT64) = 12\n  AND stn = \"725030\" -- La Guardia\nGROUP BY\n  timestamp\nORDER BY\n  timestamp ASC;",
        "error_info": null
    },
    {
        "instance_id": "ga030_1",
        "score": 1,
        "pred_sql": "WITH dates AS (\n    SELECT \n        DATE('2018-07-09') AS start_date,\n        DATE('2018-10-02') AS end_date,\n        DATE_ADD(DATE_TRUNC(DATE('2018-10-02'), WEEK(MONDAY)), INTERVAL -2 WEEK) AS min_date\n),\n\ndate_table AS (\n    SELECT DISTINCT \n        PARSE_DATE('%Y%m%d', `event_date`) AS event_date,\n        user_pseudo_id,\n        CASE \n            WHEN DATE_DIFF(PARSE_DATE('%Y%m%d', `event_date`), DATE(TIMESTAMP_MICROS(user_first_touch_timestamp)), DAY) = 0 \n            THEN 1 \n            ELSE 0 \n        END AS is_new_user\n    FROM `firebase-public-project.analytics_153293282.events_*` \n    WHERE event_name = 'session_start'\n    AND PARSE_DATE('%Y%m%d', `event_date`) >= DATE('2018-07-09')\n),\n\nnew_user_list AS (\n    SELECT DISTINCT \n        user_pseudo_id,\n        event_date\n    FROM date_table\n    WHERE is_new_user = 1\n),\n\ndays_since_start_table AS (\n    SELECT DISTINCT \n        is_new_user,\n        nu.event_date AS date_cohort,\n        dt.user_pseudo_id,\n        dt.event_date,\n        DATE_DIFF(dt.event_date, nu.event_date, DAY) AS days_since_start\n    FROM date_table dt\n    JOIN new_user_list nu ON dt.user_pseudo_id = nu.user_pseudo_id\n),\n\nweeks_retention AS (\n    SELECT \n        date_cohort,\n        DATE_TRUNC(date_cohort, WEEK(MONDAY)) AS week_cohort,\n        user_pseudo_id,\n        days_since_start,\n        CASE \n            WHEN days_since_start = 0 THEN 0 \n            ELSE CEIL(days_since_start / 7) \n        END AS weeks_since_start\n    FROM days_since_start_table\n),\n\nretention_counts AS (\n    SELECT \n        week_cohort,\n        weeks_since_start,\n        COUNT(DISTINCT user_pseudo_id) AS retained_users\n    FROM weeks_retention\n    WHERE week_cohort >= DATE('2018-07-02') AND week_cohort <= (SELECT min_date FROM dates) \n    GROUP BY \n        week_cohort,\n        weeks_since_start\n)\n\nSELECT \n    initial.week_cohort,\n    IFNULL(four_week.retained_users / initial.retained_users, 0) AS retention_rate\nFROM \n    retention_counts AS initial\nLEFT JOIN \n    retention_counts AS four_week ON initial.week_cohort = four_week.week_cohort AND four_week.weeks_since_start = 2\nWHERE \n    initial.weeks_since_start = 0\nORDER BY\nweek_cohort",
        "error_info": null
    },
    {
        "instance_id": "bq027",
        "score": 1,
        "pred_sql": "WITH patents_sample AS (               -- name of our table\nSELECT \n  t1.publication_number, \n  t1.application_number \nFROM \n  `patents-public-data.patents.publications` t1 \nWHERE \n  country_code = 'US'                                                        -- only consider US patents\n  AND grant_date between 20180101 AND 20180107                               -- grant dates between 2002 and 2006\n  AND grant_date != 0                                                        -- only consider granted patents\n  AND publication_number LIKE '%B2%'                                         -- only consider patents with kind code B2\n)\n\nSELECT\n  t1.publication_number,\n  -- count disctinct application numbers cited by our focal patent\n  COUNT(DISTINCT t3.application_number) AS backward_citations\nFROM\n  patents_sample t1\nLEFT OUTER JOIN (\n  SELECT\n    -- the publication number in the joined table is the citing publication number\n    x2.publication_number AS citing_publication_number,\n    -- the publication number in the unnested citation record is the cited publication number\n    citation_u.publication_number AS cited_publication_number,\n    -- the category in the unnested citation record is the category of the cited publication\n    citation_u.category AS cited_publication_category\n  FROM\n    `patents-public-data.patents.publications` x2,\n    UNNEST(citation) AS citation_u ) t2\nON\n  t2.citing_publication_number = t1.publication_number\n  -- citation category has to contain 'SEA'\n  AND CONTAINS_SUBSTR(t2.cited_publication_category, 'SEA')\n  -- one more join to publications table to get the application number\nLEFT OUTER JOIN\n  `patents-public-data.patents.publications` t3\nON\n  t2.cited_publication_number = t3.publication_number\nGROUP BY\n  t1.publication_number\nORDER BY\n  t1.publication_number",
        "error_info": null
    },
    {
        "instance_id": "bq172",
        "score": 1,
        "pred_sql": "WITH ny_top_drug AS (\n  SELECT\n    generic_name AS drug_name,\n    ROUND(SUM(total_claim_count)) AS total_claim_count\n  FROM\n    `bigquery-public-data.cms_medicare.part_d_prescriber_2014`\n  WHERE\n    nppes_provider_state = 'NY'\n  GROUP BY\n    drug_name\n  ORDER BY\n    total_claim_count DESC\n  LIMIT 1\n),\ntop_5_states AS (\n  SELECT\n    nppes_provider_state AS state,\n    ROUND(SUM(total_claim_count)) AS total_claim_count,\n    ROUND(SUM(total_drug_cost)) AS total_drug_cost\n  FROM\n    `bigquery-public-data.cms_medicare.part_d_prescriber_2014`\n  WHERE\n    generic_name = (SELECT drug_name FROM ny_top_drug)\n  GROUP BY\n    state\n  ORDER BY\n    total_claim_count DESC\n  LIMIT 5\n)\nSELECT\n  state,\n  total_claim_count,\n  total_drug_cost\nFROM\n  top_5_states;",
        "error_info": null
    },
    {
        "instance_id": "bq213_1",
        "score": 1,
        "pred_sql": "WITH interim_table as(\nSELECT \n    t1.publication_number, \n    SUBSTR(ipc_u.code, 0, 4) as ipc4, \n    COUNT(\n    SUBSTR(ipc_u.code, 0, 4)\n    ) as ipc4_count \nFROM \n    `patents-public-data.patents.publications` t1, \n    UNNEST(ipc) AS ipc_u \nWHERE\ncountry_code = 'US'  \nAND grant_date between 20150401 AND 20150430\n  AND grant_date != 0\n  AND publication_number LIKE '%B2%'  \nGROUP BY \n    t1.publication_number, \n    ipc4\n) \nSELECT \npublication_number, ipc4\nFROM \ninterim_table \nwhere \nconcat(\n    interim_table.publication_number, \n    interim_table.ipc4_count\n) IN (\n    SELECT \n    concat(\n        publication_number, \n        MAX(ipc4_count)\n    ) \n    FROM \n    interim_table \n    group by \n    publication_number\n)\nAND ipc4_count >= 20",
        "error_info": null
    },
    {
        "instance_id": "bq251",
        "score": 1,
        "pred_sql": "WITH PyPiData AS (\n    SELECT\n        name AS pypi_name,\n        version AS pypi_version,\n        home_page,\n        download_url,\n        project_urls,\n        requires,\n        upload_time\n    FROM\n        `spider2-public-data.pypi.distribution_metadata`\n),\n\nGitHubURLs AS (\n    SELECT\n        pypi_name,\n        pypi_version,\n        REGEXP_REPLACE(REGEXP_EXTRACT(url, r'(https?://github\\.com/[^/]+/[^/?#]+)'), r'(/issues.*)|(blob/.*)|(/pull/.*)|(tree/.*)', '') AS github_url,\n        upload_time\n    FROM\n        PyPiData,\n        UNNEST(project_urls) AS url\n    WHERE\n        url LIKE '%github.com%'\n        AND (url LIKE '%https://github.com/%' OR url LIKE '%http://github.com/%')\n),\n\nMostRecentVersions AS (\n    SELECT\n        pypi_name,\n        pypi_version,\n        github_url\n    FROM (\n        SELECT *,\n               ROW_NUMBER() OVER (PARTITION BY pypi_name ORDER BY upload_time DESC) AS rn\n        FROM GitHubURLs\n    )\n    WHERE rn = 1\n),\n\nDownloadMetrics AS (\n    SELECT\n        project,\n        COUNT(*) AS pypi_downloads\n    FROM\n        `spider2-public-data.pypi.file_downloads`\n    GROUP BY\n        project\n)\n\nSELECT\n    mv.github_url\nFROM\n    MostRecentVersions mv\nLEFT JOIN\n    DownloadMetrics dm ON mv.pypi_name = dm.project\nWHERE\n    mv.github_url IS NOT NULL \n    AND dm.pypi_downloads IS NOT NULL\nORDER BY dm.pypi_downloads DESC\nLIMIT 1;\n",
        "error_info": null
    },
    {
        "instance_id": "bq278",
        "score": 1,
        "pred_sql": "SELECT\n  #name of state\n  state_name,\n  \n  #number of buildings in Google Map suitable for solar\n  SUM(count_qualified) Google_Maps_Buildings_Avail_for_Solar,\n  \n  #percent of buildings in Google Maps covered by Project Sunroof\n  ROUND(CAST(AVG(percent_covered) AS numeric), 1) Percent_GMap_Covered_by_Proj_Sunroof,\n  \n  #percent of buildings covered by Project Sunroof that are suitable for solar\n  ROUND(CAST(AVG(percent_qualified)AS numeric), 1) Percent_Covered_that_Suitable_for_Solar,\n  \n  #total number of available buildings for solar\n  ROUND(SUM(count_qualified) * (ROUND(CAST(AVG(percent_covered)AS numeric), 1)/100) * (ROUND(CAST(AVG(percent_qualified)AS numeric), 1)/100), 0) Available_Buildings,\n  \n  #number of solar panels potential for all roof space in the region, assuming 1.650m .992m panels\n  SUM(number_of_panels_total) Total_Panels_Potential,\n  \n  #number of kW of solar potential for all roof types in region (assuming 250 watts per panel)\n  SUM(kw_total) Kw_total_all_panel_250w,\n  \n  #total solar energy generation potential for all roof space in region\n  SUM(yearly_sunlight_kwh_total) Total_Energy_Potential,\n  \n  #potential carbon dioxide abatement (The calculation uses eGRID subregion CO2 equivalent non-baseload output emission rates. https://www.epa.gov/sites/production/files/2015 10/documents/egrid2012_summarytables_0.pdf)\n  ROUND(CAST(SUM(carbon_offset_metric_tons)AS numeric),0) Carbon_Offset,\n  \n  #number of existing buildings with solar installation\n  SUM(existing_installs_count) Current_Buildings_with_Solar_Panel,\n  \n  #number of buildings without solar that potential for solar install\n  ROUND(SUM(count_qualified) * (ROUND(CAST(AVG(percent_covered)AS numeric), 1)/100) * (ROUND(CAST(AVG(percent_qualified)AS numeric), 1)/100), 0) - SUM(existing_installs_count) Building_Gap\nFROM\n  `bigquery-public-data.sunroof_solar.solar_potential_by_postal_code` sp\nGROUP BY\n  sp.state_name\nORDER BY\n  SUM(sp.count_qualified) DESC\nLIMIT 1;",
        "error_info": null
    },
    {
        "instance_id": "bq326",
        "score": 1,
        "pred_sql": "--Transposing data in the yearly columns to rows in a new table. \nWITH base AS (\n    SELECT country,\n    country_code,\n    unpivotted\n    FROM `bigquery-public-data.world_bank_global_population.population_by_country` a\n    \n  , UNNEST(fhoffa.x.unpivot(a, 'year')) unpivotted\n),\n\npop AS (SELECT country, \n country_code, \n--unpivot the returned data in the first CTE\n CAST (RIGHT(unpivotted.key,4) AS INT64) AS as_of_year,\n CASE WHEN unpivotted.value = 'null' THEN '0' ELSE unpivotted.value END AS population \nFROM base \n--selecting years from 2010 and beyond\nWHERE CAST (RIGHT(unpivotted.key,4) AS INT64)  >= 2010 ), \n----New CTE to change population data type\npop_1 AS ( \n  SELECT \n   country,\n   country_code,\n   as_of_year,\n  CAST (population as FLOAT64) AS population,\n--using lag function to calculate previous population by country_code\n  COALESCE (LAG (CAST (population AS FLOAT64), 1)\n  OVER (PARTITION BY country_code ORDER BY as_of_year), 0) AS prev_population \n  from pop ), \n--New CTE to calculate change in population and filter for year 2018 \nNumber1 as (\n  SELECT *, \n--used Coalesce to get rid of null. from division\n--Used Nullif to handle error by diving by zero.\n  COALESCE (ROUND ( population /NULLIF(prev_population,0), 2 ), 0) AS change_in_population  \n  FROM pop_1\n--filter for 2018\nwhere pop_1.as_of_year = 2018),\n--New CTE to return required columns and filter for PPP(SH.XPD.CHEX.PP.CD RETURNS PPP)\nA AS (\n SELECT\n  country_name,\n  country_code,\n  indicator_name,\n  value as PPP,\n  year,\n--using lag function to calculate previous PPP by country_code ordered by year\n LAG(value) over (partition by country_code order by year) as prePPP\n FROM `bigquery-public-data.world_bank_health_population.health_nutrition_population`\n-- filter for SH.XPD.CHEX.PP.CD\n WHERE\n  indicator_code = \"SH.XPD.CHEX.PP.CD\"),\n--CTE to calculate chane in population\nB AS (\n  SELECT\n   *,\n--used Coalesce to get rid of null. from division\n--Used Nullif to handle error by diving by zero. \n  COALESCE (ROUND ( A.PPP /NULLIF(prePPP,0), 2 ), 0) AS change_in_PPP\n  FROM A \n--filter for 2018\n  WHERE year = 2018)\n--join change in population table and change in PPP into one table based on the country code\nSELECT \n COUNT(country) AS country_count\nFROM Number1\n left join B\n  ON Number1.country_code = B.country_code\nWHERE\n B.change_in_PPP > 1 AND Number1.change_in_population > 1;",
        "error_info": null
    },
    {
        "instance_id": "bq190",
        "score": 1,
        "pred_sql": "WITH \nfemale_age AS (\n  SELECT \n    MIN(age) AS min_age, \n    MAX(age) AS max_age\n  FROM \n    `bigquery-public-data.thelook_ecommerce.users`\n  WHERE \n    gender = 'F' \n    AND created_at BETWEEN '2019-01-01 00:00:00' AND '2022-05-01 00:00:00'\n),\nmale_age AS (\n  SELECT \n    MIN(age) AS min_age, \n    MAX(age) AS max_age\n  FROM \n    `bigquery-public-data.thelook_ecommerce.users`\n  WHERE \n    gender = 'M' \n    AND created_at BETWEEN '2019-01-01 00:00:00' AND '2022-05-01 00:00:00'\n),\nyoung_old_group AS (\n  SELECT t1.first_name, t1.last_name, t1.gender, t1.age\n  FROM `bigquery-public-data.thelook_ecommerce.users` AS t1\n  JOIN female_age AS t2 ON t1.age = t2.min_age OR t1.age = t2.max_age\n  WHERE t1.gender = 'F' AND t1.created_at BETWEEN '2019-01-01 00:00:00' AND '2022-05-01 00:00:00'\n  UNION ALL\n  SELECT t3.first_name, t3.last_name, t3.gender, t3.age\n  FROM `bigquery-public-data.thelook_ecommerce.users` AS t3\n  JOIN male_age AS t4 ON t3.age = t4.min_age OR t3.age = t4.max_age\n  WHERE t3.gender = 'M' AND t3.created_at BETWEEN '2019-01-01 00:00:00' AND '2022-05-01 00:00:00'\n),\nage_tag AS (\n  SELECT *, \n    CASE \n      WHEN age IN (SELECT MIN(age) \n                   FROM `bigquery-public-data.thelook_ecommerce.users`\n                   WHERE gender = 'F' AND created_at BETWEEN '2019-01-01 00:00:00' AND '2022-05-01 00:00:00') \n           OR age IN (SELECT MIN(age) \n                      FROM `bigquery-public-data.thelook_ecommerce.users`\n                      WHERE gender = 'M' AND created_at BETWEEN '2019-01-01 00:00:00' AND '2022-05-01 00:00:00') \n           THEN 'Youngest'\n      ELSE 'Oldest'\n    END AS tag\n  FROM young_old_group \n),\ncount_summary AS (\n  SELECT \n    gender, \n    tag, \n    COUNT(*) AS user_count\n  FROM \n    age_tag\n  GROUP BY \n    gender, tag\n)\nSELECT \n  gender, \n  tag, \n  user_count\nFROM \n  count_summary\nORDER BY \n  gender, tag;",
        "error_info": null
    },
    {
        "instance_id": "bq019_1",
        "score": 1,
        "pred_sql": "SELECT\n  A.state,\n  drug_name,\n  -- total_claim_count,\n  -- day_supply,\n  -- ROUND(total_cost_millions) AS total_cost_millions\nFROM (\n  SELECT\n    generic_name AS drug_name,\n    nppes_provider_state AS state,\n    ROUND(SUM(total_claim_count)) AS total_claim_count,\n    ROUND(SUM(total_day_supply)) AS day_supply,\n    ROUND(SUM(total_drug_cost)) / 1e6 AS total_cost_millions\n  FROM\n    `bigquery-public-data.cms_medicare.part_d_prescriber_2014`\n  GROUP BY\n    state,\n    drug_name) A\nINNER JOIN (\n  SELECT\n    state,\n    MAX(total_claim_count) AS max_total_claim_count\n  FROM (\n    SELECT\n      nppes_provider_state AS state,\n      ROUND(SUM(total_claim_count)) AS total_claim_count\n    FROM\n      `bigquery-public-data.cms_medicare.part_d_prescriber_2014`\n    GROUP BY\n      state,\n      generic_name)\n  GROUP BY\n    state) B\nON\n  A.state = B.state\n  AND A.total_claim_count = B.max_total_claim_count;\n-- ORDER BY\n--   A.total_claim_count DESC;",
        "error_info": null
    },
    {
        "instance_id": "bq011",
        "score": 1,
        "pred_sql": "SELECT\n  COUNT(DISTINCT MDaysUsers.user_pseudo_id) AS n_day_inactive_users_count\nFROM\n  (\n    SELECT\n      user_pseudo_id\n    FROM\n      `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*` AS T\n    CROSS JOIN\n      UNNEST(T.event_params) AS event_params\n    WHERE\n      event_params.key = 'engagement_time_msec' AND event_params.value.int_value > 0\n      /* Has engaged in last M = 7 days */\n      AND event_timestamp > UNIX_MICROS(TIMESTAMP_SUB(TIMESTAMP('2021-01-07 23:59:59'), INTERVAL 7 DAY))\n      /* Include only relevant tables based on the fixed timestamp */\n      AND _TABLE_SUFFIX BETWEEN '20210101' AND '20210107'\n  ) AS MDaysUsers\nLEFT JOIN\n  (\n    SELECT\n      user_pseudo_id\n    FROM\n      `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*` AS T\n    CROSS JOIN\n      UNNEST(T.event_params) AS event_params\n    WHERE\n      event_params.key = 'engagement_time_msec' AND event_params.value.int_value > 0\n      /* Has engaged in last N = 2 days */\n      AND event_timestamp > UNIX_MICROS(TIMESTAMP_SUB(TIMESTAMP('2021-01-07 23:59:59'), INTERVAL 2 DAY))\n      /* Include only relevant tables based on the fixed timestamp */\n      AND _TABLE_SUFFIX BETWEEN '20210105' AND '20210107'\n  ) AS NDaysUsers\nON MDaysUsers.user_pseudo_id = NDaysUsers.user_pseudo_id\nWHERE\n  NDaysUsers.user_pseudo_id IS NULL;",
        "error_info": null
    },
    {
        "instance_id": "bq022",
        "score": 0,
        "pred_sql": "SELECT\n  FORMAT('%02.0fm to %02.0fm', min_minutes, max_minutes) AS minutes_range,\n  SUM(trips) AS total_trips,\n  FORMAT('%3.2f', SUM(total_fare) / SUM(trips)) AS average_fare\nFROM (\n  SELECT\n    MIN(duration_in_minutes) OVER (quantiles) AS min_minutes,\n    MAX(duration_in_minutes) OVER (quantiles) AS max_minutes,\n    SUM(trips) AS trips,\n    SUM(total_fare) AS total_fare\n  FROM (\n    SELECT\n      ROUND(trip_seconds / 60) AS duration_in_minutes,\n      NTILE(6) OVER (ORDER BY trip_seconds / 60) AS quantile,\n      COUNT(1) AS trips,\n      SUM(fare) AS total_fare\n    FROM\n      `bigquery-public-data.chicago_taxi_trips.taxi_trips`\n    WHERE\n      trip_seconds BETWEEN 0 AND 3600\n    GROUP BY\n      trip_seconds,\n      duration_in_minutes )\n  GROUP BY\n    duration_in_minutes,\n    quantile\n  WINDOW quantiles AS (PARTITION BY quantile)\n  )\nGROUP BY\n  minutes_range\nORDER BY\n  minutes_range\n",
        "error_info": "Result Error"
    },
    {
        "instance_id": "bq056",
        "score": 1,
        "pred_sql": "DECLARE var_State            STRING DEFAULT 'MN';\nDECLARE var_RoadType        STRING DEFAULT 'motorway';\n\nwith t_state_geo as (\n    select State\n         , state_geom as StateGeography\n      from `bigquery-public-data.geo_us_boundaries.states`\n     where LOWER(State) = LOWER(var_State)\n)\n, t_roads as (\n    select distinct Id as WayId\n      from `bigquery-public-data.geo_openstreetmap.planet_ways` pw, pw.all_tags as tag\n     where LOWER(tag.Key) = 'highway'\n       and LOWER(tag.Value) = var_RoadType\n)\n, t_state_ways as (\n    select pw.Id       as WayId\n         , pw.geometry as WayGeography\n         , pw.Nodes    as WayNodes\n      from `bigquery-public-data.geo_openstreetmap.planet_ways` pw\n      join t_state_geo ts\n        on ST_CONTAINS(ts.StateGeography, pw.geometry)\n      join t_roads tr\n        on pw.Id = tr.WayId\n)\n, t_touching_ways as (\n    select    LEAST(t1.WayId, t2.WayId) as WayId\n         , GREATEST(t1.WayId, t2.WayId) as TouchingWayId\n         , t1.WayNodes, t2.WayNodes as TouchingWayNodes\n      from t_state_ways t1\n      join t_state_ways t2\n        on ST_INTERSECTS(t1.WayGeography, t2.WayGeography)\n     where not t1.WayId = t2.WayId\n)\n, t_sharing_nodes as (\n    select distinct WayId, TouchingWayId\n      from t_touching_ways t, t.WayNodes as WayNode\n     where WayNode in UNNEST(TouchingWayNodes)\n)\n, t_overlapping_ways as (\n    select distinct WayId, TouchingWayId\n      from t_touching_ways tt\n      left join t_sharing_nodes ts\n     using (WayId, TouchingWayId)\n     where ts.WayId is NULL\n)\n, t_with_metadata as (\n    select WayId, TouchingWayId\n         , pw1.all_tags as WayTags\n         , pw2.all_tags as TouchingWayTags\n         , pw1.geometry as WayGeography\n         , pw2.geometry as TouchingWayGeography\n      from t_overlapping_ways tw\n      join `bigquery-public-data.geo_openstreetmap.planet_ways` pw1\n        on tw.WayId = pw1.Id\n      join `bigquery-public-data.geo_openstreetmap.planet_ways` pw2\n        on tw.TouchingWayId = pw2.Id\n)\n, t_has_bridge_tag as (\n    select distinct WayId, TouchingWayId\n      from t_with_metadata t, t.WayTags as WayTag, t.TouchingWayTags as TouchingWayTag\n     where (LOWER(TouchingWayTag.key) = 'bridge' and LOWER(TouchingWayTag.value) = 'yes')\n        or (LOWER(WayTag.key) = 'bridge' and LOWER(WayTag.value) = 'yes')\n)\n, filtered_results as (\n    select WayId, TouchingWayId\n    from t_with_metadata tm\n    left join t_has_bridge_tag tb\n    using (WayId, TouchingWayId)\n    where tb.WayId is NULL\n)\nSELECT COUNT(*) AS num_overlapping_ways\nFROM filtered_results;",
        "error_info": null
    },
    {
        "instance_id": "ga017",
        "score": 1,
        "pred_sql": "WITH unnested_events AS (\n  SELECT\n    MAX(CASE WHEN event_params.key = 'page_title' THEN event_params.value.string_value END) AS page_title,\n    user_pseudo_id,\n    event_timestamp\n  FROM\n    `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*`,\n    UNNEST(event_params) AS event_params\n  WHERE\n    _TABLE_SUFFIX BETWEEN '20210101' AND '20210131'\n    AND event_name = 'page_view'\n  GROUP BY user_pseudo_id,event_timestamp\n),\ntemp AS (\n    SELECT\n    page_title,\n    COUNT(*) AS event_count,\n    COUNT(DISTINCT user_pseudo_id) AS users\n    FROM\n    unnested_events\n    GROUP BY page_title\n    ORDER BY event_count DESC\n)\n\nSELECT users \nFROM\ntemp\nLIMIT 1",
        "error_info": null
    },
    {
        "instance_id": "bq223",
        "score": 1,
        "pred_sql": "SELECT\n    citing_assignee,\n    cpcdef.titleFull as cpc_title\nFROM (\n    SELECT\n        pubs.publication_number AS citing_publication_number,\n        cite.publication_number AS cited_publication_number,\n        citing_assignee_s.name AS citing_assignee,\n        SUBSTR(cpcs.code, 0, 4) AS citing_cpc_subclass\n    FROM \n        `patents-public-data.patents.publications` AS pubs,\n        UNNEST(citation) AS cite,\n        UNNEST(assignee_harmonized) AS citing_assignee_s,\n        UNNEST(cpc) AS cpcs\n    WHERE\n        cpcs.first = TRUE\n    ) AS pubs\n    JOIN (\n        SELECT\n            publication_number AS cited_publication_number,\n            cited_assignee_s.name AS cited_assignee\n        FROM\n            `patents-public-data.patents.publications`,\n            UNNEST(assignee_harmonized) AS cited_assignee_s\n    ) AS refs\n    ON\n        pubs.cited_publication_number = refs.cited_publication_number\n    JOIN\n        `patents-public-data.cpc.definition` AS cpcdef\n    ON cpcdef.symbol = citing_cpc_subclass\nWHERE\n    cited_assignee = \"AAAA\"\n    AND citing_assignee != \"AAAA\"\nGROUP BY\n    citing_assignee, cpcdef.titleFull\nORDER BY \n    COUNT(*)\nDESC LIMIT 1",
        "error_info": null
    },
    {
        "instance_id": "bq019_2",
        "score": 1,
        "pred_sql": "SELECT\n  Provider_Name\nFROM\n(\nSELECT\n  OP.provider_state AS State,\n  OP.provider_city AS City,\n  OP.provider_id AS Provider_ID,\n  OP.provider_name AS Provider_Name,\n  ROUND(OP.average_OP_cost) AS Average_OP_Cost,\n  ROUND(IP.average_IP_cost) AS Average_IP_Cost,\n  ROUND(OP.average_OP_cost + IP.average_IP_cost) AS Combined_Average_Cost\nFROM (\n  SELECT\n    provider_state,\n    provider_city,\n    provider_id,\n    provider_name,\n    SUM(average_total_payments*outpatient_services)/SUM(outpatient_services) AS average_OP_cost\n  FROM\n    `bigquery-public-data.cms_medicare.outpatient_charges_2014`\n  GROUP BY\n    provider_state,\n    provider_city,\n    provider_id,\n    provider_name ) AS OP\nINNER JOIN (\n  SELECT\n    provider_state,\n    provider_city,\n    provider_id,\n    provider_name,\n    SUM(average_medicare_payments*total_discharges)/SUM(total_discharges) AS average_IP_cost\n  FROM\n    `bigquery-public-data.cms_medicare.inpatient_charges_2014`\n  GROUP BY\n    provider_state,\n    provider_city,\n    provider_id,\n    provider_name ) AS IP\nON\n  OP.provider_id = IP.provider_id\n  AND OP.provider_state = IP.provider_state\n  AND OP.provider_city = IP.provider_city\n  AND OP.provider_name = IP.provider_name\nORDER BY\n  combined_average_cost DESC\nLIMIT\n  1\n);",
        "error_info": null
    },
    {
        "instance_id": "bq189",
        "score": 1,
        "pred_sql": "WITH \nmonthly_summary AS (\n  SELECT \n    FORMAT_DATE('%m', oi.delivered_at) AS Month,\n    FORMAT_DATE('%Y', oi.delivered_at) AS Year,\n    p.category AS Product_category,\n    SUM(oi.sale_price) AS TPV,\n    COUNT(DISTINCT oi.order_id) AS TPO\n  FROM \n    `bigquery-public-data.thelook_ecommerce.order_items` oi\n  JOIN \n    `bigquery-public-data.thelook_ecommerce.products` p ON oi.product_id = p.id\n  JOIN \n    `bigquery-public-data.thelook_ecommerce.orders` o ON oi.order_id = o.order_id\n  WHERE\n    oi.status = 'Complete'\n  GROUP BY\n    Month, Year, Product_category\n  ORDER BY \n    Year, Month\n),\n\nlagged_summary AS (\n  SELECT \n    month,\n    year,\n    Product_category,\n    TPV,\n    TPO,\n    LAG(TPV) OVER(PARTITION BY Product_category ORDER BY year, month) AS Lagged_TPV,\n    LAG(TPO) OVER(PARTITION BY Product_category ORDER BY year, month) AS Lagged_TPO\n  FROM \n    monthly_summary\n),\n\ngrowth_summary AS (\n  SELECT \n    month,\n    year,\n    Product_category,\n    TPV,\n    TPO,\n    Lagged_TPV,\n    Lagged_TPO,\n    ROUND((TPV - Lagged_TPV) / NULLIF(Lagged_TPV, 0) * 100, 2) AS Revenue_growth,\n    ROUND((TPO - Lagged_TPO) / NULLIF(Lagged_TPO, 0) * 100, 2) AS Order_growth\n  FROM \n    lagged_summary\n),\n\nmax_order_growth AS (\n  SELECT \n    Product_category,\n    AVG(Order_growth) AS avg_order_growth\n  FROM \n    growth_summary\n  GROUP BY \n    Product_category\n  ORDER BY \n    avg_order_growth DESC\n  LIMIT 1\n)\n\nSELECT \n  AVG(gs.Revenue_growth) AS average_revenue_growth\nFROM \n  growth_summary gs\nJOIN \n  max_order_growth mog ON gs.Product_category = mog.Product_category;",
        "error_info": null
    },
    {
        "instance_id": "bq225",
        "score": 1,
        "pred_sql": "WITH languages AS (\n  SELECT\n    files.id,\n    CASE REGEXP_EXTRACT(files.path, r'(\\.?[^\\/\\.]*)$')\n      WHEN '.js'          THEN 'JavaScript'\n      WHEN '.cjs'         THEN 'JavaScript'\n      WHEN '.ts'          THEN 'TypeScript'\n      WHEN '.java'        THEN 'Java'\n      WHEN '.py'          THEN 'Python'\n      WHEN '.kt'          THEN 'Kotlin'\n      WHEN '.ktm'         THEN 'Kotlin'\n      WHEN '.kts'         THEN 'Kotlin'\n      WHEN '.c'           THEN 'C'\n      WHEN '.h'           THEN 'C'\n      WHEN '.c++'         THEN 'C++'\n      WHEN '.cpp'         THEN 'C++'\n      WHEN '.h++'         THEN 'C++'\n      WHEN '.hpp'         THEN 'C++'\n      WHEN '.cs'          THEN 'C#'\n      WHEN '.erl'         THEN 'Erlang'\n      WHEN '.ex'          THEN 'Elixir'\n      WHEN '.exs'         THEN 'Elixir'\n      WHEN '.hs'          THEN 'Haskell'\n      WHEN '.go'          THEN 'Go'\n      WHEN '.php'         THEN 'PHP'\n      WHEN '.rb'          THEN 'Ruby'\n      WHEN '.rs'          THEN 'Rust'\n      WHEN '.scala'       THEN 'Scala'\n      WHEN '.swift'       THEN 'Swift'\n      WHEN '.lisp'        THEN 'Common Lisp'\n      WHEN '.clj'         THEN 'Clojure'\n      WHEN '.r'           THEN 'R'\n      WHEN '.matlab'      THEN 'MATLAB'\n      WHEN '.m'           THEN 'MATLAB'\n      WHEN '.asm'         THEN 'Assembly'\n      WHEN '.nasm'        THEN 'Assembly'\n      WHEN '.d'           THEN 'D'\n      WHEN '.dart'        THEN 'Dart'\n      WHEN '.jl'          THEN 'Julia'\n      WHEN '.groovy'      THEN 'Groovy'\n      WHEN '.hx'          THEN 'Haxe'\n      WHEN '.lua'         THEN 'Lua'\n      WHEN '.sh'          THEN 'Shell'\n      WHEN '.bash'        THEN 'Shell'\n      WHEN '.ps1'         THEN 'PowerShell'\n      WHEN '.psd1'        THEN 'PowerShell'\n      WHEN '.psm1'        THEN 'PowerShell'\n      WHEN '.sql'         THEN 'SQL'\n      WHEN 'Dockerfile'   THEN 'Dockerfile'\n      WHEN '.dockerfile'  THEN 'Dockerfile'\n      WHEN '.md'          THEN 'Markdown'\n      WHEN '.markdown'    THEN 'Markdown'\n      WHEN '.mdown'       THEN 'Markdown'\n      WHEN '.html'        THEN 'HTML'\n      WHEN '.htm'         THEN 'HTML'\n      WHEN '.css'         THEN 'CSS'\n      WHEN '.sass'        THEN 'Sass'\n      WHEN '.scss'        THEN 'SCSS'\n      WHEN '.vue'         THEN 'Vue'\n      WHEN '.json'        THEN 'JSON'\n      WHEN '.yml'         THEN 'YAML'\n      WHEN '.yaml'        THEN 'YAML'\n      WHEN '.xml'         THEN 'XML'\n    END AS language\n  FROM\n    `bigquery-public-data.github_repos.sample_files` AS files\n)\n\nSELECT\n  languages.language\nFROM\n  languages\nINNER JOIN\n  `bigquery-public-data.github_repos.sample_contents` AS contents\nON\n  contents.id = languages.id\nWHERE\n  languages.language IS NOT NULL\n  AND contents.content IS NOT NULL\nGROUP BY languages.language\nORDER BY COUNT(*) DESC\nLIMIT 3;",
        "error_info": null
    },
    {
        "instance_id": "ga018",
        "score": 1,
        "pred_sql": "-- pulling user page views from GA4 events\nWITH base_table AS (\n-- pulls relevant columns from relevant dates to decrease the size of data scanned\n  SELECT\n    event_name,\n    event_date,\n    event_timestamp,\n    user_pseudo_id,\n    user_id,\n    device,\n    geo,\n    traffic_source,\n    event_params,\n    user_properties\n  FROM\n    `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*`\n  WHERE\n    _table_suffix = '20210102'\n  AND event_name IN ('page_view')\n)\n, unnested_events AS (\n-- unnests event parameters to get to relevant keys and values\n  SELECT\n    event_date AS date,\n    event_timestamp AS event_timestamp_microseconds,\n    user_pseudo_id,\n    MAX(CASE WHEN c.key = 'ga_session_id' THEN c.value.int_value END) AS visitID,\n    MAX(CASE WHEN c.key = 'ga_session_number' THEN c.value.int_value END) AS visitNumber,\n    MAX(CASE WHEN c.key = 'page_title' THEN c.value.string_value END) AS page_title,\n    MAX(CASE WHEN c.key = 'page_location' THEN c.value.string_value END) AS page_location\n  FROM \n    base_table,\n    UNNEST (event_params) c\n  GROUP BY 1,2,3\n)\n\n, unnested_events_categorised AS (\n-- categorizing Page Titles into PDPs and PLPs\n  SELECT\n  *,\n  CASE WHEN ARRAY_LENGTH(SPLIT(page_location, '/')) >= 5 \n            AND\n            CONTAINS_SUBSTR(ARRAY_REVERSE(SPLIT(page_location, '/'))[SAFE_OFFSET(0)], '+')\n            AND (LOWER(SPLIT(page_location, '/')[SAFE_OFFSET(4)]) IN \n                                        ('accessories','apparel','brands','campus+collection','drinkware',\n                                          'electronics','google+redesign',\n                                          'lifestyle','nest','new+2015+logo','notebooks+journals',\n                                          'office','shop+by+brand','small+goods','stationery','wearables'\n                                          )\n                  OR\n                  LOWER(SPLIT(page_location, '/')[SAFE_OFFSET(3)]) IN \n                                        ('accessories','apparel','brands','campus+collection','drinkware',\n                                          'electronics','google+redesign',\n                                          'lifestyle','nest','new+2015+logo','notebooks+journals',\n                                          'office','shop+by+brand','small+goods','stationery','wearables'\n                                          )\n            )\n            THEN 'PDP'\n            WHEN NOT(CONTAINS_SUBSTR(ARRAY_REVERSE(SPLIT(page_location, '/'))[SAFE_OFFSET(0)], '+'))\n            AND (LOWER(SPLIT(page_location, '/')[SAFE_OFFSET(4)]) IN \n                                        ('accessories','apparel','brands','campus+collection','drinkware',\n                                          'electronics','google+redesign',\n                                          'lifestyle','nest','new+2015+logo','notebooks+journals',\n                                          'office','shop+by+brand','small+goods','stationery','wearables'\n                                          )\n                  OR \n                  LOWER(SPLIT(page_location, '/')[SAFE_OFFSET(3)]) IN \n                                          ('accessories','apparel','brands','campus+collection','drinkware',\n                                            'electronics','google+redesign',\n                                            'lifestyle','nest','new+2015+logo','notebooks+journals',\n                                            'office','shop+by+brand','small+goods','stationery','wearables'\n                                            )\n            )\n            THEN 'PLP'\n        ELSE page_title\n        END AS page_title_adjusted \n\n  FROM \n    unnested_events\n)\n\n\n, ranked_screens AS (\n  SELECT\n    *,\n    LAG(page_title_adjusted,1) OVER (PARTITION BY  user_pseudo_id, visitID ORDER BY event_timestamp_microseconds ASC) previous_page,\n    LEAD(page_title_adjusted,1) OVER (PARTITION BY  user_pseudo_id, visitID ORDER BY event_timestamp_microseconds ASC)  next_page\n  FROM \n    unnested_events_categorised\n\n)\n\n,PLPtoPDPTransitions AS (\n  SELECT\n    user_pseudo_id,\n    visitID\n  FROM\n    ranked_screens\n  WHERE\n    page_title_adjusted = 'PLP' AND next_page = 'PDP'\n)\n\n,TotalPLPViews AS (\n  SELECT\n    COUNT(*) AS total_plp_views\n  FROM\n    ranked_screens\n  WHERE\n    page_title_adjusted = 'PLP'\n)\n\n,TotalTransitions AS (\n  SELECT\n    COUNT(*) AS total_transitions\n  FROM\n    PLPtoPDPTransitions\n)\n\nSELECT\n  (total_transitions * 100.0) / total_plp_views AS percentage\nFROM\n  TotalTransitions, TotalPLPViews;",
        "error_info": null
    },
    {
        "instance_id": "bq131",
        "score": 1,
        "pred_sql": "WITH bounding_area AS (\n  SELECT geometry\n  FROM `bigquery-public-data.geo_openstreetmap.planet_features`\n  WHERE feature_type = \"multipolygons\"\n    AND ('wikidata', 'Q62') IN (\n      SELECT (key, value)\n      FROM unnest(all_tags)\n    )\n),\n\nINFO AS (\n  SELECT \n    COUNT(*) AS stops_count,\n    (\n      SELECT value \n      FROM unnest(all_tags) \n      WHERE key = 'network'\n    ) AS bus_network  -- Extract value of \"network\" tag\n  FROM \n    `bigquery-public-data.geo_openstreetmap.planet_features` planet_features,\n    bounding_area\n  WHERE \n    feature_type = 'points'\n    AND ('highway', 'bus_stop') IN (\n      SELECT (key, value)\n      FROM UNNEST(all_tags)\n    ) -- Select bus stops\n    AND ST_DWithin(bounding_area.geometry, planet_features.geometry, 0)  -- Filter only features within bounding_area\n  GROUP BY \n    bus_network\n  ORDER BY \n    stops_count DESC \n)\n\nSELECT stops_count\nFROM INFO\nORDER BY \n  stops_count DESC \nLIMIT 1",
        "error_info": null
    },
    {
        "instance_id": "ga007",
        "score": 1,
        "pred_sql": "WITH base_table AS (\n-- pulls relevant columns from relevant dates to decrease the size of data scanned\n  SELECT\n    event_name,\n    event_date,\n    event_timestamp,\n    user_pseudo_id,\n    user_id,\n    device,\n    geo,\n    traffic_source,\n    event_params,\n    user_properties\n  FROM\n    `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*`\n  WHERE\n    _table_suffix = '20210101'\n  AND event_name IN ('page_view')\n)\n, unnested_events AS (\n-- unnests event parameters to get to relevant keys and values\n  SELECT\n    event_date AS date,\n    event_timestamp AS event_timestamp_microseconds,\n    user_pseudo_id,\n    MAX(CASE WHEN c.key = 'ga_session_id' THEN c.value.int_value END) AS visitID,\n    MAX(CASE WHEN c.key = 'ga_session_number' THEN c.value.int_value END) AS visitNumber,\n    MAX(CASE WHEN c.key = 'page_title' THEN c.value.string_value END) AS page_title,\n    MAX(CASE WHEN c.key = 'page_location' THEN c.value.string_value END) AS page_location\n  FROM \n    base_table,\n    UNNEST (event_params) c\n  GROUP BY 1,2,3\n)\n,unnested_events_categorised AS (\n-- categorizing Page Titles into PDPs and PLPs\n  SELECT\n  *,\n  CASE WHEN ARRAY_LENGTH(SPLIT(page_location, '/')) >= 5 \n            AND\n            CONTAINS_SUBSTR(ARRAY_REVERSE(SPLIT(page_location, '/'))[SAFE_OFFSET(0)], '+')\n            AND (LOWER(SPLIT(page_location, '/')[SAFE_OFFSET(4)]) IN \n                                        ('accessories','apparel','brands','campus+collection','drinkware',\n                                          'electronics','google+redesign',\n                                          'lifestyle','nest','new+2015+logo','notebooks+journals',\n                                          'office','shop+by+brand','small+goods','stationery','wearables'\n                                          )\n                  OR\n                  LOWER(SPLIT(page_location, '/')[SAFE_OFFSET(3)]) IN \n                                        ('accessories','apparel','brands','campus+collection','drinkware',\n                                          'electronics','google+redesign',\n                                          'lifestyle','nest','new+2015+logo','notebooks+journals',\n                                          'office','shop+by+brand','small+goods','stationery','wearables'\n                                          )\n            )\n            THEN 'PDP'\n            WHEN NOT(CONTAINS_SUBSTR(ARRAY_REVERSE(SPLIT(page_location, '/'))[SAFE_OFFSET(0)], '+'))\n            AND (LOWER(SPLIT(page_location, '/')[SAFE_OFFSET(4)]) IN \n                                        ('accessories','apparel','brands','campus+collection','drinkware',\n                                          'electronics','google+redesign',\n                                          'lifestyle','nest','new+2015+logo','notebooks+journals',\n                                          'office','shop+by+brand','small+goods','stationery','wearables'\n                                          )\n                  OR \n                  LOWER(SPLIT(page_location, '/')[SAFE_OFFSET(3)]) IN \n                                          ('accessories','apparel','brands','campus+collection','drinkware',\n                                            'electronics','google+redesign',\n                                            'lifestyle','nest','new+2015+logo','notebooks+journals',\n                                            'office','shop+by+brand','small+goods','stationery','wearables'\n                                            )\n            )\n            THEN 'PLP'\n        ELSE page_title\n        END AS page_title_adjusted \n\n  FROM \n    unnested_events\n)\n\nSELECT (SELECT COUNT(*) FROM unnested_events_categorised WHERE page_title_adjusted='PDP') / (SELECT COUNT(*) FROM unnested_events_categorised);",
        "error_info": null
    },
    {
        "instance_id": "bq248",
        "score": 1,
        "pred_sql": "WITH requests AS (\n    SELECT \n        D.id,\n        D.content,\n        E.repo_name,\n        E.path\n    FROM \n        (\n            SELECT \n                id,\n                content\n            FROM \n                `bigquery-public-data.github_repos.sample_contents`\n            GROUP BY \n                id,\n                content\n        ) AS D\n        INNER JOIN \n        (\n            SELECT \n                C.id,\n                C.repo_name,\n                C.path\n            FROM \n                (\n                    SELECT \n                        id,\n                        repo_name,\n                        path\n                    FROM \n                        `bigquery-public-data.github_repos.sample_files`\n                    WHERE \n                        LOWER(path) LIKE '%requirements.txt'\n                    GROUP BY \n                        path,\n                        id,\n                        repo_name\n                ) AS C\n            INNER JOIN \n                (\n                    SELECT \n                        repo_name,\n                        language_struct.name AS language_name\n                    FROM \n                        `bigquery-public-data.github_repos.languages`,\n                        UNNEST(language) AS language_struct\n                    WHERE \n                        LOWER(language_struct.name) LIKE '%python%'\n                    GROUP BY \n                        language_name,\n                        repo_name\n                ) AS F\n            ON \n                C.repo_name = F.repo_name\n        ) AS E\n    ON \n        D.id = E.id\n)\nSELECT (SELECT COUNT(*) FROM requests WHERE content LIKE '%requests%') / COUNT(*) AS proportion\nFROM requests\n",
        "error_info": null
    },
    {
        "instance_id": "bq246",
        "score": 1,
        "pred_sql": "SELECT filterData.fwrdCitations_3\nFROM\n  `patents-public-data.patentsview.application` as app,\n  (SELECT DISTINCT cpc.patent_id, IFNULL(citation_3.bkwdCitations_3, 0) as bkwdCitations_3, IFNULL(citation_3.fwrdCitations_3, 0) as fwrdCitations_3\n  FROM\n    `patents-public-data.patentsview.cpc_current` AS cpc\n    LEFT JOIN\n    (SELECT  b.patent_id, b.bkwdCitations_3, f.fwrdCitations_3\n      FROM \n        (SELECT \n          cited.patent_id,\n          COUNT(*) as fwrdCitations_3\n          FROM \n          `patents-public-data.patentsview.uspatentcitation` AS cited,\n          `patents-public-data.patentsview.application` AS apps\n        WHERE\n          apps.country = 'US'\n          AND cited.patent_id = apps.patent_id \n          AND cited.date >= apps.date AND SAFE_CAST(cited.date AS DATE) <= DATE_ADD(SAFE_CAST(apps.date AS DATE), INTERVAL 3 YEAR)\n         GROUP BY \n         cited.patent_id) AS f,\n\n       (SELECT \n          cited.patent_id,\n          COUNT(*) as bkwdCitations_3\n          FROM \n          `patents-public-data.patentsview.uspatentcitation` AS cited,\n          `patents-public-data.patentsview.application` AS apps\n        WHERE\n          apps.country = 'US'\n          AND cited.patent_id = apps.patent_id \n          AND cited.date < apps.date AND SAFE_CAST(cited.date AS DATE) >= DATE_SUB(SAFE_CAST(apps.date AS DATE), INTERVAL 3 YEAR)\n         GROUP BY \n         cited.patent_id) AS b\n      WHERE\n      b.patent_id = f.patent_id AND b.bkwdCitations_3 IS NOT NULL AND f.fwrdCitations_3 IS NOT NULL) AS citation_3\n      ON cpc.patent_id = citation_3.patent_id\n      )\n  as filterData\n  WHERE\n  app.patent_id = filterData.patent_id\n  ORDER BY filterData.bkwdCitations_3 DESC\n  LIMIT 1",
        "error_info": null
    },
    {
        "instance_id": "bq208",
        "score": 1,
        "pred_sql": "with my_location as (\n  SELECT  ST_GEOGPOINT(-73.764, 41.197) as my_location,\n          'Chappaqua' as home\n), stations as (\n  SELECT *, ST_GEOGPOINT(lon,lat) as latlon_geo\n  FROM `bigquery-public-data.noaa_gsod.stations` \n), get_closest as (\n  SELECT home,my_location, st.*, \n  FROM (\n    SELECT ST_ASTEXT(my_location) as my_location, \n           home,\n           ARRAY_AGG( # get the closest station\n              STRUCT(usaf,wban,name,lon,lat,country,state,\n                    ST_DISTANCE(my_location, b.latlon_geo)*0.00062137 as miles)\n           ) as stations\n    FROM my_location a, stations b\n    WHERE ST_DWITHIN(my_location, b.latlon_geo, 32187)  --meters = 20 miles\n    GROUP BY my_location, home\n  ), UNNEST(stations) as st\n)  -- Thanks to Felipe Hoffa - https://stackoverflow.com/a/53678307/11748236\n-- get count of data points from closest stations for 2011-2020\nSELECT COUNT(temp) as Data_Points\nFROM get_closest gc, `bigquery-public-data.noaa_gsod.gsod20*` gs\nWHERE max != 9999.9 # code for missing data\nAND   _TABLE_SUFFIX BETWEEN '11' AND '20'\nAND   gc.usaf = gs.stn\nAND   gc.wban = gs.wban\nGROUP BY home, my_location, usaf, gc.wban, name, lon, lat, country, state, miles\nORDER BY miles ASC",
        "error_info": null
    },
    {
        "instance_id": "bq214_1",
        "score": 1,
        "pred_sql": "WITH patents_sample AS (\n    SELECT publication_number, application_number\n    FROM\n        `patents-public-data.patents.publications`\n    WHERE\n    publication_number = 'US-9023721-B2'\n),\nt AS (\n    SELECT\n        t1.publication_number,\n        t4.publication_number AS similar_publication_number,\n        (SELECT SUM(element1 * element2)\n         FROM t5.embedding_v1 element1 WITH OFFSET pos\n         JOIN t6.embedding_v1 element2 WITH OFFSET pos USING (pos)) AS similarity\n    FROM \n        (SELECT * FROM patents_sample LIMIT 1) t1\n    LEFT JOIN (\n        SELECT \n            x3.publication_number,\n            EXTRACT(YEAR FROM PARSE_DATE('%Y%m%d', CAST(x3.filing_date AS STRING))) AS focal_filing_year\n        FROM \n            `patents-public-data.patents.publications` x3\n        WHERE \n            x3.filing_date != 0\n    ) t3 ON t3.publication_number = t1.publication_number\n    LEFT JOIN (\n        SELECT \n            x4.publication_number,\n            EXTRACT(YEAR FROM PARSE_DATE('%Y%m%d', CAST(x4.filing_date AS STRING))) AS filing_year\n        FROM \n            `patents-public-data.patents.publications` x4\n        WHERE \n            x4.filing_date != 0\n    ) t4 ON\n    t4.publication_number != t1.publication_number\n    AND t3.focal_filing_year = t4.filing_year\n    LEFT JOIN `patents-public-data.google_patents_research.publications` t5 ON t5.publication_number = t1.publication_number\n    LEFT JOIN `patents-public-data.google_patents_research.publications` t6 ON t6.publication_number = t4.publication_number\n    ORDER BY \n        t1.publication_number, similarity DESC\n)\nSELECT\n    t.similar_publication_number,\n    t.similarity\nFROM (\n    SELECT\n        t.*,\n        ROW_NUMBER() OVER (PARTITION BY publication_number ORDER BY similarity DESC) AS seqnum\n    FROM\n        t\n) t\nWHERE\n    seqnum <= 5;\n\n\n",
        "error_info": null
    },
    {
        "instance_id": "bq211",
        "score": 1,
        "pred_sql": "WITH patents_sample AS (               -- name of our table\nSELECT \n  t1.publication_number, \n  t1.application_number \nFROM \n  patents-public-data.patents.publications t1 \nWHERE \n  country_code = 'US'                                                        -- only consider US patents\n  AND grant_date between 20080101 AND 20080131                               -- grant dates between 2002 and 2006\n  AND grant_date != 0                                                        -- only consider granted patents\n  AND publication_number LIKE '%B2%'                                         -- only consider patents with kind code B2\n),\n\nfamily_number AS (\nSELECT\n  t1.publication_number,\n  -- count distinct application numbers sharing same family id with our focal patents\n  COUNT(DISTINCT t3.application_number) AS family_size,\nFROM\n  patents_sample t1\n  -- join publications table to obtain family id of our focal patents\nLEFT JOIN\n  patents-public-data.patents.publications t2\nON\n  t1.publication_number = t2.publication_number\n  -- join publications table on family id to get all publications sharing the same family id\nLEFT JOIN\n  patents-public-data.patents.publications t3\nON\n  t2.family_id = t3.family_id\nGROUP BY\n  t1.publication_number\n)\n\nSELECT COUNT(*) FROM family_number WHERE family_size>300",
        "error_info": null
    },
    {
        "instance_id": "bq047",
        "score": 1,
        "pred_sql": "WITH nyc_weather AS (\n    SELECT\n    -- Create a timestamp from the date components.\n    timestamp(concat(year, \"-\", mo, \"-\", da)) as timestamp,\n    -- Replace numerical null values with actual nulls\n    AVG(IF (temp=9999.9, null, temp)) AS temperature\n    FROM\n        `bigquery-public-data.noaa_gsod.gsod20*`\n    WHERE\n        CAST(YEAR AS INT64) BETWEEN 2008 AND 2018\n    AND (stn=\"725030\" OR  -- La Guardia\n        stn=\"744860\")    -- JFK\n    GROUP BY timestamp\n)\nSELECT\n    complaint_type,\n    sum(complaint_count) as total_complaint_count,\n    count(temperature) as data_count,\n    ROUND(corr(temperature, avg_count), 4) AS corr_count,\n    ROUND(corr(temperature, avg_pct_count), 4) AS corr_pct\nFrom (\n    SELECT\n        avg(pct_count) as avg_pct_count,\n        avg(day_count) as avg_count,\n        sum(day_count) as complaint_count,\n        complaint_type,\n        temperature\n    FROM (\n        SELECT\n            DATE(timestamp) AS date,\n            temperature\n        FROM\n            nyc_weather ) a\n    JOIN (\n        SELECT x.date, complaint_type, day_count, day_count / all_calls_count as pct_count\n        FROM (\n            SELECT\n                DATE(created_date) AS date,\n                complaint_type,\n                COUNT(*) AS day_count\n            FROM\n                `bigquery-public-data.new_york.311_service_requests`\n            GROUP BY\n                date,\n                complaint_type) x\n        JOIN (\n            SELECT\n                DATE(timestamp) AS date,\n                COUNT(*) AS all_calls_count\n            FROM nyc_weather\n            GROUP BY date\n        ) y\n        ON x.date = y.date\n    ) b\n    ON a.date = b.date\n    GROUP BY\n        complaint_type,\n        temperature\n)\nGROUP BY complaint_type\nHAVING\n    ABS(corr_pct) > 0.5 AND\n    total_complaint_count > 5000\nORDER BY\n    ABS(corr_pct) DESC",
        "error_info": null
    },
    {
        "instance_id": "bq282",
        "score": 1,
        "pred_sql": "SELECT \n  district\nFROM (\n  SELECT\n    S.starting_district AS district,\n    T.start_station_id,\n    T.end_station_id\n  FROM\n    `bigquery-public-data.austin_bikeshare.bikeshare_trips` AS T\n  INNER JOIN (\n    SELECT\n      station_id,\n      council_district AS starting_district\n    FROM\n      `bigquery-public-data.austin_bikeshare.bikeshare_stations`\n    WHERE\n      status = \"active\"\n  ) AS S ON T.start_station_id = S.station_id\n  WHERE\n    S.starting_district IN (\n      SELECT council_district\n      FROM `bigquery-public-data.austin_bikeshare.bikeshare_stations`\n      WHERE\n        status = \"active\" AND\n        station_id = SAFE_CAST(T.end_station_id AS INT64)\n    )\n    AND T.start_station_id != SAFE_CAST(T.end_station_id AS INT64)\n) \nGROUP BY district\nORDER BY COUNT(*) DESC\nLIMIT 1;\n",
        "error_info": null
    },
    {
        "instance_id": "ga012",
        "score": 1,
        "pred_sql": "WITH top_category AS (\n  SELECT\n    product.item_category,\n    SUM(ecommerce.tax_value_in_usd) / SUM(ecommerce.purchase_revenue_in_usd) AS tax_rate\n  FROM\n    bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_20201130,\n    UNNEST(items) AS product\n  WHERE\n    event_name = 'purchase'\n  GROUP BY\n    product.item_category\n  ORDER BY\n    tax_rate DESC\n  LIMIT 1\n)\n\nSELECT\n    ecommerce.transaction_id,\n    SUM(ecommerce.total_item_quantity) AS total_item_quantity,\n    SUM(ecommerce.purchase_revenue_in_usd) AS purchase_revenue_in_usd,\n    SUM(ecommerce.purchase_revenue) AS purchase_revenue\nFROM\n    bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_20201130, \n    UNNEST(items) AS product\nJOIN top_category\nON product.item_category = top_category.item_category\nWHERE\n    event_name = 'purchase'\nGROUP BY\n    ecommerce.transaction_id;",
        "error_info": null
    },
    {
        "instance_id": "ga004_1",
        "score": 1,
        "pred_sql": "WITH\n  UserInfo AS (\n    SELECT\n      user_pseudo_id,\n      PARSE_DATE('%Y%m%d', event_date) AS event_date,\n      COUNTIF(event_name = 'page_view') AS page_view_count,\n      COUNTIF(event_name IN ('in_app_purchase', 'purchase')) AS purchase_event_count\n    FROM `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*`\n    WHERE _TABLE_SUFFIX BETWEEN '20201101' AND '20201130'\n    GROUP BY 1, 2\n  )\nSELECT\n  event_date,\n  SUM(page_view_count) / COUNT(*) AS avg_page_views,\n  SUM(page_view_count)\nFROM UserInfo\nWHERE purchase_event_count > 0\nGROUP BY event_date\nORDER BY event_date;",
        "error_info": null
    },
    {
        "instance_id": "ga025",
        "score": 1,
        "pred_sql": "WITH\n-- List of users who installed in Sept\nsept_cohort AS (\n    SELECT DISTINCT \n        user_pseudo_id,\n        FORMAT_DATE('%Y-%m-%d', PARSE_DATE('%Y%m%d', event_date)) AS date_first_open\n    FROM \n        `firebase-public-project.analytics_153293282.events_*`\n    WHERE \n        event_name = 'first_open'\n        AND _TABLE_SUFFIX BETWEEN '20180901' AND '20180930'\n),\n-- Get the list of users who uninstalled\nuninstallers AS (\n    SELECT DISTINCT \n        user_pseudo_id,\n        FORMAT_DATE('%Y-%m-%d', PARSE_DATE('%Y%m%d', event_date)) AS date_app_remove\n    FROM \n        `firebase-public-project.analytics_153293282.events_*`\n    WHERE \n        event_name = 'app_remove'\n        AND _TABLE_SUFFIX BETWEEN '20180901' AND '20181007'\n),\n-- Get the list of users who experienced crashes\nusers_crashes AS (\n    SELECT DISTINCT \n        user_pseudo_id,\n        FORMAT_DATE('%Y-%m-%d', PARSE_DATE('%Y%m%d', event_date)) AS date_crash\n    FROM \n        `firebase-public-project.analytics_153293282.events_*`,\n        UNNEST(event_params) e\n    WHERE \n        event_name = 'app_exception'\n        AND _TABLE_SUFFIX BETWEEN '20180901' AND '20181007'\n),\n-- Join the 3 tables\njoined AS (\n    SELECT \n        a.user_pseudo_id,\n        a.date_first_open,\n        b.date_app_remove,\n        DATE_DIFF(DATE(b.date_app_remove), DATE(a.date_first_open), DAY) AS days_to_uninstall,\n        c.date_crash\n    FROM \n        sept_cohort a\n    LEFT JOIN \n        uninstallers b ON a.user_pseudo_id = b.user_pseudo_id\n    LEFT JOIN \n        users_crashes c ON a.user_pseudo_id = c.user_pseudo_id\n)\n-- Compute the percentage\nSELECT\n    COUNT(DISTINCT CASE WHEN days_to_uninstall <= 7 AND date_crash IS NOT NULL THEN user_pseudo_id END) / \n    COUNT(DISTINCT CASE WHEN days_to_uninstall <= 7 THEN user_pseudo_id END) AS percent_users_crashes\nFROM \n    joined;",
        "error_info": null
    },
    {
        "instance_id": "bq117",
        "score": 1,
        "pred_sql": "WITH base_info AS (\n  SELECT\n    episode_id, \n    CONCAT(CAST(EXTRACT(MONTH FROM MIN(event_begin_time)) AS STRING), \"-\", CAST(EXTRACT(year FROM MIN(event_begin_time)) AS STRING)) as episode_month,\n    EXTRACT(MONTH FROM MIN(event_begin_time)) AS month,\n    STRING_AGG(DISTINCT(cz_name) LIMIT 5) as counties, \n    STRING_AGG(DISTINCT(state)) as states, \n    STRING_AGG(DISTINCT(event_type) LIMIT 5) as event_types,\n    SUM(damage_property)/1000000000 as damage_property_in_billions\n  FROM\n    `bigquery-public-data.noaa_historic_severe_storms.storms_*`\n  WHERE\n    _TABLE_SUFFIX BETWEEN CAST((EXTRACT(YEAR from CURRENT_DATE())-15) AS STRING) AND CAST(EXTRACT(YEAR from CURRENT_DATE()) AS STRING)\n  GROUP BY\n    episode_id\n  ORDER BY\n    damage_property_in_billions desc\n  LIMIT 100\n)\n\nSELECT COUNT(*) AS month_count\nFROM base_info\nGROUP BY month\nORDER BY month_count DESC\nLIMIT 1\n",
        "error_info": null
    },
    {
        "instance_id": "bq215",
        "score": 1,
        "pred_sql": "WITH patents_sample AS (               -- name of our table\nSELECT \n  t1.publication_number, \n  t1.application_number \nFROM \n  `patents-public-data.patents.publications` t1 \nWHERE \n  country_code = 'US'                                                        -- only consider US patents\n  AND grant_date between 20180101 AND 20180131                               -- grant dates between 2002 and 2006\n  AND grant_date != 0                                                        -- only consider granted patents\n  AND publication_number LIKE '%B2%'                                         -- only consider patents with kind code B2\n),\ninterim_table AS (\n    SELECT\n        t1.publication_number,\n        SUBSTR(ipc_u.code, 0, 4) AS ipc4,\n        COUNT(SUBSTR(ipc_u.code, 0, 4)) AS ipc4_count\n    FROM\n        patents-public-data.patents.publications t1,\n        UNNEST(ipc) AS ipc_u\n    GROUP BY\n        t1.publication_number,\n        ipc4\n),\nchosen_ipc4_view AS (\n    SELECT\n        *\n    FROM\n        interim_table\n    WHERE\n        CONCAT(interim_table.publication_number, interim_table.ipc4_count) IN (\n            SELECT\n                CONCAT(publication_number, MAX(ipc4_count))\n            FROM\n                interim_table\n            GROUP BY\n                publication_number\n        )\n    ORDER BY\n        ipc4_count DESC\n),\nipc_counts AS (\n  SELECT\n    t1.publication_number,\n    t3.ipc4,\n    COUNT(t3.ipc4) AS ipc_occurrences\n  FROM\n    patents_sample t1\n    -- joins backward citations\n  LEFT JOIN (\n    SELECT\n      x2.publication_number AS citing_publication_number,\n      citation_u.publication_number AS backward_citation\n    FROM\n      patents-public-data.patents.publications x2,\n      UNNEST(citation) AS citation_u) t2\n  ON\n    t2.citing_publication_number = t1.publication_number\n    -- joins 4-digit ipc codes of backward citations\n  LEFT JOIN\n    chosen_ipc4_view t3\n  ON\n    t3.publication_number = t2.backward_citation\n  GROUP BY\n    t1.publication_number,\n    t3.ipc4\n),\nmax_originality AS (\n  SELECT\n    publication_number,\n    1 - SUM(POWER(ipc_occurrences, 2)) / POWER(SUM(ipc_occurrences), 2) AS originality\n  FROM\n    ipc_counts\n  GROUP BY\n    publication_number\n  HAVING\n    SUM(ipc_occurrences) > 0\n  ORDER BY\n    originality DESC\n  LIMIT 1\n)\nSELECT \n  publication_number\nFROM \n  max_originality\n",
        "error_info": null
    },
    {
        "instance_id": "bq350",
        "score": 1,
        "pred_sql": "DECLARE\n  my_drug_list ARRAY<STRING>;\nSET\n  my_drug_list = [\n  'Keytruda',\n  'Vioxx',\n  'Humira',\n  'Premarin' ];\n\nSELECT\n  id AS drug_id,\n  tradeNameList.element AS drug_trade_name,\n  drugType AS drug_type,\n  hasBeenWithdrawn AS drug_withdrawn\nFROM\n  `open-targets-prod.platform.molecule`,\n  UNNEST (tradeNames.list) AS tradeNameList\nWHERE\n  tradeNameList.element IN UNNEST(my_drug_list)\n  AND isApproved = TRUE\n  AND blackBoxWarning = TRUE\n  AND drugType != 'Unknown';\n",
        "error_info": null
    },
    {
        "instance_id": "bq191",
        "score": 1,
        "pred_sql": "WITH repos as (\n  SELECT b.repo_with_watches as repo_name,\n         b.watches as watches\n  FROM (\n    SELECT DISTINCT repo_name AS repo_in_mirror\n    FROM `bigquery-public-data.github_repos.sample_files` \n  ) a RIGHT JOIN (\n    SELECT repo.name AS repo_with_watches, APPROX_COUNT_DISTINCT(actor.id) watches \n    FROM `githubarchive.year.2017` \n    WHERE type='WatchEvent'\n    GROUP BY 1 \n    HAVING watches > 300\n  ) b\n  ON a.repo_in_mirror = b.repo_with_watches\n  WHERE\n    a.repo_in_mirror IS NOT NULL\n),\ncontents as (\n  SELECT *\n  FROM (\n    SELECT DISTINCT *\n    FROM `bigquery-public-data.github_repos.sample_files` \n    WHERE repo_name IN (SELECT repo_name FROM repos)\n  ) a RIGHT JOIN (\n    SELECT id as idcontent,\n           content as content\n    FROM `bigquery-public-data.github_repos.sample_contents` \n  ) b\n  ON a.id = b.idcontent \n)\nSELECT repos.repo_name,\n       repos.watches\nFROM repos\nJOIN\n  contents\nON\n  repos.repo_name = contents.repo_name \nWHERE\n  contents.content LIKE '%junit</artifactId>%'\n  AND contents.path LIKE 'pom.xml'\nORDER BY\n  repos.watches DESC\nLIMIT 5",
        "error_info": null
    },
    {
        "instance_id": "bq357",
        "score": 1,
        "pred_sql": "WITH DailyAverages AS (\n    SELECT \n        year, month, day, latitude, longitude,\n        AVG(wind_speed) AS avg_wind_speed,\n    FROM \n        `bigquery-public-data.noaa_icoads.icoads_core_*`\n    WHERE\n        _TABLE_SUFFIX BETWEEN '2005' AND '2015'\n    GROUP BY \n        year, month, day, latitude, longitude\n)\nSELECT \n    year, month, day, latitude, longitude,\n    avg_wind_speed,\n\nFROM \n    DailyAverages\nWHERE\n    avg_wind_speed IS NOT NULL\n\nORDER BY avg_wind_speed DESC LIMIT 5",
        "error_info": null
    },
    {
        "instance_id": "bq025",
        "score": 1,
        "pred_sql": "SELECT\n  age.country_name,\n  SUM(age.population) AS under_25,\n  pop.midyear_population AS total,\n  ROUND((SUM(age.population) / pop.midyear_population) * 100,2) AS pct_under_25\nFROM (\n  SELECT\n    country_name,\n    population,\n    country_code\n  FROM\n    `bigquery-public-data.census_bureau_international.midyear_population_agespecific`\n  WHERE\n    year =2020\n    AND age < 20) age\nINNER JOIN (\n  SELECT\n    midyear_population,\n    country_code\n  FROM\n    `bigquery-public-data.census_bureau_international.midyear_population`\n  WHERE\n    year = 2020) pop\nON\n  age.country_code = pop.country_code\nGROUP BY\n  1,\n  3\nORDER BY\n  4 DESC\n/* Remove limit for visualization */\nLIMIT\n  10\n",
        "error_info": null
    },
    {
        "instance_id": "ga006",
        "score": 1,
        "pred_sql": "WITH\n  events AS (\n    SELECT\n      session.value.int_value AS session_id,\n      COALESCE(spend.value.int_value, spend.value.float_value, spend.value.double_value, 0.0)\n        AS spend_value,\n      event.*\n\n    -- Replace table name\n    FROM `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*` AS event\n    LEFT JOIN UNNEST(event.event_params) AS session\n      ON session.key = 'ga_session_id'\n    LEFT JOIN UNNEST(event.event_params) AS spend\n      ON spend.key = 'value'\n\n    -- Replace date range\n    WHERE _TABLE_SUFFIX BETWEEN '20201101' and '20201130'\n  ),\n\nSESSTION_INFO AS (\n  SELECT\n    user_pseudo_id,\n    COUNT(DISTINCT session_id) AS session_count,\n    SUM(spend_value) / COUNT(DISTINCT session_id) AS avg_spend_per_session_by_user\n  FROM events\n  WHERE event_name = 'purchase' and session_id IS NOT NULL\n  GROUP BY user_pseudo_id\n)\n\nSELECT user_pseudo_id, avg_spend_per_session_by_user\nFROM\nSESSTION_INFO\nWHERE session_count > 1",
        "error_info": null
    },
    {
        "instance_id": "bq192",
        "score": 1,
        "pred_sql": "WITH allowed_repos AS (\n    SELECT \n        repo_name, \n        license \n    FROM \n        `bigquery-public-data.github_repos.licenses`\n    WHERE \n        license IN UNNEST([\"artistic-2.0\", \"isc\", \"mit\", \"apache-2.0\"])\n),\nwatch_counts AS (\n    SELECT \n        repo.name AS repo,\n        COUNT(DISTINCT actor.login) AS watches\n    FROM \n        `githubarchive.month.202204`\n    WHERE \n        type = \"WatchEvent\"\n    GROUP BY \n        repo\n),\nissue_counts AS (\n    SELECT \n        repo.name AS repo,\n        COUNT(*) AS issue_events\n    FROM \n        `githubarchive.month.202204`\n    WHERE \n        type = 'IssuesEvent'\n    GROUP BY \n        repo\n),\nfork_counts AS (\n    SELECT \n        repo.name AS repo,\n        COUNT(*) AS forks\n    FROM \n        `githubarchive.month.202204`\n    WHERE \n        type = 'ForkEvent'\n    GROUP BY \n        repo\n),\nmetadata AS (\n    SELECT \n        repo_name, \n        license, \n        forks, \n        issue_events, \n        watches\n    FROM \n        allowed_repos\n    INNER JOIN \n        fork_counts \n    ON \n        repo_name = fork_counts.repo\n    INNER JOIN \n        issue_counts \n    ON \n        repo_name = issue_counts.repo\n    INNER JOIN \n        watch_counts \n    ON \n        repo_name = watch_counts.repo\n),\ngithub_files_at_head AS (\n    SELECT \n        repo_name\n    FROM \n        `bigquery-public-data.github_repos.sample_files`\n    WHERE \n        ref = \"refs/heads/master\" \n        AND ENDS_WITH(path, \".py\")\n        AND symlink_target IS NULL\n    GROUP BY \n        repo_name\n)\nSELECT \n    metadata.repo_name AS repository\nFROM \n    metadata\nINNER JOIN \n    github_files_at_head\nON \n    metadata.repo_name = github_files_at_head.repo_name\nORDER BY \n    (metadata.forks + metadata.issue_events + metadata.watches) DESC\nLIMIT 1;",
        "error_info": null
    },
    {
        "instance_id": "bq026_1",
        "score": 1,
        "pred_sql": "WITH PatentApplications AS (\n    SELECT \n        ANY_VALUE(assignee_harmonized) AS assignee_harmonized,  -- Randomly sampling assignee data\n        ANY_VALUE(filing_date) AS filing_date,  -- Randomly sampling filing date\n        application_number  -- The unique identifier for each patent application\n    FROM \n        `patents-public-data.patents.publications` AS pubs  -- Using the patent publications dataset\n    WHERE EXISTS (\n        -- Checks if there is a CPC code \"A61K39\"\n        SELECT 1 FROM UNNEST(pubs.cpc) AS c WHERE REGEXP_CONTAINS(c.code, \"A61K39\")\n    )\n    GROUP BY \n        application_number  -- Grouping by application number to ensure unique entries\n)\n\n, AssigneeApplications AS (\n    SELECT \n        COUNT(*) AS total_applications,  -- Calculating the total number of applications\n        a.name AS assignee_name,  -- Name of the assignee\n        CAST(FLOOR(filing_date / 10000) AS INT64) AS filing_year  -- Extracting the year from the filing date\n    FROM \n        PatentApplications\n    CROSS JOIN\n        UNNEST(assignee_harmonized) AS a  -- Expanding the assignee_harmonized array\n    GROUP BY \n        a.name, filing_year  -- Grouping by assignee and year\n)\n\n, TotalApplicationsPerAssignee AS (\n    SELECT\n        assignee_name,\n        SUM(total_applications) AS total_applications  -- Sum of all applications per assignee\n    FROM \n        AssigneeApplications\n    GROUP BY \n        assignee_name\n    ORDER BY \n        total_applications DESC\n    LIMIT 1  -- Selecting only the assignee with the highest total applications\n)\n\n, MaxYearForTopAssignee AS (\n    SELECT\n        aa.assignee_name,\n        aa.filing_year,\n        aa.total_applications\n    FROM \n        AssigneeApplications aa\n    INNER JOIN\n        TotalApplicationsPerAssignee tapa ON aa.assignee_name = tapa.assignee_name\n    ORDER BY \n        aa.total_applications DESC\n    LIMIT 1  -- Finding the year with the most applications for the top assignee\n)\n\nSELECT filing_year\nFROM \n    MaxYearForTopAssignee\n",
        "error_info": null
    },
    {
        "instance_id": "bq020_1",
        "score": 1,
        "pred_sql": "SELECT\n  reference_name\nFROM (\n  SELECT\n    reference_name,\n    COUNT(reference_name) / r.length AS variant_density,\n    COUNT(reference_name) AS variant_count,\n    r.length AS reference_length\n  FROM\n    `bigquery-public-data.genomics_cannabis.MNPR01_201703` v,\n    `bigquery-public-data.genomics_cannabis.MNPR01_reference_201703` r\n  WHERE\n    v.reference_name = r.name\n    AND EXISTS (\n    SELECT\n      1\n    FROM\n      UNNEST(v.call) AS call\n    WHERE\n      EXISTS (\n      SELECT\n        1\n      FROM\n        UNNEST(call.genotype) AS gt\n      WHERE\n        gt > 0))\n  GROUP BY\n    reference_name,\n    r.length ) AS d\nORDER BY\n  variant_density DESC\nLIMIT \n  1;",
        "error_info": null
    },
    {
        "instance_id": "bq351_1",
        "score": 1,
        "pred_sql": "WITH AvgScore AS (\n  SELECT\n    AVG(associations.score) AS avg_score\n  FROM\n    `open-targets-prod.platform.associationByOverallDirect` AS associations\n  JOIN\n    `open-targets-prod.platform.diseases` AS diseases\n  ON\n    associations.diseaseId = diseases.id\n  WHERE\n    diseases.name = 'psoriasis'\n)\nSELECT\n  targets.approvedSymbol AS target_approved_symbol\nFROM\n  `open-targets-prod.platform.associationByOverallDirect` AS associations\nJOIN\n  `open-targets-prod.platform.diseases` AS diseases\nON\n  associations.diseaseId = diseases.id\nJOIN\n  `open-targets-prod.platform.targets` AS targets\nON\n  associations.targetId = targets.id\nCROSS JOIN\n  AvgScore\nWHERE\n  diseases.name = 'psoriasis'\nORDER BY\n  ABS(associations.score - AvgScore.avg_score) ASC\nLIMIT 1\n",
        "error_info": null
    },
    {
        "instance_id": "bq028",
        "score": 1,
        "pred_sql": "DECLARE\n    Sys STRING DEFAULT 'NPM';\n\nWITH HighestReleases AS (\n    SELECT\n        Name,\n        Version\n    FROM (\n        SELECT\n            Name,\n            Version,\n            ROW_NUMBER() OVER (\n                PARTITION BY Name\n                ORDER BY VersionInfo.Ordinal DESC\n            ) AS RowNumber\n        FROM\n            `spider2-public-data.deps_dev_v1.PackageVersions`\n        WHERE\n            System = Sys\n            AND VersionInfo.IsRelease\n    )\n    WHERE RowNumber = 1\n),\nPVP AS (\n    SELECT\n        Name, Version, ProjectType, ProjectName\n    FROM\n        `spider2-public-data.deps_dev_v1.PackageVersionToProject`\n    JOIN\n        HighestReleases AS HR\n    USING (Name, Version)\n    WHERE\n        System = Sys\n        AND ProjectType = 'GITHUB'\n)\nSELECT PVP.Name, PVP.Version\nFROM\n    PVP\nJOIN\n    `spider2-public-data.deps_dev_v1.Projects` AS P\nON\n    PVP.ProjectType = P.Type AND PVP.ProjectName = P.Name\nORDER BY P.StarsCount DESC LIMIT 3;",
        "error_info": null
    },
    {
        "instance_id": "bq061",
        "score": 1,
        "pred_sql": "WITH acs_2018 AS (\n    SELECT\n      geo_id,\n      median_income AS median_income_2018\n    FROM\n      `bigquery-public-data.census_bureau_acs.censustract_2018_5yr` \n),\nacs_2015 AS (\n    SELECT\n      geo_id,\n      median_income AS median_income_2015\n    FROM\n      `bigquery-public-data.census_bureau_acs.censustract_2015_5yr` ),\nacs_diff AS (\n    SELECT\n      a18.geo_id,\n      a18.median_income_2018,\n      a15.median_income_2015,\n      (a18.median_income_2018 - a15.median_income_2015) AS median_income_diff,\n    FROM\n      acs_2018 a18\n    JOIN\n      acs_2015 a15\n    ON\n      a18.geo_id = a15.geo_id\n),\nmax_geo_id AS (\n    SELECT\n      geo_id\n    FROM\n      acs_diff\n    WHERE\n      median_income_diff IS NOT NULL\n      AND acs_diff.geo_id in (\n        SELECT\n          geo_id\n        FROM\n          `bigquery-public-data.geo_census_tracts.census_tracts_california`\n      )\n    ORDER BY\n      median_income_diff DESC\n    LIMIT 1\n)\nSELECT\n    tracts.tract_ce as tract_code\nFROM\n    max_geo_id\nJOIN\n    `bigquery-public-data.geo_census_tracts.census_tracts_california` AS tracts\nON\n    max_geo_id.geo_id = tracts.geo_id;",
        "error_info": null
    },
    {
        "instance_id": "bq266",
        "score": 1,
        "pred_sql": "WITH cte AS (\n  SELECT \n    t1.id AS product_id,\n    t1.name,\n    t1.cost,\n    t1.retail_price,\n    t2.created_at,\n   CONCAT(EXTRACT(YEAR FROM t2.created_at), '-', LPAD(CAST(EXTRACT(MONTH FROM t2.created_at) AS STRING), 2, '0')) AS year_month,\n    (t1.retail_price - t1.cost) AS profit\n  FROM \n    `bigquery-public-data.thelook_ecommerce.products` AS t1\n  LEFT JOIN \n    `bigquery-public-data.thelook_ecommerce.order_items` AS t2\n  ON \n    t1.id = t2.product_id\n  WHERE\n    t2.created_at BETWEEN '2020-01-01' AND '2020-12-31'\n),\n\nranked_cte AS (\n  SELECT\n    year_month,\n    product_id,\n    name,\n    cost,\n    retail_price AS sale,\n    profit,\n    DENSE_RANK() OVER (PARTITION BY year_month ORDER BY profit asc) AS rank\n  FROM \n    cte\n)\nSELECT\n  name\nFROM \n  ranked_cte\nWHERE \n  rank = 1 and year_month is not null\nORDER BY year_month",
        "error_info": null
    },
    {
        "instance_id": "bq184",
        "score": 1,
        "pred_sql": "WITH a AS (\n    SELECT \n        DATE(block_timestamp) AS date, \n        COUNT(*) AS contracts_creation\n    FROM  \n        `bigquery-public-data.crypto_ethereum.traces` AS traces\n    WHERE \n        block_timestamp < '2021-09-01 00:00:00'\n        AND trace_type = 'create'\n        AND trace_address IS null\n    GROUP BY \n        date\n),\nb AS (\n    SELECT \n        date, \n        SUM(contracts_creation) OVER (ORDER BY date) AS ccc, \n        LEAD(date, 1) OVER (ORDER BY date) AS next_date\n    FROM \n        a\n    ORDER BY \n        date\n),\ncalendar AS (\n    SELECT \n        date\n    FROM \n        UNNEST(generate_date_array('2021-08-01', '2021-08-31')) AS date\n),\nc AS (\n    SELECT \n        calendar.date, \n        b.ccc\n    FROM \n        b \n    JOIN \n        calendar \n    ON \n        b.date <= calendar.date\n        AND calendar.date < b.next_date\n    ORDER BY \n        calendar.date\n),\nd AS (\n    SELECT \n        DATE(block_timestamp) AS date1, \n        COUNT(*) AS contracts_creation1\n    FROM  \n        `bigquery-public-data.crypto_ethereum.traces` AS traces\n    WHERE \n        block_timestamp < '2021-09-01 00:00:00'\n        AND trace_type = 'create'\n        AND trace_address IS NOT null\n    GROUP BY \n        date1\n),\ne AS (\n    SELECT \n        date1, \n        SUM(contracts_creation1) OVER (ORDER BY date1) AS ccc1, \n        LEAD(date1, 1) OVER (ORDER BY date1) AS next_date1\n    FROM \n        d\n    ORDER BY \n        date1\n),\ncalendar1 AS (\n    SELECT \n        date1\n    FROM \n        UNNEST(generate_date_array('2021-08-01', '2021-08-31')) AS date1\n),\nf AS (\n    SELECT \n        calendar1.date1, \n        e.ccc1\n    FROM \n        e \n    JOIN \n        calendar1 \n    ON \n        e.date1 <= calendar1.date1\n        AND calendar1.date1 < e.next_date1\n    ORDER BY \n        calendar1.date1\n)\nSELECT \n    f.date1, \n    f.ccc1 AS cumulative_contract_creation_by_contracts, \n    c.ccc AS cumulative_contract_creation_by_users\nFROM \n    c \nJOIN \n    f \nON \n    f.date1 = c.date\nORDER BY \n    f.date1\n;",
        "error_info": null
    },
    {
        "instance_id": "bq117_1",
        "score": 1,
        "pred_sql": "SELECT\n  CONCAT(city,\", \", state_name) as city,\n  zip_code,\n  COUNT(event_id) as count_storms\nFROM\n  `bigquery-public-data.noaa_historic_severe_storms.storms_*`,\n  `bigquery-public-data.geo_us_boundaries.zip_codes` \nWHERE\n  _TABLE_SUFFIX BETWEEN CAST((EXTRACT(YEAR from CURRENT_DATE())-10) AS STRING) AND CAST(EXTRACT(YEAR from CURRENT_DATE()) AS STRING) AND\n  LOWER(event_type) = 'hail' AND\n  ST_WITHIN(event_point, zip_code_geom)\n  \nGROUP BY\n  event_type,\n  zip_code, \n  city\nORDER BY\n  count_storms desc\nLIMIT 5\n",
        "error_info": null
    },
    {
        "instance_id": "bq026",
        "score": 0,
        "pred_sql": "WITH PatentApplications AS (\n    SELECT \n        ANY_VALUE(assignee_harmonized) AS assignee_harmonized,  -- Collects any sample of harmonized assignee data.\n        ANY_VALUE(filing_date) AS filing_date,  -- Collects any sample of filing date.\n        ANY_VALUE(country_code) AS country_code,  -- Collects any sample of country code.\n        application_number  -- The unique identifier for each patent application.\n    FROM \n        `patents-public-data.patents.publications` AS pubs  -- Using the patents publications dataset.\n    WHERE EXISTS (\n        -- Checks if there exists a CPC code \"A61K39\" within the nested CPC field.\n        SELECT 1 FROM UNNEST(pubs.cpc) AS c WHERE REGEXP_CONTAINS(c.code, \"A61K39\")\n    )\n    GROUP BY \n        application_number  -- Group by application number to ensure distinct entries.\n)\n\n,AssigneeApplications AS (\n    SELECT \n        COUNT(*) AS year_country_cnt,  -- Count of applications per assignee, year, and country.\n        a.name AS assignee_name,  -- Name of the assignee.\n        CAST(FLOOR(filing_date / 10000) AS INT64) AS filing_year,  -- Extracts the year from the filing date.\n        apps.country_code  -- Country code of the application.\n    FROM \n        PatentApplications AS apps  -- Using the previously defined CTE.\n    CROSS JOIN\n    UNNEST(assignee_harmonized) AS a  -- Expanding the assignee_harmonized array.\n    GROUP BY \n        a.name, filing_year, country_code  -- Grouping by assignee, year, and country.\n)\n\n-- CTE to aggregate data by assignee and year and to collect top 5 countries by application count.\n,AggregatedData AS (\n    SELECT \n        SUM(year_country_cnt) AS year_cnt,  -- Sum of all applications per assignee per year.\n        assignee_name, \n        filing_year, \n        -- Aggregates the top 5 countries by their application counts in descending order.\n        STRING_AGG(country_code ORDER BY year_country_cnt DESC LIMIT 5) AS countries\n    FROM \n        AssigneeApplications  -- Using the AssigneeApplications CTE.\n    GROUP BY \n        assignee_name, filing_year  -- Grouping results by assignee and year.\n)\n\n-- Final aggregation to find the year with the highest application count for each assignee.\n,FinalAggregation AS (\n    SELECT \n        SUM(year_cnt) AS total_count,  -- Total count of applications for each assignee.\n        assignee_name,\n        -- Aggregates into a structure the year and countries data with the highest application count.\n        ARRAY_AGG(\n            STRUCT<cnt INT64, filing_year INT64, countries STRING>\n            (year_cnt, filing_year, countries) \n            ORDER BY year_cnt DESC LIMIT 1\n        )[SAFE_ORDINAL(1)] AS largest_year  -- Selects the year with the highest application count.\n    FROM \n        AggregatedData  -- Using the AggregatedData CTE.\n    GROUP BY \n        assignee_name  -- Grouping by assignee.\n),\nFinal_data AS (\nSELECT \n    total_count,\n    assignee_name,\n    largest_year\nFROM \n    FinalAggregation  -- Using the FinalAggregation CTE.\nORDER BY \n    total_count DESC\n)\n\nSELECT largest_year.countries\nFROM Final_data\nLIMIT 1",
        "error_info": "Result Error"
    },
    {
        "instance_id": "ga030",
        "score": 1,
        "pred_sql": "WITH dates AS (\n    SELECT \n        DATE('2018-07-02') AS start_date,\n        DATE('2018-10-02') AS end_date,\n        DATE_ADD(DATE_TRUNC(DATE('2018-10-02'), WEEK(MONDAY)), INTERVAL -4 WEEK) AS min_date\n),\n\ndate_table AS (\n    SELECT DISTINCT \n        PARSE_DATE('%Y%m%d', `event_date`) AS event_date,\n        user_pseudo_id,\n        CASE \n            WHEN DATE_DIFF(PARSE_DATE('%Y%m%d', `event_date`), DATE(TIMESTAMP_MICROS(user_first_touch_timestamp)), DAY) = 0 \n            THEN 1 \n            ELSE 0 \n        END AS is_new_user\n    FROM `firebase-public-project.analytics_153293282.events_*` \n    WHERE event_name = 'session_start'\n    AND PARSE_DATE('%Y%m%d', `event_date`) >= DATE('2018-07-02')\n),\n\nnew_user_list AS (\n    SELECT DISTINCT \n        user_pseudo_id,\n        event_date\n    FROM date_table\n    WHERE is_new_user = 1\n),\n\ndays_since_start_table AS (\n    SELECT DISTINCT \n        is_new_user,\n        nu.event_date AS date_cohort,\n        dt.user_pseudo_id,\n        dt.event_date,\n        DATE_DIFF(dt.event_date, nu.event_date, DAY) AS days_since_start\n    FROM date_table dt\n    JOIN new_user_list nu ON dt.user_pseudo_id = nu.user_pseudo_id\n),\n\nweeks_retention AS (\n    SELECT \n        date_cohort,\n        DATE_TRUNC(date_cohort, WEEK(MONDAY)) AS week_cohort,\n        user_pseudo_id,\n        days_since_start,\n        CASE \n            WHEN days_since_start = 0 THEN 0 \n            ELSE CEIL(days_since_start / 7) \n        END AS weeks_since_start\n    FROM days_since_start_table\n),\n\nretention_counts AS (\n    SELECT \n        week_cohort,\n        weeks_since_start,\n        COUNT(DISTINCT user_pseudo_id) AS retained_users\n    FROM weeks_retention\n    WHERE week_cohort >= DATE('2018-07-02') AND week_cohort <= (SELECT min_date FROM dates) \n    GROUP BY \n        week_cohort,\n        weeks_since_start\n)\n\nSELECT \n    initial.week_cohort\nFROM \n    retention_counts AS initial\nLEFT JOIN \n    retention_counts AS four_week ON initial.week_cohort = four_week.week_cohort AND four_week.weeks_since_start = 4\nWHERE \n    initial.weeks_since_start = 0\nORDER BY \n    IFNULL(four_week.retained_users / initial.retained_users, 0)\nDESC\nLIMIT 1\n;",
        "error_info": null
    },
    {
        "instance_id": "bq188",
        "score": 1,
        "pred_sql": "WITH table1 AS (\n  SELECT\n    created_at,\n    session_id,\n    sequence_number,\n    CASE WHEN event_type = 'product' THEN CAST(REPLACE(uri, '/product/', '') AS INT) ELSE NULL END product_uri_id,\n    LEAD(created_at) OVER (PARTITION BY session_id ORDER BY sequence_number) next_event\n  FROM `bigquery-public-data.thelook_ecommerce.events` \n),\n\ntable2 AS (\n  SELECT \n    p.category,\n    COUNT(o.id) times_bought\n  FROM `bigquery-public-data.thelook_ecommerce.products` p\n  LEFT JOIN `bigquery-public-data.thelook_ecommerce.order_items` o\n    ON p.id = o.product_id\n  GROUP BY 1\n),\n\ncategory_stats AS (\n  SELECT \n    p.category,  \n    COUNT(table1.product_uri_id) number_of_visits,\n    ROUND(AVG(DATE_DIFF(table1.next_event, table1.created_at, SECOND) / 60), 2) avg_time_spent,\n    table2.times_bought total_quantity_bought\n  FROM table1\n  LEFT JOIN bigquery-public-data.thelook_ecommerce.products p\n    ON table1.product_uri_id = p.id\n  LEFT JOIN table2\n    ON p.category = table2.category\n  WHERE table1.product_uri_id IS NOT NULL\n  GROUP BY 1, 4\n)\n\nSELECT \n  CAST(avg_time_spent AS STRING) \nFROM category_stats\nORDER BY category_stats.total_quantity_bought DESC\nLIMIT 1",
        "error_info": null
    },
    {
        "instance_id": "bq001",
        "score": 1,
        "pred_sql": "DECLARE start_date STRING DEFAULT '20170201';\nDECLARE end_date STRING DEFAULT '20170228';\n\nWITH visit AS (\n    SELECT\n        fullvisitorid,\n        MIN(date) AS date_first_visit\n    FROM\n        `bigquery-public-data.google_analytics_sample.ga_sessions_*`\n    WHERE\n       _TABLE_SUFFIX BETWEEN start_date AND end_date\n    GROUP BY fullvisitorid\n),\n\ntransactions AS (\n    SELECT\n        fullvisitorid,\n        MIN(date) AS date_transactions\n    FROM\n        `bigquery-public-data.google_analytics_sample.ga_sessions_*` AS ga,\n        UNNEST(ga.hits) AS hits\n    WHERE\n        hits.transaction.transactionId IS NOT NULL\n        AND\n        _TABLE_SUFFIX BETWEEN start_date AND end_date\n    GROUP BY fullvisitorid\n),\n\ndevice_transactions AS (\n    SELECT DISTINCT\n        fullvisitorid,\n        date,\n        device.deviceCategory\n    FROM\n        `bigquery-public-data.google_analytics_sample.ga_sessions_*` AS ga,\n        UNNEST(ga.hits) AS hits\n    WHERE\n        hits.transaction.transactionId IS NOT NULL\n        AND\n        _TABLE_SUFFIX BETWEEN start_date AND end_date\n),\n\nvisits_transactions AS (\n    SELECT\n        visit.fullvisitorid,\n        date_first_visit,\n        date_transactions,\n        device_transactions.deviceCategory AS device_transaction\n    FROM\n        visit\n        JOIN transactions\n        ON visit.fullvisitorid = transactions.fullvisitorid\n        JOIN device_transactions\n        ON visit.fullvisitorid = device_transactions.fullvisitorid \n        AND transactions.date_transactions = device_transactions.date\n)\n\nSELECT\n       fullvisitorid,\n       DATE_DIFF(PARSE_DATE('%Y%m%d', date_transactions), PARSE_DATE('%Y%m%d', date_first_visit), DAY) AS time,\n       device_transaction\nFROM visits_transactions\nORDER BY fullvisitorid;",
        "error_info": null
    },
    {
        "instance_id": "bq288",
        "score": 1,
        "pred_sql": "WITH state_counts AS (\n        SELECT \n            DISTINCT state_name,\n            COUNT(1) AS count_institutions\n        FROM\n            `bigquery-public-data.fdic_banks.institutions`\n        GROUP BY\n            state_name\n        ),\n\n        detailed_info AS (\n            SELECT\n                DISTINCT state_name AS state,\n                SUM(total_assets) AS sum_assets,\n            FROM\n                `bigquery-public-data.fdic_banks.institutions`\n            WHERE\n                established_date BETWEEN '1900-01-01' AND '2000-12-31'\n            AND \n                (institution_name LIKE 'Bank%')\n            GROUP BY\n                state_name\n        )\nSELECT\n    s.count_institutions AS count_institutions_in_state\nFROM\n    detailed_info d\nJOIN\n    state_counts s \nON \n    d.state = s.state_name\nORDER BY\n    d.sum_assets DESC\nLIMIT 1;",
        "error_info": null
    },
    {
        "instance_id": "bq327",
        "score": 1,
        "pred_sql": "WITH russia_Data AS (\n  SELECT DISTINCT \n    id.country_name,\n    id.value, -- Format in DataStudio\n    id.indicator_name\n  FROM (\n    SELECT\n      country_code,\n      region\n    FROM\n      bigquery-public-data.world_bank_intl_debt.country_summary\n    WHERE\n      region != \"\" -- Aggregated countries do not have a region\n  ) cs -- Aggregated countries do not have a region\n  INNER JOIN (\n    SELECT\n      country_code,\n      country_name,\n      value, \n      indicator_name\n    FROM\n      bigquery-public-data.world_bank_intl_debt.international_debt\n    WHERE\n      country_code = 'RUS'\n  ) id\n  ON\n    cs.country_code = id.country_code\n  WHERE value IS NOT NULL\n)\n-- Count the number of indicators with a value of 0 for Russia\nSELECT \n  COUNT(*) AS number_of_indicators_with_zero\nFROM \n  russia_Data\nWHERE \n  value = 0;",
        "error_info": null
    },
    {
        "instance_id": "bq276",
        "score": 0,
        "pred_sql": "DECLARE ne INT64 DEFAULT 45;\nDECLARE se INT64 DEFAULT 135;\nDECLARE sw INT64 DEFAULT 225;\nDECLARE nw INT64 DEFAULT 315;\n\nWITH convert_miles AS (\n    SELECT\n      sid AS storm_id,\n      season,\n      latitude,\n      longitude,\n      `bigquery-public-data.persistent_udfs.nautical_miles_conversion`(usa_r34_ne) AS usa_r34_ne,\n      `bigquery-public-data.persistent_udfs.nautical_miles_conversion`(usa_r34_se) AS usa_r34_se,\n      `bigquery-public-data.persistent_udfs.nautical_miles_conversion`(usa_r34_sw) AS usa_r34_sw,\n      `bigquery-public-data.persistent_udfs.nautical_miles_conversion`(usa_r34_nw) AS usa_r34_nw\n    FROM\n      `bigquery-public-data.noaa_hurricanes.hurricanes`\n    WHERE\n      basin = \"NA\"\n      AND usa_wind >= 35\n      AND name != \"NOT_NAMED\"\n      AND usa_sshs >= -1),\n\nts_wind_polygon AS (\n    SELECT\n      storm_id,\n      season,\n      ST_MakePolygon(\n        ST_MakeLine([\n          `bigquery-public-data.persistent_udfs.azimuth_to_geog_point`(latitude, longitude, ne, usa_r34_ne),\n          `bigquery-public-data.persistent_udfs.azimuth_to_geog_point`(latitude, longitude, se, usa_r34_se),\n          `bigquery-public-data.persistent_udfs.azimuth_to_geog_point`(latitude, longitude, sw, usa_r34_sw),\n          `bigquery-public-data.persistent_udfs.azimuth_to_geog_point`(latitude, longitude, nw, usa_r34_nw)]\n        )\n      ) AS tropical_storm_geom\n  FROM\n      convert_miles)\n\nSELECT\n  index_number,\n  port_name,\n  state_name,\n  STRING_AGG(DISTINCT(h.season)) AS storm_years,\n  COUNT(DISTINCT(storm_id)) AS count_storms,\n  STRING_AGG(DISTINCT(name)) AS storm_name,\n  AVG(usa_sshs) AS avg_storm_cat,\n  AVG(usa_wind) AS avg_wind_speed,\n  ST_AsText(port_geom) AS port_geom,\n  ST_AsText(tropical_storm_geom) AS tropical_storm_geom\nFROM\n  ts_wind_polygon t,\n  `bigquery-public-data.geo_international_ports.world_port_index` ,\n  `bigquery-public-data.geo_us_boundaries.states` \nJOIN\n  `bigquery-public-data.noaa_hurricanes.hurricanes` h ON h.sid = t.storm_id\nWHERE\n  port_name IS NOT NULL\n  AND region_number = '6585'\n  AND ST_WITHIN(port_geom, state_geom)\n  AND ST_WITHIN(port_geom, tropical_storm_geom)\nGROUP BY\n  index_number,\n  port_geom,\n  port_name,\n  state_name,\n  tropical_storm_geom\nORDER BY\n  avg_wind_speed DESC\nLIMIT 1;",
        "error_info": "Result Error"
    },
    {
        "instance_id": "bq063",
        "score": 1,
        "pred_sql": "DECLARE\n    Sys STRING DEFAULT 'NPM';\n\nWITH HighestReleases AS (\n    SELECT\n        Name,\n        Version,\n    FROM (\n        SELECT\n            Name,\n            Version,\n            ROW_NUMBER() OVER (\n                PARTITION BY Name\n                ORDER BY VersionInfo.Ordinal DESC\n            ) AS RowNumber\n        FROM\n            `bigquery-public-data.deps_dev_v1.PackageVersions`\n        WHERE\n            System = Sys\n            AND VersionInfo.IsRelease)\n    WHERE RowNumber = 1\n),\n\nTopDependencies AS (\n    SELECT\n        D.Name,\n        D.Version,\n        COUNT(*) AS NDependencies\n    FROM\n        `spider2-public-data.deps_dev_v1.Dependencies` AS D\n    JOIN\n        HighestReleases AS H\n    ON\n        D.Name = H.Name AND D.Version = H.Version\n    WHERE\n        D.System = Sys\n    GROUP BY\n        Name,\n        Version\n    ORDER BY\n        NDependencies DESC\n    LIMIT 100\n)\n\nSELECT\n    lnk.URL\nFROM \n    `spider2-public-data.deps_dev_v1.PackageVersions` AS P,\n    unnest(Links) as lnk\nJOIN \n    TopDependencies AS T\nON\n    T.Name = P.Name AND T.Version = P.Version\nWHERE\n    P.System = Sys\n    AND P.Name NOT LIKE '%@%'\n    AND lnk.Label = 'SOURCE_REPO'\n    AND lower(lnk.URL) LIKE '%github.com%'\nORDER BY T.NDependencies DESC\nLIMIT 1;",
        "error_info": null
    },
    {
        "instance_id": "bq100",
        "score": 1,
        "pred_sql": "WITH imports AS (\n  SELECT\n    id,\n    SPLIT(REGEXP_EXTRACT(content, r'import\\s*\\(([^)]*)\\)'), '\\n') AS lines\n  FROM\n    `bigquery-public-data.github_repos.sample_contents`\n  WHERE\n    REGEXP_CONTAINS(content, r'import\\s*\\([^)]*\\)')\n),\ngo_files AS (\n  SELECT\n    id\n  FROM\n    `bigquery-public-data.github_repos.sample_files`\n  WHERE\n    path LIKE '%.go'\n  GROUP BY\n    id\n),\nfiltered_imports AS (\n  SELECT\n    id,\n    line\n  FROM\n    imports, UNNEST(lines) AS line\n),\njoined_data AS (\n  SELECT\n    fi.line\n  FROM\n    filtered_imports fi\n  JOIN\n    go_files gf\n  ON\n    fi.id = gf.id\n)\nSELECT\n  REGEXP_EXTRACT(line, r'\"([^\"]+)\"') AS package\nFROM\n  joined_data\nGROUP BY\n  package\nHAVING\n  package IS NOT NULL\nORDER BY\n  COUNT(*) DESC\nLIMIT\n  1;",
        "error_info": null
    },
    {
        "instance_id": "bq180",
        "score": 1,
        "pred_sql": "SELECT module, COUNT(*) as occurrence_count\nFROM (\n  SELECT \n    file_id, \n    repo_name, \n    path, \n    line, \n    ARRAY_CONCAT(\n      IF(\n        ENDS_WITH(path, '.py'),\n        ARRAY_CONCAT(\n          REGEXP_EXTRACT_ALL(line, r'\\bimport\\s+(\\w+)'), \n          REGEXP_EXTRACT_ALL(line, r'\\bfrom\\s+(\\w+)')\n        ),\n        []\n      ),\n      IF(\n        ENDS_WITH(path, '.r'),\n        REGEXP_EXTRACT_ALL(line, r'library\\s*\\(\\s*([^\\s)]+)\\s*\\)'),\n        []\n      )\n    ) AS modules\n  FROM (\n    SELECT\n        ct.id AS file_id, \n        fl.repo_name, \n        path, \n        SPLIT(REPLACE(ct.content, \"\\n\", \" \\n\"), \"\\n\") AS lines\n    FROM `bigquery-public-data.github_repos.sample_files` AS fl\n    JOIN `bigquery-public-data.github_repos.sample_contents` AS ct ON fl.id = ct.id\n  ), UNNEST(lines) as line\n  WHERE\n    (ENDS_WITH(path, '.py') AND (REGEXP_CONTAINS(line, r'^import ') OR REGEXP_CONTAINS(line, r'^from '))) OR \n    (ENDS_WITH(path, '.r') AND REGEXP_CONTAINS(line, r'library\\s*\\('))\n),\nUNNEST(modules) as module\nGROUP BY module\nORDER BY occurrence_count DESC\nLIMIT 3",
        "error_info": null
    },
    {
        "instance_id": "bq338",
        "score": 1,
        "pred_sql": "WITH acs_2017 AS (\n  SELECT geo_id, median_income AS median_income_2017\n  FROM `bigquery-public-data.census_bureau_acs.censustract_2017_5yr`  \n  WHERE geo_id LIKE '36047%' --Selecting Brooklyn\n),\n\nacs_2010 AS (\n  SELECT geo_id, median_income AS median_income_2010\n  FROM `bigquery-public-data.census_bureau_acs.censustract_2010_5yr` \n  WHERE geo_id LIKE '36047%' --Selecting Brooklyn\n),\n\nacs_diff AS (\n  SELECT\n    a17.geo_id, \n    a17.median_income_2017, \n    a10.median_income_2010,\n    (a17.median_income_2017 - a10.median_income_2010) AS median_income_diff, \n    geo.tract_geom AS tract_geom\n  FROM acs_2017 a17\n  JOIN acs_2010 a10\n    ON a17.geo_id = a10.geo_id\n  JOIN `bigquery-public-data.geo_census_tracts.census_tracts_new_york`geo\n    ON a17.geo_id = geo.geo_id\n)\n\nSELECT \n   geo_id\nFROM \n   acs_diff \nWHERE \n   median_income_diff IS NOT NULL\nORDER BY \n   median_income_diff DESC\nLIMIT 1;",
        "error_info": null
    },
    {
        "instance_id": "bq226",
        "score": 1,
        "pred_sql": "SELECT\n    CONCAT(\"https://cronoscan.com/address/\", t.from_address) AS cronoscan_link,\nFROM\n    `bigquery-public-data.goog_blockchain_cronos_mainnet_us.transactions` AS t\nINNER JOIN\n    `bigquery-public-data.goog_blockchain_cronos_mainnet_us.blocks` AS b\nON\n    b.block_hash = t.block_hash\nWHERE\n    t.to_address IS NOT NULL\nAND\n    b.size > 4096\nAND\n    b.block_timestamp > TIMESTAMP(\"2023-01-01 00:00:00\")\nAND\n    t.block_timestamp > TIMESTAMP(\"2023-01-01 00:00:00\")\nGROUP BY\n    t.from_address\nORDER BY\n    COUNT(*) \nDESC\nLIMIT 1;",
        "error_info": null
    },
    {
        "instance_id": "bq255",
        "score": 1,
        "pred_sql": "SELECT\n  COUNT(commits_table.message) AS num_messages\nFROM (\n  SELECT\n    repo_name,\n    lang.name AS language_name\n  FROM\n    `bigquery-public-data.github_repos.languages` AS lang_table,\n    UNNEST(LANGUAGE) AS lang) lang_table\nJOIN\n  `bigquery-public-data.github_repos.licenses` AS license_table\nON\n  license_table.repo_name = lang_table.repo_name\nJOIN (\n  SELECT\n    *\n  FROM\n    `bigquery-public-data.github_repos.sample_commits`) commits_table\nON\n  commits_table.repo_name = lang_table.repo_name\nWHERE\n    (license_table.license LIKE 'apache-2.0')\n  AND (lang_table.language_name LIKE 'Shell')\nAND\n  LENGTH(commits_table.message) > 5\nAND \n  LENGTH(commits_table.message) < 10000\nAND LOWER(commits_table.message) NOT LIKE 'update%'\nAND LOWER(commits_table.message) NOT LIKE 'test%'\nAND LOWER(commits_table.message) NOT LIKE 'merge%';",
        "error_info": null
    },
    {
        "instance_id": "bq029",
        "score": 1,
        "pred_sql": "SELECT \n  AVG(num_inventors) AS avg_inventors,\n  COUNT(*) AS cnt,\n  filing_year\nFROM (\n  SELECT \n    ANY_VALUE(ARRAY_LENGTH(inventor)) AS num_inventors,\n    ANY_VALUE(country_code) AS country_code,\n    ANY_VALUE(CAST(FLOOR(filing_date / (5 * 10000)) AS INT64)) * 5 AS filing_year\n  FROM \n    `patents-public-data.patents.publications` AS pubs\n  WHERE \n    filing_date > 19450000 \n    AND filing_date < 20200000\n    AND ARRAY_LENGTH(inventor) > 0\n  GROUP BY \n    publication_number\n)\nWHERE country_code in ('US')\nGROUP BY \n  filing_year, \n  country_code\nORDER BY \n  filing_year;\n\n\n\n",
        "error_info": null
    },
    {
        "instance_id": "ga007_1",
        "score": 1,
        "pred_sql": "WITH base_table AS (\n-- pulls relevant columns from relevant dates to decrease the size of data scanned\n  SELECT\n    event_name,\n    event_date,\n    event_timestamp,\n    user_pseudo_id,\n    user_id,\n    device,\n    geo,\n    traffic_source,\n    event_params,\n    user_properties\n  FROM\n    `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*`\n  WHERE\n    _table_suffix ='20210102'\n  AND user_pseudo_id='1402138.5184246691'\n  AND event_name IN ('page_view')\n)\n, unnested_events AS (\n-- unnests event parameters to get to relevant keys and values\n  SELECT\n    event_date AS date,\n    event_timestamp AS event_timestamp_microseconds,\n    user_pseudo_id,\n    MAX(CASE WHEN c.key = 'ga_session_id' THEN c.value.int_value END) AS visitID,\n    MAX(CASE WHEN c.key = 'ga_session_number' THEN c.value.int_value END) AS visitNumber,\n    MAX(CASE WHEN c.key = 'page_title' THEN c.value.string_value END) AS page_title,\n    MAX(CASE WHEN c.key = 'page_location' THEN c.value.string_value END) AS page_location\n  FROM \n    base_table,\n    UNNEST (event_params) c\n  GROUP BY 1,2,3\n)\n\n\n  SELECT\n  *,\n  CASE WHEN ARRAY_LENGTH(SPLIT(page_location, '/')) >= 5 \n            AND\n            CONTAINS_SUBSTR(ARRAY_REVERSE(SPLIT(page_location, '/'))[SAFE_OFFSET(0)], '+')\n            AND (LOWER(SPLIT(page_location, '/')[SAFE_OFFSET(4)]) IN \n                                        ('accessories','apparel','brands','campus+collection','drinkware',\n                                          'electronics','google+redesign',\n                                          'lifestyle','nest','new+2015+logo','notebooks+journals',\n                                          'office','shop+by+brand','small+goods','stationery','wearables'\n                                          )\n                  OR\n                  LOWER(SPLIT(page_location, '/')[SAFE_OFFSET(3)]) IN \n                                        ('accessories','apparel','brands','campus+collection','drinkware',\n                                          'electronics','google+redesign',\n                                          'lifestyle','nest','new+2015+logo','notebooks+journals',\n                                          'office','shop+by+brand','small+goods','stationery','wearables'\n                                          )\n            )\n            THEN 'PDP'\n            WHEN NOT(CONTAINS_SUBSTR(ARRAY_REVERSE(SPLIT(page_location, '/'))[SAFE_OFFSET(0)], '+'))\n            AND (LOWER(SPLIT(page_location, '/')[SAFE_OFFSET(4)]) IN \n                                        ('accessories','apparel','brands','campus+collection','drinkware',\n                                          'electronics','google+redesign',\n                                          'lifestyle','nest','new+2015+logo','notebooks+journals',\n                                          'office','shop+by+brand','small+goods','stationery','wearables'\n                                          )\n                  OR \n                  LOWER(SPLIT(page_location, '/')[SAFE_OFFSET(3)]) IN \n                                          ('accessories','apparel','brands','campus+collection','drinkware',\n                                            'electronics','google+redesign',\n                                            'lifestyle','nest','new+2015+logo','notebooks+journals',\n                                            'office','shop+by+brand','small+goods','stationery','wearables'\n                                            )\n            )\n            THEN 'PLP'\n        ELSE page_title\n        END AS page_title_adjusted \n\n  FROM \n    unnested_events\n  \n",
        "error_info": null
    }
]